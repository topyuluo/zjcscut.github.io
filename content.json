{"meta":{"title":"Throwable's Blog","subtitle":"去创业了，太忙了，可能会不定期鸽😁😁😁😂😂😂","description":"一棵还在尝试努力生存的90后韭菜Doge","author":"Throwable","url":"http://throwable.club","root":"/"},"pages":[{"title":"404 Not Found","date":"2019-12-24T17:01:51.466Z","updated":"2019-12-24T17:01:51.466Z","comments":true,"path":"404.html","permalink":"http://throwable.club/404.html","excerpt":"","text":"404 Not Found **很抱歉，您访问的页面不存在** 可能是输入地址有误或该地址已被删除"},{"title":"关于","date":"2018-11-04T09:47:35.000Z","updated":"2020-01-16T15:05:37.592Z","comments":true,"path":"about/index.html","permalink":"http://throwable.club/about/index.html","excerpt":"","text":"2016届华南理工毕业，本专业信息与计算科学(数学学科)，本来做数值算法方面的东西，后来因为兴趣入行Java。 技术驱动，喜欢尝试和落地新技术，同时也喜欢深入研究底层原理。 2015-2016 华南师范大学网络中心实习，负责一些校内应用和公众号部分功能的开发维护。 履历 2016.6-2019.11 就职于PPmoney借贷，曾主要做业务开发，后来偏向于业务架构和基础架构。 2019.11之后 创业（太忙了，可能会不定期鸽）。 声明 这个博客里面的所有文章都是笔者在业余时间完成，有时候工作上业务比较繁忙可能需要996或者997，所以更新速度会比较缓慢。 大多数文章都是Java相关，使用的是JDK11，并不是为了标新立异，只因为JDK11是免费的LTS版本（Long Term Support，长期支持）。 所有文章都是原创，如果参考了别人的内容，为了尊重其版权一定会在末尾的参考资料中标明并且添加其链接。 毕业前后曾经写过大量文章（主要是主流框架的源码分析），由于之前的文章质量和排版有问题或者不兼容，后面修复之后会重新发布。 在某个时间后发布的文章会附带原件和图片的下载链接，具体看笔者的习惯（o(&gt;﹏&lt;)o有时候懒可能会忘记），附件链接在每篇文章的结尾部分。 每篇文章的末尾都会附带完成的日期、耗时和更新修订内容的日期。如： 12345（本文完 c-7-d e-a-20190727 r-a-20190728）意思是：cost 7 days,end at 2019-07-27,raised at 2019-07-28&#x3D;&gt; 写这篇文章花费了7天时间，完成于2019-07-27，最后修订更新于2019-07-28 文章发布平台 掘金 博客园 简书 Github Page Coding Page 除了Github Page和Coding Page，其他平台随缘更新。 To Be Continue… 只是一个普通的上班族，也许你能在广州地铁五号线遇到我，期待与你的邂逅。 加油，共勉。 ![](https://throwable-blog-1256189093.cos.ap-guangzhou.myqcloud.com/mine/about-me-1.jpg) 附录 大学中二期曾经写过的一篇短句，虽然现在回想起来不知道当时是怎么想出来，但是感觉读起来还是挺有感觉的，满是回忆： 曾经居住已久的心和世界，早已在夜路中渐行渐远 那些迷失过的路，抬头只有被高压线割破的天空 飞翔在天空的，仅是破碎的翅膀的梦 梦终究是梦，在枕底发霉，抑或潜藏在心中 心脏流过身体的每一滴血，但流血的时候我能否知道内心在想什么 想过的人或事，到头来又被时间沉淀为回忆 回忆中的苦与甜，是阳光，或是身后的阴暗面 阴暗就是这个世界的本质，本质只有白和黑 黑夜如约而至，我要为那个破碎的梦编织一个谎言 谎言走到最后总会有结局，而结局往往只是谎言的延续 延续下去的仅仅是我一个人的轮回，回到那个离开已久的心和世界 Written on 2013-11-20 21:28 by throwable"},{"title":"所有分类","date":"2019-12-24T17:55:09.888Z","updated":"2019-12-24T17:55:09.888Z","comments":true,"path":"categories/index.html","permalink":"http://throwable.club/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2020-01-07T00:32:29.610Z","updated":"2020-01-07T00:32:29.610Z","comments":true,"path":"friends/index.html","permalink":"http://throwable.club/friends/index.html","excerpt":"","text":"各位大佬想交换友链的话可以在下方留言，必须要有名称、头像链接、和至少一个标签哦～ 名称： Throwable’s Blog 头像： https://throwable-blog-1256189093.cos.ap-guangzhou.myqcloud.com/mine/doge_favicon.ico 网址： http://throwable.club 标签： Java"},{"title":"所有标签","date":"2019-12-24T17:55:01.701Z","updated":"2019-12-24T17:55:01.701Z","comments":true,"path":"tags/index.html","permalink":"http://throwable.club/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"理解和运用Java中的Lambda","slug":"java-understand-and-use-lambda","date":"2020-02-09T10:13:50.000Z","updated":"2020-02-09T14:45:48.809Z","comments":true,"path":"2020/02/09/java-understand-and-use-lambda/","link":"","permalink":"http://throwable.club/2020/02/09/java-understand-and-use-lambda/","excerpt":"前提 回想一下，JDK8是2014年发布正式版的，到现在为（2020-02-08）止已经过去了5年多。JDK8引入的两个比较强大的新特性是Lambda表达式（下文的Lambda特指JDK提供的Lambda）和Stream，这两个强大的特性让函数式编程在Java开发中发扬光大。这篇文章会从基本概念、使用方式、实现原理和实战场景等角度介绍Lambda的全貌，其中还会涉及一些函数式编程概念、JVM一些知识等等。","text":"前提 回想一下，JDK8是2014年发布正式版的，到现在为（2020-02-08）止已经过去了5年多。JDK8引入的两个比较强大的新特性是Lambda表达式（下文的Lambda特指JDK提供的Lambda）和Stream，这两个强大的特性让函数式编程在Java开发中发扬光大。这篇文章会从基本概念、使用方式、实现原理和实战场景等角度介绍Lambda的全貌，其中还会涉及一些函数式编程概念、JVM一些知识等等。 基本概念 下面介绍一些基本概念，一步一步引出Lambda的概念。 函数式接口 函数式接口和接口默认方法都是JDK8引入的新特性。函数式接口的概念可以从java.lang.FunctionalInterface注解的API注释中得知： An informative annotation type used to indicate that an interface type declaration is intended to be a functional interface as defined by the Java Language Specification. Conceptually, a functional interface has exactly one abstract method. Since {@linkplain java.lang.reflect.Method#isDefault() default methods} have an implementation, they are not abstract. 简单来说就是：@FunctionalInterface是一个提供信息的接口（其实就是标识接口），用于表明对应的接口类型声明是一个Java语言规范定义的函数式接口。从概念上说，一个函数式接口有且仅有一个抽象方法，因为接口默认方法必须予以实现，它们不是抽象方法。 所以可以这样给函数式接口定义：如果一个接口声明的时候有且仅有一个抽象方法，那么它就是函数式接口，可以使用@FunctionalInterface注解标识。 JDK中已经定义了很多内置的函数式接口，例如： 12345678910111213// java.lang.Runnable@FunctionalInterfacepublic interface Runnable &#123; public abstract void run();&#125; // java.util.function.Supplier@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; T get();&#125; 也可以自定义函数式接口，例如： 123456@FunctionalInterfacepublic interface CustomFunctionalInterface &#123; // 可以缩写为void process(); 接口方法定义的时候，默认使用public abstract修饰 public abstract void process();&#125; 接口默认方法 接口默认方法的含义可以见Java官方教程中对应的章节，在文末的参考资料可以查看具体的链接： Default methods enable you to add new functionality to the interfaces of your libraries and ensure binary compatibility with code written for older versions of those interfaces. 简单来说就是：默认方法允许你在你的类库中向接口添加新的功能，并确保新增的默认方法与这些接口的较早版本编写的代码二进制兼容。 接口默认方法（下称默认方法）通过default关键字声明，可以直接在接口中编写方法体。也就是默认方法既声明了方法，也实现了方法。这一点很重要，在默认方法特性出现之前，Java编程语言规范中，接口的本质就是方法声明的集合体，而自默认方法特性出现之后，接口的本质也改变了。默认方法的一个例子如下： 123456789101112131415161718public interface DefaultMethod &#123; default void defaultVoidMethod() &#123; &#125; default String sayHello(String name) &#123; return String.format(\"%s say hello!\", name); &#125; static void main(String[] args) throws Exception &#123; class Impl implements DefaultMethod &#123; &#125; DefaultMethod defaultMethod = new Impl(); System.out.println(defaultMethod.sayHello(\"throwable\")); // throwable say hello! &#125;&#125; 如果继承一个定义了默认方法的接口，那么可以有如下的做法： 完全忽略父接口的默认方法，那么相当于直接继承父接口的默认方法的实现（方法继承）。 重新声明默认方法，这里特指去掉default关键字，用public abstract关键字重新声明对应的方法，相当于让默认方法转变为抽象方法，子类需要进行实现（方法抽象）。 重新定义默认方法，也就是直接覆盖父接口中的实现（方法覆盖）。 结合前面一节提到的函数式接口，这里可以综合得出一个结论：函数式接口，也就是有且仅有一个抽象方法的接口，可以定义0个或者N（N &gt;= 1）个默认方法。这一点正是Stream特性引入的理论基础。举个例子： 12345678910111213@FunctionalInterfacepublic interface CustomFunctionalInterface &#123; public abstract void process(); default void defaultVoidMethod() &#123; &#125; default String sayHello(String name) &#123; return String.format(\"%s say hello!\", name); &#125;&#125; 这里说点题外话。 在写这篇文章的时候，笔者想起了一个前同事说过的话，大意如下：在软件工程中，如果从零做起，任何新功能的开发都是十分简单的，困难的是在兼容所有历史功能的前提下进行新功能的迭代。试想一下，Java迭代到今天已经过去十多年了，Hotspot VM源码工程已经十分庞大（手动编译过OpenJDK Hotspot VM源码的人都知道过程的痛苦），任何新增的特性都要向前兼容，否则很多用了历史版本的Java应用会无法升级新的JDK版本。既要二进制向前兼容，又要迭代出新的特性，Java需要进行舍夺，默认方法就是一个例子，必须舍去接口只能定义抽象方法这个延续了多年在Java开发者中根深蒂固的概念，夺取了基于默认方法实现构筑出来的流式编程体系。笔者有时候也在思考：如果要我去开发Stream这个新特性，我会怎么做或者我能怎么做？ 嵌套类(Nested Classes) 嵌套类（Nested Classes），简单来说就是：在一个类中定义另一个类，那么在类内被定义的那个类就是嵌套类，最外层的类一般称为封闭类（Enclosing Class）。嵌套类主要分为两种：静态嵌套类和非静态嵌套类，而非静态嵌套类又称为内部类（Inner Classes）。 12345678910111213// 封闭类class OuterClass &#123; ... // 静态嵌套类 static class StaticNestedClass &#123; ... &#125; // 内部类 class InnerClass &#123; ... &#125;&#125; 静态嵌套类可以直接使用封闭的类名称去访问例如：OuterClass.StaticNestedClass x = new OuterClass.StaticNestedClass();，这种使用形式和一般类实例化基本没有区别。 内部类实例的存在必须依赖于封闭类实例的存在，并且内部类可以直接访问封闭类的任意属性和方法，简单来说就是内部类的实例化必须在封闭类实例化之后，并且依赖于封闭类的实例，声明的语法有点奇特： 1234567891011121314151617181920212223242526public class OuterClass &#123; int x = 1; static class StaticNestedClass &#123; &#125; class InnerClass &#123; // 内部类可以访问封闭类的属性 int y = x; &#125; public static void main(String[] args) throws Exception &#123; OuterClass outerClass = new OuterClass(); // 必须这样实例化内部类 - 声明的语法相对奇特 OuterClass.InnerClass innerClass = outerClass.new InnerClass(); // 静态嵌套类可以一般实例化,形式为:封闭类.静态嵌套类 OuterClass.StaticNestedClass staticNestedClass = new OuterClass.StaticNestedClass(); // 如果main方法在封闭类内,可以直接使用静态嵌套类进行实例化 StaticNestedClass x = new StaticNestedClass(); &#125;&#125; 内部类中有两种特殊的类型：本地类(Local Classes)和匿名类(Anonymous Classes)。 本地类是一种声明在任意块（block）的类，例如声明在代码块、静态代码块、实例方法或者静态方法中，它可以访问封闭类的所有成员属性和方法，它的作用域就是块内，不能在块外使用。例如： 12345678910111213141516171819202122232425262728public class OuterClass &#123; static int y = 1; &#123; // 本地类A class A&#123; int z = y; &#125; A a = new A(); &#125; static &#123; // 本地类B class B&#123; int z = y; &#125; B b = new B(); &#125; private void method()&#123; // 本地类C class C&#123; int z = y; &#125; C c = new C(); &#125;&#125; 匿名类可以让代码更加简明，允许使用者在定义类的同时予以实现，匿名类和其他内部类不同的地方是：它是一种表达式，而不是类声明。例如： 1234567891011121314151617181920212223public class OuterClass &#123; interface In &#123; void method(String value); &#125; public void sayHello()&#123; // 本地类 - 类声明 class LocalClass&#123; &#125; // 匿名类 - 是一个表达式 In in = new In() &#123; @Override public void method(String value) &#123; &#125; &#125;; &#125;&#125; 如果用Java做过GUI开发，匿名类在Swing或者JavaFx的事件回调中大量使用，经常会看到类似这样的代码： 1234567JButton button = new JButton();button.addActionListener(new AbstractAction() &#123; @Override public void actionPerformed(ActionEvent e) &#123; System.out.println(\"按钮事件被触发...\"); &#125;&#125;); 嵌套类的类型关系图如下： 123456Nested Classes - Static Nested Classes - None Nested Classes - Local Classes - Anonymous Classes - Other Inner Classes Lambda表达式 下面是来自某搜索引擎百科关于Lambda表达式的定义： Lambda表达式（Lambda Expression）是一个匿名函数，Lambda表达式基于数学中的λ演算得名，直接对应于其中的Lambda抽象（Lambda Abstraction），是一个匿名函数，即没有函数名的函数。Lambda表达式可以表示闭包（注意和数学传统意义上的不同）。 Java中的Lambda表达式（下面称Lambda）表面上和上面的定义类似，本质也是匿名函数，但其实现原理区别于一般的匿名类中的匿名函数实现，她是JDK8引入的一颗新的语法糖。 引入Lambda表达式的初衷 如果一个接口只包含一个方法，那么匿名类的语法会变得十分笨拙和不清楚，产生大量的模板代码，归结一下就是：代码冗余是匿名类的最大弊端。在编程的时候，我们很多时候希望把功能作为参数传递到另一个方法，Lambda就是为此而生，Lambda允许使用者将功能视为方法参数，将代码视为数据。引入Lambda带来了如下优势： 简化代码，引入了强大的类型推断和方法引用特性，简单的功能甚至可以一行代码解决，解放匿名类的束缚。 把功能作为参数向下传递，为函数式编程提供了支持。 至此还得出一个结论：Lambda只适用于函数式接口对应唯一抽象方法的实现。 Lambda表达式的语法定义 Lambda语法的详细定义如下： 12345// en_USInterfaceType interfaceObject = [Method Argument List] -&gt; Method Body// zh_CN接口类型 接口实例 = [方法参数列表] -&gt; 方法体 更具体的描述应该是： 接口类型 接口实例临时变量 = (方法参数类型X 方法参数类型X临时变量 , 方法参数类型Y 方法参数类型Y临时变量...) -&gt; { 方法体... return 接口抽象方法返回值对应类型类型实例;} 一个Lambda表达式由五个部分组成： 返回值：接口类型以及接口类型对应的临时实例变量。 等号：=。 方法参数列表：一般由中括号()包裹，格式是(类型1 类型1的临时变量,...,类型N 类型N的临时变量)，在方法没有重载可以明确推断参数类型的时候，参数类型可以省略，只留下临时变量列表。特殊地，空参数列表用()表示，如果参数只有一个，可以省略()。 箭头：-&gt;。 方法体：一般由花括号{}包裹，格式是{方法逻辑... return 函数式接口方法返回值类型的值;}，有几点需要注意： 如果方法体是空实现，用{}表示，如Runnable runnable = () -&gt; {};。 如果函数式接口抽象方法的返回值为void类型，则不需要return关键字语句，如Runnable runnable = () -&gt; {int i=0; i++;};。 如果函数式接口抽象方法的方法体仅仅包含一个表达式，则不需要使用{}包裹，如Runnable runnable = () -&gt; System.out.println(&quot;Hello World!&quot;);。 举一些例子： 1234567891011121314151617181920// Function - 具体java.util.function.Function&lt;String, Integer&gt; functionY = (String string) -&gt; &#123; return Integer.parseInt(string);&#125;;// Function - 简化java.util.function.Function&lt;String, Integer&gt; functionX = string -&gt; Integer.parseInt(string);// Runnable - 具体Runnable runnableX = () -&gt; &#123; System.out.println(\"Hello World!\");&#125;;// Runnable - 简化Runnable runnableY = () -&gt; System.out.println(\"Hello World!\");// 整数1-100的和 - 具体int reduceX = IntStream.range(1, 101).reduce(0, (int addend, int augend) -&gt; &#123; return addend + augend;&#125;);// 整数1-100的和 - 简化int reduceY = IntStream.range(1, 101).reduce(0, Integer::sum); 目标类型与类型推断 先引入下面的一个场景： 12345678910111213// club.throwable.Runnable@FunctionalInterfacepublic interface Runnable &#123; void run(); static void main(String[] args) throws Exception &#123; java.lang.Runnable langRunnable = () -&gt; &#123;&#125;; club.throwable.Runnable customRunnable = () -&gt; &#123;&#125;; langRunnable.run(); customRunnable.run(); &#125;&#125; 笔者定义了一个和java.lang.Runnable完全一致的函数式接口club.throwable.Runnable，上面main()方法中，可以看到两个接口对应的Lambda表达式的方法体实现也是完全一致，但是很明显最终可以使用不同类型的接口去接收返回值，也就是这两个Lambda的类型是不相同的。而这两个Lambda表达式返回值的类型是我们最终期待的返回值类型（expecting a data type of XX），那么Lambda表达式就是对应的被期待的类型，这个被期待的类型就是Lambda表达式的目标类型。 为了确定Lambda表达式的目标类型，Java编译器会基于对应的Lambda表达式，使用上下文或者场景进行综合推导，判断的一个因素就是上下文中对该Lambda表达式所期待的类型。因此，只能在Java编译器能够正确推断Lambda表达式目标类型的场景下才能使用Lambda表达式，这些场景包括： 变量声明。 赋值。 返回语句。 数组初始化器。 Lambda表达式函数体。 条件表达式（condition ? processIfTrue() : processIfFalse()）。 类型转换（Cast）表达式。 Lambda表达式除了目标类型，还包含参数列表和方法体，而方法体需要依赖于参数列表进行实现，所以方法参数也是决定目标类型的一个因素。 方法参数的类型推导的过程主要依赖于两个语言特性：重载解析（Overload Resolution）和参数类型推导（Type Argument Inference）。 原文：For method arguments, the Java compiler determines the target type with two other language features: overload resolution and type argument inference 重载解析会为一个给定的方法调用（Method Invocation）寻找最合适的方法声明（Method Declaration）。由于不同的声明具有不同的签名，当Lambda表达式作为方法参数时，重载解析就会影响到Lambda表达式的目标类型。编译器会根据它对该Lambda表达式的所提供的信息的理解做出决定。如果Lambda表达式具有显式类型（参数类型被显式指定），编译器就可以直接使用Lambda表达式的返回类型；如果Lambda表达式具有隐式类型（参数类型被推导而知），重载解析则会忽略Lambda表达式函数体而只依赖Lambda表达式参数的数量。 举个例子： 12345// 显式类型Function&lt;String, String&gt; functionX = (String x) -&gt; x;// 隐式类型Function&lt;String, Integer&gt; functionY = x -&gt; Integer.parseInt(x); 如果依赖于方法参数的类型推导最佳方法声明时存在二义性（Ambiguous），我们就需要利用转型（Cast）或显式Lambda表达式来提供更多的类型信息，从而Lambda表达式的目标类型。举个例子： 12345678910111213// 编译不通过Object runnableX = () -&gt; &#123;&#125;;// 编译通过 - CastObject runnableY = (Runnable) () -&gt; &#123;&#125;;// 静态方法入参类型是函数式接口public static void function(java.util.function.Function function) &#123;&#125;function((Function&lt;String, Long&gt;) (x) -&gt; Long.parseLong(x)); 作用域 关于作用域的问题记住几点即可： &lt;1&gt;：Lambda表达式内的this引用和封闭类的this引用相同。 &lt;2&gt;：Lambda表达式基于词法作用域，它不会从超类中继承任何变量，方法体里面的变量和它外部环境的变量具有相同的语义。 &lt;3&gt;：Lambda expressions close over values, not variables，也就是Lambda表达式对值类型封闭，对变量（引用）类型开放（这一点正好解释了Lambda表达式内部引用外部的属性的时候，该属性必须定义为final）。 对于第&lt;1&gt;点举个例子： 123456789101112131415161718public class LambdaThis &#123; int x = 1; public void method() &#123; Runnable runnable = () -&gt; &#123; int y = this.x; y++; System.out.println(y); &#125;; runnable.run(); &#125; public static void main(String[] args) throws Exception &#123; LambdaThis lambdaThis = new LambdaThis(); lambdaThis.method(); // 2 &#125;&#125; 对于第&lt;2&gt;点举个例子： 1234567891011public class LambdaScope &#123; public void method() &#123; int x = 1; Runnable runnable = () -&gt; &#123; // 编译不通过 - Lambda方法体外部已经定义了同名变量 int x = 2; &#125;; runnable.run(); &#125;&#125; 对于第&lt;3&gt;点举个例子： 12345678910111213141516171819202122232425262728public class LambdaValue &#123; public void method() &#123; (final) int x = 1; Runnable runnable = () -&gt; &#123; // 编译不通过 - 外部值类型使用了final x ++; &#125;; runnable.run(); &#125;&#125;public class LambdaValue &#123; public void method() &#123; (final) IntHolder holder = new IntHolder(); Runnable runnable = () -&gt; &#123; // 编译通过 - 使用了引用类型 holder.x++; &#125;; runnable.run(); &#125; private static class IntHolder &#123; int x = 1; &#125;&#125; 方法引用 方法引用（Method Reference）是一种功能和Lambda表达式类似的表达式，需要目标类型和实现函数式接口，但是这个实现形式并不是通过方法体，而是通过方法名称（或者关键字）关联到一个已经存在的方法，本质是编译层面的技术，旨在进一步简化Lambda表达式方法体和一些特定表达式的实现。方法引用的类型归结如下： 类型 例子 静态方法引用 ClassName::methodName 指定对象实例方法引用 instanceRef::methodName 特定类型任意对象方法引用 ContainingType::methodName 超类方法引用 supper::methodName 构造器方法引用 ClassName::new 数组构造器方法引用 TypeName[]::new 可见其基本形式是：方法容器::方法名称或者关键字。 举一些基本的使用例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485// 静态方法引用public class StaticMethodRef &#123; public static void main(String[] args) throws Exception &#123; Function&lt;String, Integer&gt; function = StaticMethodRef::staticMethod; Integer result = function.apply(\"10086\"); System.out.println(result); // 10086 &#125; public static Integer staticMethod(String value) &#123; return Integer.parseInt(value); &#125;&#125;// 指定对象实例方法引用public class ParticularInstanceRef &#123; public Integer refMethod(String value) &#123; return Integer.parseInt(value); &#125; public static void main(String[] args) throws Exception&#123; ParticularInstanceRef ref = new ParticularInstanceRef(); Function&lt;String, Integer&gt; function = ref::refMethod; Integer result = function.apply(\"10086\"); System.out.println(result); // 10086 &#125;&#125;// 特定类型任意对象方法引用String[] stringArray = &#123;\"C\", \"a\", \"B\"&#125;;Arrays.sort(stringArray, String::compareToIgnoreCase);System.out.println(Arrays.toString(stringArray)); // [a, B, C]// 超类方法引用public class SupperRef &#123; public static void main(String[] args) throws Exception &#123; Sub sub = new Sub(); System.out.println(sub.refMethod(\"10086\")); // 10086 &#125; private static class Supper &#123; private Integer supperRefMethod(String value) &#123; return Integer.parseInt(value); &#125; &#125; private static class Sub extends Supper &#123; private Integer refMethod(String value) &#123; Function&lt;String, Integer&gt; function = super::supperRefMethod; return function.apply(value); &#125; &#125;&#125;// 构造器方法引用public class ConstructorRef &#123; public static void main(String[] args) throws Exception &#123; Function&lt;String, Person&gt; function = Person::new; Person person = function.apply(\"doge\"); System.out.println(person.getName()); // doge &#125; private static class Person &#123; private final String name; public Person(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; &#125;&#125;// 数组构造器方法引用Function&lt;Integer, Integer[]&gt; function = Integer[]::new;Integer[] array = function.apply(10);System.out.println(array.length); // 10 Java中Lambda的底层实现原理 重点要说三次： Lambda表达式底层不是匿名类实现。 Lambda表达式底层不是匿名类实现。 Lambda表达式底层不是匿名类实现。 在深入学习Lambda表达式之前，笔者也曾经认为Lambda就是匿名类的语法糖： 123456789// LambdaFunction&lt;String, String&gt; functionX = (String x) -&gt; x;// 错误认知Function&lt;String, String&gt; functionX = new Function&lt;String, String&gt;() &#123; @Override public Void apply(String x) &#123; return x; &#125;&#125; Lambda就是匿名类的语法糖这个认知是错误的。下面举一个例子，从源码和字节码的角度分析一下Lambda表达式编译和执行的整个流程。 123456789101112public class Sample &#123; public static void main(String[] args) throws Exception &#123; Runnable runnable = () -&gt; &#123; System.out.println(\"Hello World!\"); &#125;; runnable.run(); String hello = \"Hello \"; Function&lt;String, String&gt; function = string -&gt; hello + string; function.apply(\"Doge\"); &#125;&#125; 添加VM参数-Djdk.internal.lambda.dumpProxyClasses=.运行上面的Sample#main()方法，项目根目录动态生成了两个类如下： 123456789101112131415161718192021222324252627282930313233import java.lang.invoke.LambdaForm.Hidden;// $FF: synthetic classfinal class Sample$$Lambda$14 implements Runnable &#123; private Sample$$Lambda$14() &#123; &#125; @Hidden public void run() &#123; Sample.lambda$main$0(); &#125;&#125;import java.lang.invoke.LambdaForm.Hidden;import java.util.function.Function;// $FF: synthetic classfinal class Sample$$Lambda$15 implements Function &#123; private final String arg$1; private Sample$$Lambda$15(String var1) &#123; this.arg$1 = var1; &#125; private static Function get$Lambda(String var0) &#123; return new Sample$$Lambda$15(var0); &#125; @Hidden public Object apply(Object var1) &#123; return Sample.lambda$main$1(this.arg$1, (String)var1); &#125;&#125; 反查两个类的字节码，发现了类修饰符为final synthetic。接着直接看封闭类Sample的字节码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class club/throwable/Sample &#123; &lt;ClassVersion=52&gt; &lt;SourceFile=Sample.java&gt; public Sample() &#123; // &lt;init&gt; //()V &lt;localVar:index=0 , name=this , desc=Lclub/throwable/Sample;, sig=null, start=L1, end=L2&gt; L1 &#123; aload0 // reference to self invokespecial java/lang/Object.&lt;init&gt;()V return &#125; L2 &#123; &#125; &#125; public static main(java.lang.String[] arg0) throws java/lang/Exception &#123; //([Ljava/lang/String;)V &lt;localVar:index=0 , name=args , desc=[Ljava/lang/String;, sig=null, start=L1, end=L2&gt; &lt;localVar:index=1 , name=runnable , desc=Lclub/throwable/Runnable;, sig=null, start=L3, end=L2&gt; &lt;localVar:index=2 , name=hello , desc=Ljava/lang/String;, sig=null, start=L4, end=L2&gt; &lt;localVar:index=3 , name=function , desc=Ljava/util/function/Function;, sig=Ljava/util/function/Function&lt;Ljava/lang/String;Ljava/lang/String;&gt;;, start=L5, end=L2&gt; L1 &#123; invokedynamic java/lang/invoke/LambdaMetafactory.metafactory(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite; : run()Lclub/throwable/Runnable; ()V club/throwable/Sample.lambda$main$0()V (6) ()V astore1 &#125; L3 &#123; aload1 invokeinterface club/throwable/Runnable.run()V &#125; L6 &#123; ldc \"Hello \" (java.lang.String) astore2 &#125; L4 &#123; aload2 invokedynamic java/lang/invoke/LambdaMetafactory.metafactory(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite; : apply(Ljava/lang/String;)Ljava/util/function/Function; (Ljava/lang/Object;)Ljava/lang/Object; club/throwable/Sample.lambda$main$1(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; (6) (Ljava/lang/String;)Ljava/lang/String; astore3 &#125; L5 &#123; aload3 ldc \"Doge\" (java.lang.String) invokeinterface java/util/function/Function.apply(Ljava/lang/Object;)Ljava/lang/Object; pop &#125; L7 &#123; return &#125; L2 &#123; &#125; &#125; private static synthetic lambda$main$1(java.lang.String arg0, java.lang.String arg1) &#123; //(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; &lt;localVar:index=0 , name=hello , desc=Ljava/lang/String;, sig=null, start=L1, end=L2&gt; &lt;localVar:index=1 , name=string , desc=Ljava/lang/String;, sig=null, start=L1, end=L2&gt; L1 &#123; new java/lang/StringBuilder dup invokespecial java/lang/StringBuilder.&lt;init&gt;()V aload0 // reference to arg0 invokevirtual java/lang/StringBuilder.append(Ljava/lang/String;)Ljava/lang/StringBuilder; aload1 invokevirtual java/lang/StringBuilder.append(Ljava/lang/String;)Ljava/lang/StringBuilder; invokevirtual java/lang/StringBuilder.toString()Ljava/lang/String; areturn &#125; L2 &#123; &#125; &#125; private static synthetic lambda$main$0() &#123; //()V L1 &#123; getstatic java/lang/System.out:java.io.PrintStream ldc \"Hello World!\" (java.lang.String) invokevirtual java/io/PrintStream.println(Ljava/lang/String;)V &#125; L2 &#123; return &#125; &#125;// The following inner classes couldn't be decompiled: java/lang/invoke/MethodHandles$Lookup &#125; 上面的字节码已经被Bytecode-Viewer工具格式化过，符合于人的阅读习惯，从字节码的阅读，结合前面的分析大概可以得出下面的结论： &lt;1&gt;：Lambda表达式在编译期通过字节码增强技术新增一个模板类实现对应的接口类型，这个模板类的所有属性都使用final修饰，模板类由关键字final synthetic修饰。 &lt;2&gt;：封闭类会基于类内的Lambda表达式类型生成private static synthetic修饰的静态方法，该静态方法的方法体就是来源于Lambda方法体，这些静态方法的名称是lambda$封闭类方法名$递增数字。 &lt;3&gt;：Lambda表达式调用最终通过字节码指令invokedynamic，忽略中间过程，最后调用到第&lt;2&gt;步中对应的方法。 限于篇幅问题，这里把Lambda表达式的底层原理做了简单的梳理（这个推导过程仅限于个人理解，依据尚未充分）： &lt;1&gt;：封闭类会基于类内的Lambda表达式类型生成private static synthetic修饰的静态方法，该静态方法的方法体就是来源于Lambda方法体，这些静态方法的名称是lambda$封闭类方法名$递增数字。 &lt;2&gt;：Lambda表达式会通过LambdaMetafactory#metafactory()方法，生成一个对应函数式接口的模板类，模板类的接口方法实现引用了第&lt;1&gt;步中定义的静态方法，同时创建一个调用点ConstantCallSite实例，后面会通过Unsafe#defineAnonymousClass()实例化模板类。。 &lt;3&gt;：调用点ConstantCallSite实例中的方法句柄MethodHandle会根据不同场景选取不同的实现，MethodHandle的子类很多，这里无法一一展开。 &lt;4&gt;：通过invokedynamice指令，基于第&lt;1&gt;步中的模板类实例、第&lt;3&gt;步中的方法句柄以及方法入参进行方法句柄的调用，实际上最终委托到第&lt;1&gt;步中定义的静态方法中执行。 如果想要跟踪Lambda表达式的整个调用生命周期，可以以LambdaMetafactory#metafactory()方法为入口开始DEBUG，调用链路十分庞大，需要有足够的耐心。总的来说就是：Lambda表达式是基于JSR-292引入的动态语言调用包java.lang.invoke和Unsafe#defineAnonymousClass()定义的轻量级模板类实现的，主要用到了invokedynamice字节码指令，关联到方法句柄MethodHandle、调用点CallSite等相对复杂的知识点，这里不再详细展开。 实战 基于JdbcTemplate进行轻量级DAO封装 假设订单表的DDL如下： 1234567891011CREATE TABLE `t_order`( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP, edit_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, user_id BIGINT UNSIGNED NOT NULL COMMENT '用户ID', order_id VARCHAR(64) NOT NULL COMMENT '订单ID', amount DECIMAL(12, 2) NOT NULL DEFAULT 0 COMMENT '订单金额', INDEX idx_user_id (user_id), UNIQUE uniq_order_id (order_id)) COMMENT '订单表'; 下面基于JdbcTemplate封装一个轻量级的OrderDao： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191// 辅助接口@FunctionalInterfacepublic interface PreparedStatementProcessor &#123; void process(PreparedStatement ps) throws SQLException;&#125;@FunctionalInterfacepublic interface ResultSetConverter&lt;T&gt; &#123; T convert(ResultSet resultSet) throws SQLException;&#125;// OrderDao接口public interface OrderDao &#123; int insertSelective(Order record); int updateSelective(Order record); Order selectOneByOrderId(String orderId); List&lt;Order&gt; selectByUserId(Long userId);&#125;// OrderDao实现@Repository@RequiredArgsConstructorpublic class MySqlOrderDao implements OrderDao &#123; private final JdbcTemplate jdbcTemplate; private static final ResultSetConverter&lt;Order&gt; CONVERTER = r -&gt; &#123; Order order = new Order(); order.setId(r.getLong(\"id\")); order.setCreateTime(r.getTimestamp(\"create_time\").toLocalDateTime()); order.setEditTime(r.getTimestamp(\"edit_time\").toLocalDateTime()); order.setUserId(r.getLong(\"user_id\")); order.setAmount(r.getBigDecimal(\"amount\")); order.setOrderId(r.getString(\"order_id\")); return order; &#125;; private static final ResultSetExtractor&lt;List&lt;Order&gt;&gt; MULTI = r -&gt; &#123; List&lt;Order&gt; list = new ArrayList&lt;&gt;(); while (r.next()) &#123; list.add(CONVERTER.convert(r)); &#125; return list; &#125;; private static final ResultSetExtractor&lt;Order&gt; SINGLE = r -&gt; &#123; if (r.next()) &#123; return CONVERTER.convert(r); &#125; return null; &#125;; @Override public int insertSelective(Order record) &#123; List&lt;PreparedStatementProcessor&gt; processors = new ArrayList&lt;&gt;(); StringBuilder sql = new StringBuilder(\"INSERT INTO t_order(\"); Cursor cursor = new Cursor(); if (null != record.getId()) &#123; int idx = cursor.add(); sql.append(\"id,\"); processors.add(p -&gt; p.setLong(idx, record.getId())); &#125; if (null != record.getOrderId()) &#123; int idx = cursor.add(); sql.append(\"order_id,\"); processors.add(p -&gt; p.setString(idx, record.getOrderId())); &#125; if (null != record.getUserId()) &#123; int idx = cursor.add(); sql.append(\"user_id,\"); processors.add(p -&gt; p.setLong(idx, record.getUserId())); &#125; if (null != record.getAmount()) &#123; int idx = cursor.add(); sql.append(\"amount,\"); processors.add(p -&gt; p.setBigDecimal(idx, record.getAmount())); &#125; if (null != record.getCreateTime()) &#123; int idx = cursor.add(); sql.append(\"create_time,\"); processors.add(p -&gt; p.setTimestamp(idx, Timestamp.valueOf(record.getCreateTime()))); &#125; if (null != record.getEditTime()) &#123; int idx = cursor.add(); sql.append(\"edit_time,\"); processors.add(p -&gt; p.setTimestamp(idx, Timestamp.valueOf(record.getEditTime()))); &#125; StringBuilder realSql = new StringBuilder(sql.substring(0, sql.lastIndexOf(\",\"))); realSql.append(\") VALUES (\"); int idx = cursor.idx(); for (int i = 0; i &lt; idx; i++) &#123; if (i != idx - 1) &#123; realSql.append(\"?,\"); &#125; else &#123; realSql.append(\"?\"); &#125; &#125; realSql.append(\")\"); // 传入主键的情况 if (null != record.getId()) &#123; return jdbcTemplate.update(realSql.toString(), p -&gt; &#123; for (PreparedStatementProcessor processor : processors) &#123; processor.process(p); &#125; &#125;); &#125; else &#123; // 自增主键的情况 KeyHolder keyHolder = new GeneratedKeyHolder(); int count = jdbcTemplate.update(p -&gt; &#123; PreparedStatement ps = p.prepareStatement(realSql.toString(), Statement.RETURN_GENERATED_KEYS); for (PreparedStatementProcessor processor : processors) &#123; processor.process(ps); &#125; return ps; &#125;, keyHolder); record.setId(Objects.requireNonNull(keyHolder.getKey()).longValue()); return count; &#125; &#125; @Override public int updateSelective(Order record) &#123; List&lt;PreparedStatementProcessor&gt; processors = new ArrayList&lt;&gt;(); StringBuilder sql = new StringBuilder(\"UPDATE t_order SET \"); Cursor cursor = new Cursor(); if (null != record.getOrderId()) &#123; int idx = cursor.add(); sql.append(\"order_id = ?,\"); processors.add(p -&gt; p.setString(idx, record.getOrderId())); &#125; if (null != record.getUserId()) &#123; int idx = cursor.add(); sql.append(\"user_id = ?,\"); processors.add(p -&gt; p.setLong(idx, record.getUserId())); &#125; if (null != record.getAmount()) &#123; int idx = cursor.add(); sql.append(\"amount = ?,\"); processors.add(p -&gt; p.setBigDecimal(idx, record.getAmount())); &#125; if (null != record.getCreateTime()) &#123; int idx = cursor.add(); sql.append(\"create_time = ?,\"); processors.add(p -&gt; p.setTimestamp(idx, Timestamp.valueOf(record.getCreateTime()))); &#125; if (null != record.getEditTime()) &#123; int idx = cursor.add(); sql.append(\"edit_time = ?,\"); processors.add(p -&gt; p.setTimestamp(idx, Timestamp.valueOf(record.getEditTime()))); &#125; StringBuilder realSql = new StringBuilder(sql.substring(0, sql.lastIndexOf(\",\"))); int idx = cursor.add(); processors.add(p -&gt; p.setLong(idx, record.getId())); realSql.append(\" WHERE id = ?\"); return jdbcTemplate.update(realSql.toString(), p -&gt; &#123; for (PreparedStatementProcessor processor : processors) &#123; processor.process(p); &#125; &#125;); &#125; @Override public Order selectOneByOrderId(String orderId) &#123; return jdbcTemplate.query(\"SELECT * FROM t_order WHERE order_id = ?\", p -&gt; p.setString(1, orderId), SINGLE); &#125; @Override public List&lt;Order&gt; selectByUserId(Long userId) &#123; return jdbcTemplate.query(\"SELECT * FROM t_order WHERE order_id = ?\", p -&gt; p.setLong(1, userId), MULTI); &#125; private static class Cursor &#123; private int idx; public int add() &#123; idx++; return idx; &#125; public int idx() &#123; return idx; &#125; &#125;&#125; 类似于Mybatis Generator，上面的DAO实现笔者已经做了一个简单的生成器，只要配置好数据源的连接属性和表过滤规则就可以生成对应的实体类和DAO类。 基于Optional进行VO设置值 123456789101112131415161718192021222324// 假设VO有多个层级，每个层级都不知道父节点是否为NULL，如下// - OrderInfoVo// - UserInfoVo// - AddressInfoVo// - address(属性)// 假设我要为address属性赋值，那么就会产生箭头型代码。// 常规方法String address = \"xxx\";OrderInfoVo o = ...;if(null != o)&#123; UserInfoVo uiv = o.getUserInfoVo(); if (null != uiv)&#123; AddressInfoVo aiv = uiv.getAddressInfoVo(); if (null != aiv)&#123; aiv.setAddress(address); &#125; &#125;&#125;// 使用Optional和LambdaString address = \"xxx\";OrderInfoVo o = ...;Optional.ofNullable(o).map(OrderInfoVo::getUserInfoVo).map(UserInfoVo::getAddressInfoVo).ifPresent(a -&gt; a.setAddress(address)); 小结 Lambda是Java中一个香甜的语法糖，拥抱Lambda，拥抱函数式编程，笔者也经历过抗拒、不看好、上手和真香的过程，目前也大量使用Stream和Lambda，能在保证性能的前提下，尽可能简化代码，解放劳动力。时代在进步，Java也在进步，这是很多人活着和坚持编程事业的信念。 参考资料： Lambda Expressions Default Methods State of the Lambda JDK11部分源码 （本文完 e-a-20200208 c-5-d）","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Lambda","slug":"Java/Lambda","permalink":"http://throwable.club/blog/categories/Java/Lambda/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Lambda","slug":"Lambda","permalink":"http://throwable.club/blog/tags/Lambda/"}]},{"title":"一个基于RabbitMQ的可复用的事务消息方案","slug":"j-action-transactional-message-by-rabbit","date":"2020-02-05T13:37:56.000Z","updated":"2020-02-05T13:39:07.621Z","comments":true,"path":"2020/02/05/j-action-transactional-message-by-rabbit/","link":"","permalink":"http://throwable.club/2020/02/05/j-action-transactional-message-by-rabbit/","excerpt":"前提 分布式事务是微服务实践中一个比较棘手的问题，在笔者所实施的微服务实践方案中，都采用了折中或者规避强一致性的方案。参考Ebay多年前提出的本地消息表方案，基于RabbitMQ和MySQL（JDBC）做了轻量级的封装，实现了低入侵性的事务消息模块。本文的内容就是详细分析整个方案的设计思路和实施。环境依赖如下： JDK1.8+ spring-boot-start-web:2.x.x、spring-boot-start-jdbc:2.x.x、spring-boot-start-amqp:2.x.x HikariCP:3.x.x（spring-boot-start-jdbc自带）、mysql-connector-java:5.1.48 redisson:3.12.1","text":"前提 分布式事务是微服务实践中一个比较棘手的问题，在笔者所实施的微服务实践方案中，都采用了折中或者规避强一致性的方案。参考Ebay多年前提出的本地消息表方案，基于RabbitMQ和MySQL（JDBC）做了轻量级的封装，实现了低入侵性的事务消息模块。本文的内容就是详细分析整个方案的设计思路和实施。环境依赖如下： JDK1.8+ spring-boot-start-web:2.x.x、spring-boot-start-jdbc:2.x.x、spring-boot-start-amqp:2.x.x HikariCP:3.x.x（spring-boot-start-jdbc自带）、mysql-connector-java:5.1.48 redisson:3.12.1 方案设计思路 事务消息原则上只适合弱一致性（或者说最终一致性）的场景，常见的弱一致性场景如： 用户服务完成了注册动作，向短信服务推送一条营销相关的消息。 信贷体系中，订单服务保存订单完毕，向审批服务推送一条待审批的订单记录信息。 … 强一致性的场景一般不应该选用事务消息。 一般情况下，要求强一致性说明要严格同步，也就是所有操作必须同时成功或者同时失败，这样就会引入同步带来的额外消耗。如果一个事务消息模块设计合理，补偿、查询、监控等等功能都完毕，由于系统交互是异步的，整体吞吐要比严格同步高。在笔者负责的业务系统中基于事务消息使用还定制了一条基本原则：消息内容正确的前提下，消费方出现异常需要自理。 简单来说就是：上游保证了自身的业务正确性，成功推送了正确的消息到RabbitMQ就认为上游义务已经结束。 为了降低代码的入侵性，事务消息需要借助Spring的编程式事务或者声明式事务。编程式事务一般依赖于TransactionTemplate，而声明式事务依托于AOP模块，依赖于注解@Transactional。 接着需要自定义一个事务消息功能模块，新增一个事务消息记录表（其实就是本地消息表），用于保存每一条需要发送的消息记录。事务消息功能模块的主要功能是： 保存消息记录。 推送消息到RabbitMQ服务端。 消息记录的查询、补偿推送等等。 事务执行的逻辑单元 在事务执行的逻辑单元里面，需要进行待推送的事务消息记录的保存，也就是：本地（业务）逻辑和事务消息记录保存操作绑定在同一个事务。 发送消息到RabbitMQ服务端这一步需要延后到事务提交之后，这样才能保证事务提交成功和消息成功发送到RabbitMQ服务端这两个操作是一致的。为了把保存待发送的事务消息和发送消息到RabbitMQ两个动作从使用者感知角度合并为一个动作，这里需要用到Spring特有的事务同步器TransactionSynchronization，这里分析一下事务同步器的主要方法的回调位置，主要参考AbstractPlatformTransactionManager#commit()或者AbstractPlatformTransactionManager#processCommit()方法： 上图仅仅演示了事务正确提交的场景（不包含异常的场景）。这里可以明确知道，事务同步器TransactionSynchronization的afterCommit()和afterCompletion(int status)方法都在真正的事务提交点AbstractPlatformTransactionManager#doCommit()之后回调，因此可以选用这两个方法其中之一用于执行推送消息到RabbitMQ服务端，整体的伪代码如下： 123456789@Transactionalpublic Dto businessMethod()&#123; business transaction code block ... // 保存事务消息 [saveTransactionMessageRecord()] // 注册事务同步器 - 在afterCommit()方法中推送消息到RabbitMQ [register TransactionSynchronization,send message in method afterCommit()] business transaction code block ...&#125; 上面伪代码中，保存事务消息和注册事务同步器两个步骤可以安插在事务方法中的任意位置，也就是说与执行顺序无关。 事务消息的补偿 虽然之前提到笔者建议下游服务自理自身服务消费异常的场景，但是有些时候迫于无奈还是需要上游把对应的消息重新推送，这个算是特殊的场景。另外还有一个场景需要考虑：事务提交之后触发事务同步器TransactionSynchronization的afterCommit()方法失败。这是一个低概率的场景，但是在生产中一定会出现，一个比较典型的原因就是：事务提交完成后尚未来得及触发TransactionSynchronization#afterCommit()方法进行推送服务实例就被重启。如下图所示： 为了统一处理补偿推送的问题，使用了有限状态判断消息是否已经推送成功： 在事务方法内，保存事务消息的时候，标记消息记录推送状态为处理中。 事务同步器接口TransactionSynchronization的afterCommit()方法的实现中，推送对应的消息到RabbitMQ，然后更变事务消息记录的状态为推送成功。 还有一种极为特殊的情况是RabbitMQ服务端本身出现故障导致消息推送异常，这种情况下需要进行重试（补偿推送），经验证明短时间内的反复重试是没有意义的，故障的服务一般不会瞬时恢复，所以可以考虑使用指数退避算法进行重试，同时需要限制最大重试次数。 指数值、间隔值和最大重试次数上限需要根据实际情况设定，否则容易出现消息延时过大或者重试过于频繁等问题。 方案实施 引入核心依赖： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;properties&gt; &lt;spring.boot.version&gt;2.2.4.RELEASE&lt;/spring.boot.version&gt; &lt;redisson.version&gt;3.12.1&lt;/redisson.version&gt; &lt;mysql.connector.version&gt;5.1.48&lt;/mysql.connector.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.boot.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.connector.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;$&#123;redisson.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; spring-boot-starter-jdbc、mysql-connector-java和spring-boot-starter-aop是MySQL事务相关，而spring-boot-starter-amqp是RabbitMQ客户端的封装，redisson主要使用其分布式锁，用于补偿定时任务的加锁执行（以防止服务多个节点并发执行补偿推送）。 表设计 事务消息模块主要涉及两张表，以MySQL为例，建表DDL如下： 1234567891011121314151617181920212223242526272829303132CREATE TABLE `t_transactional_message`( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP, edit_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, creator VARCHAR(20) NOT NULL DEFAULT 'admin', editor VARCHAR(20) NOT NULL DEFAULT 'admin', deleted TINYINT NOT NULL DEFAULT 0, current_retry_times TINYINT NOT NULL DEFAULT 0 COMMENT '当前重试次数', max_retry_times TINYINT NOT NULL DEFAULT 5 COMMENT '最大重试次数', queue_name VARCHAR(255) NOT NULL COMMENT '队列名', exchange_name VARCHAR(255) NOT NULL COMMENT '交换器名', exchange_type VARCHAR(8) NOT NULL COMMENT '交换类型', routing_key VARCHAR(255) COMMENT '路由键', business_module VARCHAR(32) NOT NULL COMMENT '业务模块', business_key VARCHAR(255) NOT NULL COMMENT '业务键', next_schedule_time DATETIME NOT NULL COMMENT '下一次调度时间', message_status TINYINT NOT NULL DEFAULT 0 COMMENT '消息状态', init_backoff BIGINT UNSIGNED NOT NULL DEFAULT 10 COMMENT '退避初始化值,单位为秒', backoff_factor TINYINT NOT NULL DEFAULT 2 COMMENT '退避因子(也就是指数)', INDEX idx_queue_name (queue_name), INDEX idx_create_time (create_time), INDEX idx_next_schedule_time (next_schedule_time), INDEX idx_business_key (business_key)) COMMENT '事务消息表';CREATE TABLE `t_transactional_message_content`( id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, message_id BIGINT UNSIGNED NOT NULL COMMENT '事务消息记录ID', content TEXT COMMENT '消息内容') COMMENT '事务消息内容表'; 因为此模块有可能扩展出一个后台管理模块，所以要把消息的管理和状态相关字段和大体积的消息内容分别存放在两个表，从而避免大批量查询消息记录的时候MySQL服务IO使用率过高的问题（这是和上一个公司的DBA团队商讨后得到的一个比较合理的方案）。预留了两个业务字段business_module和business_key用于标识业务模块和业务键（一般是唯一识别号，例如订单号）。 一般情况下，如果服务通过配置自行提前声明队列和交换器的绑定关系，那么发送RabbitMQ消息的时候其实只依赖于exchangeName和routingKey两个字段（header类型的交换器是特殊的，也比较少用，这里暂时不用考虑），考虑到服务可能会遗漏声明操作，发送消息的时候会基于队列进行首次绑定声明并且缓存相关的信息（RabbitMQ中的队列-交换器绑定声明只要每次声明绑定关系的参数一致，则不会抛出异常）。 方案代码设计 下面的方案设计描述中，暂时忽略了消息事务管理后台的API设计，这些可以在后期补充。 定义贫血模型实体类TransactionalMessage和TransactionalMessageContent： 123456789101112131415161718192021222324252627282930@Datapublic class TransactionalMessage &#123; private Long id; private LocalDateTime createTime; private LocalDateTime editTime; private String creator; private String editor; private Integer deleted; private Integer currentRetryTimes; private Integer maxRetryTimes; private String queueName; private String exchangeName; private String exchangeType; private String routingKey; private String businessModule; private String businessKey; private LocalDateTime nextScheduleTime; private Integer messageStatus; private Long initBackoff; private Integer backoffFactor;&#125;@Datapublic class TransactionalMessageContent &#123; private Long id; private Long messageId; private String content;&#125; 然后定义dao接口（这里暂时不展开实现的细节代码，存储使用MySQL，如果要替换为其他类型的数据库，只需要使用不同的实现即可）： 1234567891011121314151617public interface TransactionalMessageDao &#123; void insertSelective(TransactionalMessage record); void updateStatusSelective(TransactionalMessage record); List&lt;TransactionalMessage&gt; queryPendingCompensationRecords(LocalDateTime minScheduleTime, LocalDateTime maxScheduleTime, int limit);&#125;public interface TransactionalMessageContentDao &#123; void insert(TransactionalMessageContent record); List&lt;TransactionalMessageContent&gt; queryByMessageIds(String messageIds);&#125; 接着定义事务消息服务接口TransactionalMessageService： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121// 对外提供的服务类接口public interface TransactionalMessageService &#123; void sendTransactionalMessage(Destination destination, TxMessage message);&#125;@Getter@RequiredArgsConstructorpublic enum ExchangeType &#123; FANOUT(\"fanout\"), DIRECT(\"direct\"), TOPIC(\"topic\"), DEFAULT(\"\"), ; private final String type;&#125;// 发送消息的目的地public interface Destination &#123; ExchangeType exchangeType(); String queueName(); String exchangeName(); String routingKey();&#125;@Builderpublic class DefaultDestination implements Destination &#123; private ExchangeType exchangeType; private String queueName; private String exchangeName; private String routingKey; @Override public ExchangeType exchangeType() &#123; return exchangeType; &#125; @Override public String queueName() &#123; return queueName; &#125; @Override public String exchangeName() &#123; return exchangeName; &#125; @Override public String routingKey() &#123; return routingKey; &#125;&#125;// 事务消息public interface TxMessage &#123; String businessModule(); String businessKey(); String content();&#125;@Builderpublic class DefaultTxMessage implements TxMessage &#123; private String businessModule; private String businessKey; private String content; @Override public String businessModule() &#123; return businessModule; &#125; @Override public String businessKey() &#123; return businessKey; &#125; @Override public String content() &#123; return content; &#125;&#125;// 消息状态@RequiredArgsConstructorpublic enum TxMessageStatus &#123; /** * 成功 */ SUCCESS(1), /** * 待处理 */ PENDING(0), /** * 处理失败 */ FAIL(-1), ; private final Integer status;&#125; TransactionalMessageService的实现类是事务消息的核心功能实现，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Slf4j@Service@RequiredArgsConstructorpublic class RabbitTransactionalMessageService implements TransactionalMessageService &#123; private final AmqpAdmin amqpAdmin; private final TransactionalMessageManagementService managementService; private static final ConcurrentMap&lt;String, Boolean&gt; QUEUE_ALREADY_DECLARE = new ConcurrentHashMap&lt;&gt;(); @Override public void sendTransactionalMessage(Destination destination, TxMessage message) &#123; String queueName = destination.queueName(); String exchangeName = destination.exchangeName(); String routingKey = destination.routingKey(); ExchangeType exchangeType = destination.exchangeType(); // 原子性的预声明 QUEUE_ALREADY_DECLARE.computeIfAbsent(queueName, k -&gt; &#123; Queue queue = new Queue(queueName); amqpAdmin.declareQueue(queue); Exchange exchange = new CustomExchange(exchangeName, exchangeType.getType()); amqpAdmin.declareExchange(exchange); Binding binding = BindingBuilder.bind(queue).to(exchange).with(routingKey).noargs(); amqpAdmin.declareBinding(binding); return true; &#125;); TransactionalMessage record = new TransactionalMessage(); record.setQueueName(queueName); record.setExchangeName(exchangeName); record.setExchangeType(exchangeType.getType()); record.setRoutingKey(routingKey); record.setBusinessModule(message.businessModule()); record.setBusinessKey(message.businessKey()); String content = message.content(); // 保存事务消息记录 managementService.saveTransactionalMessageRecord(record, content); // 注册事务同步器 TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter() &#123; @Override public void afterCommit() &#123; managementService.sendMessageSync(record, content); &#125; &#125;); &#125;&#125; 消息记录状态和内容持久化的管理统一放在TransactionalMessageManagementService中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110@Slf4j@RequiredArgsConstructor@Servicepublic class TransactionalMessageManagementService &#123; private final TransactionalMessageDao messageDao; private final TransactionalMessageContentDao contentDao; private final RabbitTemplate rabbitTemplate; private static final LocalDateTime END = LocalDateTime.of(2999, 1, 1, 0, 0, 0); private static final long DEFAULT_INIT_BACKOFF = 10L; private static final int DEFAULT_BACKOFF_FACTOR = 2; private static final int DEFAULT_MAX_RETRY_TIMES = 5; private static final int LIMIT = 100; public void saveTransactionalMessageRecord(TransactionalMessage record, String content) &#123; record.setMessageStatus(TxMessageStatus.PENDING.getStatus()); record.setNextScheduleTime(calculateNextScheduleTime(LocalDateTime.now(), DEFAULT_INIT_BACKOFF, DEFAULT_BACKOFF_FACTOR, 0)); record.setCurrentRetryTimes(0); record.setInitBackoff(DEFAULT_INIT_BACKOFF); record.setBackoffFactor(DEFAULT_BACKOFF_FACTOR); record.setMaxRetryTimes(DEFAULT_MAX_RETRY_TIMES); messageDao.insertSelective(record); TransactionalMessageContent messageContent = new TransactionalMessageContent(); messageContent.setContent(content); messageContent.setMessageId(record.getId()); contentDao.insert(messageContent); &#125; public void sendMessageSync(TransactionalMessage record, String content) &#123; try &#123; rabbitTemplate.convertAndSend(record.getExchangeName(), record.getRoutingKey(), content); if (log.isDebugEnabled()) &#123; log.debug(\"发送消息成功,目标队列:&#123;&#125;,消息内容:&#123;&#125;\", record.getQueueName(), content); &#125; // 标记成功 markSuccess(record); &#125; catch (Exception e) &#123; // 标记失败 markFail(record, e); &#125; &#125; private void markSuccess(TransactionalMessage record) &#123; // 标记下一次执行时间为最大值 record.setNextScheduleTime(END); record.setCurrentRetryTimes(record.getCurrentRetryTimes().compareTo(record.getMaxRetryTimes()) &gt;= 0 ? record.getMaxRetryTimes() : record.getCurrentRetryTimes() + 1); record.setMessageStatus(TxMessageStatus.SUCCESS.getStatus()); record.setEditTime(LocalDateTime.now()); messageDao.updateStatusSelective(record); &#125; private void markFail(TransactionalMessage record, Exception e) &#123; log.error(\"发送消息失败,目标队列:&#123;&#125;\", record.getQueueName(), e); record.setCurrentRetryTimes(record.getCurrentRetryTimes().compareTo(record.getMaxRetryTimes()) &gt;= 0 ? record.getMaxRetryTimes() : record.getCurrentRetryTimes() + 1); // 计算下一次的执行时间 LocalDateTime nextScheduleTime = calculateNextScheduleTime( record.getNextScheduleTime(), record.getInitBackoff(), record.getBackoffFactor(), record.getCurrentRetryTimes() ); record.setNextScheduleTime(nextScheduleTime); record.setMessageStatus(TxMessageStatus.FAIL.getStatus()); record.setEditTime(LocalDateTime.now()); messageDao.updateStatusSelective(record); &#125; /** * 计算下一次执行时间 * * @param base 基础时间 * @param initBackoff 退避基准值 * @param backoffFactor 退避指数 * @param round 轮数 * @return LocalDateTime */ private LocalDateTime calculateNextScheduleTime(LocalDateTime base, long initBackoff, long backoffFactor, long round) &#123; double delta = initBackoff * Math.pow(backoffFactor, round); return base.plusSeconds((long) delta); &#125; /** * 推送补偿 - 里面的参数应该根据实际场景定制 */ public void processPendingCompensationRecords() &#123; // 时间的右值为当前时间减去退避初始值，这里预防把刚保存的消息也推送了 LocalDateTime max = LocalDateTime.now().plusSeconds(-DEFAULT_INIT_BACKOFF); // 时间的左值为右值减去1小时 LocalDateTime min = max.plusHours(-1); Map&lt;Long, TransactionalMessage&gt; collect = messageDao.queryPendingCompensationRecords(min, max, LIMIT) .stream() .collect(Collectors.toMap(TransactionalMessage::getId, x -&gt; x)); if (!collect.isEmpty()) &#123; StringJoiner joiner = new StringJoiner(\",\", \"(\", \")\"); collect.keySet().forEach(x -&gt; joiner.add(x.toString())); contentDao.queryByMessageIds(joiner.toString()) .forEach(item -&gt; &#123; TransactionalMessage message = collect.get(item.getMessageId()); sendMessageSync(message, item.getContent()); &#125;); &#125; &#125;&#125; 这里有一点尚待优化：更新事务消息记录状态的方法可以优化为批量更新，在limit比较大的时候，批量更新的效率会更高。 最后是定时任务的配置类： 123456789101112131415161718192021222324252627282930313233343536@Slf4j@RequiredArgsConstructor@Configuration@EnableSchedulingpublic class ScheduleJobAutoConfiguration &#123; private final TransactionalMessageManagementService managementService; /** * 这里用的是本地的Redis,实际上要做成配置 */ private final RedissonClient redisson = Redisson.create(); @Scheduled(fixedDelay = 10000) public void transactionalMessageCompensationTask() throws Exception &#123; RLock lock = redisson.getLock(\"transactionalMessageCompensationTask\"); // 等待时间5秒,预期300秒执行完毕,这两个值需要按照实际场景定制 boolean tryLock = lock.tryLock(5, 300, TimeUnit.SECONDS); if (tryLock) &#123; try &#123; long start = System.currentTimeMillis(); log.info(\"开始执行事务消息推送补偿定时任务...\"); managementService.processPendingCompensationRecords(); long end = System.currentTimeMillis(); long delta = end - start; // 以防锁过早释放 if (delta &lt; 5000) &#123; Thread.sleep(5000 - delta); &#125; log.info(\"执行事务消息推送补偿定时任务完毕,耗时:&#123;&#125; ms...\", end - start); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;&#125; 基本代码编写完，整个项目的结构如下： 最后添加两个测试类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@RequiredArgsConstructor@Componentpublic class MockBusinessRunner implements CommandLineRunner &#123; private final MockBusinessService mockBusinessService; @Override public void run(String... args) throws Exception &#123; mockBusinessService.saveOrder(); &#125;&#125;@Slf4j@RequiredArgsConstructor@Servicepublic class MockBusinessService &#123; private final JdbcTemplate jdbcTemplate; private final TransactionalMessageService transactionalMessageService; private final ObjectMapper objectMapper; @Transactional(rollbackFor = Exception.class) public void saveOrder() throws Exception &#123; String orderId = UUID.randomUUID().toString(); BigDecimal amount = BigDecimal.valueOf(100L); Map&lt;String, Object&gt; message = new HashMap&lt;&gt;(); message.put(\"orderId\", orderId); message.put(\"amount\", amount); jdbcTemplate.update(\"INSERT INTO t_order(order_id,amount) VALUES (?,?)\", p -&gt; &#123; p.setString(1, orderId); p.setBigDecimal(2, amount); &#125;); String content = objectMapper.writeValueAsString(message); transactionalMessageService.sendTransactionalMessage( DefaultDestination.builder() .exchangeName(\"tm.test.exchange\") .queueName(\"tm.test.queue\") .routingKey(\"tm.test.key\") .exchangeType(ExchangeType.DIRECT) .build(), DefaultTxMessage.builder() .businessKey(orderId) .businessModule(\"SAVE_ORDER\") .content(content) .build() ); log.info(\"保存订单:&#123;&#125;成功...\", orderId); &#125;&#125; 某次测试结果如下： 12020-02-05 21:10:13.287 INFO 49556 --- [ main] club.throwable.cm.MockBusinessService : 保存订单:07a75323-460b-42cb-aa63-1a0a45ce19bf成功... 模拟订单数据成功保存，而且RabbitMQ消息在事务成功提交后正常发送到RabbitMQ服务端中，如RabbitMQ控制台数据所示。 小结 事务消息模块的设计仅仅是使异步消息推送这个功能实现趋向于完备，其实一个合理的异步消息交互系统，一定会提供同步查询接口，这一点是基于异步消息没有回调或者没有响应的特性导致的。一般而言，一个系统的吞吐量和系统的异步化处理占比成正相关（这一点可以参考Amdahl's Law），所以在系统架构设计实际中应该尽可能使用异步交互，提高系统吞吐量同时减少同步阻塞带来的无谓等待。事务消息模块可以扩展出一个后台管理，甚至可以配合Micrometer、Prometheus和Grafana体系做实时数据监控。 本文demo项目仓库：rabbit-transactional-message demo必须本地安装MySQL、Redis和RabbitMQ才能正常启动，本地必须新建一个数据库命名local。 （本文完 c-5-d e-a-20200202 疫情严重，马上要开始在家办公，少出门多看书）","categories":[{"name":"In Action","slug":"In-Action","permalink":"http://throwable.club/blog/categories/In-Action/"},{"name":"Distributed Transaction","slug":"In-Action/Distributed-Transaction","permalink":"http://throwable.club/blog/categories/In-Action/Distributed-Transaction/"}],"tags":[{"name":"In Action","slug":"In-Action","permalink":"http://throwable.club/blog/tags/In-Action/"},{"name":"Distributed Transaction","slug":"Distributed-Transaction","permalink":"http://throwable.club/blog/tags/Distributed-Transaction/"}]},{"title":"从源码上理解Netty并发工具-Promise","slug":"netty-common-promise-source-code-usage","date":"2020-01-23T15:34:42.000Z","updated":"2020-01-23T15:36:23.803Z","comments":true,"path":"2020/01/23/netty-common-promise-source-code-usage/","link":"","permalink":"http://throwable.club/2020/01/23/netty-common-promise-source-code-usage/","excerpt":"前提 最近一直在看Netty相关的内容，也在编写一个轻量级的RPC框架来练手，途中发现了Netty的源码有很多亮点，某些实现甚至可以用苛刻来形容。另外，Netty提供的工具类也是相当优秀，可以开箱即用。这里分析一下个人比较喜欢的领域，并发方面的一个Netty工具模块 - Promise。 环境版本： Netty:4.1.44.Final JDK1.8","text":"前提 最近一直在看Netty相关的内容，也在编写一个轻量级的RPC框架来练手，途中发现了Netty的源码有很多亮点，某些实现甚至可以用苛刻来形容。另外，Netty提供的工具类也是相当优秀，可以开箱即用。这里分析一下个人比较喜欢的领域，并发方面的一个Netty工具模块 - Promise。 环境版本： Netty:4.1.44.Final JDK1.8 Promise简介 Promise，中文翻译为承诺或者许诺，含义是人与人之间，一个人对另一个人所说的具有一定憧憬的话，一般是可以实现的。 io.netty.util.concurrent.Promise在注释中只有一句话：特殊的可写的io.netty.util.concurrent.Future（Promise接口是io.netty.util.concurrent.Future的子接口）。而io.netty.util.concurrent.Future是java.util.concurrent.Future的扩展，表示一个异步操作的结果。我们知道，JDK并发包中的Future是不可写，也没有提供可监听的入口（没有应用观察者模式），而Promise很好地弥补了这两个问题。另一方面从继承关系来看，DefaultPromise是这些接口的最终实现类，所以分析源码的时候需要把重心放在DefaultPromise类。一般一个模块提供的功能都由接口定义，这里分析一下两个接口的功能列表： io.netty.util.concurrent.Promise io.netty.util.concurrent.Future 先看io.netty.util.concurrent.Future接口： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public interface Future&lt;V&gt; extends java.util.concurrent.Future&lt;V&gt; &#123; // I/O操作是否执行成功 boolean isSuccess(); // 标记是否可以通过下面的cancel(boolean mayInterruptIfRunning)取消I/O操作 boolean isCancellable(); // 返回I/O操作的异常实例 - 如果I/O操作本身是成功的，此方法返回null Throwable cause(); // 为当前Future实例添加监听Future操作完成的监听器 - isDone()方法激活之后所有监听器实例会得到回调 Future&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); Future&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); // 为当前Future移除监听Future操作完成的监听器 Future&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); Future&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); // 同步等待Future完成得到最终结果（成功）或者抛出异常（失败），响应中断 Future&lt;V&gt; sync() throws InterruptedException; // 同步等待Future完成得到最终结果（成功）或者抛出异常（失败），不响应中断 Future&lt;V&gt; syncUninterruptibly(); // 等待Future完成，响应中断 Future&lt;V&gt; await() throws InterruptedException; // 等待Future完成，不响应中断 Future&lt;V&gt; awaitUninterruptibly(); // 带超时时限的等待Future完成，响应中断 boolean await(long timeout, TimeUnit unit) throws InterruptedException; boolean await(long timeoutMillis) throws InterruptedException; // 带超时时限的等待Future完成，不响应中断 boolean awaitUninterruptibly(long timeout, TimeUnit unit); boolean awaitUninterruptibly(long timeoutMillis); // 非阻塞马上返回Future的结果，如果Future未完成，此方法一定返回null；有些场景下如果Future成功获取到的结果是null则需要二次检查isDone()方法是否为true V getNow(); // 取消当前Future实例的执行，如果取消成功会抛出CancellationException异常 @Override boolean cancel(boolean mayInterruptIfRunning);&#125; sync()和await()方法类似，只是sync()会检查异常执行的情况，一旦发现执行异常马上把异常实例包装抛出，而await()方法对异常无感知。 接着看io.netty.util.concurrent.Promise接口： 12345678910111213141516171819202122232425262728293031323334353637383940414243public interface Promise&lt;V&gt; extends Future&lt;V&gt; &#123; // 标记当前Future成功，设置结果，如果设置成功，则通知所有的监听器，如果Future已经成功或者失败，则抛出IllegalStateException Promise&lt;V&gt; setSuccess(V result); // 标记当前Future成功，设置结果，如果设置成功，则通知所有的监听器并且返回true，否则返回false boolean trySuccess(V result); // 标记当前Future失败，设置结果为异常实例，如果设置成功，则通知所有的监听器，如果Future已经成功或者失败，则抛出IllegalStateException Promise&lt;V&gt; setFailure(Throwable cause); // 标记当前Future失败，设置结果为异常实例，如果设置成功，则通知所有的监听器并且返回true，否则返回false boolean tryFailure(Throwable cause); // 标记当前的Promise实例为不可取消，设置成功返回true，否则返回false boolean setUncancellable(); // 下面的方法和io.netty.util.concurrent.Future中的方法基本一致，只是修改了返回类型为Promise @Override Promise&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); @Override Promise&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); @Override Promise&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); @Override Promise&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); @Override Promise&lt;V&gt; await() throws InterruptedException; @Override Promise&lt;V&gt; awaitUninterruptibly(); @Override Promise&lt;V&gt; sync() throws InterruptedException; @Override Promise&lt;V&gt; syncUninterruptibly();&#125; 到此，Promise接口的所有功能都分析完毕，接下来从源码角度详细分析Promise的实现。 Promise源码实现 Promise的实现类为io.netty.util.concurrent.DefaultPromise（其实DefaultPromise还有很多子类，某些实现是为了定制特定的场景做了扩展），而DefaultPromise继承自io.netty.util.concurrent.AbstractFuture： 12345678910111213141516171819202122232425262728293031323334353637383940414243public abstract class AbstractFuture&lt;V&gt; implements Future&lt;V&gt; &#123; // 永久阻塞等待获取结果的方法 @Override public V get() throws InterruptedException, ExecutionException &#123; // 调用响应中断的永久等待方法进行阻塞 await(); // 从永久阻塞中唤醒后，先判断Future是否执行异常 Throwable cause = cause(); if (cause == null) &#123; // 异常为空说明执行成功，调用getNow()方法返回结果 return getNow(); &#125; // 异常为空不为空，这里区分特定的取消异常则转换为CancellationException抛出 if (cause instanceof CancellationException) &#123; throw (CancellationException) cause; &#125; // 非取消异常的其他所有异常都被包装为执行异常ExecutionException抛出 throw new ExecutionException(cause); &#125; // 带超时阻塞等待获取结果的方法 @Override public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; // 调用响应中断的带超时时限等待方法进行阻塞 if (await(timeout, unit)) &#123; // 从带超时时限阻塞中唤醒后，先判断Future是否执行异常 Throwable cause = cause(); if (cause == null) &#123; // 异常为空说明执行成功，调用getNow()方法返回结果 return getNow(); &#125; // 异常为空不为空，这里区分特定的取消异常则转换为CancellationException抛出 if (cause instanceof CancellationException) &#123; throw (CancellationException) cause; &#125; // 在非等待超时的前提下，非取消异常的其他所有异常都被包装为执行异常ExecutionException抛出 throw new ExecutionException(cause); &#125; // 方法步入此处说明等待超时，则抛出超时异常TimeoutException throw new TimeoutException(); &#125;&#125; AbstractFuture仅仅对get()和get(long timeout, TimeUnit unit)两个方法进行了实现，其实这两处的实现和java.util.concurrent.FutureTask中的实现方式十分相似。 DefaultPromise的源码比较多，这里分开多个部分去阅读，先看它的属性和构造函数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class DefaultPromise&lt;V&gt; extends AbstractFuture&lt;V&gt; implements Promise&lt;V&gt; &#123; // 正常日志的日志句柄，InternalLogger是Netty内部封装的日志接口 private static final InternalLogger logger = InternalLoggerFactory.getInstance(DefaultPromise.class); // 任务拒绝执行时候的日志句柄 - Promise需要作为一个任务提交到线程中执行，如果任务拒绝则使用此日志句柄打印日志 private static final InternalLogger rejectedExecutionLogger = InternalLoggerFactory.getInstance(DefaultPromise.class.getName() + \".rejectedExecution\"); // 监听器的最大栈深度，默认值为8，这个值是防止嵌套回调调用的时候栈深度过大导致内存溢出，后面会举个例子说明它的用法 private static final int MAX_LISTENER_STACK_DEPTH = Math.min(8, SystemPropertyUtil.getInt(\"io.netty.defaultPromise.maxListenerStackDepth\", 8)); // 结果更新器，用于CAS更新结果result的值 @SuppressWarnings(\"rawtypes\") private static final AtomicReferenceFieldUpdater&lt;DefaultPromise, Object&gt; RESULT_UPDATER = AtomicReferenceFieldUpdater.newUpdater(DefaultPromise.class, Object.class, \"result\"); // 用于填充result的值，当设置结果result传入null，Promise执行成功，用这个值去表示成功的结果 private static final Object SUCCESS = new Object(); // 用于填充result的值，表示Promise不能被取消 private static final Object UNCANCELLABLE = new Object(); // CancellationException实例的持有器，用于判断Promise取消状态和抛出CancellationException private static final CauseHolder CANCELLATION_CAUSE_HOLDER = new CauseHolder(ThrowableUtil.unknownStackTrace( new CancellationException(), DefaultPromise.class, \"cancel(...)\")); // CANCELLATION_CAUSE_HOLDER的异常栈信息元素数组 private static final StackTraceElement[] CANCELLATION_STACK = CANCELLATION_CAUSE_HOLDER.cause.getStackTrace(); // 真正的结果对象，使用Object类型，最终有可能为null、真正的结果实例、SUCCESS、UNCANCELLABLE或者CANCELLATION_CAUSE_HOLDER等等 private volatile Object result; // 事件执行器，这里暂时不做展开，可以理解为单个调度线程 private final EventExecutor executor; // 监听器集合，可能是单个GenericFutureListener实例或者DefaultFutureListeners（监听器集合）实例 private Object listeners; // 等待获取结果的线程数量 private short waiters; // 标记是否正在回调监听器 private boolean notifyingListeners; // 构造函数依赖于EventExecutor public DefaultPromise(EventExecutor executor) &#123; this.executor = checkNotNull(executor, \"executor\"); &#125; protected DefaultPromise() &#123; // only for subclasses - 这个构造函数预留给子类 executor = null; &#125; // ... 省略其他代码 ... // 私有静态内部类，用于存放Throwable实例，也就是持有异常的原因实例 private static final class CauseHolder &#123; final Throwable cause; CauseHolder(Throwable cause) &#123; this.cause = cause; &#125; &#125; // 私有静态内部类，用于覆盖CancellationException的栈信息为前面定义的CANCELLATION_STACK，同时覆盖了toString()返回CancellationException的全类名 private static final class LeanCancellationException extends CancellationException &#123; private static final long serialVersionUID = 2794674970981187807L; @Override public Throwable fillInStackTrace() &#123; setStackTrace(CANCELLATION_STACK); return this; &#125; @Override public String toString() &#123; return CancellationException.class.getName(); &#125; &#125; // ... 省略其他代码 ...&#125; Promise目前支持两种类型的监听器： GenericFutureListener：支持泛型的Future监听器。 GenericProgressiveFutureListener：它是GenericFutureListener的子类，支持进度表示和支持泛型的Future监听器（有些场景需要多个步骤实现，类似于进度条那样）。 1234567891011// GenericFutureListenerpublic interface GenericFutureListener&lt;F extends Future&lt;?&gt;&gt; extends EventListener &#123; void operationComplete(F future) throws Exception;&#125;// GenericProgressiveFutureListenerpublic interface GenericProgressiveFutureListener&lt;F extends ProgressiveFuture&lt;?&gt;&gt; extends GenericFutureListener&lt;F&gt; &#123; void operationProgressed(F future, long progress, long total) throws Exception;&#125; 为了让Promise支持多个监听器，Netty添加了一个默认修饰符修饰的DefaultFutureListeners类用于保存监听器实例数组： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677// DefaultFutureListenersfinal class DefaultFutureListeners &#123; private GenericFutureListener&lt;? extends Future&lt;?&gt;&gt;[] listeners; private int size; private int progressiveSize; // the number of progressive listeners // 这个构造相对特别，是为了让Promise中的listeners（Object类型）实例由单个GenericFutureListener实例转换为DefaultFutureListeners类型 @SuppressWarnings(\"unchecked\") DefaultFutureListeners(GenericFutureListener&lt;? extends Future&lt;?&gt;&gt; first, GenericFutureListener&lt;? extends Future&lt;?&gt;&gt; second) &#123; listeners = new GenericFutureListener[2]; listeners[0] = first; listeners[1] = second; size = 2; if (first instanceof GenericProgressiveFutureListener) &#123; progressiveSize ++; &#125; if (second instanceof GenericProgressiveFutureListener) &#123; progressiveSize ++; &#125; &#125; public void add(GenericFutureListener&lt;? extends Future&lt;?&gt;&gt; l) &#123; GenericFutureListener&lt;? extends Future&lt;?&gt;&gt;[] listeners = this.listeners; final int size = this.size; // 注意这里，每次扩容数组长度是原来的2倍 if (size == listeners.length) &#123; this.listeners = listeners = Arrays.copyOf(listeners, size &lt;&lt; 1); &#125; // 把当前的GenericFutureListener加入数组中 listeners[size] = l; // 监听器总数量加1 this.size = size + 1; // 如果为GenericProgressiveFutureListener，则带进度指示的监听器总数量加1 if (l instanceof GenericProgressiveFutureListener) &#123; progressiveSize ++; &#125; &#125; public void remove(GenericFutureListener&lt;? extends Future&lt;?&gt;&gt; l) &#123; final GenericFutureListener&lt;? extends Future&lt;?&gt;&gt;[] listeners = this.listeners; int size = this.size; for (int i = 0; i &lt; size; i ++) &#123; if (listeners[i] == l) &#123; // 计算需要需要移动的监听器的下标 int listenersToMove = size - i - 1; if (listenersToMove &gt; 0) &#123; // listenersToMove后面的元素全部移动到数组的前端 System.arraycopy(listeners, i + 1, listeners, i, listenersToMove); &#125; // 当前监听器总量的最后一个位置设置为null，数量减1 listeners[-- size] = null; this.size = size; // 如果监听器是GenericProgressiveFutureListener，则带进度指示的监听器总数量减1 if (l instanceof GenericProgressiveFutureListener) &#123; progressiveSize --; &#125; return; &#125; &#125; &#125; // 返回监听器实例数组 public GenericFutureListener&lt;? extends Future&lt;?&gt;&gt;[] listeners() &#123; return listeners; &#125; // 返回监听器总数量 public int size() &#123; return size; &#125; // 返回带进度指示的监听器总数量 public int progressiveSize() &#123; return progressiveSize; &#125;&#125; 接下来看DefaultPromise的剩余方法实现，笔者觉得DefaultPromise方法实现在代码顺序上是有一定的艺术的。先看几个判断Promise执行状态的方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class DefaultPromise&lt;V&gt; extends AbstractFuture&lt;V&gt; implements Promise&lt;V&gt; &#123; // ... 省略其他代码 ... @Override public boolean setUncancellable() &#123; // 通过结果更新器CAS更新result为UNCANCELLABLE，期望旧值为null，更新值为UNCANCELLABLE属性，如果成功则返回true if (RESULT_UPDATER.compareAndSet(this, null, UNCANCELLABLE)) &#123; return true; &#125; Object result = this.result; // 步入这里说明result当前值不为null，isDone0()和isCancelled0()都是终态，这里如果命中终态就返回false //（笔者注：其实可以这样认为，这里result不能为null，如果不为终态，它只能是UNCANCELLABLE属性实例） return !isDone0(result) || !isCancelled0(result); &#125; @Override public boolean isSuccess() &#123; Object result = this.result; // 如果执行成功，则结果不为null，同时不为UNCANCELLABLE，同时不为CauseHolder类型 //（笔者注：其实可以这样认为，Promise为成功，则result只能是一个开发者定义的实例或者SUCCESS属性实例） return result != null &amp;&amp; result != UNCANCELLABLE &amp;&amp; !(result instanceof CauseHolder); &#125; @Override public boolean isCancellable() &#123; // 是否可取消的，result为null说明Promise处于初始化状态尚未执行，则认为可以取消 return result == null; &#125; @Override public Throwable cause() &#123; // 通过当前result获取Throwable实例 return cause0(result); &#125; private Throwable cause0(Object result) &#123; // result非CauseHolder类型，则直接返回null if (!(result instanceof CauseHolder)) &#123; return null; &#125; // 如果result为CANCELLATION_CAUSE_HOLDER（静态CancellationException的持有） if (result == CANCELLATION_CAUSE_HOLDER) &#123; // 则新建一个自定义LeanCancellationException实例 CancellationException ce = new LeanCancellationException(); // 如果CAS更新结果result为LeanCancellationException新实例则返回 if (RESULT_UPDATER.compareAndSet(this, CANCELLATION_CAUSE_HOLDER, new CauseHolder(ce))) &#123; return ce; &#125; // 走到这里说明了result是非CANCELLATION_CAUSE_HOLDER的自定义CauseHolder实例 result = this.result; &#125; // 兜底返回CauseHolder持有的cause return ((CauseHolder) result).cause; &#125; // 静态方法，判断Promise是否为取消，依据是result必须是CauseHolder类型，同时CauseHolder中的cause必须为CancellationException类型或者其子类 private static boolean isCancelled0(Object result) &#123; return result instanceof CauseHolder &amp;&amp; ((CauseHolder) result).cause instanceof CancellationException; &#125; // 静态方法，判断Promise是否完成，依据是result不为null同时不为UNCANCELLABLE属性实例 private static boolean isDone0(Object result) &#123; return result != null &amp;&amp; result != UNCANCELLABLE; &#125; // 判断Promise实例是否取消 @Override public boolean isCancelled() &#123; return isCancelled0(result); &#125; // 判断Promise实例是否完成 @Override public boolean isDone() &#123; return isDone0(result); &#125; // ... 省略其他代码 ...&#125; 接着看监听器的添加和移除方法（这其中也包含了通知监听器的逻辑）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188public class DefaultPromise&lt;V&gt; extends AbstractFuture&lt;V&gt; implements Promise&lt;V&gt; &#123; // ... 省略其他代码 ... @Override public Promise&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener) &#123; // 入参非空校验 checkNotNull(listener, \"listener\"); // 加锁，锁定的对象是Promise实例自身 synchronized (this) &#123; // 添加监听器 addListener0(listener); &#125; // 如果Promise实例已经执行完毕，则通知监听器进行回调 if (isDone()) &#123; notifyListeners(); &#125; return this; &#125; @Override public Promise&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners) &#123; // 入参非空校验 checkNotNull(listeners, \"listeners\"); // 加锁，锁定的对象是Promise实例自身 synchronized (this) &#123; // 遍历入参数组添加监听器，有空元素直接跳出 for (GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener : listeners) &#123; if (listener == null) &#123; break; &#125; addListener0(listener); &#125; &#125; // 如果Promise实例已经执行完毕，则通知监听器进行回调 if (isDone()) &#123; notifyListeners(); &#125; return this; &#125; @Override public Promise&lt;V&gt; removeListener(final GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener) &#123; // 入参非空校验 checkNotNull(listener, \"listener\"); // 加锁，锁定的对象是Promise实例自身 synchronized (this) &#123; // 移除监听器 removeListener0(listener); &#125; return this; &#125; @Override public Promise&lt;V&gt; removeListeners(final GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners) &#123; // 入参非空校验 checkNotNull(listeners, \"listeners\"); // 加锁，锁定的对象是Promise实例自身 synchronized (this) &#123; // 遍历入参数组移除监听器，有空元素直接跳出 for (GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener : listeners) &#123; if (listener == null) &#123; break; &#125; removeListener0(listener); &#125; &#125; return this; &#125; private void addListener0(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener) &#123; // 如果Promise实例持有listeners为null，则直接设置为入参listener if (listeners == null) &#123; listeners = listener; &#125; else if (listeners instanceof DefaultFutureListeners) &#123; // 如果当前Promise实例持有listeners的是DefaultFutureListeners类型，则调用它的add()方法进行添加 ((DefaultFutureListeners) listeners).add(listener); &#125; else &#123; // 步入这里说明当前Promise实例持有listeners为单个GenericFutureListener实例，需要转换为DefaultFutureListeners实例 listeners = new DefaultFutureListeners((GenericFutureListener&lt;?&gt;) listeners, listener); &#125; &#125; private void removeListener0(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener) &#123; // 如果当前Promise实例持有listeners的是DefaultFutureListeners类型，则调用它的remove()方法进行移除 if (listeners instanceof DefaultFutureListeners) &#123; ((DefaultFutureListeners) listeners).remove(listener); &#125; else if (listeners == listener) &#123; // 如果当前Promise实例持有listeners不为DefaultFutureListeners类型，也就是单个GenericFutureListener并且和传入的listener相同， // 则Promise实例持有listeners置为null listeners = null; &#125; &#125; private void notifyListeners() &#123; EventExecutor executor = executor(); // 当前执行线程是事件循环线程，那么直接同步调用，简单来说就是调用notifyListeners()方法的线程和EventExecutor是同一个线程 if (executor.inEventLoop()) &#123; // 下面的ThreadLocal和listenerStackDepth是调用栈深度保护相关，博文会另起一个章节专门讲解这个问题，这里可以暂时忽略 final InternalThreadLocalMap threadLocals = InternalThreadLocalMap.get(); final int stackDepth = threadLocals.futureListenerStackDepth(); if (stackDepth &lt; MAX_LISTENER_STACK_DEPTH) &#123; threadLocals.setFutureListenerStackDepth(stackDepth + 1); try &#123; notifyListenersNow(); &#125; finally &#123; threadLocals.setFutureListenerStackDepth(stackDepth); &#125; return; &#125; &#125; // 当前执行线程不是事件循环线程，则把notifyListenersNow()包装为Runnable实例放到EventExecutor中执行 safeExecute(executor, new Runnable() &#123; @Override public void run() &#123; notifyListenersNow(); &#125; &#125;); &#125; // 使用EventExecutor进行任务执行，execute()方法抛出的异常会使用rejectedExecutionLogger句柄打印 private static void safeExecute(EventExecutor executor, Runnable task) &#123; try &#123; executor.execute(task); &#125; catch (Throwable t) &#123; rejectedExecutionLogger.error(\"Failed to submit a listener notification task. Event loop shut down?\", t); &#125; &#125; // 马上通知所有监听器进行回调 private void notifyListenersNow() &#123; Object listeners; // 这里加锁，在锁的保护下设置notifyingListeners的值，如果多个线程调用同一个Promise实例的notifyListenersNow()方法 // 命中notifyingListeners的线程可以直接返回 synchronized (this) &#123; // Only proceed if there are listeners to notify and we are not already notifying listeners. if (notifyingListeners || this.listeners == null) &#123; return; &#125; notifyingListeners = true; // 临时变量listeners存放瞬时的监听器实例，方便下一步设置Promise实例的listeners为null listeners = this.listeners; // 重置当前Promise实例的listeners为null this.listeners = null; &#125; for (;;) &#123; if (listeners instanceof DefaultFutureListeners) &#123; // 多个监听器情况下的通知 notifyListeners0((DefaultFutureListeners) listeners); &#125; else &#123; // 单个监听器情况下的通知 notifyListener0(this, (GenericFutureListener&lt;?&gt;) listeners); &#125; synchronized (this) &#123; if (this.listeners == null) &#123; // 这里因为没有异常抛出的可能，不用在finally块中编写，重置notifyingListeners为false并且返回跳出循环 notifyingListeners = false; return; &#125; // 临时变量listeners存放瞬时的监听器实例，回调操作判断是基于临时实例去做 - 这里可能由另一个线程更新了listeners的值 listeners = this.listeners; // 重置当前Promise实例的listeners为null，确保监听器只会被回调一次，下一次跳出for死循环 this.listeners = null; &#125; &#125; &#125; // 遍历DefaultFutureListeners中的listeners数组，调用静态方法notifyListener0() private void notifyListeners0(DefaultFutureListeners listeners) &#123; GenericFutureListener&lt;?&gt;[] a = listeners.listeners(); int size = listeners.size(); for (int i = 0; i &lt; size; i ++) &#123; notifyListener0(this, a[i]); &#125; &#125; // 这个静态方法是最终监听器回调的方法,也就是简单调用GenericFutureListener#operationComplete()传入的是当前的Promise实例，捕获一切异常打印warn日志 @SuppressWarnings(&#123; \"unchecked\", \"rawtypes\" &#125;) private static void notifyListener0(Future future, GenericFutureListener l) &#123; try &#123; l.operationComplete(future); &#125; catch (Throwable t) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"An exception was thrown by \" + l.getClass().getName() + \".operationComplete()\", t); &#125; &#125; &#125;&#125; 然后看wait()和sync()方法体系： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216public class DefaultPromise&lt;V&gt; extends AbstractFuture&lt;V&gt; implements Promise&lt;V&gt; &#123; // ... 省略其他代码 ... @Override public Promise&lt;V&gt; await() throws InterruptedException &#123; // 如果Promise执行完毕，直接返回 if (isDone()) &#123; return this; &#125; // 如果当前线程中断则直接抛出InterruptedException if (Thread.interrupted()) &#123; throw new InterruptedException(toString()); &#125; // 死锁检测 checkDeadLock(); // 加锁，加锁对象是当前Promise实例 synchronized (this) &#123; // 这里设置一个死循环，终止条件是isDone()为true while (!isDone()) &#123; // 等待线程数加1 incWaiters(); try &#123; // 这里调用的是Object#wait()方法进行阻塞，如果线程被中断会抛出InterruptedException wait(); &#125; finally &#123; // 解除阻塞后等待线程数减1 decWaiters(); &#125; &#125; &#125; return this; &#125; @Override public Promise&lt;V&gt; awaitUninterruptibly() &#123; // 如果Promise执行完毕，直接返回 if (isDone()) &#123; return this; &#125; // 死锁检测 checkDeadLock(); boolean interrupted = false; // 加锁，加锁对象是当前Promise实例 synchronized (this) &#123; // 这里设置一个死循环，终止条件是isDone()为true while (!isDone()) &#123; // 等待线程数加1 incWaiters(); try &#123; // 这里调用的是Object#wait()方法进行阻塞，捕获了InterruptedException异常，如果抛出InterruptedException记录线程的中断状态到interrupted wait(); &#125; catch (InterruptedException e) &#123; // Interrupted while waiting. interrupted = true; &#125; finally &#123; // 解除阻塞后等待线程数减1 decWaiters(); &#125; &#125; &#125; // 如果线程被中断跳出等待阻塞，则清除线程的中断标志位 if (interrupted) &#123; Thread.currentThread().interrupt(); &#125; return this; &#125; // 后面的几个带超时时限的wait()方法都是调用await0() @Override public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; return await0(unit.toNanos(timeout), true); &#125; @Override public boolean await(long timeoutMillis) throws InterruptedException &#123; return await0(MILLISECONDS.toNanos(timeoutMillis), true); &#125; @Override public boolean awaitUninterruptibly(long timeout, TimeUnit unit) &#123; try &#123; return await0(unit.toNanos(timeout), false); &#125; catch (InterruptedException e) &#123; // Should not be raised at all. throw new InternalError(); &#125; &#125; @Override public boolean awaitUninterruptibly(long timeoutMillis) &#123; try &#123; return await0(MILLISECONDS.toNanos(timeoutMillis), false); &#125; catch (InterruptedException e) &#123; // Should not be raised at all. throw new InternalError(); &#125; &#125; // 检查死锁，这里判断了等待线程是事件循环线程则直接抛出BlockingOperationException异常 // 简单来说就是：Promise的执行线程和等待结果的线程，不能是同一个线程，否则依赖会成环 protected void checkDeadLock() &#123; EventExecutor e = executor(); if (e != null &amp;&amp; e.inEventLoop()) &#123; throw new BlockingOperationException(toString()); &#125; &#125; @Override public Promise&lt;V&gt; sync() throws InterruptedException &#123; // 同步永久阻塞等待 await(); // 阻塞等待解除，如果执行存在异常，则直接抛出 rethrowIfFailed(); return this; &#125; @Override public Promise&lt;V&gt; syncUninterruptibly() &#123; // 同步永久阻塞等待 - 响应中断 awaitUninterruptibly(); // 塞等待解除，如果执行存在异常，则直接抛出 rethrowIfFailed(); return this; &#125; // waiters加1，如果超过Short.MAX_VALUE则抛出IllegalStateException private void incWaiters() &#123; if (waiters == Short.MAX_VALUE) &#123; throw new IllegalStateException(\"too many waiters: \" + this); &#125; ++waiters; &#125; // waiters减1 private void decWaiters() &#123; --waiters; &#125; // cause不为null则抛出 private void rethrowIfFailed() &#123; Throwable cause = cause(); if (cause == null) &#123; return; &#125; PlatformDependent.throwException(cause); &#125; private boolean await0(long timeoutNanos, boolean interruptable) throws InterruptedException &#123; // 如果Promise执行完毕，直接返回 if (isDone()) &#123; return true; &#125; // 如果超时时限小于0那么返回isDone()的结果 if (timeoutNanos &lt;= 0) &#123; return isDone(); &#125; // 如果允许中断，当前线程的中断标志位为true，则抛出InterruptedException if (interruptable &amp;&amp; Thread.interrupted()) &#123; throw new InterruptedException(toString()); &#125; // 死锁检测 checkDeadLock(); // 记录当前的纳秒时间戳 long startTime = System.nanoTime(); // 等待时间的长度 - 单位为纳秒 long waitTime = timeoutNanos; // 记录线程是否被中断 boolean interrupted = false; try &#123; // 死循环 for (;;) &#123; synchronized (this) &#123; // 如果Promise执行完毕，直接返回true - 这一步是先验判断，命中了就不需要阻塞等待 if (isDone()) &#123; return true; &#125; // 等待线程数加1 incWaiters(); try &#123; // 这里调用的是带超时时限的Object#wait()方法进行阻塞 wait(waitTime / 1000000, (int) (waitTime % 1000000)); &#125; catch (InterruptedException e) &#123; // 线程被中断并且外部允许中断，那么直接抛出InterruptedException if (interruptable) &#123; throw e; &#125; else &#123; // 否则只记录中断过的状态 interrupted = true; &#125; &#125; finally &#123; // 解除阻塞后等待线程数减1 decWaiters(); &#125; &#125; // 解除阻塞后，如果Promise执行完毕，直接返回true if (isDone()) &#123; return true; &#125; else &#123; // 步入这里说明Promise尚未执行完毕，则重新计算等待时间间隔的长度数量（修正），如果大于0则进入下一轮循环 waitTime = timeoutNanos - (System.nanoTime() - startTime); if (waitTime &lt;= 0) &#123; return isDone(); &#125; &#125; &#125; &#125; finally &#123; // 如果线程被中断跳出等待阻塞，则清除线程的中断标志位 if (interrupted) &#123; Thread.currentThread().interrupt(); &#125; &#125; &#125; // ... 省略其他代码 ...&#125; 最后是几个设置结果和获取结果的方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156public class DefaultPromise&lt;V&gt; extends AbstractFuture&lt;V&gt; implements Promise&lt;V&gt; &#123; // ... 省略其他代码 ... @Override public Promise&lt;V&gt; setSuccess(V result) &#123; // 设置成功结果，如果设置成功则返回当前Promise实例 if (setSuccess0(result)) &#123; return this; &#125; // 设置失败说明了多次设置，Promise已经执行完毕，则抛出异常 throw new IllegalStateException(\"complete already: \" + this); &#125; @Override public boolean trySuccess(V result) &#123; // 设置成功结果，返回的布尔值表示成功或失败 return setSuccess0(result); &#125; @Override public Promise&lt;V&gt; setFailure(Throwable cause) &#123; // 设置失败结果，如果设置成功则返回当前Promise实例 if (setFailure0(cause)) &#123; return this; &#125; // 设置失败说明了多次设置，Promise已经执行完毕，则抛出异常 throw new IllegalStateException(\"complete already: \" + this, cause); &#125; @Override public boolean tryFailure(Throwable cause) &#123; // 设置失败结果，返回的布尔值表示成功或失败 return setFailure0(cause); &#125; @SuppressWarnings(\"unchecked\") @Override public V getNow() &#123; // 非阻塞获取结果，如果result是CauseHolder类型、SUCCESS属性实例或者UNCANCELLABLE实行实例则返回null，否则返回转换类型后的result值 // 对异常无感知，如果CauseHolder包裹了异常，此方法依然返回null Object result = this.result; if (result instanceof CauseHolder || result == SUCCESS || result == UNCANCELLABLE) &#123; return null; &#125; return (V) result; &#125; @SuppressWarnings(\"unchecked\") @Override public V get() throws InterruptedException, ExecutionException &#123; // 永久阻塞获取结果 Object result = this.result; // 如果Promise未执行完毕则进行永久阻塞等待 if (!isDone0(result)) &#123; await(); // 更新结果临时变量 result = this.result; &#125; // result为SUCCESS属性实例或者UNCANCELLABLE属性实例的时候直接返回null if (result == SUCCESS || result == UNCANCELLABLE) &#123; return null; &#125; // 如果result为CauseHolder类型，则获取其中持有的cause属性，也有可能为null Throwable cause = cause0(result); if (cause == null) &#123; // 执行成功的前提下转换类型后的result值返回 return (V) result; &#125; // 取消的情况，抛出CancellationException if (cause instanceof CancellationException) &#123; throw (CancellationException) cause; &#125; // 剩余的情况一律封装为ExecutionException异常 throw new ExecutionException(cause); &#125; @SuppressWarnings(\"unchecked\") @Override public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; // 带超时时限的阻塞获取结果 Object result = this.result; // 如果Promise未执行完毕则进行带超时时限的阻塞等待 if (!isDone0(result)) &#123; if (!await(timeout, unit)) &#123; // 等待超时直接抛出TimeoutException throw new TimeoutException(); &#125; // 更新结果临时变量 result = this.result; &#125; // result为SUCCESS属性实例或者UNCANCELLABLE属性实例的时候直接返回null if (result == SUCCESS || result == UNCANCELLABLE) &#123; return null; &#125; // 如果result为CauseHolder类型，则获取其中持有的cause属性，也有可能为null Throwable cause = cause0(result); if (cause == null) &#123; // 执行成功的前提下转换类型后的result值返回 return (V) result; &#125; // 取消的情况，抛出CancellationException if (cause instanceof CancellationException) &#123; throw (CancellationException) cause; &#125; // 剩余的情况一律封装为ExecutionException异常 throw new ExecutionException(cause); &#125; @Override public boolean cancel(boolean mayInterruptIfRunning) &#123; // CAS更新result为CANCELLATION_CAUSE_HOLDER，result的期望值必须为null if (RESULT_UPDATER.compareAndSet(this, null, CANCELLATION_CAUSE_HOLDER)) &#123; // 判断是否需要进行等待线程的通知 if (checkNotifyWaiters()) &#123; // 通知监听器进行回调 notifyListeners(); &#125; return true; &#125; return false; &#125; private boolean setSuccess0(V result) &#123; // 设置执行成功的结果，如果入参result为null，则选用SUCCESS属性，否则使用result return setValue0(result == null ? SUCCESS : result); &#125; private boolean setFailure0(Throwable cause) &#123; // 设置执行失败的结果，入参是Throwable类型，封装为CauseHolder，存放在CauseHolder实例的cause属性 return setValue0(new CauseHolder(checkNotNull(cause, \"cause\"))); &#125; private boolean setValue0(Object objResult) &#123; // CAS更新result为入参objResult，result的期望值必须为null或者UNCANCELLABLE才能更新成功 if (RESULT_UPDATER.compareAndSet(this, null, objResult) || RESULT_UPDATER.compareAndSet(this, UNCANCELLABLE, objResult)) &#123; // 判断是否需要进行等待线程的通知 if (checkNotifyWaiters()) &#123; // 通知监听器进行回调 notifyListeners(); &#125; return true; &#125; return false; &#125; // 判断是否需要进行等待线程的通知 - 其实是判断是否需要通知监听器回调 private synchronized boolean checkNotifyWaiters() &#123; // 如果等待线程数量大于0则调用Object#notifyAll()唤醒所有等待线程 if (waiters &gt; 0) &#123; notifyAll(); &#125; // 如果listeners不为空（也就是存在监听器）的时候才返回true return listeners != null; &#125; // ... 省略其他代码 ...&#125; Promise的基本使用 要使用Netty的Promise模块，并不需要引入Netty的所有依赖，这里只需要引入netty-common： 12345&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-common&lt;/artifactId&gt; &lt;version&gt;4.1.44.Final&lt;/version&gt;&lt;/dependency&gt; EventExecutor选取方面，Netty已经准备了一个GlobalEventExecutor用于全局事件处理，这里可以直接选用（当然也可以自行实现EventExecutor或者用EventExecutor的其他实现类）： 12EventExecutor executor = GlobalEventExecutor.INSTANCE;Promise&lt;String&gt; promise = new DefaultPromise&lt;&gt;(executor); 这里设计一个场景：异步下载一个链接的资源到磁盘上，下载完成之后需要异步通知下载完的磁盘文件路径，得到通知之后打印下载结果到控制台中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class PromiseMain &#123; public static void main(String[] args) throws Exception &#123; String url = \"http://xxx.yyy.zzz\"; EventExecutor executor = GlobalEventExecutor.INSTANCE; Promise&lt;DownloadResult&gt; promise = new DefaultPromise&lt;&gt;(executor); promise.addListener(new DownloadResultListener()); Thread thread = new Thread(() -&gt; &#123; try &#123; System.out.println(\"开始下载资源,url:\" + url); long start = System.currentTimeMillis(); // 模拟下载耗时 Thread.sleep(2000); String location = \"C:\\\\xxx\\\\yyy\\\\z.md\"; long cost = System.currentTimeMillis() - start; System.out.println(String.format(\"下载资源成功,url:%s,保存到:%s,耗时:%d ms\", url, location, cost)); DownloadResult result = new DownloadResult(); result.setUrl(url); result.setFileDiskLocation(location); result.setCost(cost); // 通知结果 promise.setSuccess(result); &#125; catch (Exception ignore) &#123; &#125; &#125;, \"Download-Thread\"); thread.start(); Thread.sleep(Long.MAX_VALUE); &#125; @Data private static class DownloadResult &#123; private String url; private String fileDiskLocation; private long cost; &#125; private static class DownloadResultListener implements GenericFutureListener&lt;Future&lt;DownloadResult&gt;&gt; &#123; @Override public void operationComplete(Future&lt;DownloadResult&gt; future) throws Exception &#123; if (future.isSuccess()) &#123; DownloadResult downloadResult = future.getNow(); System.out.println(String.format(\"下载完成通知,url:%s,文件磁盘路径:%s,耗时:%d ms\", downloadResult.getUrl(), downloadResult.getFileDiskLocation(), downloadResult.getCost())); &#125; &#125; &#125;&#125; 执行后控制台输出： 123开始下载资源,url:http://xxx.yyy.zzz下载资源成功,url:http://xxx.yyy.zzz,保存到:C:\\xxx\\yyy\\z.md,耗时:2000 ms下载完成通知,url:http://xxx.yyy.zzz,文件磁盘路径:C:\\xxx\\yyy\\z.md,耗时:2000 ms Promise适用的场景很多，除了异步通知的场景也能用于同步调用，它在设计上比JUC的Future灵活很多，基于Future扩展出很多新的特性，有需要的可以单独引入此依赖直接使用。 Promise监听器栈深度的问题 有些时候，由于封装或者人为编码异常等原因，监听器的回调可能出现基于多个Promise形成的链（参考Issue-5302，a promise listener chain），这样子有可能出现递归调用深度过大而导致栈溢出，因此需要设置一个阈值，限制递归调用的最大栈深度，这个深度阈值暂且称为栈深度保护阈值，默认值是8，可以通过系统参数io.netty.defaultPromise.maxListenerStackDepth覆盖设置。这里贴出前面提到过的代码块： 1234567891011121314151617181920212223242526272829private void notifyListeners() &#123; EventExecutor executor = executor(); // 事件执行器必须是事件循环类型，也就是executor.inEventLoop()为true的时候才启用递归栈深度保护 if (executor.inEventLoop()) &#123; // 获取当前线程绑定的InternalThreadLocalMap实例，这里类似于ThreadLocal final InternalThreadLocalMap threadLocals = InternalThreadLocalMap.get(); // 获取当前线程的监听器调用栈深度 final int stackDepth = threadLocals.futureListenerStackDepth(); // 监听器调用栈深度如果不超过阈值MAX_LISTENER_STACK_DEPTH if (stackDepth &lt; MAX_LISTENER_STACK_DEPTH) &#123; // 调用notifyListenersNow()前先设置监听器调用栈深度 + 1 threadLocals.setFutureListenerStackDepth(stackDepth + 1); try &#123; notifyListenersNow(); &#125; finally &#123; // 调用notifyListenersNow()完毕后设置监听器调用栈深度为调用前的数值，也就是恢复线程的监听器调用栈深度 threadLocals.setFutureListenerStackDepth(stackDepth); &#125; return; &#125; &#125; // 如果监听器调用栈深度超过阈值MAX_LISTENER_STACK_DEPTH，则直接每次通知监听器当成一个新的异步任务处理 safeExecute(executor, new Runnable() &#123; @Override public void run() &#123; notifyListenersNow(); &#125; &#125;);&#125; 如果我们想模拟一个例子触发监听器调用栈深度保护，那么只需要想办法在同一个EventLoop类型的线程中递归调用notifyListeners()方法即可。 最典型的例子就是在上一个Promise监听器回调的方法里面触发下一个Promise的监听器的setSuccess()（简单理解就是套娃），画个图理解一下： 测试代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class PromiseListenerMain &#123; private static final AtomicInteger COUNTER = new AtomicInteger(0); public static void main(String[] args) throws Exception &#123; EventExecutor executor = ImmediateEventExecutor.INSTANCE; // root Promise&lt;String&gt; root = new DefaultPromise&lt;&gt;(executor); Promise&lt;String&gt; p1 = new DefaultPromise&lt;&gt;(executor); Promise&lt;String&gt; p2 = new DefaultPromise&lt;&gt;(executor); Promise&lt;String&gt; p3 = new DefaultPromise&lt;&gt;(executor); Promise&lt;String&gt; p4 = new DefaultPromise&lt;&gt;(executor); Promise&lt;String&gt; p5 = new DefaultPromise&lt;&gt;(executor); Promise&lt;String&gt; p6 = new DefaultPromise&lt;&gt;(executor); Promise&lt;String&gt; p7 = new DefaultPromise&lt;&gt;(executor); Promise&lt;String&gt; p8 = new DefaultPromise&lt;&gt;(executor); Promise&lt;String&gt; p9 = new DefaultPromise&lt;&gt;(executor); Promise&lt;String&gt; p10 = new DefaultPromise&lt;&gt;(executor); p1.addListener(new Listener(p2)); p2.addListener(new Listener(p3)); p3.addListener(new Listener(p4)); p4.addListener(new Listener(p5)); p5.addListener(new Listener(p6)); p6.addListener(new Listener(p7)); p7.addListener(new Listener(p8)); p8.addListener(new Listener(p9)); p9.addListener(new Listener(p10)); root.addListener(new Listener(p1)); root.setSuccess(\"success\"); Thread.sleep(Long.MAX_VALUE); &#125; private static class Listener implements GenericFutureListener&lt;Future&lt;String&gt;&gt; &#123; private final String name; private final Promise&lt;String&gt; promise; public Listener(Promise&lt;String&gt; promise) &#123; this.name = \"listener-\" + COUNTER.getAndIncrement(); this.promise = promise; &#125; @Override public void operationComplete(Future&lt;String&gt; future) throws Exception &#123; System.out.println(String.format(\"监听器[%s]回调成功...\", name)); if (null != promise) &#123; promise.setSuccess(\"success\"); &#125; &#125; &#125;&#125; 因为有safeExecute()兜底执行，上面的所有Promise都会回调，这里可以采用IDEA的高级断点功能，在步入断点的地方添加额外的日志，输出如下： 1234567891011121314151617181920MAX_LISTENER_STACK_DEPTH(notifyListenersNow)执行---监听器[listener-9]回调成功...MAX_LISTENER_STACK_DEPTH(notifyListenersNow)执行---监听器[listener-0]回调成功...MAX_LISTENER_STACK_DEPTH(notifyListenersNow)执行---监听器[listener-1]回调成功...MAX_LISTENER_STACK_DEPTH(notifyListenersNow)执行---监听器[listener-2]回调成功...MAX_LISTENER_STACK_DEPTH(notifyListenersNow)执行---监听器[listener-3]回调成功...MAX_LISTENER_STACK_DEPTH(notifyListenersNow)执行---监听器[listener-4]回调成功...MAX_LISTENER_STACK_DEPTH(notifyListenersNow)执行---监听器[listener-5]回调成功...MAX_LISTENER_STACK_DEPTH(notifyListenersNow)执行---监听器[listener-6]回调成功...safeExecute(notifyListenersNow)执行----------监听器[listener-7]回调成功...safeExecute(notifyListenersNow)执行----------监听器[listener-8]回调成功... 这里笔者有点疑惑，如果调用栈深度大于8，超出的部分会包装为Runnable实例提交到事件执行器执行，岂不是把递归栈溢出的隐患变成了内存溢出的隐患（因为异步任务也有可能积压，除非拒绝任务提交，那么具体要看EventExecutor的实现了）？ 小结 Netty提供的Promise工具的源码和使用方式都分析完了，设计理念和代码都是十分值得借鉴，同时能够开箱即用，可以在日常编码中直接引入，减少重复造轮子的劳动和风险。 （本文完 e-a-20200123 c-3-d）","categories":[{"name":"Netty","slug":"Netty","permalink":"http://throwable.club/blog/categories/Netty/"},{"name":"Java","slug":"Netty/Java","permalink":"http://throwable.club/blog/categories/Netty/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Netty","slug":"Netty","permalink":"http://throwable.club/blog/tags/Netty/"}]},{"title":"线程上下文类加载器ContextClassLoader内存泄漏隐患","slug":"java-thread-context-class-loader-memory-leak-risk","date":"2020-01-19T15:07:48.000Z","updated":"2020-01-20T00:32:17.916Z","comments":true,"path":"2020/01/19/java-thread-context-class-loader-memory-leak-risk/","link":"","permalink":"http://throwable.club/2020/01/19/java-thread-context-class-loader-memory-leak-risk/","excerpt":"前提 今天（2020-01-18）在编写Netty相关代码的时候，从Netty源码中的ThreadDeathWatcher和GlobalEventExecutor追溯到两个和线程上下文类加载器ContextClassLoader内存泄漏相关的Issue： ThreadDeathWatcher causes custom classLoader script memory leaks Ensure ThreadDeathWatcher and GlobalEventExecutor will not cause clas… 两个Issue分别是两位前辈在2017-12的时候提出的，描述的是同一类问题，最后被Netty的负责人采纳，并且修复了对应的问题从而关闭了Issue。这里基于这两个Issue描述的内容，对ContextClassLoader内存泄漏隐患做一次复盘。","text":"前提 今天（2020-01-18）在编写Netty相关代码的时候，从Netty源码中的ThreadDeathWatcher和GlobalEventExecutor追溯到两个和线程上下文类加载器ContextClassLoader内存泄漏相关的Issue： ThreadDeathWatcher causes custom classLoader script memory leaks Ensure ThreadDeathWatcher and GlobalEventExecutor will not cause clas… 两个Issue分别是两位前辈在2017-12的时候提出的，描述的是同一类问题，最后被Netty的负责人采纳，并且修复了对应的问题从而关闭了Issue。这里基于这两个Issue描述的内容，对ContextClassLoader内存泄漏隐患做一次复盘。 ClassLoader相关的内容 一个JVM实例（Java应用程序）里面的所有类都是通过ClassLoader加载的。 不同的ClassLoader在JVM中有不同的命名空间，一个类实例（Class）的唯一标识是全类名 + ClassLoader，也就是不同的ClassLoader加载同一个类文件，也会得到不相同的Class实例。 JVM不提供类卸载的功能，从目前参考到的资料来看，类卸载需要满足下面几点： 条件一：Class的所有实例不被强引用（不可达）。 条件二：Class本身不被强引用（不可达）。 条件三：加载该Class的ClassLoader实例不被强引用（不可达）。 有些场景下需要实现类的热部署和卸载，例如定义一个接口，然后由外部动态传入代码的实现。 这一点很常见，最典型的就是在线编程，代码传到服务端再进行编译和运行。 由于应用启动期所有非JDK类库的类都是由AppClassLoader加载，我们没有办法通过AppClassLoader去加载非类路径下的已存在同名的类文件（对于一个ClassLoader而言，每个类文件只能加载一次，生成唯一的Class），所以为了动态加载类，每次必须使用完全不同的自定义ClassLoader实例加载同一个类文件或者使用同一个自定义的ClassLoader实例加载不同的类文件。类的热部署这里举个简单例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// 此文件在项目类路径package club.throwable.loader;public class DefaultHelloService implements HelloService &#123; @Override public String sayHello() &#123; return \"default say hello!\"; &#125;&#125;// 下面两个文件编译后放在I盘根目录// I:\\\\DefaultHelloService1.classpackage club.throwable.loader;public class DefaultHelloService1 implements HelloService &#123; @Override public String sayHello() &#123; return \"1 say hello!\"; &#125;&#125;// I:\\\\DefaultHelloService2.classpackage club.throwable.loader;public class DefaultHelloService2 implements HelloService &#123; @Override public String sayHello() &#123; return \"2 say hello!\"; &#125;&#125;// 接口和运行方法public interface HelloService &#123; String sayHello(); static void main(String[] args) throws Exception &#123; HelloService helloService = new DefaultHelloService(); System.out.println(helloService.sayHello()); ClassLoader loader = new ClassLoader() &#123; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; String location = \"I:\\\\DefaultHelloService1.class\"; if (name.contains(\"DefaultHelloService2\")) &#123; location = \"I:\\\\DefaultHelloService2.class\"; &#125; File classFile = new File(location); ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); try &#123; InputStream stream = new FileInputStream(classFile); int b; while ((b = stream.read()) != -1) &#123; outputStream.write(b); &#125; &#125; catch (IOException e) &#123; throw new IllegalArgumentException(e); &#125; byte[] bytes = outputStream.toByteArray(); return super.defineClass(name, bytes, 0, bytes.length); &#125; &#125;; Class&lt;?&gt; klass = loader.loadClass(\"club.throwable.loader.DefaultHelloService1\"); helloService = (HelloService) klass.newInstance(); System.out.println(helloService.sayHello()); klass = loader.loadClass(\"club.throwable.loader.DefaultHelloService2\"); helloService = (HelloService) klass.newInstance(); System.out.println(helloService.sayHello()); &#125;&#125;// 控制台输出default say hello!1 say hello!2 say hello! 如果新建过多的ClassLoader实例和Class实例，会占用大量的内存，如果由于上面几个条件无法全部满足，也就是这些ClassLoader实例和Class实例一直堆积无法卸载，那么就会导致内存泄漏（memory leak，后果很严重，有可能耗尽服务器的物理内存，因为JDK1.8+类相关元信息存在在元空间metaspace，而元空间使用的是native memory）。 线程中的ContextClassLoader ContextClassLoader其实指的是线程类java.lang.Thread中的contextClassLoader属性，它是ClassLoader类型，也就是类加载器实例。有些场景下，JDK提供了一些标准接口需要第三方提供商去实现（最常见的就是SPI，Service Provider Interface，例如java.sql.Driver），这些标准接口类是由启动类加载器(Bootstrap ClassLoader)加载，但是这些接口的实现类需要从外部引入，本身不属于JDK的原生类库，无法用启动类加载器加载。为了解决此困境，引入了线程上下文类加载器Thread Context ClassLoader。线程java.lang.Thread实例在初始化的时候会调用Thread#init()方法，Thread类和contextClassLoader相关的核心代码块如下： 1234567891011121314151617181920212223242526272829303132// 线程实例的初始化方法,new Thread()的时候一定会调用private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) &#123; // 省略其他代码 Thread parent = currentThread(); // 省略其他代码 if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; // 省略其他代码&#125;public void setContextClassLoader(ClassLoader cl) &#123; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; sm.checkPermission(new RuntimePermission(\"setContextClassLoader\")); &#125; contextClassLoader = cl;&#125;@CallerSensitivepublic ClassLoader getContextClassLoader() &#123; if (contextClassLoader == null) return null; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; ClassLoader.checkClassLoaderPermission(contextClassLoader, Reflection.getCallerClass()); &#125; return contextClassLoader;&#125; 首先明确两点： Thread实例允许手动设置contextClassLoader属性，覆盖当前的线程上下文类加载器实例。 Thread在初始化实例（调用new Thread()）的时候一定会调用Thread#init()方法，新建的子线程实例会继承父线程的contextClassLoader属性，而应用主线程[main]的contextClassLoader一般是应用类加载器（Application ClassLoader，有时也称为系统类加载器），其他用户线程都是主线程派生出来的后代线程，如果不覆盖contextClassLoader，那么新建的后代线程的contextClassLoader就是应用类加载器。 分析到这里，笔者只想说明一个结论：后代线程的线程上下文类加载器会继承父线程的线程上下文类加载器，其实这里用继承这个词语也不是太准确，准确来说应该是后代线程的线程上下文类加载器和父线程的上下文类加载器完全相同，如果都派生自主线程，那么都是应用类加载器。对于这个结论可以验证一下（下面例子在JDK8中运行）： 1234567891011121314151617public class ThreadContextClassLoaderMain &#123; public static void main(String[] args) throws Exception &#123; AtomicReference&lt;Thread&gt; grandSonThreadReference = new AtomicReference&lt;&gt;(); Thread sonThread = new Thread(() -&gt; &#123; Thread thread = new Thread(()-&gt; &#123;&#125;,\"grand-son-thread\"); grandSonThreadReference.set(thread); &#125;, \"son-thread\"); sonThread.start(); Thread.sleep(100); Thread main = Thread.currentThread(); Thread grandSonThread = grandSonThreadReference.get(); System.out.println(String.format(\"ContextClassLoader of [main]:%s\", main.getContextClassLoader())); System.out.println(String.format(\"ContextClassLoader of [%s]:%s\",sonThread.getName(), sonThread.getContextClassLoader())); System.out.println(String.format(\"ContextClassLoader of [%s]:%s\", grandSonThread.getName(), grandSonThread.getContextClassLoader())); &#125;&#125; 控制台输出如下： 123ContextClassLoader of [main]:sun.misc.Launcher$AppClassLoader@18b4aac2ContextClassLoader of [son-thread]:sun.misc.Launcher$AppClassLoader@18b4aac2ContextClassLoader of [grand-son-thread]:sun.misc.Launcher$AppClassLoader@18b4aac2 印证了前面的结论，主线程、子线程、孙子线程的线程上下文类加载器都是AppClassLoader类型，并且指向同一个实例sun.misc.Launcher$AppClassLoader@18b4aac2。 ContextClassLoader设置不当导致内存泄漏的隐患 只要有大量热加载和卸载动态类的场景，就需要警惕后代线程ContextClassLoader设置不当导致内存泄漏。画个图就能比较清楚： 父线程中设置了一个自定义类加载器，用于加载动态类，子线程新建的时候直接使用了父线程的自定义类加载器，导致该自定义类加载器一直被子线程强引用，结合前面的类卸载条件分析，所有由该自定义类加载器加载出来的动态类都不能被卸载，导致了内存泄漏。这里还是基于文章前面的那个例子做改造： 新增一个线程X用于进行类加载，新建一个自定义类加载器，设置线程X的上下文类加载器为该自定义类加载器。 线程X运行方法中创建一个新线程Y，用于接收类加载成功的事件并且进行打印。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public interface HelloService &#123; String sayHello(); BlockingQueue&lt;String&gt; CLASSES = new LinkedBlockingQueue&lt;&gt;(); BlockingQueue&lt;String&gt; EVENTS = new LinkedBlockingQueue&lt;&gt;(); AtomicBoolean START = new AtomicBoolean(false); static void main(String[] args) throws Exception &#123; Thread thread = new Thread(() -&gt; &#123; ClassLoader loader = new ClassLoader() &#123; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; String location = \"I:\\\\DefaultHelloService1.class\"; if (name.contains(\"DefaultHelloService2\")) &#123; location = \"I:\\\\DefaultHelloService2.class\"; &#125; File classFile = new File(location); ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); try &#123; InputStream stream = new FileInputStream(classFile); int b; while ((b = stream.read()) != -1) &#123; outputStream.write(b); &#125; &#125; catch (IOException e) &#123; throw new IllegalArgumentException(e); &#125; byte[] bytes = outputStream.toByteArray(); Class&lt;?&gt; defineClass = super.defineClass(name, bytes, 0, bytes.length); try &#123; EVENTS.put(String.format(\"加载类成功,类名:%s\", defineClass.getName())); &#125; catch (Exception ignore) &#123; &#125; return defineClass; &#125; &#125;; Thread x = new Thread(() -&gt; &#123; try &#123; if (START.compareAndSet(false, true)) &#123; Thread y = new Thread(() -&gt; &#123; try &#123; for (; ; ) &#123; String event = EVENTS.take(); System.out.println(\"接收到事件,事件内容:\" + event); &#125; &#125; catch (Exception ignore) &#123; &#125; &#125;, \"Y\"); y.setDaemon(true); y.start(); &#125; for (; ; ) &#123; String take = CLASSES.take(); Class&lt;?&gt; klass = loader.loadClass(take); HelloService helloService = (HelloService) klass.newInstance(); System.out.println(helloService.sayHello()); &#125; &#125; catch (Exception ignore) &#123; &#125; &#125;, \"X\"); x.setContextClassLoader(loader); x.setDaemon(true); x.start(); &#125;); thread.start(); CLASSES.put(\"club.throwable.loader.DefaultHelloService1\"); CLASSES.put(\"club.throwable.loader.DefaultHelloService2\"); Thread.sleep(5000); System.gc(); Thread.sleep(5000); System.gc(); Thread.sleep(Long.MAX_VALUE); &#125;&#125; 控制台输出： 1234接收到事件,事件内容:加载类成功,类名:club.throwable.loader.DefaultHelloService11 say hello!接收到事件,事件内容:加载类成功,类名:club.throwable.loader.DefaultHelloService22 say hello! 打开VisualVM，Dump对应进程的内存快照，多执行几次GC，发现了所有动态类都没有被卸载（这里除非主动终止线程Y释放自定义ClassLoader，否则永远都不可能释放该强引用），验证了前面的结论。 当然，这里只是加载了两个动态类，如果在特殊场景之下，例如在线编码和运行代码，那么有可能极度频繁动态编译和动态类加载，如果出现了上面类似的内存泄漏，那么很容易导致服务器内存耗尽。 解决方案 参考那两个Issue，解决方案（或者说预防手段）基本上有两个： 不需要使用自定义类加载器的线程（如事件派发线程等）优先初始化，那么一般它的线程上下文类加载器是应用类加载器。 新建后代线程的时候，手动覆盖它的线程上下文类加载器，参考Netty的做法，在线程初始化的时候做如下的操作： 12345678// ThreadDeathWatcher || GlobalEventExecutorAccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; @Override public Void run() &#123; watcherThread.setContextClassLoader(null); return null; &#125;&#125;); 小结 这篇文章算是近期研究得比较深入的一篇文章，ContextClassLoader内存泄漏的隐患归根到底是引用使用不当导致一些本来在方法栈退出之后需要释放的引用无法释放导致的。这种问题有些时候隐藏得很深，而一旦命中了同样的问题并且在并发的场景之下，那么内存泄漏的问题会恶化得十分快。这类问题归类为性能优化，而性能优化是十分大的专题，以后应该也会遇到类似的各类问题，这些经验希望能对未来产生正向的作用。 参考资料： 《深入理解Java虚拟机 - 3rd》 （本文完 c-2-d e-a-20200119）","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Concurrency","slug":"Java/Concurrency","permalink":"http://throwable.club/blog/categories/Java/Concurrency/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Thread","slug":"Thread","permalink":"http://throwable.club/blog/tags/Thread/"}]},{"title":"基于Netty和SpringBoot实现一个轻量级RPC框架-Client端请求响应同步化处理","slug":"netty-custom-rpc-framework-client-sync","date":"2020-01-18T06:52:32.000Z","updated":"2020-01-18T06:53:02.380Z","comments":true,"path":"2020/01/18/netty-custom-rpc-framework-client-sync/","link":"","permalink":"http://throwable.club/2020/01/18/netty-custom-rpc-framework-client-sync/","excerpt":"前提 前置文章： 《基于Netty和SpringBoot实现一个轻量级RPC框架-协议篇》 《基于Netty和SpringBoot实现一个轻量级RPC框架-Server篇》 《基于Netty和SpringBoot实现一个轻量级RPC框架-Client篇》 前一篇文章简单介绍了通过动态代理完成了Client端契约接口调用转换为发送RPC协议请求的功能。这篇文章主要解决一个遗留的技术难题：请求-响应同步化处理。 需要的依赖如下： JDK1.8+ Netty:4.1.44.Final SpringBoot:2.2.2.RELEASE","text":"前提 前置文章： 《基于Netty和SpringBoot实现一个轻量级RPC框架-协议篇》 《基于Netty和SpringBoot实现一个轻量级RPC框架-Server篇》 《基于Netty和SpringBoot实现一个轻量级RPC框架-Client篇》 前一篇文章简单介绍了通过动态代理完成了Client端契约接口调用转换为发送RPC协议请求的功能。这篇文章主要解决一个遗留的技术难题：请求-响应同步化处理。 需要的依赖如下： JDK1.8+ Netty:4.1.44.Final SpringBoot:2.2.2.RELEASE 简单分析Netty请求-响应的处理流程 图中已经忽略了编码解码器和其他入站出站处理器，不同颜色的线程代表完全不相同的线程，不同线程之间的处理逻辑是完全异步，也就是Netty IO线程（n-l-g-1）接收到Server端的消息并且解析完成的时候，用户调用线程（u-t-1）无法感知到解析完毕的消息包，那么这里要做的事情就是让用户调用线程（u-t-1）获取到Netty IO线程（n-l-g-1）接收并且解析完成的消息包。 这里可以用一个简单的例子来说明模拟Client端调用线程等待Netty IO线程的处理结果再同步返回的过程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114@Slf4jpublic class NettyThreadSyncTest &#123; @ToString private static class ResponseFuture &#123; private final long beginTimestamp = System.currentTimeMillis(); @Getter private final long timeoutMilliseconds; @Getter private final String requestId; @Setter @Getter private volatile boolean sendRequestSucceed = false; @Setter @Getter private volatile Throwable cause; @Getter private volatile Object response; private final CountDownLatch latch = new CountDownLatch(1); public ResponseFuture(String requestId, long timeoutMilliseconds) &#123; this.requestId = requestId; this.timeoutMilliseconds = timeoutMilliseconds; &#125; public boolean timeout() &#123; return System.currentTimeMillis() - beginTimestamp &gt; timeoutMilliseconds; &#125; public Object waitResponse(final long timeoutMilliseconds) throws InterruptedException &#123; latch.await(timeoutMilliseconds, TimeUnit.MILLISECONDS); return response; &#125; public void putResponse(Object response) throws InterruptedException &#123; this.response = response; latch.countDown(); &#125; &#125; static ExecutorService REQUEST_THREAD; static ExecutorService NETTY_IO_THREAD; static Callable&lt;Object&gt; REQUEST_TASK; static Runnable RESPONSE_TASK; static String processBusiness(String name) &#123; return String.format(\"%s say hello!\", name); &#125; private static final Map&lt;String /* request id */, ResponseFuture&gt; RESPONSE_FUTURE_TABLE = Maps.newConcurrentMap(); @BeforeClass public static void beforeClass() throws Exception &#123; String requestId = UUID.randomUUID().toString(); String requestContent = \"throwable\"; REQUEST_TASK = () -&gt; &#123; try &#123; // 3秒没有得到响应认为超时 ResponseFuture responseFuture = new ResponseFuture(requestId, 3000); RESPONSE_FUTURE_TABLE.put(requestId, responseFuture); // 这里忽略发送请求的操作,只打印日志和模拟耗时1秒 Thread.sleep(1000); log.info(\"发送请求成功,请求ID:&#123;&#125;,请求内容:&#123;&#125;\", requestId, requestContent); // 更新标记属性 responseFuture.setSendRequestSucceed(true); // 剩余2秒等待时间 - 这里只是粗略计算 return responseFuture.waitResponse(3000 - 1000); &#125; catch (Exception e) &#123; log.info(\"发送请求失败,请求ID:&#123;&#125;,请求内容:&#123;&#125;\", requestId, requestContent); throw new RuntimeException(e); &#125; &#125;; RESPONSE_TASK = () -&gt; &#123; String responseContent = processBusiness(requestContent); try &#123; ResponseFuture responseFuture = RESPONSE_FUTURE_TABLE.get(requestId); if (null != responseFuture) &#123; log.warn(\"处理响应成功,请求ID:&#123;&#125;,响应内容:&#123;&#125;\", requestId, responseContent); responseFuture.putResponse(responseContent); &#125; else &#123; log.warn(\"请求ID[&#123;&#125;]对应的ResponseFuture不存在,忽略处理\", requestId); &#125; &#125; catch (Exception e) &#123; log.info(\"处理响应失败,请求ID:&#123;&#125;,响应内容:&#123;&#125;\", requestId, responseContent); throw new RuntimeException(e); &#125; &#125;; REQUEST_THREAD = Executors.newSingleThreadExecutor(runnable -&gt; &#123; Thread thread = new Thread(runnable, \"REQUEST_THREAD\"); thread.setDaemon(true); return thread; &#125;); NETTY_IO_THREAD = Executors.newSingleThreadExecutor(runnable -&gt; &#123; Thread thread = new Thread(runnable, \"NETTY_IO_THREAD\"); thread.setDaemon(true); return thread; &#125;); &#125; @Test public void testProcessSync() throws Exception &#123; log.info(\"异步提交请求处理任务......\"); Future&lt;Object&gt; future = REQUEST_THREAD.submit(REQUEST_TASK); // 模拟请求耗时 Thread.sleep(1500); log.info(\"异步提交响应处理任务......\"); NETTY_IO_THREAD.execute(RESPONSE_TASK); // 这里可以设置超时 log.info(\"同步获取请求结果:&#123;&#125;\", future.get()); Thread.sleep(Long.MAX_VALUE); &#125;&#125; 执行testProcessSync()方法，控制台输出如下： 123452020-01-18 13:17:07 [main] INFO c.t.client.NettyThreadSyncTest - 异步提交请求处理任务......2020-01-18 13:17:08 [REQUEST_THREAD] INFO c.t.client.NettyThreadSyncTest - 发送请求成功,请求ID:71f47e27-c17c-458d-b271-4e74fad33a7b,请求内容:throwable2020-01-18 13:17:09 [main] INFO c.t.client.NettyThreadSyncTest - 异步提交响应处理任务......2020-01-18 13:17:09 [NETTY_IO_THREAD] WARN c.t.client.NettyThreadSyncTest - 处理响应成功,请求ID:71f47e27-c17c-458d-b271-4e74fad33a7b,响应内容:throwable say hello!2020-01-18 13:17:09 [main] INFO c.t.client.NettyThreadSyncTest - 同步获取请求结果:throwable say hello! 上面这个例子里面的线程同步处理主要参考主流的Netty框架客户端部分的实现逻辑：RocketMQ（具体是NettyRemotingClient类）以及Redisson（具体是RedisExecutor类），它们就是用这种方式使得异步线程处理转化为同步处理。 Client端请求响应同步化处理 按照前面的例子，首先新增一个ResponseFuture用于承载已发送但未响应的请求： 1234567891011121314151617181920212223242526272829303132333435363738@ToStringpublic class ResponseFuture &#123; private final long beginTimestamp = System.currentTimeMillis(); @Getter private final long timeoutMilliseconds; @Getter private final String requestId; @Setter @Getter private volatile boolean sendRequestSucceed = false; @Setter @Getter private volatile Throwable cause; @Getter private volatile ResponseMessagePacket response; private final CountDownLatch latch = new CountDownLatch(1); public ResponseFuture(String requestId, long timeoutMilliseconds) &#123; this.requestId = requestId; this.timeoutMilliseconds = timeoutMilliseconds; &#125; public boolean timeout() &#123; return System.currentTimeMillis() - beginTimestamp &gt; timeoutMilliseconds; &#125; public ResponseMessagePacket waitResponse(final long timeoutMilliseconds) throws InterruptedException &#123; latch.await(timeoutMilliseconds, TimeUnit.MILLISECONDS); return response; &#125; public void putResponse(ResponseMessagePacket response) throws InterruptedException &#123; this.response = response; latch.countDown(); &#125;&#125; 接着需要新增一个HashMap去缓存这些返送成功但是未得到响应处理的ResponseFuture： 1Map&lt;String /* request id */, ResponseFuture&gt; RESPONSE_FUTURE_TABLE = Maps.newConcurrentMap(); 这里的KEY选用requestId，而requestId之前已经定义为UUID，确保每个请求不会重复。为了简单起见，目前所有的逻辑都编写在契约代理工厂ContractProxyFactory，添加下面的功能： 添加一个同步发送方法sendRequestSync()处理消息包的发送和同步响应，RequestMessagePacket转换为调用代理目标方法返回值类型的逻辑暂时也编写在此方法中。 添加一个核心线程数量为逻辑核心数量 * 2的线程池用于处理请求。 添加一个单线程的调度线程池用于定时清理那些过期的ResponseFuture，清理方法为scanResponseFutureTable()。 修改后的ContractProxyFactory如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107@Slf4jpublic class ContractProxyFactory &#123; private static final RequestArgumentExtractor EXTRACTOR = new DefaultRequestArgumentExtractor(); private static final ConcurrentMap&lt;Class&lt;?&gt;, Object&gt; CACHE = Maps.newConcurrentMap(); static final ConcurrentMap&lt;String /* request id */, ResponseFuture&gt; RESPONSE_FUTURE_TABLE = Maps.newConcurrentMap(); // 定义请求的最大超时时间为3秒 private static final long REQUEST_TIMEOUT_MS = 3000; private static final ExecutorService EXECUTOR; private static final ScheduledExecutorService CLIENT_HOUSE_KEEPER; private static final Serializer SERIALIZER = FastJsonSerializer.X; @SuppressWarnings(\"unchecked\") public static &lt;T&gt; T ofProxy(Class&lt;T&gt; interfaceKlass) &#123; // 缓存契约接口的代理类实例 return (T) CACHE.computeIfAbsent(interfaceKlass, x -&gt; Proxy.newProxyInstance(interfaceKlass.getClassLoader(), new Class[]&#123;interfaceKlass&#125;, (target, method, args) -&gt; &#123; RequestArgumentExtractInput input = new RequestArgumentExtractInput(); input.setInterfaceKlass(interfaceKlass); input.setMethod(method); RequestArgumentExtractOutput output = EXTRACTOR.extract(input); // 封装请求参数 RequestMessagePacket packet = new RequestMessagePacket(); packet.setMagicNumber(ProtocolConstant.MAGIC_NUMBER); packet.setVersion(ProtocolConstant.VERSION); packet.setSerialNumber(SerialNumberUtils.X.generateSerialNumber()); packet.setMessageType(MessageType.REQUEST); packet.setInterfaceName(output.getInterfaceName()); packet.setMethodName(output.getMethodName()); packet.setMethodArgumentSignatures(output.getMethodArgumentSignatures().toArray(new String[0])); packet.setMethodArguments(args); Channel channel = ClientChannelHolder.CHANNEL_REFERENCE.get(); return sendRequestSync(channel, packet, method.getReturnType()); &#125;)); &#125; /** * 同步发送请求 * * @param channel channel * @param packet packet * @return Object */ static Object sendRequestSync(Channel channel, RequestMessagePacket packet, Class&lt;?&gt; returnType) &#123; long beginTimestamp = System.currentTimeMillis(); ResponseFuture responseFuture = new ResponseFuture(packet.getSerialNumber(), REQUEST_TIMEOUT_MS); RESPONSE_FUTURE_TABLE.put(packet.getSerialNumber(), responseFuture); try &#123; // 获取到承载响应Packet的Future Future&lt;ResponseMessagePacket&gt; packetFuture = EXECUTOR.submit(() -&gt; &#123; channel.writeAndFlush(packet).addListener((ChannelFutureListener) future -&gt; responseFuture.setSendRequestSucceed(true)); return responseFuture.waitResponse(REQUEST_TIMEOUT_MS - (System.currentTimeMillis() - beginTimestamp)); &#125;); ResponseMessagePacket responsePacket = packetFuture.get( REQUEST_TIMEOUT_MS - (System.currentTimeMillis() - beginTimestamp), TimeUnit.MILLISECONDS); if (null == responsePacket) &#123; // 超时导致响应包获取失败 throw new SendRequestException(String.format(\"ResponseMessagePacket获取超时,请求ID:%s\", packet.getSerialNumber())); &#125; else &#123; ByteBuf payload = (ByteBuf) responsePacket.getPayload(); byte[] bytes = ByteBufferUtils.X.readBytes(payload); return SERIALIZER.decode(bytes, returnType); &#125; &#125; catch (Exception e) &#123; log.error(\"同步发送请求异常,请求包:&#123;&#125;\", JSON.toJSONString(packet), e); if (e instanceof RuntimeException) &#123; throw (RuntimeException) e; &#125; else &#123; throw new SendRequestException(e); &#125; &#125; &#125; static void scanResponseFutureTable() &#123; log.info(\"开始执行ResponseFutureTable清理任务......\"); Iterator&lt;Map.Entry&lt;String, ResponseFuture&gt;&gt; iterator = RESPONSE_FUTURE_TABLE.entrySet().iterator(); while (iterator.hasNext()) &#123; Map.Entry&lt;String, ResponseFuture&gt; entry = iterator.next(); ResponseFuture responseFuture = entry.getValue(); if (responseFuture.timeout()) &#123; iterator.remove(); log.warn(\"移除过期的请求ResponseFuture,请求ID:&#123;&#125;\", entry.getKey()); &#125; &#125; log.info(\"执行ResponseFutureTable清理任务结束......\"); &#125; static &#123; int n = Runtime.getRuntime().availableProcessors(); EXECUTOR = new ThreadPoolExecutor(n * 2, n * 2, 0, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(50), runnable -&gt; &#123; Thread thread = new Thread(runnable); thread.setDaemon(true); thread.setName(\"CLIENT_REQUEST_EXECUTOR\"); return thread; &#125;); CLIENT_HOUSE_KEEPER = new ScheduledThreadPoolExecutor(1, runnable -&gt; &#123; Thread thread = new Thread(runnable); thread.setDaemon(true); thread.setName(\"CLIENT_HOUSE_KEEPER\"); return thread; &#125;); CLIENT_HOUSE_KEEPER.scheduleWithFixedDelay(ContractProxyFactory::scanResponseFutureTable, 5, 5, TimeUnit.SECONDS); &#125;&#125; 接着添加一个客户端入站处理器，用于通过reuqestId匹配目标ResponseFuture实例，同时设置ResponseFuture实例中的response属性为响应包，同时释放闭锁： 1234567891011121314@Slf4jpublic class ClientHandler extends SimpleChannelInboundHandler&lt;ResponseMessagePacket&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, ResponseMessagePacket packet) throws Exception &#123; log.info(\"接收到响应包,内容:&#123;&#125;\", JSON.toJSONString(packet)); ResponseFuture responseFuture = ContractProxyFactory.RESPONSE_FUTURE_TABLE.get(packet.getSerialNumber()); if (null != responseFuture) &#123; responseFuture.putResponse(packet); &#125; else &#123; log.warn(\"接收响应包查询ResponseFuture不存在,请求ID:&#123;&#125;\", packet.getSerialNumber()); &#125; &#125;&#125; 最后，客户端启动类ClientApplication中添加ClientHandler到Netty的处理器流水线中即可： 123456789101112bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new LengthFieldBasedFrameDecoder(1024, 0, 4, 0, 4)); ch.pipeline().addLast(new LengthFieldPrepender(4)); ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)); ch.pipeline().addLast(new RequestMessagePacketEncoder(FastJsonSerializer.X)); ch.pipeline().addLast(new ResponseMessagePacketDecoder()); ch.pipeline().addLast(new ClientHandler()); &#125;&#125;); 先运行之前- 《基于Netty和SpringBoot实现一个轻量级RPC框架-Server篇》中编写好的ServerApplication，再启动ClientApplication，日志输出如下： 12345678910// 服务端2020-01-18 14:32:59 [nioEventLoopGroup-3-2] INFO club.throwable.server.ServerHandler - 服务端接收到:RequestMessagePacket(interfaceName=club.throwable.contract.HelloService, methodName=sayHello, methodArgumentSignatures=[java.lang.String], methodArguments=[PooledUnsafeDirectByteBuf(ridx: 0, widx: 11, cap: 11/144)])2020-01-18 14:32:59 [nioEventLoopGroup-3-2] INFO club.throwable.server.ServerHandler - 查找目标实现方法成功,目标类:club.throwable.server.contract.DefaultHelloService,宿主类:club.throwable.server.contract.DefaultHelloService,宿主方法:sayHello2020-01-18 14:32:59 [nioEventLoopGroup-3-2] INFO club.throwable.server.ServerHandler - 服务端输出:&#123;\"attachments\":&#123;&#125;,\"errorCode\":200,\"magicNumber\":10086,\"message\":\"Success\",\"messageType\":\"RESPONSE\",\"payload\":\"\\\"throwable say hello!\\\"\",\"serialNumber\":\"21d131d26fc74f91b4691e0207826b90\",\"version\":1&#125;// 客户端2020-01-18 14:32:59 [nioEventLoopGroup-2-1] INFO club.throwable.client.ClientHandler - 接收到响应包,内容:&#123;\"attachments\":&#123;&#125;,\"errorCode\":200,\"magicNumber\":10086,\"message\":\"Success\",\"messageType\":\"RESPONSE\",\"payload\":&#123;\"contiguous\":true,\"direct\":true,\"readOnly\":false,\"readable\":true,\"writable\":false&#125;,\"serialNumber\":\"21d131d26fc74f91b4691e0207826b90\",\"version\":1&#125;2020-01-18 14:32:59 [main] INFO c.throwable.client.ClientApplication - HelloService[throwable]调用结果:\"throwable say hello!\"2020-01-18 14:33:04 [CLIENT_HOUSE_KEEPER] INFO c.t.client.ContractProxyFactory - 开始执行ResponseFutureTable清理任务......2020-01-18 14:33:04 [CLIENT_HOUSE_KEEPER] WARN c.t.client.ContractProxyFactory - 移除过期的请求ResponseFuture,请求ID:21d131d26fc74f91b4691e0207826b90 可见异步线程模型已经被改造为同步化，现在可以通过契约接口通过RPC同步调用服务端。 小结 Client端的请求-响应同步化处理基本改造完毕，到此为止，一个RPC框架大致已经完成，接下来会对Client端和Server端进行一些改造，让契约相关组件托管到IOC容器，实现契约接口自动注入等等功能。 Demo项目地址： ch0-custom-rpc-protocol （本文完e-a-20200118 c-2-d）","categories":[{"name":"Netty","slug":"Netty","permalink":"http://throwable.club/blog/categories/Netty/"},{"name":"Java","slug":"Netty/Java","permalink":"http://throwable.club/blog/categories/Netty/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Netty","slug":"Netty","permalink":"http://throwable.club/blog/tags/Netty/"}]},{"title":"基于Netty和SpringBoot实现一个轻量级RPC框架-Client篇","slug":"netty-custom-rpc-framework-client","date":"2020-01-16T14:56:51.000Z","updated":"2020-01-16T14:57:36.225Z","comments":true,"path":"2020/01/16/netty-custom-rpc-framework-client/","link":"","permalink":"http://throwable.club/2020/01/16/netty-custom-rpc-framework-client/","excerpt":"前提 前置文章： 《基于Netty和SpringBoot实现一个轻量级RPC框架-协议篇》 《基于Netty和SpringBoot实现一个轻量级RPC框架-Server篇》 前一篇文章相对简略地介绍了RPC服务端的编写，而这篇博文最要介绍服务端（Client）的实现。RPC调用一般是面向契约编程的，而Client的核心功能就是：把契约接口方法的调用抽象为使用Netty向RPC服务端通过私有协议发送一个请求。这里最底层的实现依赖于动态代理，因此动态代理是动态实现接口的最简单方式（如果字节码研究得比较深入，可以通过字节码编程实现接口）。需要的依赖如下： JDK1.8+ Netty:4.1.44.Final SpringBoot:2.2.2.RELEASE","text":"前提 前置文章： 《基于Netty和SpringBoot实现一个轻量级RPC框架-协议篇》 《基于Netty和SpringBoot实现一个轻量级RPC框架-Server篇》 前一篇文章相对简略地介绍了RPC服务端的编写，而这篇博文最要介绍服务端（Client）的实现。RPC调用一般是面向契约编程的，而Client的核心功能就是：把契约接口方法的调用抽象为使用Netty向RPC服务端通过私有协议发送一个请求。这里最底层的实现依赖于动态代理，因此动态代理是动态实现接口的最简单方式（如果字节码研究得比较深入，可以通过字节码编程实现接口）。需要的依赖如下： JDK1.8+ Netty:4.1.44.Final SpringBoot:2.2.2.RELEASE 动态代理的简单使用 一般可以通过JDK动态代理或者Cglib的字节码增强来实现此功能，为了简单起见，不引入额外的依赖，这里选用JDK动态代理。这里重新搬出前面提到的契约接口HelloService： 1234public interface HelloService &#123; String sayHello(String name);&#125; 接下来需要通过动态代理为此接口添加一个实现： 12345678910111213141516171819202122232425public class TestDynamicProxy &#123; public static void main(String[] args) throws Exception &#123; Class&lt;HelloService&gt; interfaceKlass = HelloService.class; InvocationHandler handler = new HelloServiceImpl(interfaceKlass); HelloService helloService = (HelloService) Proxy.newProxyInstance(interfaceKlass.getClassLoader(), new Class[]&#123;interfaceKlass&#125;, handler); System.out.println(helloService.sayHello(\"throwable\")); &#125; @RequiredArgsConstructor private static class HelloServiceImpl implements InvocationHandler &#123; private final Class&lt;?&gt; interfaceKlass; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 这里应该根据方法的返回值类型去决定返回结果 return String.format(\"[%s#%s]方法被调用,参数列表:%s\", interfaceKlass.getName(), method.getName(), JSON.toJSONString(args)); &#125; &#125;&#125;// 控制台输出结果[club.throwable.contract.HelloService#sayHello]方法被调用,参数列表:[\"throwable\"] 这里可以确认两点： InvocationHandler实现后会对被代理接口生成一个动态实现类。 动态实现类（接口）方法被调用的时候，实际上是调用InvocationHandler对应实例的invoke()方法，传入的参数就是当前方法调用的元数据。 Client端代码实现 Client端需要通过动态代理为契约接口生成一个动态实现类，然后提取契约接口调用方法时候所能提供的元数据，通过这些元数据和Netty客户端的支持（例如Netty的Channel）基于私有RPC协议组装请求信息并且发送请求。这里先定义一个请求参数提取器接口RequestArgumentExtractor： 1234567891011121314151617181920212223@Datapublic class RequestArgumentExtractInput &#123; private Class&lt;?&gt; interfaceKlass; private Method method;&#125;@Datapublic class RequestArgumentExtractOutput &#123; private String interfaceName; private String methodName; private List&lt;String&gt; methodArgumentSignatures;&#125;// 接口public interface RequestArgumentExtractor &#123; RequestArgumentExtractOutput extract(RequestArgumentExtractInput input);&#125; 简单实现一下，解析结果添加到缓存中，实现类DefaultRequestArgumentExtractor代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class DefaultRequestArgumentExtractor implements RequestArgumentExtractor &#123; private final ConcurrentMap&lt;CacheKey, RequestArgumentExtractOutput&gt; cache = Maps.newConcurrentMap(); @Override public RequestArgumentExtractOutput extract(RequestArgumentExtractInput input) &#123; Class&lt;?&gt; interfaceKlass = input.getInterfaceKlass(); Method method = input.getMethod(); String methodName = method.getName(); Class&lt;?&gt;[] parameterTypes = method.getParameterTypes(); return cache.computeIfAbsent(new CacheKey(interfaceKlass.getName(), methodName, Lists.newArrayList(parameterTypes)), x -&gt; &#123; RequestArgumentExtractOutput output = new RequestArgumentExtractOutput(); output.setInterfaceName(interfaceKlass.getName()); List&lt;String&gt; methodArgumentSignatures = Lists.newArrayList(); for (Class&lt;?&gt; klass : parameterTypes) &#123; methodArgumentSignatures.add(klass.getName()); &#125; output.setMethodArgumentSignatures(methodArgumentSignatures); output.setMethodName(methodName); return output; &#125;); &#125; @RequiredArgsConstructor private static class CacheKey &#123; private final String interfaceName; private final String methodName; private final List&lt;Class&lt;?&gt;&gt; parameterTypes; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; CacheKey cacheKey = (CacheKey) o; return Objects.equals(interfaceName, cacheKey.interfaceName) &amp;&amp; Objects.equals(methodName, cacheKey.methodName) &amp;&amp; Objects.equals(parameterTypes, cacheKey.parameterTypes); &#125; @Override public int hashCode() &#123; return Objects.hash(interfaceName, methodName, parameterTypes); &#125; &#125;&#125; 在不考虑重连、断连等情况下，新增一个类ClientChannelHolder用于保存Netty客户端的Channel实例： 1234public class ClientChannelHolder &#123; public static final AtomicReference&lt;Channel&gt; CHANNEL_REFERENCE = new AtomicReference&lt;&gt;();&#125; 接着新增一个契约动态代理工厂（工具类）ContractProxyFactory，用于为契约接口生成代理类实例： 12345678910111213141516171819202122232425262728293031323334public class ContractProxyFactory &#123; private static final RequestArgumentExtractor EXTRACTOR = new DefaultRequestArgumentExtractor(); private static final ConcurrentMap&lt;Class&lt;?&gt;, Object&gt; CACHE = Maps.newConcurrentMap(); @SuppressWarnings(\"unchecked\") public static &lt;T&gt; T ofProxy(Class&lt;T&gt; interfaceKlass) &#123; // 缓存契约接口的代理类实例 return (T) CACHE.computeIfAbsent(interfaceKlass, x -&gt; Proxy.newProxyInstance(interfaceKlass.getClassLoader(), new Class[]&#123;interfaceKlass&#125;, (target, method, args) -&gt; &#123; RequestArgumentExtractInput input = new RequestArgumentExtractInput(); input.setInterfaceKlass(interfaceKlass); input.setMethod(method); RequestArgumentExtractOutput output = EXTRACTOR.extract(input); // 封装请求参数 RequestMessagePacket packet = new RequestMessagePacket(); packet.setMagicNumber(ProtocolConstant.MAGIC_NUMBER); packet.setVersion(ProtocolConstant.VERSION); packet.setSerialNumber(SerialNumberUtils.X.generateSerialNumber()); packet.setMessageType(MessageType.REQUEST); packet.setInterfaceName(output.getInterfaceName()); packet.setMethodName(output.getMethodName()); packet.setMethodArgumentSignatures(output.getMethodArgumentSignatures().toArray(new String[0])); packet.setMethodArguments(args); Channel channel = ClientChannelHolder.CHANNEL_REFERENCE.get(); // 发起请求 channel.writeAndFlush(packet); // 这里方法返回值需要进行同步处理,相对复杂,后面专门开一篇文章讲解,暂时统一返回字符串 // 如果契约接口的返回值类型不是字符串,这里方法返回后会抛出异常 return String.format(\"[%s#%s]调用成功,发送了[%s]到NettyServer[%s]\", output.getInterfaceName(), output.getMethodName(), JSON.toJSONString(packet), channel.remoteAddress()); &#125;)); &#125;&#125; 最后编写客户端ClientApplication的代码: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Slf4jpublic class ClientApplication &#123; public static void main(String[] args) throws Exception &#123; int port = 9092; EventLoopGroup workerGroup = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); try &#123; bootstrap.group(workerGroup); bootstrap.channel(NioSocketChannel.class); bootstrap.option(ChannelOption.SO_KEEPALIVE, Boolean.TRUE); bootstrap.option(ChannelOption.TCP_NODELAY, Boolean.TRUE); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new LengthFieldBasedFrameDecoder(1024, 0, 4, 0, 4)); ch.pipeline().addLast(new LengthFieldPrepender(4)); ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)); ch.pipeline().addLast(new RequestMessagePacketEncoder(FastJsonSerializer.X)); ch.pipeline().addLast(new ResponseMessagePacketDecoder()); ch.pipeline().addLast(new SimpleChannelInboundHandler&lt;ResponseMessagePacket&gt;() &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, ResponseMessagePacket packet) throws Exception &#123; Object targetPayload = packet.getPayload(); if (targetPayload instanceof ByteBuf) &#123; ByteBuf byteBuf = (ByteBuf) targetPayload; int readableByteLength = byteBuf.readableBytes(); byte[] bytes = new byte[readableByteLength]; byteBuf.readBytes(bytes); targetPayload = FastJsonSerializer.X.decode(bytes, String.class); byteBuf.release(); &#125; packet.setPayload(targetPayload); log.info(\"接收到来自服务端的响应消息,消息内容:&#123;&#125;\", JSON.toJSONString(packet)); &#125; &#125;); &#125; &#125;); ChannelFuture future = bootstrap.connect(\"localhost\", port).sync(); // 保存Channel实例,暂时不考虑断连重连 ClientChannelHolder.CHANNEL_REFERENCE.set(future.channel()); // 构造契约接口代理类实例 HelloService helloService = ContractProxyFactory.ofProxy(HelloService.class); String result = helloService.sayHello(\"throwable\"); log.info(result); future.channel().closeFuture().sync(); &#125; finally &#123; workerGroup.shutdownGracefully(); &#125; &#125;&#125; 先启动《基于Netty和SpringBoot实现一个轻量级RPC框架-Server篇》一文中的ServerApplication，再启动ClientApplication，控制台输出如下： 123456789// 服务端日志2020-01-16 22:34:51 [main] INFO c.throwable.server.ServerApplication - 启动NettyServer[9092]成功...2020-01-16 22:36:35 [nioEventLoopGroup-3-1] INFO club.throwable.server.ServerHandler - 服务端接收到:RequestMessagePacket(interfaceName=club.throwable.contract.HelloService, methodName=sayHello, methodArgumentSignatures=[java.lang.String], methodArguments=[PooledUnsafeDirectByteBuf(ridx: 0, widx: 11, cap: 11/144)])2020-01-16 22:36:35 [nioEventLoopGroup-3-1] INFO club.throwable.server.ServerHandler - 查找目标实现方法成功,目标类:club.throwable.server.contract.DefaultHelloService,宿主类:club.throwable.server.contract.DefaultHelloService,宿主方法:sayHello2020-01-16 22:36:35 [nioEventLoopGroup-3-1] INFO club.throwable.server.ServerHandler - 服务端输出:&#123;\"attachments\":&#123;&#125;,\"errorCode\":200,\"magicNumber\":10086,\"message\":\"Success\",\"messageType\":\"RESPONSE\",\"payload\":\"\\\"throwable say hello!\\\"\",\"serialNumber\":\"63d386214d30410c9e5f04de03d8b2da\",\"version\":1&#125;// 客户端日志2020-01-16 22:36:35 [main] INFO c.throwable.client.ClientApplication - [club.throwable.contract.HelloService#sayHello]调用成功,发送了[&#123;\"attachments\":&#123;&#125;,\"interfaceName\":\"club.throwable.contract.HelloService\",\"magicNumber\":10086,\"messageType\":\"REQUEST\",\"methodArgumentSignatures\":[\"java.lang.String\"],\"methodArguments\":[\"throwable\"],\"methodName\":\"sayHello\",\"serialNumber\":\"63d386214d30410c9e5f04de03d8b2da\",\"version\":1&#125;]到NettyServer[localhost/127.0.0.1:9092]2020-01-16 22:36:35 [nioEventLoopGroup-2-1] INFO c.throwable.client.ClientApplication - 接收到来自服务端的响应消息,消息内容:&#123;\"attachments\":&#123;&#125;,\"errorCode\":200,\"magicNumber\":10086,\"message\":\"Success\",\"messageType\":\"RESPONSE\",\"payload\":\"\\\"throwable say hello!\\\"\",\"serialNumber\":\"63d386214d30410c9e5f04de03d8b2da\",\"version\":1&#125; 小结 Client端主要负责契约接口调用转换为发送RPC协议请求这一步，核心技术就是动态代理，在不进行模块封装优化的前提下实现是相对简单的。这里其实Client端还有一个比较大的技术难题没有解决，上面例子中客户端日志输出如果眼尖的伙伴会发现，Client端发送RPC请求的线程（main线程）和Client端接收Server端RPC响应处理的线程（nioEventLoopGroup-2-1线程）并不相同，这一点是Netty处理网络请求之所以能够如此高效的根源（简单来说就是请求和响应是异步的，两个流程本来是互不感知的）。但是更多情况下，我们希望外部请求是同步的，希望发送RPC请求的线程得到响应结果再返回（这里请求和响应有可能依然是异步流程）。下一篇文章会详细分析一下如果对请求-响应做同步化处理。 Demo项目地址： ch0-custom-rpc-protocol （c-2-d e-a-20200116）","categories":[{"name":"Netty","slug":"Netty","permalink":"http://throwable.club/blog/categories/Netty/"},{"name":"Java","slug":"Netty/Java","permalink":"http://throwable.club/blog/categories/Netty/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Netty","slug":"Netty","permalink":"http://throwable.club/blog/tags/Netty/"}]},{"title":"基于Netty和SpringBoot实现一个轻量级RPC框架-Server篇","slug":"netty-custom-rpc-framework-server","date":"2020-01-14T16:13:38.000Z","updated":"2020-01-15T13:27:37.832Z","comments":true,"path":"2020/01/15/netty-custom-rpc-framework-server/","link":"","permalink":"http://throwable.club/2020/01/15/netty-custom-rpc-framework-server/","excerpt":"前提 前置文章： Github Page：《基于Netty和SpringBoot实现一个轻量级RPC框架-协议篇》 Coding Page：《基于Netty和SpringBoot实现一个轻量级RPC框架-协议篇》 在前置的《基于Netty和SpringBoot实现一个轻量级RPC框架-协议篇》一文中已经定义了一个相对简单的RPC私有协议，并且实现了对应的编码和解码模块。这篇文章基于协议篇，完成Server端代码调用的编写。考虑到目前相对主流的IOC容器是Spring，这里选用了spring-boot-starter（非MVC容器，只是单纯管理Bean），依赖JDK1.8+。","text":"前提 前置文章： Github Page：《基于Netty和SpringBoot实现一个轻量级RPC框架-协议篇》 Coding Page：《基于Netty和SpringBoot实现一个轻量级RPC框架-协议篇》 在前置的《基于Netty和SpringBoot实现一个轻量级RPC框架-协议篇》一文中已经定义了一个相对简单的RPC私有协议，并且实现了对应的编码和解码模块。这篇文章基于协议篇，完成Server端代码调用的编写。考虑到目前相对主流的IOC容器是Spring，这里选用了spring-boot-starter（非MVC容器，只是单纯管理Bean），依赖JDK1.8+。 思路 首先RPC私有协议定义了Client端会传过来四个和服务调用息息相关的字段：接口全类名interfaceName、方法名methodName、方法参数签名字符串数组methodArgumentSignatures（可选，这个参数不是必须传入的）以及方法参数数组methodArguments（可选，空方法列表的时候不需要传入参数）。主要流程如下： 把Server端的所有服务端（实现）类交由IOC容器托管。 Client端发起RPC请求。 通过前面提到的最多四个参数，从Server服务实例的IOC容器中匹配出吻合度最高的一个方法java.lang.reflect.Method实例、该方法实例的宿主类以及宿主类对应的Bean实例，如果这一步匹配的目标方法超过1个或者为0个，可以直接返回异常信息。 把前一步得到的Method实例、宿主类Bean实例，结合方法参数数组methodArguments进行反射调用，得到调用结果。 Server端把响应结果封装到payload通过私有协议发送回Client端。 Server端代码实现 为了暂时方便起见，部分数组入参被重新封装为ArrayList，实际上编写RPC框架的时候应该优先考虑性能问题，像JDK提供的集合类库等等应该尽可能少用（以ArrayList为例，扩容的时候存在底层Object[]拷贝，造成性能损失和额外的内存消耗），极尽可能使用基本类型和数组。 先定义方法匹配器MethodMatcher相关的类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public interface MethodMatcher &#123; /** * 查找一个匹配度最高的方法信息 * * @param input input * @return output */ MethodMatchOutput selectOneBestMatchMethod(MethodMatchInput input);&#125;// 输入值@EqualsAndHashCode@Datapublic class MethodMatchInput &#123; private String interfaceName; private String methodName; private List&lt;String&gt; methodArgumentSignatures; private int methodArgumentArraySize;&#125;// 输出值@Datapublic class MethodMatchOutput &#123; /** * 目标方法实例 */ private Method targetMethod; /** * 目标实现类 - 这个有可能是被Cglib增强过的类型,是宿主类的子类,如果没有被Cglib增强过,那么它就是宿主类 */ private Class&lt;?&gt; targetClass; /** * 宿主类 */ private Class&lt;?&gt; targetUserClass; /** * 宿主类Bean实例 */ private Object target; /** * 方法参数类型列表 */ private List&lt;Class&lt;?&gt;&gt; parameterTypes;&#125; 目标方法匹配的逻辑大致如下： 方法名称和方法实例的宿主类型一定作为匹配条件的一部分。 如果传入了参数签名列表，优先使用参数签名列表类型进行匹配。 如果没有传入参数签名列表，那么使用参数的数量进行匹配。 如果参数签名列表和参数列表都没有传入，那么只能通过方法名称和方法实例的宿主类型匹配。 考虑到方法匹配解析的过程相对耗时，需要把结果缓存起来。 分析至此，可以基于反射，编写一个抽象的方法匹配器BaseMethodMatcher，然后把获取宿主类信息的功能委托到子类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public class MethodMatchException extends RuntimeException &#123; public MethodMatchException(String message) &#123; super(message); &#125; public MethodMatchException(String message, Throwable cause) &#123; super(message, cause); &#125; public MethodMatchException(Throwable cause) &#123; super(cause); &#125;&#125;@Datapublic class HostClassMethodInfo &#123; private Class&lt;?&gt; hostClass; private Class&lt;?&gt; hostUserClass; private Object hostTarget;&#125;@Slf4jabstract class BaseMethodMatcher implements MethodMatcher &#123; private final ConcurrentMap&lt;MethodMatchInput, MethodMatchOutput&gt; cache = Maps.newConcurrentMap(); @Override public MethodMatchOutput selectOneBestMatchMethod(MethodMatchInput input) &#123; return cache.computeIfAbsent(input, in -&gt; &#123; try &#123; MethodMatchOutput output = new MethodMatchOutput(); Class&lt;?&gt; interfaceClass = Class.forName(in.getInterfaceName()); // 获取宿主类信息 HostClassMethodInfo info = findHostClassMethodInfo(interfaceClass); List&lt;Method&gt; targetMethods = Lists.newArrayList(); ReflectionUtils.doWithMethods(info.getHostUserClass(), targetMethods::add, method -&gt; &#123; String methodName = method.getName(); Class&lt;?&gt; declaringClass = method.getDeclaringClass(); List&lt;Class&lt;?&gt;&gt; inputParameterTypes = Optional.ofNullable(in.getMethodArgumentSignatures()) .map(mas -&gt; &#123; List&lt;Class&lt;?&gt;&gt; list = Lists.newArrayList(); mas.forEach(ma -&gt; list.add(ClassUtils.resolveClassName(ma, null))); return list; &#125;).orElse(Lists.newArrayList()); output.setParameterTypes(inputParameterTypes); // 如果传入了参数签名列表，优先使用参数签名列表类型进行匹配 if (!inputParameterTypes.isEmpty()) &#123; List&lt;Class&lt;?&gt;&gt; parameterTypes = Lists.newArrayList(method.getParameterTypes()); return Objects.equals(methodName, in.getMethodName()) &amp;&amp; Objects.equals(info.getHostUserClass(), declaringClass) &amp;&amp; Objects.equals(parameterTypes, inputParameterTypes); &#125; // 如果没有传入参数签名列表，那么使用参数的数量进行匹配 if (in.getMethodArgumentArraySize() &gt; 0) &#123; List&lt;Class&lt;?&gt;&gt; parameterTypes = Lists.newArrayList(method.getParameterTypes()); return Objects.equals(methodName, in.getMethodName()) &amp;&amp; Objects.equals(info.getHostUserClass(), declaringClass) &amp;&amp; in.getMethodArgumentArraySize() == parameterTypes.size(); &#125; // 如果参数签名列表和参数列表都没有传入，那么只能通过方法名称和方法实例的宿主类型匹配 return Objects.equals(methodName, in.getMethodName()) &amp;&amp; Objects.equals(info.getHostUserClass(), declaringClass); &#125;); if (targetMethods.size() != 1) &#123; throw new MethodMatchException(String.format(\"查找到目标方法数量不等于1,interface:%s,method:%s\", in.getInterfaceName(), in.getMethodName())); &#125; Method targetMethod = targetMethods.get(0); output.setTargetClass(info.getHostClass()); output.setTargetMethod(targetMethod); output.setTargetUserClass(info.getHostUserClass()); output.setTarget(info.getHostTarget()); return output; &#125; catch (Exception e) &#123; log.error(\"查找匹配度最高的方法失败,输入参数:&#123;&#125;\", JSON.toJSONString(in), e); if (e instanceof MethodMatchException) &#123; throw (MethodMatchException) e; &#125; else &#123; throw new MethodMatchException(e); &#125; &#125; &#125;); &#125; /** * 获取宿主类的信息 * * @param interfaceClass interfaceClass * @return HostClassMethodInfo */ abstract HostClassMethodInfo findHostClassMethodInfo(Class&lt;?&gt; interfaceClass);&#125; 接着，通过接口类型获取宿主类的功能就委托给Spring实现，从IOC容器中获取，定义SpringMethodMatcher： 123456789101112131415161718192021@Componentpublic class SpringMethodMatcher extends BaseMethodMatcher implements BeanFactoryAware &#123; private DefaultListableBeanFactory beanFactory; @Override public void setBeanFactory(@NonNull BeanFactory beanFactory) throws BeansException &#123; this.beanFactory = (DefaultListableBeanFactory) beanFactory; &#125; @Override HostClassMethodInfo findHostClassMethodInfo(Class&lt;?&gt; interfaceClass) &#123; HostClassMethodInfo info = new HostClassMethodInfo(); // 从容器中通过接口类型获取对应的实现,实现必须只有一个 Object bean = beanFactory.getBean(interfaceClass); info.setHostTarget(bean); info.setHostClass(bean.getClass()); info.setHostUserClass(ClassUtils.getUserClass(bean.getClass())); return info; &#125;&#125; 至此，目标方法匹配的模块已经编写完毕，接下来需要处理方法参数列表的反序列化。编写协议的时候，笔者把方法参数列表methodArguments存放在Object数组中，传输的时候序列化为byte数组，经过协议解析之后，方法参数列表的实际类型为ByteBuf数组（这是因为Netty中的字节容器就是ByteBuf），那么需要考虑把ByteBuf数组转换为目标方法的参数类型实例。主要步骤如下： 如果方法参数列表为空，那么什么都不用做，也就是调用了无参数的方法。 如果方法参数列表不为空同时方法参数类型列表不为空，优先选用方法参数类型列表进行转换。 如果方法参数列表不为空同时方法参数类型列表为空，则使用Method#getParameterTypes()得到的方法参数列表类型进行转换。 定义一个方法参数转换器接口MethodArgumentConverter： 123456789101112131415161718192021222324252627282930public interface MethodArgumentConverter &#123; ArgumentConvertOutput convert(ArgumentConvertInput input);&#125;@Datapublic class ArgumentConvertInput &#123; /** * 目标方法 */ private Method method; /** * 方法参数类型列表 */ private List&lt;Class&lt;?&gt;&gt; parameterTypes; /** * 方法参数列表 */ private List&lt;Object&gt; arguments;&#125;@Datapublic class ArgumentConvertOutput &#123; private Object[] arguments;&#125; 方法参数转换器的默认实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Slf4j@Componentpublic class DefaultMethodArgumentConverter implements MethodArgumentConverter &#123; private final Serializer serializer = FastJsonSerializer.X; @Override public ArgumentConvertOutput convert(ArgumentConvertInput input) &#123; ArgumentConvertOutput output = new ArgumentConvertOutput(); try &#123; if (null == input.getArguments() || input.getArguments().isEmpty()) &#123; output.setArguments(new Object[0]); return output; &#125; List&lt;Class&lt;?&gt;&gt; inputParameterTypes = input.getParameterTypes(); int size = inputParameterTypes.size(); if (size &gt; 0) &#123; Object[] arguments = new Object[size]; for (int i = 0; i &lt; size; i++) &#123; ByteBuf byteBuf = (ByteBuf) input.getArguments().get(i); int readableBytes = byteBuf.readableBytes(); byte[] bytes = new byte[readableBytes]; byteBuf.readBytes(bytes); arguments[i] = serializer.decode(bytes, inputParameterTypes.get(i)); byteBuf.release(); &#125; output.setArguments(arguments); return output; &#125; Class&lt;?&gt;[] parameterTypes = input.getMethod().getParameterTypes(); int len = parameterTypes.length; Object[] arguments = new Object[len]; for (int i = 0; i &lt; len; i++) &#123; ByteBuf byteBuf = (ByteBuf) input.getArguments().get(i); int readableBytes = byteBuf.readableBytes(); byte[] bytes = new byte[readableBytes]; byteBuf.readBytes(bytes); arguments[i] = serializer.decode(bytes, parameterTypes[i]); byteBuf.release(); &#125; output.setArguments(arguments); return output; &#125; catch (Exception e) &#123; throw new ArgumentConvertException(e); &#125; &#125;&#125; 所有前置工作都完成了，现在编写一个Server端的入站处理器ServerHandler，暂时不做代码逻辑优化，只做实现，把反射调用的模块直接在此类中编写： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Component@Slf4jpublic class ServerHandler extends SimpleChannelInboundHandler&lt;RequestMessagePacket&gt; &#123; @Autowired private MethodMatcher methodMatcher; @Autowired private MethodArgumentConverter methodArgumentConverter; @Override protected void channelRead0(ChannelHandlerContext ctx, RequestMessagePacket packet) throws Exception &#123; log.info(\"服务端接收到:&#123;&#125;\", packet); MethodMatchInput input = new MethodMatchInput(); input.setInterfaceName(packet.getInterfaceName()); input.setMethodArgumentSignatures(Optional.ofNullable(packet.getMethodArgumentSignatures()) .map(Lists::newArrayList).orElse(Lists.newArrayList())); input.setMethodName(packet.getMethodName()); Object[] methodArguments = packet.getMethodArguments(); input.setMethodArgumentArraySize(null != methodArguments ? methodArguments.length : 0); MethodMatchOutput output = methodMatcher.selectOneBestMatchMethod(input); log.info(\"查找目标实现方法成功,目标类:&#123;&#125;,宿主类:&#123;&#125;,宿主方法:&#123;&#125;\", output.getTargetClass().getCanonicalName(), output.getTargetUserClass().getCanonicalName(), output.getTargetMethod().getName() ); Method targetMethod = output.getTargetMethod(); ArgumentConvertInput convertInput = new ArgumentConvertInput(); convertInput.setArguments(input.getMethodArgumentArraySize() &gt; 0 ? Lists.newArrayList(methodArguments) : Lists.newArrayList()); convertInput.setMethod(output.getTargetMethod()); convertInput.setParameterTypes(output.getParameterTypes()); ArgumentConvertOutput convertOutput = methodArgumentConverter.convert(convertInput); ReflectionUtils.makeAccessible(targetMethod); // 反射调用 Object result = targetMethod.invoke(output.getTarget(), convertOutput.getArguments()); ResponseMessagePacket response = new ResponseMessagePacket(); response.setMagicNumber(packet.getMagicNumber()); response.setVersion(packet.getVersion()); response.setSerialNumber(packet.getSerialNumber()); response.setAttachments(packet.getAttachments()); response.setMessageType(MessageType.RESPONSE); response.setErrorCode(200L); response.setMessage(\"Success\"); response.setPayload(JSON.toJSONString(result)); log.info(\"服务端输出:&#123;&#125;\", JSON.toJSONString(response)); ctx.writeAndFlush(response); &#125;&#125; 编写一个Server的启动类ServerApplication，在Spring容器启动之后，启动Netty服务： 12345678910111213141516171819202122232425262728293031323334353637383940414243@SpringBootApplication(scanBasePackages = \"club.throwable.server\")@Slf4jpublic class ServerApplication implements CommandLineRunner &#123; @Value(\"$&#123;netty.port:9092&#125;\") private Integer nettyPort; @Autowired private ServerHandler serverHandler; public static void main(String[] args) throws Exception &#123; SpringApplication.run(ServerApplication.class, args); &#125; @Override public void run(String... args) throws Exception &#123; int port = nettyPort; ServerBootstrap bootstrap = new ServerBootstrap(); EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new LengthFieldBasedFrameDecoder(1024, 0, 4, 0, 4)); ch.pipeline().addLast(new LengthFieldPrepender(4)); ch.pipeline().addLast(new RequestMessagePacketDecoder()); ch.pipeline().addLast(new ResponseMessagePacketEncoder(FastJsonSerializer.X)); ch.pipeline().addLast(serverHandler); &#125; &#125;); ChannelFuture future = bootstrap.bind(port).sync(); log.info(\"启动NettyServer[&#123;&#125;]成功...\", port); future.channel().closeFuture().sync(); &#125; finally &#123; workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125;&#125; 最后，编写契约包和契约实现： 12345678910- ch0-custom-rpc-protocol 项目根目录 - club.throwable - utils 工具类 - protocol 协议 - exception 异常 - contract 契约 - HelloService 契约接口 - server 服务端 - contract - DefaultHelloService 契约接口实现 1234567891011121314public interface HelloService &#123; String sayHello(String name);&#125;// 实现@Servicepublic class DefaultHelloService implements HelloService &#123; @Override public String sayHello(String name) &#123; return String.format(\"%s say hello!\", name); &#125;&#125; 先启动服务端ServerApplication，再启动上一节提到的TestProtocolClient，输出结果： 12345678910// 服务端日志2020-01-15 00:05:57.898 INFO 14420 --- [ main] club.throwable.server.ServerApplication : 启动NettyServer[9092]成功...2020-01-15 00:06:05.980 INFO 14420 --- [ntLoopGroup-3-1] club.throwable.server.ServerHandler : 服务端接收到:RequestMessagePacket(interfaceName=club.throwable.contract.HelloService, methodName=sayHello, methodArgumentSignatures=[java.lang.String], methodArguments=[PooledUnsafeDirectByteBuf(ridx: 0, widx: 6, cap: 6/139)])2020-01-15 00:06:07.448 INFO 14420 --- [ntLoopGroup-3-1] club.throwable.server.ServerHandler : 查找目标实现方法成功,目标类:club.throwable.server.contract.DefaultHelloService,宿主类:club.throwable.server.contract.DefaultHelloService,宿主方法:sayHello2020-01-15 00:06:07.521 INFO 14420 --- [ntLoopGroup-3-1] club.throwable.server.ServerHandler : 服务端输出:&#123;\"attachments\":&#123;&#125;,\"errorCode\":200,\"magicNumber\":10086,\"message\":\"Success\",\"messageType\":\"RESPONSE\",\"payload\":\"\\\"doge say hello!\\\"\",\"serialNumber\":\"65f01b8e89bb479b8a36a60bd6519617\",\"version\":1&#125;// 客户端日志00:06:05.891 [main] INFO club.throwable.protocol.TestProtocolClient - 启动NettyClient[9092]成功......省略...00:06:13.197 [nioEventLoopGroup-2-1] INFO club.throwable.protocol.TestProtocolClient - 接收到来自服务端的响应消息,消息内容:&#123;\"attachments\":&#123;&#125;,\"errorCode\":200,\"magicNumber\":10086,\"message\":\"Success\",\"messageType\":\"RESPONSE\",\"payload\":\"\\\"doge say hello!\\\"\",\"serialNumber\":\"65f01b8e89bb479b8a36a60bd6519617\",\"version\":1&#125; 可见RPC调用成功。 小结 编写RPC的Server端技巧在于处理目标方法和宿主类的查找，在转换方法参数的时候，需要考虑简化处理和提高效率，剩下的就是做好异常处理和模块封装。限于篇幅，后面会先分析Client端的处理，再分析心跳处理、服务端优化、甚至是对接注册中心等等，在Netty、SpringBoot等优秀框架的加持下编写一个RPC框架其实并不困难，困难的是性能优化和生态圈的支持。 Demo项目地址： ch0-custom-rpc-protocol （本文完 c-1-d e-a-20200115）","categories":[{"name":"Netty","slug":"Netty","permalink":"http://throwable.club/blog/categories/Netty/"},{"name":"Java","slug":"Netty/Java","permalink":"http://throwable.club/blog/categories/Netty/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Netty","slug":"Netty","permalink":"http://throwable.club/blog/tags/Netty/"}]},{"title":"基于Netty和SpringBoot实现一个轻量级RPC框架-协议篇","slug":"netty-custom-rpc-framework-protocol","date":"2020-01-12T14:47:21.000Z","updated":"2020-01-15T13:25:44.253Z","comments":true,"path":"2020/01/12/netty-custom-rpc-framework-protocol/","link":"","permalink":"http://throwable.club/2020/01/12/netty-custom-rpc-framework-protocol/","excerpt":"前提 最近对网络编程方面比较有兴趣，在微服务实践上也用到了相对主流的RPC框架如Spring Cloud Gateway底层也切换为Reactor-Netty，像Redisson底层也是使用Netty封装通讯协议，最近调研和准备使用的SOFARpc也是基于Netty封装实现了多种协议的兼容。因此，基于Netty造一个轮子，在SpringBoot的加持下，实现一个轻量级的RPC框架。这篇博文介绍的是RPC框架协议的定义以及对应的编码解码处理的实现。","text":"前提 最近对网络编程方面比较有兴趣，在微服务实践上也用到了相对主流的RPC框架如Spring Cloud Gateway底层也切换为Reactor-Netty，像Redisson底层也是使用Netty封装通讯协议，最近调研和准备使用的SOFARpc也是基于Netty封装实现了多种协议的兼容。因此，基于Netty造一个轮子，在SpringBoot的加持下，实现一个轻量级的RPC框架。这篇博文介绍的是RPC框架协议的定义以及对应的编码解码处理的实现。 依赖引入 截止本文（2020-01-12）编写完成之时，Netty的最新版本为4.1.44.Final，而SpringBoot的最新版本为2.2.2.RELEASE，因此引入这两个版本的依赖，加上其他工具包和序列化等等的支持，pom文件的核心内容如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.boot.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;$&#123;netty.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.10&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.61&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;28.1-jre&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 部分参数的序列化会依赖到FastJson或者Jackson，具体看偏好而定。 自定义协议的定义 为了提高协议传输的效率，需要定制一套高效的RPC协议，设计协议所需的字段和类型。 基础Packet字段： 字段名 字段类型 字节数(byte) 字段功能 备注 magicNumber int 2 魔数，类似于Java的字节码文件的魔数是0xcafebase version int 2 版本号 预留字段，默认为1 serialNumber java.lang.String 4 请求流水号 十分重要，每个请求的唯一标识 messageType MessageType 1 消息类型 自定义的枚举类型，见下面的MessageType类 attachments Map&lt;String, String&gt; 视实际情况而定 附件 K-V形式，类似于HTTP协议中的Header 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// 消息枚举类型@RequiredArgsConstructorpublic enum MessageType &#123; /** * 请求 */ REQUEST((byte) 1), /** * 响应 */ RESPONSE((byte) 2), /** * PING */ PING((byte) 3), /** * PONG */ PONG((byte) 4), /** * NULL */ NULL((byte) 5), ; @Getter private final Byte type; public static MessageType fromValue(byte value) &#123; for (MessageType type : MessageType.values()) &#123; if (type.getType() == value) &#123; return type; &#125; &#125; throw new IllegalArgumentException(String.format(\"value = %s\", value)); &#125;&#125;// 基础Packet@Datapublic abstract class BaseMessagePacket implements Serializable &#123; /** * 魔数 */ private int magicNumber; /** * 版本号 */ private int version; /** * 流水号 */ private String serialNumber; /** * 消息类型 */ private MessageType messageType; /** * 附件 - K-V形式 */ private Map&lt;String, String&gt; attachments = new HashMap&lt;&gt;(); /** * 添加附件 */ public void addAttachment(String key, String value) &#123; attachments.put(key, value); &#125;&#125; 请求Packet扩展字段： 字段名 字段类型 字节数(byte) 字段功能 备注 interfaceName java.lang.String 视实际情况而定 接口全类名 methodName java.lang.String 视实际情况而定 方法名 methodArgumentSignatures java.lang.String[] 视实际情况而定 方法参数签名字符串数组 存放方法参数类型全类名字符串数组 methodArguments java.lang.Object[] 视实际情况而定 方法参数数组 因为未知方法参数类型，所以用Object表示 123456789101112131415161718192021222324@EqualsAndHashCode(callSuper = true)@Datapublic class RequestMessagePacket extends BaseMessagePacket &#123; /** * 接口全类名 */ private String interfaceName; /** * 方法名 */ private String methodName; /** * 方法参数签名 */ private String[] methodArgumentSignatures; /** * 方法参数 */ private Object[] methodArguments;&#125; 响应Packet扩展字段： 字段名 字段类型 字节数(byte) 字段功能 备注 errorCode java.lang.Long 4 响应码 message java.lang.String 视实际情况而定 响应消息 如果出现异常，message就是对应的异常信息 payload java.lang.Object 视实际情况而定 消息载荷 业务处理返回的消息载荷，定义为Object类型 12345678910111213141516171819@EqualsAndHashCode(callSuper = true)@Datapublic class ResponseMessagePacket extends BaseMessagePacket &#123; /** * error code */ private Long errorCode; /** * 消息描述 */ private String message; /** * 消息载荷 */ private Object payload;&#125; 需要注意以下几点： 非基本类型在序列化和反序列化的时候，一定注意要先写入或者先读取序列的长度，以java.lang.String类型为例： 1234567// 序列化 - 流水号out.writeInt(packet.getSerialNumber().length());out.writeCharSequence(packet.getSerialNumber(), ProtocolConstant.UTF_8);// 反序列化 - 流水号int serialNumberLength = in.readInt();packet.setSerialNumber(in.readCharSequence(serialNumberLength, ProtocolConstant.UTF_8).toString()); 特殊编码的字符串在序列化的时候，要注意字符串编码的长度，例如UTF-8编码下一个中文字符占3个字节，这一点可以抽取一个工具类专门处理字符串的序列化： 123456789101112public enum ByteBufferUtils &#123; // 单例 X; public void encodeUtf8CharSequence(ByteBuf byteBuf, CharSequence charSequence) &#123; int writerIndex = byteBuf.writerIndex(); byteBuf.writeInt(0); int length = ByteBufUtil.writeUtf8(byteBuf, charSequence); byteBuf.setInt(writerIndex, length); &#125;&#125; 方法参数数组的序列化和反序列化方案需要定制，笔者为了简化自定义协议，定义了方法参数签名数组，长度和方法参数数组一致，这样做方便后面编写服务端代码的时候，简化对方法参数数组进行反序列化以及宿主类目标方法的查找。注意一下Object[]的序列化和反序列化相对特殊，因为ByteBuf无法处理自定义类型的写入和读取（这个很好理解，网络编程就是面向0和1的编程）： 123write Object --&gt; ByteBuf#writeInt() &amp;&amp; ByteBuf#writeBytes()read Object --&gt; ByteBuf#readInt() &amp;&amp; ByteBuf#readBytes() [&lt;== 这个方法返回值是ByteBuf实例] 最后注意释放ByteBuf的引用，否则有可能导致内存泄漏。 自定义协议编码解码实现 自定义协议编码解码主要包括四个部分的编码解码器： 请求Packet编码器：RequestMessagePacketEncoder，主要用于客户端把RequestMessagePacket实例序列化为二进制序列。 请求Packet解码器：RequestMessagePacketDecoder，主要用于服务端把二进制序列反序列化为RequestMessagePacket实例。 响应Packet编码器：ResponseMessagePacketEncoder，主要用于服务端把ResponseMessagePacket实例序列化为二进制序列。 响应Packet解码器：ResponseMessagePacketDecoder，主要用于客户端把二进制序列反序列化为ResponseMessagePacket实例。 画个图描述一下几个组件的交互流程（省略了部分入站和出站处理器）： 序列化器Serializer的代码如下： 1234567891011121314151617181920212223public interface Serializer &#123; byte[] encode(Object target); Object decode(byte[] bytes, Class&lt;?&gt; targetClass);&#125;// FastJson实现public enum FastJsonSerializer implements Serializer &#123; // 单例 X; @Override public byte[] encode(Object target) &#123; return JSON.toJSONBytes(target); &#125; @Override public Object decode(byte[] bytes, Class&lt;?&gt; targetClass) &#123; return JSON.parseObject(bytes, targetClass); &#125;&#125; 请求Packet编码器RequestMessagePacketEncoder的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@RequiredArgsConstructorpublic class RequestMessagePacketEncoder extends MessageToByteEncoder&lt;RequestMessagePacket&gt; &#123; private final Serializer serializer; @Override protected void encode(ChannelHandlerContext context, RequestMessagePacket packet, ByteBuf out) throws Exception &#123; // 魔数 out.writeInt(packet.getMagicNumber()); // 版本 out.writeInt(packet.getVersion()); // 流水号 out.writeInt(packet.getSerialNumber().length()); out.writeCharSequence(packet.getSerialNumber(), ProtocolConstant.UTF_8); // 消息类型 out.writeByte(packet.getMessageType().getType()); // 附件size Map&lt;String, String&gt; attachments = packet.getAttachments(); out.writeInt(attachments.size()); // 附件内容 attachments.forEach((k, v) -&gt; &#123; out.writeInt(k.length()); out.writeCharSequence(k, ProtocolConstant.UTF_8); out.writeInt(v.length()); out.writeCharSequence(v, ProtocolConstant.UTF_8); &#125;); // 接口全类名 out.writeInt(packet.getInterfaceName().length()); out.writeCharSequence(packet.getInterfaceName(), ProtocolConstant.UTF_8); // 方法名 out.writeInt(packet.getMethodName().length()); out.writeCharSequence(packet.getMethodName(), ProtocolConstant.UTF_8); // 方法参数签名(String[]类型) - 非必须 if (null != packet.getMethodArgumentSignatures()) &#123; int len = packet.getMethodArgumentSignatures().length; // 方法参数签名数组长度 out.writeInt(len); for (int i = 0; i &lt; len; i++) &#123; String methodArgumentSignature = packet.getMethodArgumentSignatures()[i]; out.writeInt(methodArgumentSignature.length()); out.writeCharSequence(methodArgumentSignature, ProtocolConstant.UTF_8); &#125; &#125; else &#123; out.writeInt(0); &#125; // 方法参数(Object[]类型) - 非必须 if (null != packet.getMethodArguments()) &#123; int len = packet.getMethodArguments().length; // 方法参数数组长度 out.writeInt(len); for (int i = 0; i &lt; len; i++) &#123; byte[] bytes = serializer.encode(packet.getMethodArguments()[i]); out.writeInt(bytes.length); out.writeBytes(bytes); &#125; &#125; else &#123; out.writeInt(0); &#125; &#125;&#125; 请求Packet解码器RequestMessagePacketDecoder的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@RequiredArgsConstructorpublic class RequestMessagePacketDecoder extends ByteToMessageDecoder &#123; @Override protected void decode(ChannelHandlerContext context, ByteBuf in, List&lt;Object&gt; list) throws Exception &#123; RequestMessagePacket packet = new RequestMessagePacket(); // 魔数 packet.setMagicNumber(in.readInt()); // 版本 packet.setVersion(in.readInt()); // 流水号 int serialNumberLength = in.readInt(); packet.setSerialNumber(in.readCharSequence(serialNumberLength, ProtocolConstant.UTF_8).toString()); // 消息类型 byte messageTypeByte = in.readByte(); packet.setMessageType(MessageType.fromValue(messageTypeByte)); // 附件 Map&lt;String, String&gt; attachments = Maps.newHashMap(); packet.setAttachments(attachments); int attachmentSize = in.readInt(); if (attachmentSize &gt; 0) &#123; for (int i = 0; i &lt; attachmentSize; i++) &#123; int keyLength = in.readInt(); String key = in.readCharSequence(keyLength, ProtocolConstant.UTF_8).toString(); int valueLength = in.readInt(); String value = in.readCharSequence(valueLength, ProtocolConstant.UTF_8).toString(); attachments.put(key, value); &#125; &#125; // 接口全类名 int interfaceNameLength = in.readInt(); packet.setInterfaceName(in.readCharSequence(interfaceNameLength, ProtocolConstant.UTF_8).toString()); // 方法名 int methodNameLength = in.readInt(); packet.setMethodName(in.readCharSequence(methodNameLength, ProtocolConstant.UTF_8).toString()); // 方法参数签名 int methodArgumentSignatureArrayLength = in.readInt(); if (methodArgumentSignatureArrayLength &gt; 0) &#123; String[] methodArgumentSignatures = new String[methodArgumentSignatureArrayLength]; for (int i = 0; i &lt; methodArgumentSignatureArrayLength; i++) &#123; int methodArgumentSignatureLength = in.readInt(); methodArgumentSignatures[i] = in.readCharSequence(methodArgumentSignatureLength, ProtocolConstant.UTF_8).toString(); &#125; packet.setMethodArgumentSignatures(methodArgumentSignatures); &#125; // 方法参数 int methodArgumentArrayLength = in.readInt(); if (methodArgumentArrayLength &gt; 0) &#123; // 这里的Object[]实际上是ByteBuf[] - 后面需要二次加工为对应类型的实例 Object[] methodArguments = new Object[methodArgumentArrayLength]; for (int i = 0; i &lt; methodArgumentArrayLength; i++) &#123; int byteLength = in.readInt(); methodArguments[i] = in.readBytes(byteLength); &#125; packet.setMethodArguments(methodArguments); &#125; list.add(packet); &#125;&#125; 响应Packet编码器ResponseMessagePacketEncoder的代码如下： 12345678910111213141516171819202122232425262728293031323334353637@RequiredArgsConstructorpublic class ResponseMessagePacketEncoder extends MessageToByteEncoder&lt;ResponseMessagePacket&gt; &#123; private final Serializer serializer; @Override protected void encode(ChannelHandlerContext ctx, ResponseMessagePacket packet, ByteBuf out) throws Exception &#123; // 魔数 out.writeInt(packet.getMagicNumber()); // 版本 out.writeInt(packet.getVersion()); // 流水号 out.writeInt(packet.getSerialNumber().length()); out.writeCharSequence(packet.getSerialNumber(), ProtocolConstant.UTF_8); // 消息类型 out.writeByte(packet.getMessageType().getType()); // 附件size Map&lt;String, String&gt; attachments = packet.getAttachments(); out.writeInt(attachments.size()); // 附件内容 attachments.forEach((k, v) -&gt; &#123; out.writeInt(k.length()); out.writeCharSequence(k, ProtocolConstant.UTF_8); out.writeInt(v.length()); out.writeCharSequence(v, ProtocolConstant.UTF_8); &#125;); // error code out.writeLong(packet.getErrorCode()); // message String message = packet.getMessage(); ByteBufferUtils.X.encodeUtf8CharSequence(out, message); // payload byte[] bytes = serializer.encode(packet.getPayload()); out.writeInt(bytes.length); out.writeBytes(bytes); &#125;&#125; 响应Packet解码器ResponseMessagePacketDecoder的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839public class ResponseMessagePacketDecoder extends ByteToMessageDecoder &#123; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; ResponseMessagePacket packet = new ResponseMessagePacket(); // 魔数 packet.setMagicNumber(in.readInt()); // 版本 packet.setVersion(in.readInt()); // 流水号 int serialNumberLength = in.readInt(); packet.setSerialNumber(in.readCharSequence(serialNumberLength, ProtocolConstant.UTF_8).toString()); // 消息类型 byte messageTypeByte = in.readByte(); packet.setMessageType(MessageType.fromValue(messageTypeByte)); // 附件 Map&lt;String, String&gt; attachments = Maps.newHashMap(); packet.setAttachments(attachments); int attachmentSize = in.readInt(); if (attachmentSize &gt; 0) &#123; for (int i = 0; i &lt; attachmentSize; i++) &#123; int keyLength = in.readInt(); String key = in.readCharSequence(keyLength, ProtocolConstant.UTF_8).toString(); int valueLength = in.readInt(); String value = in.readCharSequence(valueLength, ProtocolConstant.UTF_8).toString(); attachments.put(key, value); &#125; &#125; // error code packet.setErrorCode(in.readLong()); // message int messageLength = in.readInt(); packet.setMessage(in.readCharSequence(messageLength, ProtocolConstant.UTF_8).toString()); // payload - ByteBuf实例 int payloadLength = in.readInt(); packet.setPayload(in.readBytes(payloadLength)); out.add(packet); &#125;&#125; 核心的编码解码器已经编写完，接着要注意一下TCP协议二进制包发送的时候只保证了包的发送顺序、确认发送以及重传，无法保证二进制包是否完整（有些博客也称此类场景为粘包、半包等等，其实网络协议里面并没有定义这些术语，估计是有人杜撰出来），因此这里采取了定长帧编码和解码器LengthFieldPrepender和LengthFieldBasedFrameDecoder，简单来说就是在消息帧的开头几位定义了整个帧的长度，读取到整个长度的消息帧才认为是一个完整的二进制报文。举个几个例子： 12|&lt;--------packet frame---------&gt;|| Length Field | Actual Content | 序号 Length Field Actual Content 0 4 abcd 1 9 throwable 2 14 {“name”:“doge”} 编写测试客户端和服务端 客户端代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Slf4jpublic class TestProtocolClient &#123; public static void main(String[] args) throws Exception &#123; int port = 9092; EventLoopGroup workerGroup = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); try &#123; bootstrap.group(workerGroup); bootstrap.channel(NioSocketChannel.class); bootstrap.option(ChannelOption.SO_KEEPALIVE, Boolean.TRUE); bootstrap.option(ChannelOption.TCP_NODELAY, Boolean.TRUE); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new LengthFieldBasedFrameDecoder(1024, 0, 4, 0, 4)); ch.pipeline().addLast(new LengthFieldPrepender(4)); ch.pipeline().addLast(new RequestMessagePacketEncoder(FastJsonSerializer.X)); ch.pipeline().addLast(new ResponseMessagePacketDecoder()); ch.pipeline().addLast(new SimpleChannelInboundHandler&lt;ResponseMessagePacket&gt;() &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, ResponseMessagePacket packet) throws Exception &#123; Object targetPayload = packet.getPayload(); if (targetPayload instanceof ByteBuf) &#123; ByteBuf byteBuf = (ByteBuf) targetPayload; int readableByteLength = byteBuf.readableBytes(); byte[] bytes = new byte[readableByteLength]; byteBuf.readBytes(bytes); targetPayload = FastJsonSerializer.X.decode(bytes, String.class); byteBuf.release(); &#125; packet.setPayload(targetPayload); log.info(\"接收到来自服务端的响应消息,消息内容:&#123;&#125;\", JSON.toJSONString(packet)); &#125; &#125;); &#125; &#125;); ChannelFuture future = bootstrap.connect(\"localhost\", port).sync(); log.info(\"启动NettyClient[&#123;&#125;]成功...\", port); Channel channel = future.channel(); RequestMessagePacket packet = new RequestMessagePacket(); packet.setMagicNumber(ProtocolConstant.MAGIC_NUMBER); packet.setVersion(ProtocolConstant.VERSION); packet.setSerialNumber(SerialNumberUtils.X.generateSerialNumber()); packet.setMessageType(MessageType.REQUEST); packet.setInterfaceName(\"club.throwable.contract.HelloService\"); packet.setMethodName(\"sayHello\"); packet.setMethodArgumentSignatures(new String[]&#123;\"java.lang.String\"&#125;); packet.setMethodArguments(new Object[]&#123;\"doge\"&#125;); channel.writeAndFlush(packet); future.channel().closeFuture().sync(); &#125; finally &#123; workerGroup.shutdownGracefully(); &#125; &#125;&#125; 服务端代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Slf4jpublic class TestProtocolServer &#123; public static void main(String[] args) throws Exception &#123; int port = 9092; ServerBootstrap bootstrap = new ServerBootstrap(); EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new LengthFieldBasedFrameDecoder(1024, 0, 4, 0, 4)); ch.pipeline().addLast(new LengthFieldPrepender(4)); ch.pipeline().addLast(new RequestMessagePacketDecoder()); ch.pipeline().addLast(new ResponseMessagePacketEncoder(FastJsonSerializer.X)); ch.pipeline().addLast(new SimpleChannelInboundHandler&lt;RequestMessagePacket&gt;() &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, RequestMessagePacket packet) throws Exception &#123; log.info(\"接收到来自客户端的请求消息,消息内容:&#123;&#125;\", JSON.toJSONString(packet)); ResponseMessagePacket response = new ResponseMessagePacket(); response.setMagicNumber(packet.getMagicNumber()); response.setVersion(packet.getVersion()); response.setSerialNumber(packet.getSerialNumber()); response.setAttachments(packet.getAttachments()); response.setMessageType(MessageType.RESPONSE); response.setErrorCode(200L); response.setMessage(\"Success\"); response.setPayload(\"&#123;\\\"name\\\":\\\"throwable\\\"&#125;\"); ctx.writeAndFlush(response); &#125; &#125;); &#125; &#125;); ChannelFuture future = bootstrap.bind(port).sync(); log.info(\"启动NettyServer[&#123;&#125;]成功...\", port); future.channel().closeFuture().sync(); &#125; finally &#123; workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125;&#125; 这里在测试的环境中，最大的消息帧长度暂时定义为1024。先启动服务端，再启动客户端，见控制台输出如下： 123456789// 服务端22:29:32.596 [main] INFO club.throwable.protocol.TestProtocolServer - 启动NettyServer[9092]成功......省略其他日志...22:29:53.538 [nioEventLoopGroup-3-1] INFO club.throwable.protocol.TestProtocolServer - 接收到来自客户端的请求消息,消息内容:&#123;\"attachments\":&#123;&#125;,\"interfaceName\":\"club.throwable.contract.HelloService\",\"magicNumber\":10086,\"messageType\":\"REQUEST\",\"methodArgumentSignatures\":[\"java.lang.String\"],\"methodArguments\":[&#123;\"contiguous\":true,\"direct\":true,\"readOnly\":false,\"readable\":true,\"writable\":false&#125;],\"methodName\":\"sayHello\",\"serialNumber\":\"7f992c7cf9f445258601def1cac9bec0\",\"version\":1&#125;// 客户端22:31:28.360 [main] INFO club.throwable.protocol.TestProtocolClient - 启动NettyClient[9092]成功......省略其他日志...22:31:39.320 [nioEventLoopGroup-2-1] INFO club.throwable.protocol.TestProtocolClient - 接收到来自服务端的响应消息,消息内容:&#123;\"attachments\":&#123;&#125;,\"errorCode\":200,\"magicNumber\":10086,\"message\":\"Success\",\"messageType\":\"RESPONSE\",\"payload\":\"&#123;\\\"name\\\":\\\"throwable\\\"&#125;\",\"serialNumber\":\"320808e709b34edbb91ba557780b58ad\",\"version\":1&#125; 小结 一个基于Netty实现的简单的自定义协议基本完成，但是要编写一个优秀的RPC框架，还需要做服务端的宿主类和目标方法查询、调用，客户端的动态代理，Netty的NIO模式下的同步调用改造，心跳处理，异常处理等等。后面会使用多篇文章逐个问题解决，网络编程其实挺好玩了，就是编码量会比较大(゜-゜)つロ。 Demo项目： ch0-custom-rpc-protocol （e-a-20200112 c-1-d）","categories":[{"name":"Netty","slug":"Netty","permalink":"http://throwable.club/blog/categories/Netty/"},{"name":"Java","slug":"Netty/Java","permalink":"http://throwable.club/blog/categories/Netty/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Netty","slug":"Netty","permalink":"http://throwable.club/blog/tags/Netty/"}]},{"title":"SofaBoot使用Nacos进行服务注册发现","slug":"sofa-boot-nacos-get-start","date":"2020-01-01T15:30:41.000Z","updated":"2020-01-02T09:35:56.367Z","comments":true,"path":"2020/01/01/sofa-boot-nacos-get-start/","link":"","permalink":"http://throwable.club/2020/01/01/sofa-boot-nacos-get-start/","excerpt":"前提 最近创业公司的项目组基于业务需要，开发一套新的微服务，考虑到选用的组件必须是主流、社区活跃、生态完善以及方便迁移到云上等因素，引入了SOFAStack全家桶。微服务开发里面，一个很重要的功能就是服务发现与注册，笔者花了点时间做了一个SOFABoot、SOFARpc结合Nacos实现微服务发现注册与远程调用的示例。","text":"前提 最近创业公司的项目组基于业务需要，开发一套新的微服务，考虑到选用的组件必须是主流、社区活跃、生态完善以及方便迁移到云上等因素，引入了SOFAStack全家桶。微服务开发里面，一个很重要的功能就是服务发现与注册，笔者花了点时间做了一个SOFABoot、SOFARpc结合Nacos实现微服务发现注册与远程调用的示例。 依赖版本踩坑 笔者花了点时间去尝试SOFABoot、SOFARpc结合Nacos客户端的依赖版本关系，截止本文编写完成的时候（2020-01-01），sofaboot-dependencies的最新版本为3.2.1，对应于SOFABoot-3.2.1、SOFARpc-5.6.3和SpringBoot-2.1.x.RELEASE。在这两个最新版本的项目中，无论引入什么版本的nacos-clinet，都没有办法向Nacos-Server注册服务信息。关于这一点，笔者曾经从Issues里面查找相关的内容，暂时无果，于是把示例项目分享给社区的大佬进行分析，如果有解决方案，会在这篇博文中更新。试出来的可用的版本组合为： sofaboot-dependencies:3.2.0 spring-boot-dependencies:2.1.0.RELEASE nacos-api:0.6.0和nacos-client:0.6.0 引入依赖如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;properties&gt; &lt;sofa.boot.version&gt;3.2.0&lt;/sofa.boot.version&gt; &lt;spring.boot.version&gt;2.1.0.RELEASE&lt;/spring.boot.version&gt; &lt;nacos.version&gt;0.6.0&lt;/nacos.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.boot.version&#125;&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt; &lt;artifactId&gt;sofaboot-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;sofa.boot.version&#125;&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt; &lt;artifactId&gt;healthcheck-sofa-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt; &lt;artifactId&gt;rpc-sofa-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;version&gt;$&#123;nacos.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-api&lt;/artifactId&gt; &lt;version&gt;$&#123;nacos.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 编写服务提供方和服务消费方代码 这里有一个前提，需要启动一个Nacos-Server，为了方便起见，使用单机模式本地启动即可，那么服务注册的地址就是http://127.0.0.1:8848。示例项目的结构如下： 123456789101112131415161718├─src│ └─main│ ├─java│ │ └─club│ │ └─throwable│ │ ├─client│ │ │ ClientApplication.java│ │ │ │ │ ├─contract│ │ │ HelloService.java│ │ │ │ │ └─server│ │ DefaultHelloService.java│ │ ServerApplication.java│ │ │ └─resources│ application-client.properties│ application-server.properties 其中contract为契约包，可以提供给客户端和服务端使用，client包里面编写客户端（comsumer）的代码，而server包里面编写服务端（provider）的代码。 契约接口HelloService很简单： 1234public interface HelloService &#123; String sayHello(String name);&#125; 服务提供方需要实现此接口，实现类是DefaultHelloService： 1234567891011@Service@SofaService(interfaceType = HelloService.class, bindings = &#123; @SofaServiceBinding(bindingType = \"bolt\")&#125;)public class DefaultHelloService implements HelloService &#123; @Override public String sayHello(String name) &#123; return String.format(\"%s say hello!\", name); &#125;&#125; 这里使用的服务协议绑定类型为bolt，是官方示例建议的协议，当然还有dubbo、http等等，可以混合配置。接着编写服务提供方启动类ServerApplication： 1234567@SpringBootApplication(scanBasePackages = &#123;\"club.throwable.server\", \"club.throwable.contract\"&#125;)public class ServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServerApplication.class, args); &#125;&#125; 服务提供方应用的配置文件application-server.properties如下： 1234spring.application.name=sofa-rpc-providerserver.port=9092# 用Nacos做注册中心com.alipay.sofa.rpc.registry-address=nacos://127.0.0.1:8848 使用spring.profiles.active=server启动ServerApplication，启动成功后用浏览器打开Nacos-Console： 可见目前sofa-rpc-provider服务已经成功注册到Nacos-Server。接着编写客户端代码，为了方便起见，所有的代码编写在启动类ClientApplication： 12345678910111213141516@Slf4j@SpringBootApplication(scanBasePackages = &#123;\"club.throwable.client\", \"club.throwable.contract\"&#125;)public class ClientApplication implements CommandLineRunner &#123; @SofaReference(binding = @SofaReferenceBinding(bindingType = \"bolt\")) private HelloService helloService; public static void main(String[] args) &#123; SpringApplication.run(ClientApplication.class, args); &#125; @Override public void run(String... args) throws Exception &#123; log.info(\"调用HelloService#sayHello(),结果:&#123;&#125;\", helloService.sayHello(\"throwable\")); &#125;&#125; 服务消费方的配置文件application-client.properties如下： 1234spring.application.name=sofa-rpc-consumerserver.port=9091# 用Nacos做注册中心com.alipay.sofa.rpc.registry-address=nacos://127.0.0.1:8848 使用spring.profiles.active=client启动ClientApplication，启动完成后控制台输出： 12020-01-02 17:07:58.782 INFO 2900 --- [main] club.throwable.client.ClientApplication : 调用HelloService#sayHello(),结果:throwable say hello! 基本原理如下： 小结 SOFABoot、SOFARpc底层依赖于Spring容器，可以跟随SpringBoot版本迭代升级，底层通讯使用Netty，在性能上有保障，而且真正做到了兼容HTTP、Dubbo、Service Mesh（后面应该会把Service Mesh作为通讯协议进行兼容）等等协议，对于开发者而言相对友好，学习成本低，做到真正的开箱添加少量配置即可使用。除了目前发现依赖版本的问题，暂时没有大的坑，尝尝鲜的感觉还是挺不错的。 示例项目： sofa-boot-nacos （本文完 c-1-d e-a-20200101）","categories":[{"name":"SOFAStack","slug":"SOFAStack","permalink":"http://throwable.club/blog/categories/SOFAStack/"},{"name":"Nacos","slug":"SOFAStack/Nacos","permalink":"http://throwable.club/blog/categories/SOFAStack/Nacos/"}],"tags":[{"name":"SOFAStack","slug":"SOFAStack","permalink":"http://throwable.club/blog/tags/SOFAStack/"},{"name":"Nacos","slug":"Nacos","permalink":"http://throwable.club/blog/tags/Nacos/"}]},{"title":"SpringBoot使用Nacos进行服务注册发现与配置管理","slug":"spring-boot-nacos-get-start","date":"2020-01-01T15:20:41.000Z","updated":"2020-01-02T03:31:05.133Z","comments":true,"path":"2020/01/01/spring-boot-nacos-get-start/","link":"","permalink":"http://throwable.club/2020/01/01/spring-boot-nacos-get-start/","excerpt":"前提 最近由于业务发展，需要调研一套完善和主流的基础架构，进行中台化（微服务）的实施，考虑到技术栈切换到SOFAStack。既然整个体系都切换到蚂蚁金服的技术栈，那么自然考虑一些基础组件如服务注册发现、配置管理等都切换为阿里的技术栈。考虑到目前比较热的服务发现组件是Nacos，需要调研SpringBoot服务接入Nacos的可行性，为以后强制要求新服务使用SOFAStack + Nacos的技术栈进行服务开发打下基础。","text":"前提 最近由于业务发展，需要调研一套完善和主流的基础架构，进行中台化（微服务）的实施，考虑到技术栈切换到SOFAStack。既然整个体系都切换到蚂蚁金服的技术栈，那么自然考虑一些基础组件如服务注册发现、配置管理等都切换为阿里的技术栈。考虑到目前比较热的服务发现组件是Nacos，需要调研SpringBoot服务接入Nacos的可行性，为以后强制要求新服务使用SOFAStack + Nacos的技术栈进行服务开发打下基础。 Nacos简介 下面的简介来源于Nacos的官网： Nacos致力于帮助您发现、配置和管理微服务。Nacos提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。 Nacos帮助您更敏捷和容易地构建、交付和管理微服务平台。Nacos是构建以服务为中心的现代应用架构（例如微服务范式、云原生范式）的服务基础设施。 Nacos地图： Nacos生态图： 从Nacos提供的发展地图来看，它基本提供了目前微服务实施中一些核心问题：监控、服务发现注册、配置灰度发布、配置回滚等等。另外，它在生态上能够融入目前主流的K8S、Docker、SpringCloud、Consul、Zookeeper等等（有点像屏蔽底层细节，只需少量配置就可以切换底层架构的实现），这一点十分重要。目前Nacos在阿里云上提供了商用版本（记得有前辈说过开源的终极目标就是商用，大概如此）。如果在项目中使用的是SpringCloud全家桶，引入Nacos以及它和SpringCloud之间的胶水层，可以完全替代Eureka组件的功能，替代和强化部分Spring Cloud Config的功能。 Nacos服务部署 Nacos-Server部署相对简单，它的发布版本见Github的Releases页面。下载完成后进行解压，Windows系下启动Nacos-Server只需进入解压后的${解压目录}\\nacos\\bin目录，执行startup.cmd即可，服务启动成功的结果如下： 单机模式在不修改配置的前提下直接启动，使用的是内存数据库，重启后数据会被清空。如果需要数据持久化，则需要建立数据库，具体的步骤是： 建表的脚本在${解压目录}\\nacos\\conf目录下，见schema.sql和nacos-mysql.sql两个文件。 自行通过建表的脚本建立数据库。 需要指定数据库，则需要修改${解压目录}\\nacos\\conf\\application.properties，在文件的尾部追加数据源的连接配置，下面是官方给出的多数据源的例子： 123456# 需要确保多个数据源的用户名和密码一致db.num=2db.url.0=jdbc:mysql://11.162.196.16:3306/nacos_devtest?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.url.1=jdbc:mysql://11.163.152.9:3306/nacos_devtest?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=nacos_devtestdb.password=nacos 测试获取已经注册的服务： 12λ curl -X GET http://127.0.0.1:8848/nacos/v1/ns/instance/list?serviceName=nacos.naming.serviceName&#123;\"hosts\":[],\"name\":\"DEFAULT_GROUP@@nacos.naming.serviceName\",\"clusters\":\"\"&#125; 访问http://127.0.0.1:8848/nacos即可打开Nacos-Console，初始的登录账号和密码都是nacos： 更多运维部署相关的内容见文档运维指南中的一节。 SpirngBoot应用使用Nacos作为注册中心 SpringBoot应用使用Nacos作为注册中心需要引入依赖nacos-discovery-spring-boot-starter，笔者编写本文的时候（2020-01-01），该依赖的最新版本为0.2.4，对应于SpringBoot的版本为2.0.3.RELEASE，引入如下依赖： 12345678910111213141516171819202122&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-discovery-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.4&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 为了方便起见，笔者把控制器、服务注册的代码都写在启动类ProvideApplication中： 12345678910111213141516171819202122232425262728@RestController@SpringBootApplication(scanBasePackages = \"club.throwable.provide\")public class ProvideApplication implements CommandLineRunner &#123; @NacosInjected private NamingService namingService; @Value(\"$&#123;spring.application.name&#125;\") private String applicationName; @Value(\"$&#123;server.port&#125;\") private Integer serverPort; public static void main(String[] args) &#123; SpringApplication.run(ProvideApplication.class, args); &#125; @GetMapping(path = \"/hello\") public String hello(@RequestParam(name = \"name\") String name) &#123; return String.format(\"%s say hello!\", name); &#125; @Override public void run(String... args) throws Exception &#123; // 通过Naming服务注册实例到注册中心 namingService.registerInstance(applicationName, \"127.0.0.1\", serverPort); &#125;&#125; 配置文件application-provide.properties内容如下： 123spring.application.name=provide-serviceserver.port=9092nacos.discovery.server-addr=127.0.0.1:8848 使用spring.profiles.active=provide启动ProvideApplication，启动成功后用浏览器打开Nacos-Console： 暂时可知服务的提供方已经注册成功。接着编写服务的消费方代码，引入的最小依赖和服务提供方完全一致，编写启动类ConsumeApplication如下： 123456789101112131415161718192021@SpringBootApplication(scanBasePackages = \"club.throwable.consume\")public class ConsumeApplication implements CommandLineRunner &#123; @NacosInjected private NamingService namingService; public static void main(String[] args) &#123; SpringApplication.run(ConsumeApplication.class, args); &#125; @Override public void run(String... args) throws Exception &#123; // 根据服务名从注册中心获取一个健康的服务实例 Instance instance = namingService.selectOneHealthyInstance(\"provide-service\"); // 这里只是为了方便才新建RestTemplate实例 RestTemplate template = new RestTemplate(); String url = String.format(\"http://%s:%d/hello?name=throwable\", instance.getIp(), instance.getPort()); String result = template.getForObject(url, String.class); System.out.println(String.format(\"请求URL:%s,响应结果:%s\", url, result)); &#125;&#125; 消费服务的配置文件application-consume.properties内容如下： 123spring.application.name=consume-serviceserver.port=9091nacos.discovery.server-addr=127.0.0.1:8848 使用spring.profiles.active=consume启动ConsumeApplication，CommandLineRunner执行完毕后控制台打印： 1请求URL:http://127.0.0.1:9092/hello?name=throwable,响应结果:throwable say hello! 这种方式使用起来会感觉模板代码比较多，不够简洁。如果在SpringCloud体系中，结合Feign客户端则可以省略这些模板代码。 SpirngBoot应用使用Nacos管理配置 如果使用Nacos进行配置管理，则需要引入nacos-config-spring-boot-starter依赖，笔者编写本文的时候（2020-01-01），该依赖的最新版本为0.2.4： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-config-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.4&lt;/version&gt;&lt;/dependency&gt; 新建一个启动类ConfigApplication如下： 1234567891011121314151617@RestController@NacosPropertySource(dataId = \"example\", autoRefreshed = true)@SpringBootApplication(scanBasePackages = \"club.throwable.config\")public class ConfigApplication &#123; @NacosValue(value = \"$&#123;counter:0&#125;\", autoRefreshed = true) public Long counter; public static void main(String[] args) &#123; SpringApplication.run(ConfigApplication.class, args); &#125; @GetMapping(path = \"/get\") public String get() &#123; return String.format(\"Counter value:%d\", counter); &#125;&#125; 笔者定义了一个长整型的计数器，设置了autoRefreshed（自动刷新）为true，新建一个配置文件application-config.properties： 123spring.application.name=config-serviceserver.port=9093nacos.config.server-addr=127.0.0.1:8848 使用spring.profiles.active=config启动ConfigApplication，启动成功后通过CURL调用下面的接口： 12λ curl -X GET http://127.0.0.1:9093/getCounter value:0 接着通过Nacos-Console添加一个配置： 点击发布按钮后再次调用接口： 12λ curl -X GET http://127.0.0.1:9093/getCounter value:10086 可见计数器的值已经动态刷新。配置项里面还有很多高级配置如：指定配置生效的服务、Beta发布等等，可以按照合适的场景进行设置。 另外，Nacos Server提供Open API从而可以使用HTTP客户端就可以轻松进行配置查询、配置更新发布等操作（目前这些API没有做鉴权，社区也有人曾提出这样会引发安全性问题，Nacos官方已经立项在后续新版本中加入鉴权的功能，目前建议屏蔽或者仅允许内网访问这些Open API）： 获取配置：curl -X GET http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=${DATA_ID}&amp;group=${GROUP} 发布配置：curl -X POST http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=${DATA_ID}&amp;group=${GROUP}&amp;content=${CONFIG_CONTENT} 小结 本文只是简单介绍了SpringBoot中使用Nacos作为注册中心以及进行配置管理。Nacos项目Github仓库当前（2020-01-01）的star数已经接近10000，社区也十分活跃，Issues和交流群的响应都十分迅速。加之Netflix的部分开源产品如Eureka、Hystrix等已经停止迭代，但Nacos还在飞速迭代，甚至已经在阿里云衍生出商业版本，所以笔者认为Nacos值得使用，在相对熟悉它的大部分特性之后会付之于生产环境中使用。 参考资料： Nacos文档 本文的Demo项目： spring-boot-nacos 下一篇博文会介绍一下SOFAStack中基于SOFABoot、SOFARpc以及Nacos等组件作为基础架构搭建一套微服务的详细过程。 （本文完 c-2-d e-a-20200101 23:11）","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://throwable.club/blog/categories/SpringBoot/"},{"name":"Nacos","slug":"SpringBoot/Nacos","permalink":"http://throwable.club/blog/categories/SpringBoot/Nacos/"}],"tags":[{"name":"Nacos","slug":"Nacos","permalink":"http://throwable.club/blog/tags/Nacos/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://throwable.club/blog/tags/SpringBoot/"}]},{"title":"聊聊Java内省Introspector","slug":"java-introspector-usage","date":"2019-12-25T00:45:06.000Z","updated":"2020-01-18T07:07:04.344Z","comments":true,"path":"2019/12/25/java-introspector-usage/","link":"","permalink":"http://throwable.club/2019/12/25/java-introspector-usage/","excerpt":"前提 这篇文章主要分析一下Introspector(内省)的用法。Introspector是一个专门处理JavaBean的工具类，用来获取JavaBean里描述符号，常用的JavaBean的描述符号相关类有BeanInfo、PropertyDescriptor，MethodDescriptor、BeanDescriptor、EventSetDescriptor和ParameterDescriptor。下面会慢慢分析这些类的使用方式，以及Introspector的一些特点。","text":"前提 这篇文章主要分析一下Introspector(内省)的用法。Introspector是一个专门处理JavaBean的工具类，用来获取JavaBean里描述符号，常用的JavaBean的描述符号相关类有BeanInfo、PropertyDescriptor，MethodDescriptor、BeanDescriptor、EventSetDescriptor和ParameterDescriptor。下面会慢慢分析这些类的使用方式，以及Introspector的一些特点。 JavaBean是什么 JavaBean是一种特殊（其实说普通也可以，也不是十分特殊）的类，主要用于传递数据信息，这种类中的方法主要用于访问私有的字段，且方法名符合某种命名规则（字段都是私有，每个字段具备Setter和Getter方法，方法和字段命名满足首字母小写驼峰命名规则）。如果在两个模块之间传递信息，可以将信息封装进JavaBean中，这种对象称为值对象(Value Object)或者VO。这些信息储存在类的私有变量中，通过Setter、Getter方法获得。JavaBean的信息在Introspector里对应的概念是BeanInfo，它包含了JavaBean所有的Descriptor(描述符)，主要有PropertyDescriptor，MethodDescriptor(MethodDescriptor里面包含ParameterDescriptor)、BeanDescriptor和EventSetDescriptor。 属性Field和属性描述PropertiesDescriptor的区别 如果是严格的JavaBean(Field名称不重复，并且Field具备Setter和Getter方法)，它的PropertyDescriptor会通过解析Setter和Getter方法，合并解析结果，最终得到对应的PropertyDescriptor实例。所以PropertyDescriptor包含了属性名称和属性的Setter和Getter方法(如果存在的话)。 内省Introspector和反射Reflection的区别 Reflection：反射就是运行时获取一个类的所有信息，可以获取到类的所有定义的信息（包括成员变量，成员方法，构造器等）可以操纵类的字段、方法、构造器等部分。可以想象为镜面反射或者照镜子，这样的操作是带有客观色彩的，也就是反射获取到的类信息是必定正确的。 Introspector：内省基于反射实现，主要用于操作JavaBean，基于JavaBean的规范进行Bean信息描述符的解析，依据于类的Setter和Getter方法，可以获取到类的描述符。可以想象为“自我反省”，这样的操作带有主观的色彩，不一定是正确的(如果一个类中的属性没有Setter和Getter方法，无法使用内省)。 常用的内省相关类 主要介绍一下几个核心类所提供的方法。 Introspector Introspector类似于BeanInfo的静态工厂类，主要是提供静态方法通过Class实例获取到BeanInfo，得到BeanInfo之后，就能够获取到其他描述符。主要方法： public static BeanInfo getBeanInfo(Class&lt;?&gt; beanClass)：通过Class实例获取到BeanInfo实例。 BeanInfo BeanInfo是一个接口，具体实现是GenericBeanInfo，通过这个接口可以获取一个类的各种类型的描述符。主要方法： BeanDescriptor getBeanDescriptor()：获取JavaBean描述符。 EventSetDescriptor[] getEventSetDescriptors()：获取JavaBean的所有的EventSetDescriptor。 PropertyDescriptor[] getPropertyDescriptors()：获取JavaBean的所有的PropertyDescriptor。 MethodDescriptor[] getMethodDescriptors()：获取JavaBean的所有的MethodDescriptor。 这里要注意一点，通过BeanInfo#getPropertyDescriptors()获取到的PropertyDescriptor数组中，除了Bean属性的之外，还会带有一个属性名为class的PropertyDescriptor实例，它的来源是Class的getClass方法，如果不需要这个属性那么最好判断后过滤。 PropertyDescriptor PropertyDescriptor类表示JavaBean类通过存储器(Setter和Getter)导出一个属性，它应该是内省体系中最常见的类。主要方法： synchronized Class&lt;?&gt; getPropertyType()：获得属性的Class对象。 synchronized Method getReadMethod()：获得用于读取属性值的方法； synchronized Method getWriteMethod()：获得用于写入属性值的方法。 int hashCode()：获取对象的哈希值。 synchronized void setReadMethod(Method readMethod)：设置用于读取属性(Getter)值的方法。 synchronized void setWriteMethod(Method writeMethod)：设置用于写入属性值(Setter)的方法。 举个例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Main &#123; public static void main(String[] args) throws Exception &#123; BeanInfo beanInfo = Introspector.getBeanInfo(Person.class); PropertyDescriptor[] propertyDescriptors = beanInfo.getPropertyDescriptors(); for (PropertyDescriptor propertyDescriptor : propertyDescriptors) &#123; if (!\"class\".equals(propertyDescriptor.getName())) &#123; System.out.println(propertyDescriptor.getName()); System.out.println(propertyDescriptor.getWriteMethod().getName()); System.out.println(propertyDescriptor.getReadMethod().getName()); System.out.println(\"=======================\"); &#125; &#125; &#125; public static class Person &#123; private Long id; private String name; private Integer age; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; &#125;&#125; 输出结果： 123456789101112agesetAgegetAge=======================idsetIdgetId=======================namesetNamegetName======================= 不正当使用Introspector会导致内存溢出 如果框架或者程序用到了JavaBeans Introspector，那么就相当于启用了一个系统级别的缓存，这个缓存会存放一些曾加载并分析过的Javabean的引用，当web服务器关闭的时候，由于这个缓存中存放着这些Javabean的引用，所以垃圾回收器不能对Web容器中的JavaBean对象进行回收，导致内存越来越大。还有一点值得注意，清除Introspector缓存的唯一方式是刷新整个缓存缓冲区，这是因为JDK没法判断哪些是属于当前的应用的引用，所以刷新整个Introspector缓存缓冲区会导致把服务器的所有应用的Introspector缓存都删掉。Spring中提供的org.springframework.web.util.IntrospectorCleanupListener就是为了解决这个问题，它会在Web服务器停止的时候，清理一下这个Introspector缓存，使那些Javabean能被垃圾回收器正确回收。 也就是说JDK的Introspector缓存管理是有一定缺陷的。但是如果使用在Spring体系则不会出现这种问题，因为Spring把Introspector缓存的管理移交到Spring自身而不是JDK（或者在Web容器销毁后完全不管），在加载并分析完所有类之后，会针对类加载器对Introspector缓存进行清理，避免内存泄漏的问题，详情可以看CachedIntrospectionResults和SpringBoot刷新上下文的方法AbstractApplicationContext#refresh()中finally代码块中存在清理缓存的方法AbstractApplicationContext#resetCommonCaches();。但是有很多程序和框架在使用了JavaBeans Introspector之后，都没有进行清理工作，比如Quartz、Struts等，这类操作会成为内存泄漏的隐患。 小结 在标准的JavaBean中，可以考虑使用Introspector体系解析JavaBean，主要是方便使用反射之前的时候快速获取到JavaBean的Setter和Getter方法。 在Spring体系中，为了防止JDK对内省信息的缓存无法被垃圾回收机制回收导致内存溢出，主要的操作除了可以通过配置IntrospectorCleanupListener预防，还有另外一种方式，就是通过CachedIntrospectionResults类自行管理Introspector中的缓存(这种方式才是优雅的方式，这样可以避免刷新整个Introspector的缓存缓冲区而导致其他应用的Introspector也被清空)，也就是把Jdk自行管理的Introspector相关缓存交给Spring自己去管理。在SpringBoot刷新上下文的方法AbstractApplicationContext#refresh()中finally代码块中存在清理缓存的方法AbstractApplicationContext#resetCommonCaches();，里面调用到的CachedIntrospectionResults#clearClassLoader(getClassLoader())方法就是清理指定的ClassLoader下的所有Introspector中的缓存的引用。 （本文完 e-a-20191225 c-1-d 更新了博客主题，感觉比以前好看一点点…）","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Introspector","slug":"Java/Introspector","permalink":"http://throwable.club/blog/categories/Java/Introspector/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Introspector","slug":"Introspector","permalink":"http://throwable.club/blog/tags/Introspector/"}]},{"title":"Go语言基本环境变量与依赖管理","slug":"golang-module-usage","date":"2019-12-22T16:29:00.000Z","updated":"2019-12-22T16:36:18.310Z","comments":true,"path":"2019/12/23/golang-module-usage/","link":"","permalink":"http://throwable.club/2019/12/23/golang-module-usage/","excerpt":"前提 最近开始系统学习一下Golang这么新语言，记录一下它的基本环境变量配置以及依赖管理方式。编写本文的时候使用的Golang版本为go1.13.5 windows/amd64，其他版本不一定保证适合本文的内容。因为习惯，可能有时候把Go语言称为Go，有时候称为Golang。","text":"前提 最近开始系统学习一下Golang这么新语言，记录一下它的基本环境变量配置以及依赖管理方式。编写本文的时候使用的Golang版本为go1.13.5 windows/amd64，其他版本不一定保证适合本文的内容。因为习惯，可能有时候把Go语言称为Go，有时候称为Golang。 理解一下Golang的环境变量 安装完Golang之后，可以通过go env命令查看环境变量配置，下面是笔者执行此命令的结果： 123456789101112131415161718192021222324252627282930313233λ go envset GO111MODULE=set GOARCH=amd64set GOBIN=set GOCACHE=C:\\Users\\doge\\AppData\\Local\\go-buildset GOENV=C:\\Users\\doge\\AppData\\Roaming\\go\\envset GOEXE=.exeset GOFLAGS=set GOHOSTARCH=amd64set GOHOSTOS=windowsset GONOPROXY=set GONOSUMDB=set GOOS=windowsset GOPATH=C:\\Users\\doge\\goset GOPRIVATE=set GOPROXY=https://goproxy.cn,directset GOROOT=I:\\Environment\\Goset GOSUMDB=sum.golang.orgset GOTMPDIR=set GOTOOLDIR=I:\\Environment\\Go\\pkg\\tool\\windows_amd64set GCCGO=gccgoset AR=arset CC=gccset CXX=g++set CGO_ENABLED=1set GOMOD=set CGO_CFLAGS=-g -O2set CGO_CPPFLAGS=set CGO_CXXFLAGS=-g -O2set CGO_FFLAGS=-g -O2set CGO_LDFLAGS=-g -O2set PKG_CONFIG=pkg-configset GOGCCFLAGS=-m64 -mthreads -fmessage-length=0 -fdebug-prefix-map=C:\\Users\\doge\\AppData\\Local\\Temp\\go-build779409438=/tmp/go-build -gno-record-gcc-switches 在日常开发中，我们需要重点关注GOPROXY、GOROOT、GOPATH和GOBIN，其他配置项可以在需要的时候再查询文档进行配置。 GOPROXY GOPROXY就是设置Golang的全局代理。在下载依赖包的时候，一般是访问github的仓库，国内的环境很容易被墙，所以最好设置一个速度快的代理。Go在此版本中GOPROXY的默认值为https://proxy.golang.org，国内是无法访问的。因此，这里推荐使用七牛云的代理https://goproxy.cn： 1go env -w GOPROXY=https://goproxy.cn,direct 设置完此代理之后，下载依赖的速度就能相对正常。 GOROOT GOROOT其实就是Golang安装的绝对路径，例如笔者把他安装在I:\\Environment\\Go目录下，所以： 1234λ go env...set GOROOT=I:\\Environment\\Go... GOROOT需要加入到系统变量Path里面，添加成功后才能在命令行使用go [Command]。 GOPATH和GOBIN GOPATH可以简单理解为工作目录，如果用过Eclipse，那么GOPATH可以类比为Eclipse中的WorkSpace的概念。GOPATH目录约定由三个子目录： 1234$GOPATH - src --- 存放源代码，go run、go install等命令就是在当前的工作路径中执行（也就是这些命令执行的目标文件夹就是这个src文件夹） - pkg --- 存放编译时生成的中间文件 - bin --- 存放编译后生成的可执行文件 GOPATH变量可以设置多个值，多个值之间使用特定的分隔符隔开，例如在Windows系统，分隔符是英文的分号;： 1234λ go env...set GOPATH=C:\\Users\\doge\\go;I:G-Projects... 值得注意的是：go get命令下载的依赖包会下载在GOPATH指定的第一个值对应的目录中，也就是$Users/$User/go目录下。 GOBIN用于指定go install目标保存路径，目的是避免将所有工作空间的bin路径添加到PATH环境变量中（因此在使用版本控制时，尽量忽略bin、pkg，建议直接在src，或者具体的子包下创建代码仓库）。于此相反的做法，就是在Linux或者Unix系统中，可以在PATH中添加export PATH=$PATH:${GOPATH//://bin:}/bin下把每个GOPATH下的bin都加入到PATH中。 重点来了：Module的出现，就是为了弱化GOPATH的概念，使用Module去管理项目的依赖，那么可以基本忽略GOPATH的原有的功能。 Golang提供的命令 可以通过命令行go help查看Go提供的命令行工具： 这里可以关注一下前面一个栏目的基础命令即可： 命令 功能 使用例子 go bug 报告一个BUG，会调用系统默认浏览器打开提交BUG报告的页面 go bug go build 编译所有的包和依赖 go build [-o output] [-i] [build flags] [packages] go clean 清理执行其它命令时产生的一些文件和目录 go clean [clean flags] [build flags] [packages] go doc 打印附于Go语言程序实体上的文档 go doc pkg.app go env 展示Go的环境变量配置 go env go fix 把指定代码包的所有Go语言源码文件中的旧版本代码修正为新版本的代码，这里的版本是指Go的版本 - go fmt 格式化指定代码为统一的风格 - go generate 扫描与当前包相关的源代码文件，找出所有包含&quot;//go:generate&quot;的特殊注释，提取并执行该特殊注释后面的命令，命令为可执行程序 - go get 根据要求和实际情况从互联网上下载或更新指定的代码包及其依赖包，并对它们进行编译和安装 go get github.com/x/y go install 编译并安装指定的代码包及它们的依赖包 go install go list 列出指定的代码包的信息 - go mod Module相关命令 见下文分析 go run 编译并运行命令源码文件 - go test 对Go语言编写的程序进行测试，简单来说就是运行测试代码 go test mine_test.go go tool 运行特定的Go提供的工具 go tool fix go version 打印Golang的版本 go version go vet 检查Go语言源码中静态错误 go vet 如果想了解每个命令的详细使用教程可以通过go help 命令Topic得到对应的结果，更多或更详细的用法后面在探究Golang编码和基础知识的时候再深入展开。 Golang依赖管理 之前跟一个前辈讨论对比Java和Golang的生态的时候，笔者指出了Golang在工程化方面对比Java感觉偏弱，最常见的例子就是Java有全球通用的依赖中央仓库，国内也有阿里的Maven仓库做加速，开发者可以很轻易通过GAV（GroupId、ArtifactId和Version）去拉取不同版本的依赖包，这一点在Golang中展现出了弱势。回想起来时间已经过去一年了，Golang也在进步，依赖管理也开始完善，笔者的过去狭隘的思维也改变了（其实不能总用Java的角度去学习其他编程语言，否则很难体会到其他语言的精髓，甚至有时候会衍生一些奇怪的想法，例如：总是想Golang中是否存在类似Java中的Spring或者Mybatis这类框架）。 Golang从1.11版本之后引入了Module作为依赖管理工具，从1.13或者之后的版本，Module作为官方默认的依赖管理工具，对应的命令是go mod [Command]。Module功能的启用与否由环境变量中的GO111MODULE决定，而GO111MODULE有三个可选值： GO111MODULE=off，禁用Module功能，则编译的时候会从GOPATH和vendor文件夹中查找依赖包。 GO111MODULE=on，启用Module功能，则编译的时候会忽略GOPATH和vendor文件夹，编译所需的依赖由go.mod文件描述，从本地缓存$GOPATH/pkg/mod目录中加载。 GO111MODULE=auto，自动判断是否启用Module功能，此选项是默认值，当项目在$GOPATH/src外且项目根目录有go.mod文件时，则启用Module功能。 Module存在的意义是：没有必要在GOPATH中创建项目，管理项目依赖的第三方包信息可以独立管理。go mod支持的所有命令如下： go mod命令 功能 go mod download 下载依赖的模块到本地缓存中，本地缓存的默认路径是$GOPATH/pkg/mod目录 go mod edit 编辑go.mod文件 go mod graph 打印模块依赖图 go mod init 基于当前文件夹初始化一个新模块,，创建go.mod文件 go mod tidy 添加缺失的模块，移除无用的模块 go mod vendor 把所有依赖拷贝到vendor文件夹中 go mod verify 校验依赖，检查依赖内容是否和预期一致 go mod why 解释为什么需要引入包（packages）和模块（modules） 使用Module进行依赖管理 先使用JetBrains Goland创建一个新项目，项目里面创建bin、pkg和src三个目录： 项目创建完成后，根目录中已经存在了一个go.mod文件，也就是JetBrains Goland已经帮我们在当前目录执行过go mod init，文件内容是： 1module \"module-sample\" src目录下引入一个app.go文件： 123456789101112131415161718192021222324252627package mainimport ( \"fmt\" \"github.com/garyburd/redigo/redis\")func main() &#123; connection, err := redis.Dial(\"tcp\", \"127.0.0.1:6379\", redis.DialDatabase(0)) if nil != err &#123; fmt.Println(\"连接到Redis异常\", err) return &#125; defer connection.Close() n, err := connection.Do(\"SET\", \"name\", \"throwable\") if nil != err &#123; fmt.Println(err) &#125; if n == \"OK\" &#123; fmt.Println(\"执行Set命令成功\") &#125; value, err := redis.String(connection.Do(\"GET\", \"name\")) if nil != err &#123; fmt.Println(err) &#125; fmt.Println(\"Get命令执行结果:\", value)&#125; 会发现，整个文件的依赖都是标红的，也就是依赖没有下载和导入： 此时使用go mod tidy进行依赖整理，执行完毕之后，发现根目录生成了一个新的go.sum，它用于记录锁定的依赖记录（依赖的包、路径、版本以及哈希值）。go.sum文件如下： 12github.com/garyburd/redigo v1.6.0 h1:0VruCpn7yAIIu7pWVClQC8wxCJEcG3nyzpMSHKi1PQc=github.com/garyburd/redigo v1.6.0/go.mod h1:NR3MbYisc3/PwhQ00EMzDiPmrwpPxAn5GI05/YaO1SY= 而go.mod文件也被修改： 12345module module-samplego 1.13require github.com/garyburd/redigo v1.6.0 然后使用go mod download下载依赖到本地缓存中，下载完成后，使用go mod vendor把依赖拷贝到当前模块的vendor目录下，那么原来标红的文件就能正常编译了。 go mod管理依赖支持语义化版本号，例如： 依赖版本：foo@v1.2.3。 Git分支的Tag：foo@master。 Git提交点的SHA-1值：foo@e3702bed2。 其他值：如&lt;=v1.1.1、latest等等。 go.mod文件中可以使用如下关键字： module：模块名。 require：引入所需依赖，注意包名和版本，例如： 1require github.com/garyburd/redigo v1.6.0 replace：替换依赖，例如： 12345replace ( golang.org/x/crypto v0.0.0-20180820150726-614d502a4dac =&gt; github.com/golang/crypto v0.0.0-20180820150726-614d502a4dac golang.org/x/net v0.0.0-20180821023952-922f4815f713 =&gt; github.com/golang/net v0.0.0-20180826012351-8a410e7b638d golang.org/x/text v0.3.0 =&gt; github.com/golang/text v0.3.0) indirect：指明是间接引用，例如： 1234require ( github.com/garyburd/redigo v1.6.0 github.com/garyburd/xx v1.0.0 // indirect) 另外，可以单独使用go get命令下载对应的依赖，而go mod download会下载所有用到的依赖。最后附上一些小技巧： 命令 功能 go mod edit -fmt 格式化go.mod文件 go mod edit -require=需要的依赖 添加依赖到go.mod文件 go mod edit -droprequire=指定的依赖 从go.mod文件移除对应的依赖 go mod tidy、go mod download、go mod vendor 三个命令组合使用，相当于全局更新一次所需的依赖 如果熟练使用这些命令，那么依赖管理就会变得相对容易。 小结 本文简单介绍了Golang的Module依赖管理功能，这里简单记录几个要点： go mod download下载的依赖包会存放在Go本地缓存中，具体位置是$GOPATH/pkg/mod（这里的GOPATH一般是就是全局的那个GOPATH，值为$Users/$User/go） 启用Module功能后，模块根目录生成一个go.mod用于记录当前模块的依赖关系。 启用Module功能后，一旦下载了新的依赖，就会在模块根目录生成一个go.sum用于记录被锁定的依赖记录。 go.mod和go.sum最终决定了一棵锁定好的依赖树，最终编译以及安装都是通过这两个描述文件，关联到本地缓存下载好的依赖包完成后续的工作。 （本文完 c-1-d e-a-20191222）","categories":[{"name":"Go","slug":"Go","permalink":"http://throwable.club/blog/categories/Go/"},{"name":"Golang","slug":"Go/Golang","permalink":"http://throwable.club/blog/categories/Go/Golang/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://throwable.club/blog/tags/Go/"},{"name":"Golang","slug":"Golang","permalink":"http://throwable.club/blog/tags/Golang/"}]},{"title":"Mybatis代码生成器Mybatis-Generator使用详解","slug":"mybatis-generator-usage","date":"2019-12-15T17:06:00.000Z","updated":"2019-12-15T17:07:59.251Z","comments":true,"path":"2019/12/16/mybatis-generator-usage/","link":"","permalink":"http://throwable.club/2019/12/16/mybatis-generator-usage/","excerpt":"前提 最近在做创业项目的时候因为有比较多的新需求，需要频繁基于DDL生成Mybatis适合的实体、Mapper接口和映射文件。其中，代码生成器是MyBatis Generator(MBG)，用到了Mybatis-Generator-Core相关依赖，这里通过一篇文章详细地分析这个代码生成器的使用方式。本文编写的时候使用的Mybatis-Generator版本为1.4.0，其他版本没有进行过调研。","text":"前提 最近在做创业项目的时候因为有比较多的新需求，需要频繁基于DDL生成Mybatis适合的实体、Mapper接口和映射文件。其中，代码生成器是MyBatis Generator(MBG)，用到了Mybatis-Generator-Core相关依赖，这里通过一篇文章详细地分析这个代码生成器的使用方式。本文编写的时候使用的Mybatis-Generator版本为1.4.0，其他版本没有进行过调研。 引入插件 Mybatis-Generator的运行方式有很多种： 基于mybatis-generator-core-x.x.x.jar和其XML配置文件，通过命令行运行。 通过Ant的Task结合其XML配置文件运行。 通过Maven插件运行。 通过Java代码和其XML配置文件运行。 通过Java代码和编程式配置运行。 通过Eclipse Feature运行。 这里只介绍通过Maven插件运行和通过Java代码和其XML配置文件运行这两种方式，两种方式有个特点：都要提前编写好XML配置文件。个人感觉XML配置文件相对直观，后文会花大量篇幅去说明XML配置文件中的配置项及其作用。这里先注意一点：默认的配置文件为ClassPath:generatorConfig.xml。 通过编码和配置文件运行 通过编码方式去运行插件先需要引入mybatis-generator-core依赖，编写本文的时候最新的版本为： 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt; 假设编写好的XML配置文件是ClassPath下的generator-configuration.xml，那么使用代码生成器的编码方式大致如下： 123456789List&lt;String&gt; warnings = new ArrayList&lt;&gt;();// 如果已经存在生成过的文件是否进行覆盖boolean overwrite = true;File configFile = new File(\"ClassPath路径/generator-configuration.xml\");ConfigurationParser cp = new ConfigurationParser(warnings);Configuration config = cp.parseConfiguration(configFile);DefaultShellCallback callback = new DefaultShellCallback(overwrite);MyBatisGenerator generator = new MyBatisGenerator(config, callback, warnings);generator.generate(null); 通过Maven插件运行 如果使用Maven插件，那么不需要引入mybatis-generator-core依赖，只需要引入一个Maven的插件mybatis-generator-maven-plugin： 1234567891011121314151617181920212223&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Generate MyBatis Artifacts&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!-- 输出详细信息 --&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;!-- 覆盖生成文件 --&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;!-- 定义配置文件 --&gt; &lt;configurationFile&gt;$&#123;basedir&#125;/src/main/resources/generator-configuration.xml&lt;/configurationFile&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/plugins&gt; mybatis-generator-maven-plugin的更详细配置和可选参数可以参考：Running With Maven。插件配置完毕之后，使用下面的命令即可运行： 1mvn mybatis-generator:generate XML配置文件详解 XML配置文件才是Mybatis-Generator的核心，它用于控制代码生成的所有行为。所有非标签独有的公共配置的Key可以在mybatis-generator-core的PropertyRegistry类中找到。下面是一个相对完整的配置文件的模板： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"&gt;&lt;generatorConfiguration&gt; &lt;properties resource=\"db.properties\"/&gt; &lt;classPathEntry location=\"/Program Files/IBM/SQLLIB/java/db2java.zip\" /&gt; &lt;context id=\"DB2Tables\" targetRuntime=\"MyBatis3\"&gt; &lt;jdbcConnection driverClass=\"COM.ibm.db2.jdbc.app.DB2Driver\" connectionURL=\"jdbc:db2:TEST\" userId=\"db2admin\" password=\"db2admin\"&gt; &lt;/jdbcConnection&gt; &lt;plugin type=\"org.mybatis.generator.plugins.SerializablePlugin\"/&gt; &lt;commentGenerator&gt; &lt;property name=\"suppressDate\" value=\"true\"/&gt; &lt;property name=\"suppressAllComments\" value=\"true\"/&gt; &lt;/commentGenerator&gt; &lt;javaTypeResolver&gt; &lt;property name=\"forceBigDecimals\" value=\"false\" /&gt; &lt;/javaTypeResolver&gt; &lt;javaModelGenerator targetPackage=\"test.model\" targetProject=\"\\MBGTestProject\\src\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\" /&gt; &lt;property name=\"trimStrings\" value=\"true\" /&gt; &lt;/javaModelGenerator&gt; &lt;sqlMapGenerator targetPackage=\"test.xml\" targetProject=\"\\MBGTestProject\\src\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\" /&gt; &lt;/sqlMapGenerator&gt; &lt;javaClientGenerator type=\"XMLMAPPER\" targetPackage=\"test.dao\" targetProject=\"\\MBGTestProject\\src\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\" /&gt; &lt;/javaClientGenerator&gt; &lt;table schema=\"DB2ADMIN\" tableName=\"ALLTYPES\" domainObjectName=\"Customer\" &gt; &lt;property name=\"useActualColumnNames\" value=\"true\"/&gt; &lt;generatedKey column=\"ID\" sqlStatement=\"DB2\" identity=\"true\" /&gt; &lt;columnOverride column=\"DATE_FIELD\" property=\"startDate\" /&gt; &lt;ignoreColumn column=\"FRED\" /&gt; &lt;columnOverride column=\"LONG_VARCHAR_FIELD\" jdbcType=\"VARCHAR\" /&gt; &lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 配置文件中，最外层的标签为&lt;generatorConfiguration&gt;，它的子标签包括： 0或者1个&lt;properties&gt;标签，用于指定全局配置文件，下面可以通过占位符的形式读取&lt;properties&gt;指定文件中的值。 0或者N个&lt;classPathEntry&gt;标签，&lt;classPathEntry&gt;只有一个location属性，用于指定数据源驱动包（jar或者zip）的绝对路径，具体选择什么驱动包取决于连接什么类型的数据源。 1或者N个&lt;context&gt;标签，用于运行时的解析模式和具体的代码生成行为，所以这个标签里面的配置是最重要的。 下面分别列举和分析一下&lt;context&gt;标签和它的主要子标签的一些属性配置和功能。 context标签 &lt;context&gt;标签在mybatis-generator-core中对应的实现类为org.mybatis.generator.config.Context，它除了大量的子标签配置之外，比较主要的属性是： id：Context示例的唯一ID，用于输出错误信息时候作为唯一标记。 targetRuntime：用于执行代码生成模式。 defaultModelType：控制Domain类的生成行为。执行引擎为MyBatis3DynamicSql或者MyBatis3Kotlin时忽略此配置，可选值： conditional：默认值，类似hierarchical，但是只有一个主键的时候会合并所有属性生成在同一个类。 flat：所有内容全部生成在一个对象中。 hierarchical：键生成一个XXKey对象，Blob等单独生成一个对象，其他简单属性在一个对象中。 targetRuntime属性的可选值比较多，这里做个简单的小结： 属性 功能描述 MyBatis3DynamicSql 默认值，兼容JDK8+和MyBatis 3.4.2+，不会生成XML映射文件，忽略&lt;sqlMapGenerator&gt;的配置项，也就是Mapper全部注解化，依赖于MyBatis Dynamic SQL类库 MyBatis3Kotlin 行为类似于MyBatis3DynamicSql，不过兼容Kotlin的代码生成 MyBatis3 提供基本的基于动态SQL的CRUD方法和XXXByExample方法，会生成XML映射文件 MyBatis3Simple 提供基本的基于动态SQL的CRUD方法，会生成XML映射文件 MyBatis3DynamicSqlV1 已经过时，不推荐使用 笔者偏向于把SQL文件和代码分离，所以一般选用MyBatis3或者MyBatis3Simple。例如： 1&lt;context id=\"default\" targetRuntime=\"MyBatis3\"&gt; &lt;context&gt;标签支持0或N个&lt;property&gt;标签，&lt;property&gt;的可选属性有： property属性 功能描述 默认值 备注 autoDelimitKeywords 是否使用分隔符号括住数据库关键字 false 例如MySQL中会使用反引号括住关键字 beginningDelimiter 分隔符号的开始符号 &quot; endingDelimiter 分隔符号的结束号 &quot; javaFileEncoding 文件的编码 系统默认值 来源于java.nio.charset.Charset javaFormatter 类名和文件格式化器 DefaultJavaFormatter 见JavaFormatter和DefaultJavaFormatter targetJava8 是否JDK8和启动其特性 true kotlinFileEncoding Kotlin文件编码 系统默认值 来源于java.nio.charset.Charset kotlinFormatter Kotlin类名和文件格式化器 DefaultKotlinFormatter 见KotlinFormatter和DefaultKotlinFormatter xmlFormatter XML文件格式化器 DefaultXmlFormatter 见XmlFormatter和DefaultXmlFormatter jdbcConnection标签 &lt;jdbcConnection&gt;标签用于指定数据源的连接信息，它在mybatis-generator-core中对应的实现类为org.mybatis.generator.config.JDBCConnectionConfiguration，主要属性包括： 属性 功能描述 是否必须 driverClass 数据源驱动的全类名 Y connectionURL JDBC的连接URL Y userId 连接到数据源的用户名 N password 连接到数据源的密码 N commentGenerator标签 &lt;commentGenerator&gt;标签是可选的，用于控制生成的实体的注释内容。它在mybatis-generator-core中对应的实现类为org.mybatis.generator.internal.DefaultCommentGenerator，可以通过可选的type属性指定一个自定义的CommentGenerator实现。&lt;commentGenerator&gt;标签支持0或N个&lt;property&gt;标签，&lt;property&gt;的可选属性有： property属性 功能描述 默认值 suppressAllComments 是否生成注释 false suppressDate 是否在注释中添加生成的时间戳 false dateFormat 配合suppressDate使用，指定输出时间戳的格式 java.util.Date#toString() addRemarkComments 是否输出表和列的Comment信息 false 笔者建议保持默认值，也就是什么注释都不输出，生成代码干净的实体。 javaTypeResolver标签 &lt;javaTypeResolver&gt;标签是&lt;context&gt;的子标签，用于解析和计算数据库列类型和Java类型的映射关系，该标签只包含一个type属性，用于指定org.mybatis.generator.api.JavaTypeResolver接口的实现类。&lt;javaTypeResolver&gt;标签支持0或N个&lt;property&gt;标签，&lt;property&gt;的可选属性有： property属性 功能描述 默认值 forceBigDecimals 是否强制把所有的数字类型强制使用java.math.BigDecimal类型表示 false useJSR310Types 是否支持JSR310，主要是JSR310的新日期类型 false 如果useJSR310Types属性设置为true，那么生成代码的时候类型映射关系如下（主要针对日期时间类型）： 数据库（JDBC）类型 Java类型 DATE java.time.LocalDate TIME java.time.LocalTime TIMESTAMP java.time.LocalDateTime TIME_WITH_TIMEZONE java.time.OffsetTime TIMESTAMP_WITH_TIMEZONE java.time.OffsetDateTime 引入mybatis-generator-core后，可以查看JavaTypeResolver的默认实现为JavaTypeResolverDefaultImpl，从它的源码可以得知一些映射关系： 123456BIGINT --&gt; LongBIT --&gt; BooleanINTEGER --&gt; IntegerSMALLINT --&gt; ShortTINYINT --&gt; Byte...... 有些时候，我们希望INTEGER、SMALLINT和TINYINT都映射为Integer，那么我们需要覆盖JavaTypeResolverDefaultImpl的构造方法： 12345678910public class DefaultJavaTypeResolver extends JavaTypeResolverDefaultImpl &#123; public DefaultJavaTypeResolver() &#123; super(); typeMap.put(Types.SMALLINT, new JdbcTypeInformation(\"SMALLINT\", new FullyQualifiedJavaType(Integer.class.getName()))); typeMap.put(Types.TINYINT, new JdbcTypeInformation(\"TINYINT\", new FullyQualifiedJavaType(Integer.class.getName()))); &#125;&#125; 注意一点的是这种自定义实现JavaTypeResolver接口的方式使用编程式运行MBG会相对方便，如果需要使用Maven插件运行，那么需要把上面的DefaultJavaTypeResolver类打包到插件中。 javaModelGenerator标签 &lt;javaModelGenerator标签&gt;标签是&lt;context&gt;的子标签，主要用于控制实体（Model）类的代码生成行为。它支持的属性如下： 属性 功能描述 是否必须 备注 targetPackage 生成的实体类的包名 Y 例如club.throwable.model targetProject 生成的实体类文件相对于项目（根目录）的位置 Y 例如src/main/java &lt;javaModelGenerator标签&gt;标签支持0或N个&lt;property&gt;标签，&lt;property&gt;的可选属性有： property属性 功能描述 默认值 备注 constructorBased 是否生成一个带有所有字段属性的构造函数 false MyBatis3Kotlin模式下忽略此属性配置 enableSubPackages 是否允许通过Schema生成子包 false 如果为true，例如包名为club.throwable，如果Schema为xyz，那么实体类文件最终会生成在club.throwable.xyz目录 exampleTargetPackage 生成的伴随实体类的Example类的包名 - - exampleTargetProject 生成的伴随实体类的Example类文件相对于项目（根目录）的位置 - - immutable 是否不可变 false 如果为true，则不会生成Setter方法，所有字段都使用final修饰，提供一个带有所有字段属性的构造函数 rootClass 为生成的实体类添加父类 - 通过value指定父类的全类名即可 trimStrings Setter方法是否对字符串类型进行一次trim操作 false - javaClientGenerator标签 &lt;javaClientGenerator&gt;标签是&lt;context&gt;的子标签，主要用于控制Mapper接口的代码生成行为。它支持的属性如下： 属性 功能描述 是否必须 备注 type Mapper接口生成策略 Y &lt;context&gt;标签的targetRuntime属性为MyBatis3DynamicSql或者MyBatis3Kotlin时此属性配置忽略 targetPackage 生成的Mapper接口的包名 Y 例如club.throwable.mapper targetProject 生成的Mapper接口文件相对于项目（根目录）的位置 Y 例如src/main/java type属性的可选值如下： ANNOTATEDMAPPER：Mapper接口生成的时候依赖于注解和SqlProviders（也就是纯注解实现），不会生成XML映射文件。 XMLMAPPER：Mapper接口生成接口方法，对应的实现代码生成在XML映射文件中（也就是纯映射文件实现）。 MIXEDMAPPER：Mapper接口生成的时候复杂的方法实现生成在XML映射文件中，而简单的实现通过注解和SqlProviders实现（也就是注解和映射文件混合实现）。 注意两点： &lt;context&gt;标签的targetRuntime属性指定为MyBatis3Simple的时候，type只能选用ANNOTATEDMAPPER或者XMLMAPPER。 &lt;context&gt;标签的targetRuntime属性指定为MyBatis3的时候，type可以选用ANNOTATEDMAPPER、XMLMAPPER或者MIXEDMAPPER。 &lt;javaClientGenerator&gt;标签支持0或N个&lt;property&gt;标签，&lt;property&gt;的可选属性有： property属性 功能描述 默认值 备注 enableSubPackages 是否允许通过Schema生成子包 false 如果为true，例如包名为club.throwable，如果Schema为xyz，那么Mapper接口文件最终会生成在club.throwable.xyz目录 useLegacyBuilder 是否通过SQL Builder生成动态SQL false rootInterface 为生成的Mapper接口添加父接口 - 通过value指定父接口的全类名即可 sqlMapGenerator标签 &lt;sqlMapGenerator&gt;标签是&lt;context&gt;的子标签，主要用于控制XML映射文件的代码生成行为。它支持的属性如下： 属性 功能描述 是否必须 备注 targetPackage 生成的XML映射文件的包名 Y 例如mappings targetProject 生成的XML映射文件相对于项目（根目录）的位置 Y 例如src/main/resources &lt;sqlMapGenerator&gt;标签支持0或N个&lt;property&gt;标签，&lt;property&gt;的可选属性有： property属性 功能描述 默认值 备注 enableSubPackages 是否允许通过Schema生成子包 false - plugin标签 &lt;plugin&gt;标签是&lt;context&gt;的子标签，用于引入一些插件对代码生成的一些特性进行扩展，该标签只包含一个type属性，用于指定org.mybatis.generator.api.Plugin接口的实现类。内置的插件实现见Supplied Plugins。例如：引入org.mybatis.generator.plugins.SerializablePlugin插件会让生成的实体类自动实现java.io.Serializable接口并且添加serialVersionUID属性。 table标签 &lt;table&gt;标签是&lt;context&gt;的子标签，主要用于配置要生成代码的数据库表格，定制一些代码生成行为等等。它支持的属性众多，列举如下： 属性 功能描述 是否必须 备注 tableName 数据库表名称 Y 例如t_order schema 数据库Schema N - catalog 数据库Catalog N - alias 表名称标签 N 如果指定了此值，则查询列的时候结果格式为alias_column domainObjectName 表对应的实体类名称，可以通过.指定包路径 N 如果指定了bar.User，则包名为bar，实体类名称为User mapperName 表对应的Mapper接口类名称，可以通过.指定包路径 N 如果指定了bar.UserMapper，则包名为bar，Mapper接口类名称为UserMapper sqlProviderName 动态SQL提供类SqlProvider的类名称 N - enableInsert 是否允许生成insert方法 N 默认值为true，执行引擎为MyBatis3DynamicSql或者MyBatis3Kotlin时忽略此配置 enableSelectByPrimaryKey 是否允许生成selectByPrimaryKey方法 N 默认值为true，执行引擎为MyBatis3DynamicSql或者MyBatis3Kotlin时忽略此配置 enableSelectByExample 是否允许生成selectByExample方法 N 默认值为true，执行引擎为MyBatis3DynamicSql或者MyBatis3Kotlin时忽略此配置 enableUpdateByPrimaryKey 是否允许生成updateByPrimaryKey方法 N 默认值为true，执行引擎为MyBatis3DynamicSql或者MyBatis3Kotlin时忽略此配置 enableDeleteByPrimaryKey 是否允许生成deleteByPrimaryKey方法 N 默认值为true，执行引擎为MyBatis3DynamicSql或者MyBatis3Kotlin时忽略此配置 enableDeleteByExample 是否允许生成deleteByExample方法 N 默认值为true，执行引擎为MyBatis3DynamicSql或者MyBatis3Kotlin时忽略此配置 enableCountByExample 是否允许生成countByExample方法 N 默认值为true，执行引擎为MyBatis3DynamicSql或者MyBatis3Kotlin时忽略此配置 enableUpdateByExample 是否允许生成updateByExample方法 N 默认值为true，执行引擎为MyBatis3DynamicSql或者MyBatis3Kotlin时忽略此配置 selectByPrimaryKeyQueryId value指定对应的主键列提供列表查询功能 N 执行引擎为MyBatis3DynamicSql或者MyBatis3Kotlin时忽略此配置 selectByExampleQueryId value指定对应的查询ID提供列表查询功能 N 执行引擎为MyBatis3DynamicSql或者MyBatis3Kotlin时忽略此配置 modelType 覆盖&lt;context&gt;的defaultModelType属性 N 见&lt;context&gt;的defaultModelType属性 escapeWildcards 是否对通配符进行转义 N - delimitIdentifiers 标记匹配表名称的时候是否需要使用分隔符去标记生成的SQL N - delimitAllColumns 是否所有的列都添加分隔符 N 默认值为false，如果设置为true，所有列名会添加起始和结束分隔符 &lt;table&gt;标签支持0或N个&lt;property&gt;标签，&lt;property&gt;的可选属性有： property属性 功能描述 默认值 备注 constructorBased 是否为实体类生成一个带有所有字段的构造函数 false 执行引擎为MyBatis3Kotlin的时候此属性忽略 ignoreQualifiersAtRuntime 是否在运行时忽略别名 false 如果为true，则不会在生成表的时候把schema和catalog作为表的前缀 immutable 实体类是否不可变 false 执行引擎为MyBatis3Kotlin的时候此属性忽略 modelOnly 是否仅仅生成实体类 false - rootClass 如果配置此属性，则实体类会继承此指定的超类 - 如果有主键属性会把主键属性在超类生成 rootInterface 如果配置此属性，则实体类会实现此指定的接口 - 执行引擎为MyBatis3Kotlin或者MyBatis3DynamicSql的时候此属性忽略 runtimeCatalog 指定运行时的Catalog - 当生成表和运行时的表的Catalog不一样的时候可以使用该属性进行配置 runtimeSchema 指定运行时的Schema - 当生成表和运行时的表的Schema不一样的时候可以使用该属性进行配置 runtimeTableName 指定运行时的表名称 - 当生成表和运行时的表的表名称不一样的时候可以使用该属性进行配置 selectAllOrderByClause 指定字句内容添加到selectAll()方法的order by子句之中 - 执行引擎为MyBatis3Simple的时候此属性才适用 trimStrings 实体类的字符串类型属性会做trim处理 - 执行引擎为MyBatis3Kotlin的时候此属性忽略 useActualColumnNames 是否使用列名作为实体类的属性名 false - useColumnIndexes XML映射文件中生成的ResultMap使用列索引定义而不是列名称 false 执行引擎为MyBatis3Kotlin或者MyBatis3DynamicSql的时候此属性忽略 useCompoundPropertyNames 是否把列名和列备注拼接起来生成实体类属性名 false - &lt;table&gt;标签还支持众多的非property的子标签： 0或1个&lt;generatedKey&gt;用于指定主键生成的规则，指定此标签后会生成一个&lt;selectKey&gt;标签： 12345&lt;!-- column：指定主键列 --&gt;&lt;!-- sqlStatement：查询主键的SQL语句，例如填写了MySql，则使用SELECT LAST_INSERT_ID() --&gt;&lt;!-- type：可选值为pre或者post，pre指定selectKey标签的order为BEFORE，post指定selectKey标签的order为AFTER --&gt;&lt;!-- identity：true的时候，指定selectKey标签的order为AFTER --&gt;&lt;generatedKey column=\"id\" sqlStatement=\"MySql\" type=\"post\" identity=\"true\" /&gt; 0或1个&lt;domainObjectRenamingRule&gt;用于指定实体类重命名规则： 1234&lt;!-- searchString中正则命中的实体类名部分会替换为replaceString --&gt;&lt;domainObjectRenamingRule searchString=\"^Sys\" replaceString=\"\"/&gt;&lt;!-- 例如 SysUser会变成User --&gt;&lt;!-- 例如 SysUserMapper会变成UserMapper --&gt; 0或1个&lt;columnRenamingRule&gt;用于指定列重命名规则： 1234&lt;!-- searchString中正则命中的列名部分会替换为replaceString --&gt;&lt;columnRenamingRule searchString=\"^CUST_\" replaceString=\"\"/&gt;&lt;!-- 例如 CUST_BUSINESS_NAME会变成BUSINESS_NAME（useActualColumnNames=true） --&gt;&lt;!-- 例如 CUST_BUSINESS_NAME会变成businessName（useActualColumnNames=false） --&gt; 0或N个&lt;columnOverride&gt;用于指定具体列的覆盖映射规则： 12345678&lt;!-- column：指定要覆盖配置的列 --&gt;&lt;!-- property：指定要覆盖配置的属性 --&gt;&lt;!-- delimitedColumnName：是否为列名添加定界符，例如`&#123;column&#125;` --&gt;&lt;!-- isGeneratedAlways：是否一定生成此列 --&gt;&lt;columnOverride column=\"customer_name\" property=\"customerName\" javaType=\"\" jdbcType=\"\" typeHandler=\"\" delimitedColumnName=\"\" isGeneratedAlways=\"\"&gt; &lt;!-- 覆盖table或者javaModelGenerator级别的trimStrings属性配置 --&gt; &lt;property name=\"trimStrings\" value=\"true\"/&gt;&lt;columnOverride/&gt; 0或N个&lt;ignoreColumn&gt;用于指定忽略生成的列： 1&lt;ignoreColumn column=\"version\" delimitedColumnName=\"false\"/&gt; 实战 如果需要深度定制一些代码生成行为，建议引入mybatis-generator-core并且通过编程式执行代码生成方法，否则可以选用Maven插件。假设我们在本地数据local有一张t_order表如下： 123456789CREATE TABLE `t_order`( id BIGINT UNSIGNED PRIMARY KEY COMMENT '主键', order_id VARCHAR(64) NOT NULL COMMENT '订单ID', create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', amount DECIMAL(10, 2) NOT NULL DEFAULT 0 COMMENT '金额', order_status TINYINT NOT NULL DEFAULT 0 COMMENT '订单状态', UNIQUE uniq_order_id (`order_id`)) COMMENT '订单表'; 假设项目的结构如下： 123456mbg-sample - main - java - club - throwable - resources 下面会基于此前提举三个例子。编写基础的XML配置文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"&gt;&lt;generatorConfiguration&gt; &lt;!-- 驱动包绝对路径 --&gt; &lt;classPathEntry location=\"I:\\Develop\\Maven-Repository\\mysql\\mysql-connector-java\\5.1.48\\mysql-connector-java-5.1.48.jar\"/&gt; &lt;context id=\"default\" targetRuntime=\"这里选择合适的引擎\"&gt; &lt;property name=\"javaFileEncoding\" value=\"UTF-8\"/&gt; &lt;!-- 不输出注释 --&gt; &lt;commentGenerator&gt; &lt;property name=\"suppressDate\" value=\"true\"/&gt; &lt;property name=\"suppressAllComments\" value=\"true\"/&gt; &lt;/commentGenerator&gt; &lt;jdbcConnection driverClass=\"com.mysql.jdbc.Driver\" connectionURL=\"jdbc:mysql://localhost:3306/local\" userId=\"root\" password=\"root\"&gt; &lt;/jdbcConnection&gt; &lt;!-- 不强制把所有的数字类型转化为BigDecimal --&gt; &lt;javaTypeResolver&gt; &lt;property name=\"forceBigDecimals\" value=\"false\"/&gt; &lt;/javaTypeResolver&gt; &lt;javaModelGenerator targetPackage=\"club.throwable.entity\" targetProject=\"src/main/java\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/javaModelGenerator&gt; &lt;sqlMapGenerator targetPackage=\"mappings\" targetProject=\"src/main/resources\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/sqlMapGenerator&gt; &lt;javaClientGenerator type=\"这里选择合适的Mapper类型\" targetPackage=\"club.throwable.dao\" targetProject=\"src/main/java\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/javaClientGenerator&gt; &lt;table tableName=\"t_order\" enableCountByExample=\"false\" enableDeleteByExample=\"false\" enableSelectByExample=\"false\" enableUpdateByExample=\"false\" domainObjectName=\"Order\" mapperName=\"OrderMapper\"&gt; &lt;generatedKey column=\"id\" sqlStatement=\"MySql\"/&gt; &lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 纯注解 使用纯注解需要引入mybatis-dynamic-sql： 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.dynamic-sql&lt;/groupId&gt; &lt;artifactId&gt;mybatis-dynamic-sql&lt;/artifactId&gt; &lt;version&gt;1.1.4&lt;/version&gt;&lt;/dependency&gt; 需要修改两个位置： 12345&lt;context id=\"default\" targetRuntime=\"MyBatis3DynamicSql\"&gt;...&lt;javaClientGenerator type=\"ANNOTATEDMAPPER\"... 运行结果会生成三个类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256// club.throwable.entitypublic class Order &#123; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") private Long id; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") private String orderId; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") private Date createTime; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") private BigDecimal amount; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") private Byte orderStatus; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public Long getId() &#123; return id; &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public void setId(Long id) &#123; this.id = id; &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public String getOrderId() &#123; return orderId; &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public void setOrderId(String orderId) &#123; this.orderId = orderId; &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public Date getCreateTime() &#123; return createTime; &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public void setCreateTime(Date createTime) &#123; this.createTime = createTime; &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public BigDecimal getAmount() &#123; return amount; &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public void setAmount(BigDecimal amount) &#123; this.amount = amount; &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public Byte getOrderStatus() &#123; return orderStatus; &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public void setOrderStatus(Byte orderStatus) &#123; this.orderStatus = orderStatus; &#125;&#125;// club.throwable.daopublic final class OrderDynamicSqlSupport &#123; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public static final Order order = new Order(); @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public static final SqlColumn&lt;Long&gt; id = order.id; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public static final SqlColumn&lt;String&gt; orderId = order.orderId; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public static final SqlColumn&lt;Date&gt; createTime = order.createTime; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public static final SqlColumn&lt;BigDecimal&gt; amount = order.amount; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public static final SqlColumn&lt;Byte&gt; orderStatus = order.orderStatus; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") public static final class Order extends SqlTable &#123; public final SqlColumn&lt;Long&gt; id = column(\"id\", JDBCType.BIGINT); public final SqlColumn&lt;String&gt; orderId = column(\"order_id\", JDBCType.VARCHAR); public final SqlColumn&lt;Date&gt; createTime = column(\"create_time\", JDBCType.TIMESTAMP); public final SqlColumn&lt;BigDecimal&gt; amount = column(\"amount\", JDBCType.DECIMAL); public final SqlColumn&lt;Byte&gt; orderStatus = column(\"order_status\", JDBCType.TINYINT); public Order() &#123; super(\"t_order\"); &#125; &#125;&#125;@Mapperpublic interface OrderMapper &#123; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") BasicColumn[] selectList = BasicColumn.columnList(id, orderId, createTime, amount, orderStatus); @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") @SelectProvider(type=SqlProviderAdapter.class, method=\"select\") long count(SelectStatementProvider selectStatement); @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") @DeleteProvider(type=SqlProviderAdapter.class, method=\"delete\") int delete(DeleteStatementProvider deleteStatement); @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") @InsertProvider(type=SqlProviderAdapter.class, method=\"insert\") @SelectKey(statement=\"SELECT LAST_INSERT_ID()\", keyProperty=\"record.id\", before=true, resultType=Long.class) int insert(InsertStatementProvider&lt;Order&gt; insertStatement); @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") @SelectProvider(type=SqlProviderAdapter.class, method=\"select\") @Results(id=\"OrderResult\", value = &#123; @Result(column=\"id\", property=\"id\", jdbcType=JdbcType.BIGINT, id=true), @Result(column=\"order_id\", property=\"orderId\", jdbcType=JdbcType.VARCHAR), @Result(column=\"create_time\", property=\"createTime\", jdbcType=JdbcType.TIMESTAMP), @Result(column=\"amount\", property=\"amount\", jdbcType=JdbcType.DECIMAL), @Result(column=\"order_status\", property=\"orderStatus\", jdbcType=JdbcType.TINYINT) &#125;) Optional&lt;Order&gt; selectOne(SelectStatementProvider selectStatement); @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") @SelectProvider(type=SqlProviderAdapter.class, method=\"select\") @Results(id=\"OrderResult\", value = &#123; @Result(column=\"id\", property=\"id\", jdbcType=JdbcType.BIGINT, id=true), @Result(column=\"order_id\", property=\"orderId\", jdbcType=JdbcType.VARCHAR), @Result(column=\"create_time\", property=\"createTime\", jdbcType=JdbcType.TIMESTAMP), @Result(column=\"amount\", property=\"amount\", jdbcType=JdbcType.DECIMAL), @Result(column=\"order_status\", property=\"orderStatus\", jdbcType=JdbcType.TINYINT) &#125;) List&lt;Order&gt; selectMany(SelectStatementProvider selectStatement); @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") @UpdateProvider(type=SqlProviderAdapter.class, method=\"update\") int update(UpdateStatementProvider updateStatement); @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") default long count(CountDSLCompleter completer) &#123; return MyBatis3Utils.countFrom(this::count, order, completer); &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") default int delete(DeleteDSLCompleter completer) &#123; return MyBatis3Utils.deleteFrom(this::delete, order, completer); &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") default int deleteByPrimaryKey(Long id_) &#123; return delete(c -&gt; c.where(id, isEqualTo(id_)) ); &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") default int insert(Order record) &#123; return MyBatis3Utils.insert(this::insert, record, order, c -&gt; c.map(id).toProperty(\"id\") .map(orderId).toProperty(\"orderId\") .map(createTime).toProperty(\"createTime\") .map(amount).toProperty(\"amount\") .map(orderStatus).toProperty(\"orderStatus\") ); &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") default int insertSelective(Order record) &#123; return MyBatis3Utils.insert(this::insert, record, order, c -&gt; c.map(id).toProperty(\"id\") .map(orderId).toPropertyWhenPresent(\"orderId\", record::getOrderId) .map(createTime).toPropertyWhenPresent(\"createTime\", record::getCreateTime) .map(amount).toPropertyWhenPresent(\"amount\", record::getAmount) .map(orderStatus).toPropertyWhenPresent(\"orderStatus\", record::getOrderStatus) ); &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") default Optional&lt;Order&gt; selectOne(SelectDSLCompleter completer) &#123; return MyBatis3Utils.selectOne(this::selectOne, selectList, order, completer); &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") default List&lt;Order&gt; select(SelectDSLCompleter completer) &#123; return MyBatis3Utils.selectList(this::selectMany, selectList, order, completer); &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") default List&lt;Order&gt; selectDistinct(SelectDSLCompleter completer) &#123; return MyBatis3Utils.selectDistinct(this::selectMany, selectList, order, completer); &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") default Optional&lt;Order&gt; selectByPrimaryKey(Long id_) &#123; return selectOne(c -&gt; c.where(id, isEqualTo(id_)) ); &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") default int update(UpdateDSLCompleter completer) &#123; return MyBatis3Utils.update(this::update, order, completer); &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") static UpdateDSL&lt;UpdateModel&gt; updateAllColumns(Order record, UpdateDSL&lt;UpdateModel&gt; dsl) &#123; return dsl.set(id).equalTo(record::getId) .set(orderId).equalTo(record::getOrderId) .set(createTime).equalTo(record::getCreateTime) .set(amount).equalTo(record::getAmount) .set(orderStatus).equalTo(record::getOrderStatus); &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") static UpdateDSL&lt;UpdateModel&gt; updateSelectiveColumns(Order record, UpdateDSL&lt;UpdateModel&gt; dsl) &#123; return dsl.set(id).equalToWhenPresent(record::getId) .set(orderId).equalToWhenPresent(record::getOrderId) .set(createTime).equalToWhenPresent(record::getCreateTime) .set(amount).equalToWhenPresent(record::getAmount) .set(orderStatus).equalToWhenPresent(record::getOrderStatus); &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") default int updateByPrimaryKey(Order record) &#123; return update(c -&gt; c.set(orderId).equalTo(record::getOrderId) .set(createTime).equalTo(record::getCreateTime) .set(amount).equalTo(record::getAmount) .set(orderStatus).equalTo(record::getOrderStatus) .where(id, isEqualTo(record::getId)) ); &#125; @Generated(\"org.mybatis.generator.api.MyBatisGenerator\") default int updateByPrimaryKeySelective(Order record) &#123; return update(c -&gt; c.set(orderId).equalToWhenPresent(record::getOrderId) .set(createTime).equalToWhenPresent(record::getCreateTime) .set(amount).equalToWhenPresent(record::getAmount) .set(orderStatus).equalToWhenPresent(record::getOrderStatus) .where(id, isEqualTo(record::getId)) ); &#125;&#125; 极简XML映射文件 极简XML映射文件生成只需要简单修改配置文件： 12345&lt;context id=\"default\" targetRuntime=\"MyBatis3Simple\"&gt;...&lt;javaClientGenerator type=\"XMLMAPPER\"... 生成三个文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147// club.throwable.entitypublic class Order &#123; private Long id; private String orderId; private Date createTime; private BigDecimal amount; private Byte orderStatus; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getOrderId() &#123; return orderId; &#125; public void setOrderId(String orderId) &#123; this.orderId = orderId; &#125; public Date getCreateTime() &#123; return createTime; &#125; public void setCreateTime(Date createTime) &#123; this.createTime = createTime; &#125; public BigDecimal getAmount() &#123; return amount; &#125; public void setAmount(BigDecimal amount) &#123; this.amount = amount; &#125; public Byte getOrderStatus() &#123; return orderStatus; &#125; public void setOrderStatus(Byte orderStatus) &#123; this.orderStatus = orderStatus; &#125;&#125;// club.throwable.daopublic interface OrderMapper &#123; int deleteByPrimaryKey(Long id); int insert(Order record); Order selectByPrimaryKey(Long id); List&lt;Order&gt; selectAll(); int updateByPrimaryKey(Order record);&#125;// mappings&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"club.throwable.dao.OrderMapper\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"club.throwable.entity.Order\"&gt; &lt;id column=\"id\" jdbcType=\"BIGINT\" property=\"id\"/&gt; &lt;result column=\"order_id\" jdbcType=\"VARCHAR\" property=\"orderId\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"amount\" jdbcType=\"DECIMAL\" property=\"amount\"/&gt; &lt;result column=\"order_status\" jdbcType=\"TINYINT\" property=\"orderStatus\"/&gt; &lt;/resultMap&gt; &lt;delete id=\"deleteByPrimaryKey\" parameterType=\"java.lang.Long\"&gt; delete from t_order where id = #&#123;id,jdbcType=BIGINT&#125; &lt;/delete&gt; &lt;insert id=\"insert\" parameterType=\"club.throwable.entity.Order\"&gt; &lt;selectKey keyProperty=\"id\" order=\"AFTER\" resultType=\"java.lang.Long\"&gt; SELECT LAST_INSERT_ID() &lt;/selectKey&gt; insert into t_order (order_id, create_time, amount, order_status) values (#&#123;orderId,jdbcType=VARCHAR&#125;, #&#123;createTime,jdbcType=TIMESTAMP&#125;, #&#123;amount,jdbcType=DECIMAL&#125;, #&#123;orderStatus,jdbcType=TINYINT&#125;) &lt;/insert&gt; &lt;update id=\"updateByPrimaryKey\" parameterType=\"club.throwable.entity.Order\"&gt; update t_order set order_id = #&#123;orderId,jdbcType=VARCHAR&#125;, create_time = #&#123;createTime,jdbcType=TIMESTAMP&#125;, amount = #&#123;amount,jdbcType=DECIMAL&#125;, order_status = #&#123;orderStatus,jdbcType=TINYINT&#125; where id = #&#123;id,jdbcType=BIGINT&#125; &lt;/update&gt; &lt;select id=\"selectByPrimaryKey\" parameterType=\"java.lang.Long\" resultMap=\"BaseResultMap\"&gt; select id, order_id, create_time, amount, order_status from t_order where id = #&#123;id,jdbcType=BIGINT&#125; &lt;/select&gt; &lt;select id=\"selectAll\" resultMap=\"BaseResultMap\"&gt; select id, order_id, create_time, amount, order_status from t_order &lt;/select&gt; &lt;resultMap id=\"BaseResultMap\" type=\"club.throwable.entity.Order\"&gt; &lt;id column=\"id\" jdbcType=\"BIGINT\" property=\"id\"/&gt; &lt;result column=\"order_id\" jdbcType=\"VARCHAR\" property=\"orderId\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;result column=\"amount\" jdbcType=\"DECIMAL\" property=\"amount\"/&gt; &lt;result column=\"order_status\" jdbcType=\"TINYINT\" property=\"orderStatus\"/&gt; &lt;/resultMap&gt; &lt;delete id=\"deleteByPrimaryKey\" parameterType=\"java.lang.Long\"&gt; delete from t_order where id = #&#123;id,jdbcType=BIGINT&#125; &lt;/delete&gt; &lt;insert id=\"insert\" parameterType=\"club.throwable.entity.Order\"&gt; &lt;selectKey keyProperty=\"id\" order=\"BEFORE\" resultType=\"java.lang.Long\"&gt; SELECT LAST_INSERT_ID() &lt;/selectKey&gt; insert into t_order (id, order_id, create_time, amount, order_status) values (#&#123;id,jdbcType=BIGINT&#125;, #&#123;orderId,jdbcType=VARCHAR&#125;, #&#123;createTime,jdbcType=TIMESTAMP&#125;, #&#123;amount,jdbcType=DECIMAL&#125;, #&#123;orderStatus,jdbcType=TINYINT&#125;) &lt;/insert&gt; &lt;update id=\"updateByPrimaryKey\" parameterType=\"club.throwable.entity.Order\"&gt; update t_order set order_id = #&#123;orderId,jdbcType=VARCHAR&#125;, create_time = #&#123;createTime,jdbcType=TIMESTAMP&#125;, amount = #&#123;amount,jdbcType=DECIMAL&#125;, order_status = #&#123;orderStatus,jdbcType=TINYINT&#125; where id = #&#123;id,jdbcType=BIGINT&#125; &lt;/update&gt; &lt;select id=\"selectByPrimaryKey\" parameterType=\"java.lang.Long\" resultMap=\"BaseResultMap\"&gt; select id, order_id, create_time, amount, order_status from t_order where id = #&#123;id,jdbcType=BIGINT&#125; &lt;/select&gt; &lt;select id=\"selectAll\" resultMap=\"BaseResultMap\"&gt; select id, order_id, create_time, amount, order_status from t_order &lt;/select&gt;&lt;/mapper&gt; 编程式自定义类型映射 笔者喜欢把所有的非长整型的数字，统一使用Integer接收，因此需要自定义类型映射。编写映射器如下： 12345678910public class DefaultJavaTypeResolver extends JavaTypeResolverDefaultImpl &#123; public DefaultJavaTypeResolver() &#123; super(); typeMap.put(Types.SMALLINT, new JdbcTypeInformation(\"SMALLINT\", new FullyQualifiedJavaType(Integer.class.getName()))); typeMap.put(Types.TINYINT, new JdbcTypeInformation(\"TINYINT\", new FullyQualifiedJavaType(Integer.class.getName()))); &#125;&#125; 此时最好使用编程式运行代码生成器，修改XML配置文件： 1234&lt;javaTypeResolver type=\"club.throwable.mbg.DefaultJavaTypeResolver\"&gt; &lt;property name=\"forceBigDecimals\" value=\"false\"/&gt;&lt;/javaTypeResolver&gt;... 运行方法代码如下： 12345678910111213public class Main &#123; public static void main(String[] args) throws Exception &#123; List&lt;String&gt; warnings = new ArrayList&lt;&gt;(); // 如果已经存在生成过的文件是否进行覆盖 boolean overwrite = true; ConfigurationParser cp = new ConfigurationParser(warnings); Configuration config = cp.parseConfiguration(Main.class.getResourceAsStream(\"/generator-configuration.xml\")); DefaultShellCallback callback = new DefaultShellCallback(overwrite); MyBatisGenerator generator = new MyBatisGenerator(config, callback, warnings); generator.generate(null); &#125;&#125; 数据库的order_status是TINYINT类型，生成出来的文件中的orderStatus字段全部替换使用Integer类型定义。 小结 本文相对详尽地介绍了Mybatis Generator的使用方式，具体分析了XML配置文件中主要标签以及标签属性的功能。因为Mybatis在Java的ORM框架体系中还会有一段很长的时间处于主流地位，了解Mybatis Generator可以简化CRUD方法模板代码、实体以及Mapper接口代码生成，从而解放大量生产力。Mybatis Generator有不少第三方的扩展，例如tk.mapper或者mybatis-plus自身的扩展，可能附加的功能不一样，但是基本的使用是一致的。 参考资料： MyBatis Generator （本文完 c-5-d e-a-20191216 1:00）","categories":[{"name":"Framework","slug":"Framework","permalink":"http://throwable.club/blog/categories/Framework/"},{"name":"Mybatis","slug":"Framework/Mybatis","permalink":"http://throwable.club/blog/categories/Framework/Mybatis/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"http://throwable.club/blog/tags/Mybatis/"}]},{"title":"你的SpringBoot应用真的部署更新成功了吗","slug":"spring-boot-server-deploy-monitor","date":"2019-12-08T17:44:12.000Z","updated":"2019-12-08T17:45:46.863Z","comments":true,"path":"2019/12/09/spring-boot-server-deploy-monitor/","link":"","permalink":"http://throwable.club/2019/12/09/spring-boot-server-deploy-monitor/","excerpt":"前提 当我们在生产环境部署了SpringBoot应用的时候，虽然可以通过Jenkins的构建状态和Linux的ps命令去感知应用是否在新的一次发布中部署和启动成功，但是这种监控手段是运维层面的。那么，可以提供一种手段能够在应用层面感知服务在新的一次发布中的构建部署和启动是否成功吗？这个问题笔者花了一点时间想通了这个问题，通过这篇文章提供一个简单的实现思路。","text":"前提 当我们在生产环境部署了SpringBoot应用的时候，虽然可以通过Jenkins的构建状态和Linux的ps命令去感知应用是否在新的一次发布中部署和启动成功，但是这种监控手段是运维层面的。那么，可以提供一种手段能够在应用层面感知服务在新的一次发布中的构建部署和启动是否成功吗？这个问题笔者花了一点时间想通了这个问题，通过这篇文章提供一个简单的实现思路。 基本思路 其实基本思路很简单，一般SpringBoot应用会使用Maven插件打包（笔者不熟悉Gradle，所以暂时不对Gradle做分析），所以可以这样考虑： Maven插件打包的时候，把构建时间和pom文件中的版本号都写到jar包的描述文件中，正确来说就是MANIFEST.MF文件中。 引入spring-boot-starter-actuator，通过/actuator/info端点去暴露应用的信息（最好控制网络访问权限为只允许内网访问）。 把第1步中打包到jar包中的MANIFEST.MF文件的内容读取并且加载到SpringBoot环境属性中的info.*属性中，以便可以通过/actuator/info访问。 思路定好了，那么下面开始实施编码。 编码实现 最近刚好在调研蚂蚁金服的SofaStack体系，这里引入SofaBoot编写示例。pom文件如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;club.throwable&lt;/groupId&gt; &lt;artifactId&gt;sofa-boot-sample&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;sofa-boot-sample&lt;/name&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;sofa.boot.version&gt;3.2.0&lt;/sofa.boot.version&gt; &lt;spring.boot.version&gt;2.1.0.RELEASE&lt;/spring.boot.version&gt; &lt;maven.build.timestamp.format&gt;yyyy-MM-dd HH:mm:ss.SSS&lt;/maven.build.timestamp.format&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.boot.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt; &lt;artifactId&gt;sofaboot-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;sofa.boot.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt; &lt;artifactId&gt;healthcheck-sofa-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;sofa-boot-sample&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;$&#123;maven.compiler.source&#125;&lt;/source&gt; &lt;target&gt;$&#123;maven.compiler.target&#125;&lt;/target&gt; &lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.boot.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addBuildEnvironmentEntries&gt;true&lt;/addBuildEnvironmentEntries&gt; &lt;/manifest&gt; &lt;manifestEntries&gt; &lt;Application-Name&gt;$&#123;project.groupId&#125;:$&#123;project.artifactId&#125;:$&#123;project.version&#125;&lt;/Application-Name&gt; &lt;Build-Timestamp&gt;$&#123;maven.build.timestamp&#125;&lt;/Build-Timestamp&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; pom文件中一些属性和占位符的设置，可以参考一下这两个链接：Maven-Archiver和Available Variables。SpringBoot的配置文件application.yaml如下： 12345678910111213141516server: port: 9091management: server: port: 10091 endpoints: enabled-by-default: false web: exposure: include: info endpoint: info: enabled: truespring: application: name: sofa-boot-sample 这里要注意一点：SpringBoot应用通过其Maven插件打出来的jar包解压后的目录如下： 12345678910sofa-boot-sample.jar - META-INF - MANIFEST.MF - maven ... - org - springframework - boot ... - BOOT-INF - classes ... - lib ... 了解此解压目录是我们编写MANIFEST.MF文件的解析实现过程的前提。编写MANIFEST.MF文件的解析类： 12345678910111213141516171819202122232425262728293031323334353637383940414243@SuppressWarnings(\"ConstantConditions\")public enum ManiFestFileExtractUtils &#123; /** * 单例 */ X; private static Map&lt;String, String&gt; RESULT = new HashMap&lt;&gt;(16); private static final Logger LOGGER = LoggerFactory.getLogger(ManiFestFileExtractUtils.class); static &#123; String jarFilePath = ClassUtils.getDefaultClassLoader().getResource(\"\").getPath().replace(\"!/BOOT-INF/classes!/\", \"\"); if (jarFilePath.startsWith(\"file\")) &#123; jarFilePath = jarFilePath.substring(5); &#125; LOGGER.info(\"读取的Jar路径为:&#123;&#125;\", jarFilePath); try (JarFile jarFile = new JarFile(jarFilePath)) &#123; JarEntry entry = jarFile.getJarEntry(\"META-INF/MANIFEST.MF\"); if (null != entry) &#123; BufferedReader reader = new BufferedReader(new InputStreamReader(jarFile.getInputStream(entry), StandardCharsets.UTF_8)); String line; while (null != (line = reader.readLine())) &#123; LOGGER.info(\"读取到行:&#123;&#125;\", line); int i = line.indexOf(\":\"); if (i &gt; -1) &#123; String key = line.substring(0, i).trim(); String value = line.substring(i + 1).trim(); RESULT.put(key, value); &#125; &#125; &#125; &#125; catch (Exception e) &#123; LOGGER.warn(\"解析MANIFEST.MF文件异常\", e); &#125; &#125; public Map&lt;String, String&gt; extract() &#123; return RESULT; &#125;&#125; 可以通过一个CommandLineRunner的实现把MANIFEST.MF文件的内容写到Environment实例中： 1234567891011121314151617181920@Componentpublic class SofaBootSampleRunner implements CommandLineRunner &#123; @Autowired private ConfigurableEnvironment configurableEnvironment; @Override public void run(String... args) throws Exception &#123; MutablePropertySources propertySources = configurableEnvironment.getPropertySources(); Map&lt;String, String&gt; result = ManiFestFileExtractUtils.X.extract(); Properties properties = new Properties(); for (Map.Entry&lt;String, String&gt; entry : result.entrySet()) &#123; String key = \"info.\" + entry.getKey(); properties.setProperty(key, entry.getValue()); &#125; if (!properties.isEmpty()) &#123; propertySources.addFirst(new PropertiesPropertySource(\"infoProperties\", properties)); &#125; &#125;&#125; 启动类如下： 1234567@SpringBootApplicationpublic class SofaBootSampleApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SofaBootSampleApplication.class, args); &#125;&#125; 最终效果 在项目的根目录使用命令mvn package，打出jar包后直接启动： 12cd Jar包的目录java -jar sofa-boot-sample.jar 调用http://localhost:10091/actuator/info接口输出如下： 123456789101112&#123; \"Spring-Boot-Version\": \"2.1.0.RELEASE\", \"Start-Class\": \"club.throwable.sofa.SofaBootSampleApplication\", \"Main-Class\": \"org.springframework.boot.loader.JarLauncher\", \"Manifest-Version\": \"1.0\", \"Build-Jdk-Spec\": \"1.8\", \"Spring-Boot-Classes\": \"BOOT-INF/classes/\", \"Created-By\": \"Maven Jar Plugin 3.2.0\", \"Build-Timestamp\": \"2019-12-08 17:41:21.844\", \"Spring-Boot-Lib\": \"BOOT-INF/lib/\", \"Application-Name\": \"club.throwable:sofa-boot-sample:1.0-SNAPSHOT\"&#125; 改变pom文件中的版本标签&lt;version&gt;为1.0.0，再次打包并且启动成功后调用http://localhost:10091/actuator/info接口输出如下： 123456789101112&#123; \"Spring-Boot-Version\": \"2.1.0.RELEASE\", \"Start-Class\": \"club.throwable.sofa.SofaBootSampleApplication\", \"Main-Class\": \"org.springframework.boot.loader.JarLauncher\", \"Manifest-Version\": \"1.0\", \"Build-Jdk-Spec\": \"1.8\", \"Spring-Boot-Classes\": \"BOOT-INF/classes/\", \"Created-By\": \"Maven Jar Plugin 3.2.0\", \"Build-Timestamp\": \"2019-12-08 17:42:07.273\", \"Spring-Boot-Lib\": \"BOOT-INF/lib/\", \"Application-Name\": \"club.throwable:sofa-boot-sample:1.0.0\"&#125; 可见构建时间戳Build-Timestamp和服务名Application-Name都发生了变化，达到了监控服务是否正常部署和启动的目的。如果有多个服务节点，可以添加一个ip属性加以区分。 小结 这篇文章通过SpringBoot一些实用技巧实现了应用层面监控应用是否正常打包部署更新和启动成功的问题。 （本文完 e-a-20191209:1:39 c-1-d）","categories":[{"name":"Spring","slug":"Spring","permalink":"http://throwable.club/blog/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"http://throwable.club/blog/categories/Spring/SpringBoot/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://throwable.club/blog/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://throwable.club/blog/tags/SpringBoot/"}]},{"title":"SpringMVC请求参数接收总结(一)","slug":"spring-mvc-param-handle-summary-1","date":"2019-12-03T17:21:58.000Z","updated":"2019-12-03T17:24:23.170Z","comments":true,"path":"2019/12/04/spring-mvc-param-handle-summary-1/","link":"","permalink":"http://throwable.club/2019/12/04/spring-mvc-param-handle-summary-1/","excerpt":"前提 在日常使用SpringMVC进行开发的时候，有可能遇到前端各种类型的请求参数，这里做一次相对全面的总结。SpringMVC中处理控制器参数的接口是HandlerMethodArgumentResolver，此接口有众多子类，分别处理不同(注解类型)的参数，下面只列举几个子类： RequestParamMethodArgumentResolver：解析处理使用了@RequestParam注解的参数、MultipartFile类型参数和Simple类型(如long、int等类型)参数。 RequestResponseBodyMethodProcessor：解析处理@RequestBody注解的参数。 PathVariableMapMethodArgumentResolver：解析处理@PathVariable注解的参数。","text":"前提 在日常使用SpringMVC进行开发的时候，有可能遇到前端各种类型的请求参数，这里做一次相对全面的总结。SpringMVC中处理控制器参数的接口是HandlerMethodArgumentResolver，此接口有众多子类，分别处理不同(注解类型)的参数，下面只列举几个子类： RequestParamMethodArgumentResolver：解析处理使用了@RequestParam注解的参数、MultipartFile类型参数和Simple类型(如long、int等类型)参数。 RequestResponseBodyMethodProcessor：解析处理@RequestBody注解的参数。 PathVariableMapMethodArgumentResolver：解析处理@PathVariable注解的参数。 实际上，一般在解析一个控制器的请求参数的时候，用到的是HandlerMethodArgumentResolverComposite，里面装载了所有启用的HandlerMethodArgumentResolver子类。而HandlerMethodArgumentResolver子类在解析参数的时候使用到HttpMessageConverter（实际上也是一个列表，进行遍历匹配解析）子类进行匹配解析，常见的如MappingJackson2HttpMessageConverter（使用Jackson进行序列化和反序列化）。而HandlerMethodArgumentResolver子类到底依赖什么HttpMessageConverter实例实际上是由请求头中的Content-Type（在SpringMVC中统一命名为MediaType，见org.springframework.http.MediaType）决定的，因此我们在处理控制器的请求参数之前必须要明确外部请求的Content-Type到底是什么。上面的逻辑可以直接看源码AbstractMessageConverterMethodArgumentResolver#readWithMessageConverters，思路是比较清晰的。在@RequestMapping注解中，produces和consumes属性就是和请求或者响应的Content-Type相关的： consumes属性：指定处理请求的提交内容类型（Content-Type），例如application/json、text/html等等，只有命中了对应的Content-Type的值才会接受该请求。 produces属性：指定返回的内容类型，仅当某个请求的请求头中的（Accept）类型中包含该指定类型才返回，如果返回的是JSON数据一般考虑使用application/json;charset=UTF-8。 另外提一点，SpringMVC中默认使用Jackson作为JSON的工具包，如果不是完全理解透整套源码的运作，一般不是十分建议修改默认使用的MappingJackson2HttpMessageConverter（例如有些人喜欢使用FastJson，实现HttpMessageConverter引入FastJson做HTTP消息转换器，这种做法并不推荐）。 SpringMVC请求参数接收 其实一般的表单或者JSON数据的请求都是相对简单的，一些复杂的处理主要包括URL路径参数、文件上传、数组或者列表类型数据等。另外，关于参数类型中存在日期类型属性（例如java.util.Date、java.sql.Date、java.time.LocalDate、java.time.LocalDateTime、java.time.ZonedDateTime等等），解析的时候一般需要自定义实现的逻辑实现String--&gt;日期类型的转换。其实道理很简单，日期相关的类型对于每个国家、每个时区甚至每个使用者来说认知都不一定相同，所以SpringMVC并没有对于日期时间类型的解析提供一个通用的解决方案。在演示一些例子可能用到下面的模特类： 1234567891011121314@Datapublic class User &#123; private String name; private Integer age; private List&lt;Contact&gt; contacts;&#125;@Datapublic class Contact &#123; private String name; private String phone;&#125; 下面主要以HTTP的GET方法和POST方法提交在SpringMVC体系中正确处理参数的例子进行分析，还会花精力整理SpringMVC体系中独有的URL路径参数处理的一些技巧以及最常见的日期参数处理的合理实践（对于GET方法和POST方法提交的参数处理，基本囊括了其他如DELETE、PUT等方法的参数处理，随机应变即可）。 GET方法请求参数处理 HTTP(s)协议使用GET方法进行请求的时候，提交的参数位于URL模式的Query部分，也就是URL的?之后的参数，格式是key1=value1&amp;key2=value2。GET方法请求参数可以有多种方法获取： 使用@RequestParam注解处理。 使用对象接收，注意对象的属性名称要和Query中的参数名称一致。 使用HttpServletRequest实例提供的方法（不推荐，存在硬编码）。 假设请求的URL为http://localhost:8080/get?name=doge&amp;age=26，那么控制器如下： 1234567891011121314151617181920212223242526272829@Slf4j@RestControllerpublic class SampleController &#123; @GetMapping(path = \"/get1\") public void get1(@RequestParam(name = \"name\") String name, @RequestParam(name = \"age\") Integer age) &#123; log.info(\"name:&#123;&#125;,age:&#123;&#125;\", name, age); &#125; @GetMapping(path = \"/get2\") public void get2(UserVo vo) &#123; log.info(\"name:&#123;&#125;,age:&#123;&#125;\", vo.getName(), vo.getAge()); &#125; @GetMapping(path = \"/get3\") public void get3(HttpServletRequest request) &#123; String name = request.getParameter(\"name\"); String age = request.getParameter(\"age\"); log.info(\"name:&#123;&#125;,age:&#123;&#125;\", name, age); &#125; @Data public static class UserVo &#123; private String name; private Integer age; &#125;&#125; 表单参数 表单参数，一般对应于页面上&lt;form&gt;标签内的所有&lt;input&gt;标签的name-value聚合而成的参数，一般Content-Type指定为application/x-www-form-urlencoded，也就是会进行URL编码。下面介绍几种常见的表单参数提交的参数形式。 【非对象】- 非对象类型单个参数接收。 对应的控制器如下： 1234567@PostMapping(value = \"/post\")public String post(@RequestParam(name = \"name\") String name, @RequestParam(name = \"age\") Integer age) &#123; String content = String.format(\"name = %s,age = %d\", name, age); log.info(content); return content;&#125; 说实话，如果有毅力的话，所有的复杂参数的提交最终都可以转化为多个单参数接收，不过这样做会产生十分多冗余的代码，而且可维护性比较低。这种情况下，用到的参数处理器是RequestParamMapMethodArgumentResolver。 【对象】 - 对象类型参数接收。 我们接着写一个接口用于提交用户信息，用到的是上面提到的模特类，主要包括用户姓名、年龄和联系人信息列表，这个时候，我们目标的控制器最终编码如下： 12345@PostMapping(value = \"/user\")public User saveUser(User user) &#123; log.info(user.toString()); return user;&#125; 我们还是指定Content-Type为application/x-www-form-urlencoded，接着我们需要构造请求参数： 因为没有使用注解，最终的参数处理器为ServletModelAttributeMethodProcessor，主要是把HttpServletRequest中的表单参数封装到MutablePropertyValues实例中，再通过参数类型实例化(通过构造反射创建User实例)，反射匹配属性进行值的填充。另外，请求复杂参数里面的列表属性请求参数看起来比较奇葩，实际上和在.properties文件中添加最终映射到Map类型的参数的写法是一致的。那么，能不能把整个请求参数塞在一个字段中提交呢？ 直接这样做是不行的，因为实际提交的Form表单，key是user字符串，value实际上也是一个字符串，缺少一个String-&gt;User类型的转换器，实际上RequestParamMethodArgumentResolver依赖WebConversionService中Converter实例列表进行参数转换： 解决办法还是有的，添加一个org.springframework.core.convert.converter.Converter实现即可： 123456789101112131415@Componentpublic class StringUserConverter implements Converter&lt;String, User&gt; &#123; @Autowaired private ObjectMapper objectMapper; @Override public User convert(String source) &#123; try &#123; return objectMapper.readValue(source, User.class); &#125; catch (IOException e) &#123; throw new IllegalArgumentException(e); &#125; &#125;&#125; 上面这种做法属于曲线救国的做法，不推荐使用在生产环境，但是如果有些第三方接口的对接无法避免这种参数，可以选择这种实现方式。 【数组】 - 列表或者数组类型参数。 极度不推荐使用在application/x-www-form-urlencoded这种媒体类型的表单提交的形式下强行使用列表或者数组类型参数，除非是为了兼容处理历史遗留系统的参数提交处理。例如提交的参数形式是： 1list &#x3D; [&quot;string-1&quot;, &quot;string-2&quot;, &quot;string-3&quot;] 那么表单参数的形式要写成： name value list[0] string-1 list[1] string-2 list[2] string-3 控制器的代码如下： 1234@PostMapping(path = \"/list\")public void list(@RequestParam(name=\"list\") List&lt;String&gt; list) &#123; log.info(list);&#125; 一个更加复杂的例子如下，假设想要提交的报文格式如下： 1user &#x3D; [&#123;&quot;name&quot;:&quot;doge-1&quot;,&quot;age&quot;: 21&#125;,&#123;&quot;name&quot;:&quot;doge-2&quot;,&quot;age&quot;: 22&#125;] 那么表单参数的形式要写成： name value user[0].name doge-1 user[0].age 21 user[1].name doge-2 user[1].age 22 控制器的代码如下： 1234567891011@PostMapping(path = \"/user\")public void saveUsers(@RequestParam(name=\"user\") List&lt;UserVo&gt; users) &#123; log.info(users);&#125;@Datapublic class UserVo&#123; private String name; private Integer age;&#125; JSON参数 一般来说，直接在POST请求中的请求体提交一个JSON字符串这种方式对于SpringMVC来说是比较友好的，只需要把Content-Type设置为application/json，提交一个原始的JSON字符串即可，控制器方法参数使用@RequestBody注解处理： 后端控制器的代码也比较简单： 12345@PostMapping(value = \"/user-2\")public User saveUser2(@RequestBody User user) &#123; log.info(user.toString()); return user;&#125; 因为使用了@RequestBody注解，最终使用到的参数处理器为RequestResponseBodyMethodProcessor，实际上会用到MappingJackson2HttpMessageConverter进行参数类型的转换，底层依赖到Jackson相关的包。推荐使用这种方式，这是最常用也是最稳健的JSON参数处理方式。 URL路径参数 URL路径参数，或者叫请求路径参数是基于URL模板获取到的参数，例如/user/{userId}是一个URL模板(URL模板中的参数占位符是{})，实际请求的URL为/user/1，那么通过匹配实际请求的URL和URL模板就能提取到userId为1。在SpringMVC中，URL模板中的路径参数叫做PathVariable，对应注解@PathVariable，对应的参数处理器为PathVariableMethodArgumentResolver。注意一点是，@PathVariable的解析是按照value(name)属性进行匹配，和URL参数的顺序是无关的。举个简单的例子： 后台的控制器如下： 1234567@GetMapping(value = \"/user/&#123;name&#125;/&#123;age&#125;\")public String findUser1(@PathVariable(value = \"age\") Integer age, @PathVariable(value = \"name\") String name) &#123; String content = String.format(\"name = %s,age = %d\", name, age); log.info(content); return content;&#125; 这种用法被广泛使用于Representational State Transfer(REST)的软件架构风格，个人觉得这种风格是比较灵活和清晰的(从URL和请求方法就能完全理解接口的意义和功能)。下面再介绍两种相对特殊的使用方式。 带条件的URL参数。 其实路径参数支持正则表达式，例如我们在使用/sex/{sex}接口的时候，要求sex必须是F(Female)或者M(Male)，那么我们的URL模板可以定义为/sex/{sex:M|F}，代码如下： 12345@GetMapping(value = \"/sex/&#123;sex:M|F&#125;\")public String findUser2(@PathVariable(value = \"sex\") String sex)&#123; log.info(sex); return sex;&#125; 只有/sex/F或者/sex/M的请求才会进入findUser2()控制器方法，其他该路径前缀的请求都是非法的，会返回404状态码。这里仅仅是介绍了一个最简单的URL参数正则表达式的使用方式，更强大的用法可以自行摸索。 @MatrixVariable的使用。 MatrixVariable也是URL参数的一种，对应注解@MatrixVariable，不过它并不是URL中的一个值(这里的值指定是两个&quot;/“之间的部分)，而是值的一部分，它通过”;“进行分隔，通过”=&quot;进行K-V设置。说起来有点抽象，举个例子：假如我们需要打电话给一个名字为doge，性别是男，分组是码畜的程序员，GET请求的URL可以表示为：/call/doge;gender=male;group=programmer，我们设计的控制器方法如下： 12345678@GetMapping(value = \"/call/&#123;name&#125;\")public String find(@PathVariable(value = \"name\") String name, @MatrixVariable(value = \"gender\") String gender, @MatrixVariable(value = \"group\") String group) &#123; String content = String.format(\"name = %s,gender = %s,group = %s\", name, gender, group); log.info(content); return content;&#125; 当然，如果你按照上面的例子写好代码，尝试请求一下该接口发现是报错的：400 Bad Request - Missing matrix variable 'gender' for method parameter of type String。这是因为@MatrixVariable注解的使用是不安全的，在SpringMVC中默认是关闭对其支持。要开启对@MatrixVariable的支持，需要设置RequestMappingHandlerMapping#setRemoveSemicolonContent方法为false： 1234567891011@Configurationpublic class CustomMvcConfiguration implements InitializingBean &#123; @Autowired private RequestMappingHandlerMapping requestMappingHandlerMapping; @Override public void afterPropertiesSet() throws Exception &#123; requestMappingHandlerMapping.setRemoveSemicolonContent(false); &#125;&#125; 除非有很特殊的需要，否则不建议使用@MatrixVariable。 文件上传 文件上传在使用POSTMAN模拟请求的时候需要选择form-data，POST方式进行提交： 假设我们在D盘有一个图片文件叫doge.jpg，现在要通过本地服务接口把文件上传，控制器的代码如下： 1234567@PostMapping(value = \"/file1\")public String file1(@RequestPart(name = \"file1\") MultipartFile multipartFile) &#123; String content = String.format(\"name = %s,originName = %s,size = %d\", multipartFile.getName(), multipartFile.getOriginalFilename(), multipartFile.getSize()); log.info(content); return content;&#125; 控制台输出是： 1name = file1,originName = doge.jpg,size = 68727 可能有点疑惑，参数是怎么来的，我们可以用Fildder软件抓个包看下： 可知MultipartFile实例的主要属性分别来自Content-Disposition、Content-Type和Content-Length，另外，InputStream用于读取请求体的最后部分(文件的字节序列)。参数处理器用到的是RequestPartMethodArgumentResolver(记住一点，使用了@RequestPart和MultipartFile一定是使用此参数处理器)。在其他情况下，使用@RequestParam和MultipartFile或者仅仅使用MultipartFile(参数的名字必须和POST表单中的Content-Disposition描述的name一致)也可以接收上传的文件数据，主要是通过RequestParamMethodArgumentResolver进行解析处理的，它的功能比较强大，具体可以看其supportsParameter方法，这两种情况的控制器方法代码如下： 123456789101112131415@PostMapping(value = \"/file2\")public String file2(MultipartFile file1) &#123; String content = String.format(\"name = %s,originName = %s,size = %d\", file1.getName(), file1.getOriginalFilename(), file1.getSize()); log.info(content); return content;&#125;@PostMapping(value = \"/file3\")public String file3(@RequestParam(name = \"file1\") MultipartFile multipartFile) &#123; String content = String.format(\"name = %s,originName = %s,size = %d\", multipartFile.getName(), multipartFile.getOriginalFilename(), multipartFile.getSize()); log.info(content); return content;&#125; 其他参数 其他参数主要包括请求头、Cookie、Model、Map等相关参数，还有一些并不是很常用或者一些相对原生的属性值获取(例如HttpServletRequest、HttpServletResponse等)不做讨论。 请求头 请求头的值主要通过@RequestHeader注解的参数获取，参数处理器是RequestHeaderMethodArgumentResolver，需要在注解中指定请求头的Key。简单实用如下： 控制器方法代码： 1234@PostMapping(value = \"/header\")public String header(@RequestHeader(name = \"Content-Type\") String Content-Type) &#123; return Content-Type;&#125; Cookie Cookie的值主要通过@CookieValue注解的参数获取，参数处理器为ServletCookieValueMethodArgumentResolver，需要在注解中指定Cookie的Key。控制器方法代码如下： 1234@PostMapping(value = \"/cookie\")public String cookie(@CookieValue(name = \"JSESSIONID\") String sessionId) &#123; return sessionId;&#125; Model类型参数 Model类型参数的处理器是ModelMethodProcessor，实际上处理此参数是直接返回ModelAndViewContainer实例中的Model(ModelMap类型)，因为要桥接不同的接口和类的功能，因此回调的实例是BindingAwareModelMap类型，此类型继承自ModelMap同时实现了Model接口。举个例子： 12345@GetMapping(value = \"/model\")public String model(Model model, ModelMap modelMap) &#123; log.info(\"&#123;&#125;\", model == modelMap); return \"success\";&#125; 注意调用此接口，控制台输出INFO日志内容为：true。还要注意一点：ModelMap或者Model中添加的属性项会附加到HttpRequestServlet实例中带到页面中进行渲染。 @ModelAttribute参数 @ModelAttribute注解处理的参数处理器为ModelAttributeMethodProcessor，@ModelAttribute的功能源码的注释如下： 1Annotation that binds a method parameter or method return value to a named model attribute, exposed to a web view. 简单来说，就是通过key-value形式绑定方法参数或者方法返回值到Model(Map)中，区别下面三种情况： @ModelAttribute使用在方法(返回值)上，方法没有返回值(void类型)， Model(Map)参数需要自行设置。 @ModelAttribute使用在方法(返回值)上，方法有返回值(非void类型)，返回值会添加到Model(Map)参数，key由@ModelAttribute的value指定，否则会使用返回值类型字符串(首写字母变为小写，如返回值类型为Integer，则key为integer)。 @ModelAttribute使用在方法参数中，则可以获取同一个控制器中的已经设置的@ModelAttribute对应的值。 在一个控制器(使用了@Controller)中，如果存在一到多个使用了@ModelAttribute的方法，这些方法总是在进入控制器方法之前执行，并且执行顺序是由加载顺序决定的(具体的顺序是带参数的优先，并且按照方法首字母升序排序)，举个例子： 123456789101112131415161718192021222324252627282930313233343536@Slf4j@RestControllerpublic class ModelAttributeController &#123; @ModelAttribute public void before(Model model) &#123; log.info(\"before..........\"); model.addAttribute(\"before\", \"beforeValue\"); &#125; @ModelAttribute(value = \"beforeArg\") public String beforeArg() &#123; log.info(\"beforeArg..........\"); return \"beforeArgValue\"; &#125; @GetMapping(value = \"/modelAttribute\") public String modelAttribute(Model model, @ModelAttribute(value = \"beforeArg\") String beforeArg) &#123; log.info(\"modelAttribute..........\"); log.info(\"beforeArg..........&#123;&#125;\", beforeArg); log.info(\"&#123;&#125;\", model); return \"success\"; &#125; @ModelAttribute public void after(Model model) &#123; log.info(\"after..........\"); model.addAttribute(\"after\", \"afterValue\"); &#125; @ModelAttribute(value = \"afterArg\") public String afterArg() &#123; log.info(\"afterArg..........\"); return \"afterArgValue\"; &#125;&#125; 调用此接口，控制台输出日志如下： 1234567after..........before..........afterArg..........beforeArg..........modelAttribute..........beforeArg..........beforeArgValue&#123;after&#x3D;afterValue, before&#x3D;beforeValue, afterArg&#x3D;afterArgValue, beforeArg&#x3D;beforeArgValue&#125; 可以印证排序规则和参数设置、获取的结果和前面的分析是一致的。 Errors或者BindingResult参数 Errors其实是BindingResult的父接口，BindingResult主要用于回调JSR参数校验异常的属性项，如果JSR校验异常，一般会抛出MethodArgumentNotValidException异常，并且会返回400(Bad Request)，见全局异常处理器DefaultHandlerExceptionResolver。Errors类型的参数处理器为ErrorsMethodArgumentResolver。举个例子： 12345678910111213141516171819@PostMapping(value = \"/errors\")public String errors(@RequestBody @Validated ErrorsModel errors, BindingResult bindingResult) &#123; if (bindingResult.hasErrors()) &#123; for (ObjectError objectError : bindingResult.getAllErrors()) &#123; log.warn(\"name=&#123;&#125;,message=&#123;&#125;\", objectError.getObjectName(), objectError.getDefaultMessage()); &#125; &#125; return errors.toString();&#125;//ErrorsModel@Data@NoArgsConstructorpublic class ErrorsModel &#123; @NotNull(message = \"id must not be null!\") private Integer id; @NotEmpty(message = \"errors name must not be empty!\") private String name;&#125; 调用接口控制台Warn日志如下： 1name&#x3D;errors,message&#x3D;errors name must not be empty! 一般情况下，不建议用这种方式处理JSR校验异常的属性项，因为会涉及到大量的重复的硬编码工作，建议：方式一直接继承ResponseEntityExceptionHandler覆盖对应的方法或者方式二同时使用@ExceptionHandler和@(Rest)ControllerAdvice注解进行异常处理。例如： 12345678@RestControllerAdvicepublic class ApplicationRestControllerAdvice&#123; @ExceptionHandler(BusinessException.class) public Response handleBusinessException(BusinessException e, HttpServletRequest request)&#123; // 这里处理异常和返回值 &#125;&#125; @Value参数 控制器方法的参数可以是@Value注解修饰的参数，会从Environment实例中装配和转换属性值到对应的参数中(也就是参数的来源并不是请求体)，参数处理器为ExpressionValueMethodArgumentResolver。举个例子： 12345@GetMapping(value = \"/value\")public String value(@Value(value = \"$&#123;spring.application.name&#125;\") String name) &#123; log.info(\"spring.application.name=&#123;&#125;\", name); return name;&#125; spring.application.name属性一般在配置文件中指定，在加载配置文件属性的时候添加到全局的Environment中。 Map类型参数 Map类型参数的范围相对比较广，对应一系列的参数处理器，注意区别使用了上面提到的部分注解的Map类型和完全不使用注解的Map类型参数，两者的处理方式不相同。下面列举几个相对典型的Map类型参数处理例子。 不使用任何注解的Map&lt;String,Object&gt;参数 这种情况下参数实际上直接回调ModelAndViewContainer中的ModelMap实例，参数处理器为MapMethodProcessor，往Map参数中添加的属性将会带到页面中。 使用@RequestParam注解的Map&lt;String,Object&gt;参数 这种情况下的参数处理器为RequestParamMapMethodArgumentResolver，使用的请求方式需要指定Content-Type为x-www-form-urlencoded，不能使用application/json的方式： 控制器代码为： 12345@PostMapping(value = \"/map\")public String mapArgs(@RequestParam Map&lt;String, Object&gt; map) &#123; log.info(\"&#123;&#125;\", map); return map.toString();&#125; 使用@RequestHeader注解的Map&lt;String,Object&gt;参数 这种情况下的参数处理器为RequestHeaderMapMethodArgumentResolver，作用是获取请求的所有请求头的Key-Value。 使用@PathVariable注解的Map&lt;String,Object&gt;参数 这种情况下的参数处理器为PathVariableMapMethodArgumentResolver，作用是获取所有路径参数封装为Key-Value结构。 MultipartFile集合-批量文件上传 批量文件上传的时候，我们一般需要接收一个MultipartFile集合，可以有两种选择： 使用MultipartHttpServletRequest参数，直接调用getFiles方法获取MultipartFile列表。 使用@RequestParam注解修饰MultipartFile列表，参数处理器是RequestParamMethodArgumentResolver，其实就是第1种方式的封装而已。 控制器方法代码如下： 12345@PostMapping(value = \"/parts\")public String partArgs(@RequestParam(name = \"file\") List&lt;MultipartFile&gt; parts) &#123; log.info(\"&#123;&#125;\", parts); return parts.toString();&#125; 日期类型参数处理 日期参数处理个人认为是请求参数处理中最复杂的，因为一般日期处理的逻辑不是通用的，过多的定制化处理导致很难有一个统一的标准处理逻辑去处理和转换日期类型的参数。不过，这里介绍几个通用的方法，以应对各种奇葩的日期格式。下面介绍的例子中全部使用Jdk8中引入的日期时间API，围绕java.util.Date为核心的日期时间API的使用方式类同。 一、统一以字符串形式接收 这种是最原始但是最奏效的方式，统一以字符串形式接收，然后自行处理类型转换，下面给个小例子： 12345678910111213141516171819202122232425@PostMapping(value = \"/date1\")public String date1(@RequestBody UserDto userDto) &#123; UserEntity userEntity = new UserEntity(); userEntity.setUserId(userDto.getUserId()); userEntity.setBirthdayTime(LocalDateTime.parse(userDto.getBirthdayTime(), FORMATTER)); userEntity.setGraduationTime(LocalDateTime.parse(userDto.getGraduationTime(), FORMATTER)); log.info(userEntity.toString()); return \"success\";&#125;@Datapublic class UserDto &#123; private String userId; private String birthdayTime; private String graduationTime;&#125;@Datapublic class UserEntity &#123; private String userId; private LocalDateTime birthdayTime; private LocalDateTime graduationTime;&#125; 使用字符串接收后再转换的缺点就是模板代码太多，编码风格不够简洁，重复性工作太多。 二、使用注解@DateTimeFormat或者@JsonFormat @DateTimeFormat注解配合@RequestBody的参数使用的时候，会发现抛出InvalidFormatException异常，提示转换失败，这是因为在处理此注解的时候，只支持Form表单提交(Content-Type为x-www-form-urlencoded)，例子如下： 123456789101112131415161718192021222324@Datapublic class UserDto2 &#123; private String userId; @DateTimeFormat(pattern = \"yyyy-MM-dd HH:mm:ss\") private LocalDateTime birthdayTime; @DateTimeFormat(pattern = \"yyyy-MM-dd HH:mm:ss\") private LocalDateTime graduationTime;&#125;@PostMapping(value = \"/date2\")public String date2(UserDto2 userDto2) &#123; log.info(userDto2.toString()); return \"success\";&#125;//或者像下面这样@PostMapping(value = \"/date2\")public String date2(@RequestParam(\"name\"=\"userId\")String userId, @RequestParam(\"name\"=\"birthdayTime\") @DateTimeFormat(pattern = \"yyyy-MM-dd HH:mm:ss\") LocalDateTime birthdayTime, @RequestParam(\"name\"=\"graduationTime\") @DateTimeFormat(pattern = \"yyyy-MM-dd HH:mm:ss\") LocalDateTime graduationTime) &#123; return \"success\";&#125; 而@JsonFormat注解可使用在Form表单或者JSON请求参数的场景，因此更推荐使用@JsonFormat注解，不过注意需要指定时区(timezone属性，例如在中国是东八区GMT+8)，否则有可能导致出现时差，举个例子： 123456789101112131415@PostMapping(value = \"/date2\")public String date2(@RequestBody UserDto2 userDto2) &#123; log.info(userDto2.toString()); return \"success\";&#125;@Datapublic class UserDto2 &#123; private String userId; @JsonFormat(pattern = \"yyyy-MM-dd HH:mm:ss\", timezone = \"GMT+8\") private LocalDateTime birthdayTime; @JsonFormat(pattern = \"yyyy-MM-dd HH:mm:ss\", timezone = \"GMT+8\") private LocalDateTime graduationTime;&#125; 三、Jackson序列化和反序列化定制 因为SpringMVC默认使用Jackson处理@RequestBody的参数转换，因此可以通过定制序列化器和反序列化器来实现日期类型的转换，这样我们就可以使用application/json的形式提交请求参数。这里的例子是转换请求Json参数中的字符串为LocalDateTime类型，属于Json反序列化，因此需要定制反序列化器： 12345678910111213141516171819202122@PostMapping(value = \"/date3\")public String date3(@RequestBody UserDto3 userDto3) &#123; log.info(userDto3.toString()); return \"success\";&#125;@Datapublic class UserDto3 &#123; private String userId; @JsonDeserialize(using = CustomLocalDateTimeDeserializer.class) private LocalDateTime birthdayTime; @JsonDeserialize(using = CustomLocalDateTimeDeserializer.class) private LocalDateTime graduationTime;&#125;public class CustomLocalDateTimeDeserializer extends LocalDateTimeDeserializer &#123; public CustomLocalDateTimeDeserializer() &#123; super(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\")); &#125;&#125; 四、最佳实践 前面三种方式都存在硬编码等问题，其实最佳实践是直接修改MappingJackson2HttpMessageConverter中的ObjectMapper对于日期类型处理默认的序列化器和反序列化器，这样就能全局生效，不需要再使用其他注解或者定制序列化方案(当然，有些时候需要特殊处理定制)，或者说，在需要特殊处理的场景才使用其他注解或者定制序列化方案。使用钩子接口Jackson2ObjectMapperBuilderCustomizer可以实现对容器中的ObjectMapper单例中的属性定制： 123456789@Beanpublic Jackson2ObjectMapperBuilderCustomizer jackson2ObjectMapperBuilderCustomizer()&#123; return customizer-&gt;&#123; customizer.serializerByType(LocalDateTime.class,new LocalDateTimeSerializer( DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); customizer.deserializerByType(LocalDateTime.class,new LocalDateTimeDeserializer( DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); &#125;;&#125; 这样就能定制化MappingJackson2HttpMessageConverter中持有的ObjectMapper，上面的LocalDateTime序列化和反序列化器对全局生效。 请求URL匹配 前面基本介绍完了主流的请求参数处理，其实SpringMVC中还会按照URL的模式进行匹配，使用的是Ant路径风格，处理工具类为org.springframework.util.AntPathMatcher，从此类的注释来看，匹配规则主要包括下面四点 ： ?匹配1个字符。 *匹配0个或者多个字符。 **匹配路径中0个或者多个目录。 正则支持，如{spring:[a-z]+}将正则表达式[a-z]+匹配到的值，赋值给名为spring的路径变量。 举些例子： ’?'形式的URL： 12345678910@GetMapping(value = \"/pattern?\")public String pattern() &#123; return \"success\";&#125;/pattern 404 Not Found/patternd 200 OK/patterndd 404 Not Found/pattern/ 404 Not Found/patternd/s 404 Not Found ’*'形式的URL： 123456789@GetMapping(value = \"/pattern*\")public String pattern() &#123; return \"success\";&#125;/pattern 200 OK/pattern/ 200 OK/patternd 200 OK/pattern/a 404 Not Found ’**'形式的URL： 12345678@GetMapping(value = \"/pattern/**/p\")public String pattern() &#123; return \"success\";&#125;/pattern/p 200 OK/pattern/x/p 200 OK/pattern/x/y/p 200 OK {spring:[a-z]+}形式的URL： 12345678910@GetMapping(value = \"/pattern/&#123;key:[a-c]+&#125;\")public String pattern(@PathVariable(name = \"key\") String key) &#123; return \"success\";&#125;/pattern/a 200 OK/pattern/ab 200 OK/pattern/abc 200 OK/pattern 404 Not Found/pattern/abcd 404 Not Found 上面的四种URL模式可以组合使用，千变万化。 URL匹配还遵循精确匹配原则，也就是存在两个模式对同一个URL都能够匹配成功，则选取最精确的URL匹配，进入对应的控制器方法，举个例子： 123456789@GetMapping(value = \"/pattern/**/p\")public String pattern1() &#123; return \"success\";&#125;@GetMapping(value = \"/pattern/p\")public String pattern2() &#123; return \"success\";&#125; 上面两个控制器，如果请求URL为/pattern/p，最终进入的方法为pattern2。 最后，org.springframework.util.AntPathMatcher作为一个工具类，可以单独使用，不仅仅可以用于匹配URL，也可以用于匹配系统文件路径，不过需要使用其带参数构造改变内部的pathSeparator变量，例如： 1AntPathMatcher antPathMatcher = new AntPathMatcher(File.separator); 小结 笔者在前一段时间曾经花大量时间梳理和分析过Spring、SpringMVC的源码，但是后面一段很长的时间需要进行业务开发，对架构方面的东西有点生疏了，毕竟东西不用就会生疏，这个是常理。这篇文章基于一些SpringMVC的源码经验总结了请求参数的处理相关的一些知识，希望帮到自己和大家。 参考资料： spring-boot-web-starter:2.0.3.RELEASE源码。 （本文完 c-7-d e-a-20180512 旧文重发）","categories":[{"name":"Spring","slug":"Spring","permalink":"http://throwable.club/blog/categories/Spring/"},{"name":"SpringMVC","slug":"Spring/SpringMVC","permalink":"http://throwable.club/blog/categories/Spring/SpringMVC/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://throwable.club/blog/tags/Spring/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://throwable.club/blog/tags/SpringMVC/"}]},{"title":"SpringMVC请求参数和响应结果全局加密和解密","slug":"spring-mvc-param-global-encryption-decryption-in-action","date":"2019-11-28T16:57:38.000Z","updated":"2019-11-28T16:59:32.793Z","comments":true,"path":"2019/11/29/spring-mvc-param-global-encryption-decryption-in-action/","link":"","permalink":"http://throwable.club/2019/11/29/spring-mvc-param-global-encryption-decryption-in-action/","excerpt":"前提 前段时间在做一个对外的网关项目，涉及到加密和解密模块，这里详细分析解决方案和适用的场景。为了模拟真实的交互场景，先定制一下整个交互流程。第三方传输(包括请求和响应)数据报文包括三个部分： 1、timestamp，long类型，时间戳。 2、data，String类型，实际的业务请求数据转化成的Json字符串再进行加密得到的密文。 3、sign，签名，生成规则算法伪代码是SHA-256(data=xxx&amp;timestamp=11111)，防篡改。 为了简单起见，加密和解密采用AES，对称秘钥为&quot;throwable&quot;。上面的场景和加解密例子仅仅是为了模拟真实场景，安全系数低，切勿直接用于生产环境。","text":"前提 前段时间在做一个对外的网关项目，涉及到加密和解密模块，这里详细分析解决方案和适用的场景。为了模拟真实的交互场景，先定制一下整个交互流程。第三方传输(包括请求和响应)数据报文包括三个部分： 1、timestamp，long类型，时间戳。 2、data，String类型，实际的业务请求数据转化成的Json字符串再进行加密得到的密文。 3、sign，签名，生成规则算法伪代码是SHA-256(data=xxx&amp;timestamp=11111)，防篡改。 为了简单起见，加密和解密采用AES，对称秘钥为&quot;throwable&quot;。上面的场景和加解密例子仅仅是为了模拟真实场景，安全系数低，切勿直接用于生产环境。 现在还有一个地方要考虑，就是无法得知第三方如何提交请求数据，假定都是采用POST的Http请求方法，提交报文的时候指定ContentType为application/json或者application/x-www-form-urlencoded，两种ContentType提交方式的请求体是不相同的： 12345//application/x-www-form-urlencodedtimestamp=xxxx&amp;data=yyyyyy&amp;sign=zzzzzzz//application/json&#123;\"timestamp\":xxxxxx,\"data\":\"yyyyyyyy\",\"sign\":\"zzzzzzz\"&#125; 最后一个要考虑的地方是，第三方强制要求部分接口需要用明文进行请求，在提供一些接口方法的时候，允许使用明文交互。总结一下就是要做到以下三点： 1、需要加解密的接口请求参数要进行解密，响应结果要进行加密。 2、不需要加解密的接口可以用明文请求。 3、兼容ContentType为application/json或者application/x-www-form-urlencoded两种方式。 上面三种情况要同时兼容算是十分严苛的场景，在生产环境中可能也是极少情况下才遇到，不过还是能找到相对优雅的解决方案。先定义两个特定场景的接口： 1、下单接口(加密) URL：/order/save HTTP METHOD：POST ContentType：application/x-www-form-urlencoded 原始参数：orderId=yyyyyyyyy&amp;userId=xxxxxxxxx&amp;amount=zzzzzzzzz 加密参数：timestamp=xxxx&amp;data=yyyyyy&amp;sign=zzzzzzz 2、订单查询接口(明文) URL：/order/query ContentType：application/json HTTP METHOD：POST 原始参数：{“userId”:“xxxxxxxx”} 两个接口的ContentType不相同是为了故意复杂化场景，在下面的可取方案中，做法是把application/x-www-form-urlencoded中的形式如xxx=yyy&amp;aaa=bbb的表单参数和application/json中形式如{“key”:“value”}的请求参数统一当做application/json形式的参数处理，这样的话，我们就可以直接在控制器方法中使用@RequestBody。 方案 我们首先基于上面说到的加解密方案，提供一个加解密工具类： 123456789101112131415161718192021222324252627282930313233343536373839404142public enum EncryptUtils &#123; /** * SINGLETON */ SINGLETON; private static final String SECRET = \"throwable\"; private static final String CHARSET = \"UTF-8\"; public String sha(String raw) throws Exception &#123; MessageDigest messageDigest = MessageDigest.getInstance(\"SHA-256\"); messageDigest.update(raw.getBytes(CHARSET)); return Hex.encodeHexString(messageDigest.digest()); &#125; private Cipher createAesCipher() throws Exception &#123; return Cipher.getInstance(\"AES\"); &#125; public String encryptByAes(String raw) throws Exception &#123; Cipher aesCipher = createAesCipher(); KeyGenerator keyGenerator = KeyGenerator.getInstance(\"AES\"); keyGenerator.init(128, new SecureRandom(SECRET.getBytes(CHARSET))); SecretKey secretKey = keyGenerator.generateKey(); SecretKeySpec secretKeySpec = new SecretKeySpec(secretKey.getEncoded(), \"AES\"); aesCipher.init(Cipher.ENCRYPT_MODE, secretKeySpec); byte[] bytes = aesCipher.doFinal(raw.getBytes(CHARSET)); return Hex.encodeHexString(bytes); &#125; public String decryptByAes(String raw) throws Exception &#123; byte[] bytes = Hex.decodeHex(raw); Cipher aesCipher = createAesCipher(); KeyGenerator keyGenerator = KeyGenerator.getInstance(\"AES\"); keyGenerator.init(128, new SecureRandom(SECRET.getBytes(CHARSET))); SecretKey secretKey = keyGenerator.generateKey(); SecretKeySpec secretKeySpec = new SecretKeySpec(secretKey.getEncoded(), \"AES\"); aesCipher.init(Cipher.DECRYPT_MODE, secretKeySpec); return new String(aesCipher.doFinal(bytes), CHARSET); &#125;&#125; 注意为了简化加解密操作引入了apache的codec依赖： 12345&lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;version&gt;1.11&lt;/version&gt;&lt;/dependency&gt; 上面的加解密过程中要注意两点： 1、加密后的结果是byte数组，要把二进制转化为十六进制字符串。 2、解密的时候要把原始密文由十六进制转化为二进制的byte数组。 上面两点必须注意，否则会产生乱码，这个和编码相关，具体可以看之前写的一篇博客。 不推荐的方案 其实最暴力的方案是直接定制每个控制器的方法参数类型，因为我们可以和第三方磋商哪些请求路径需要加密，哪些是不需要加密，甚至哪些是application/x-www-form-urlencoded，哪些是application/json的请求，这样我们可以通过大量的硬编码达到最终的目标。举个例子： 123456789101112131415161718192021222324252627282930313233343536373839404142@RestControllerpublic class Controller1 &#123; @Autowired private ObjectMapper objectMapper; @PostMapping(value = \"/order/save\", consumes = MediaType.APPLICATION_FORM_URLENCODED_VALUE, produces = MediaType.APPLICATION_JSON_UTF8_VALUE) public ResponseEntity&lt;EncryptModel&gt; saveOrder(@RequestParam(name = \"sign\") String sign, @RequestParam(name = \"timestamp\") Long timestamp, @RequestParam(name = \"data\") String data) throws Exception &#123; EncryptModel model = new EncryptModel(); model.setData(data); model.setTimestamp(timestamp); model.setSign(sign); String inRawSign = String.format(\"data=%s&amp;timestamp=%d\", model.getData(), model.getTimestamp()); String inSign = EncryptUtils.SINGLETON.sha(inRawSign); if (!inSign.equals(model.getSign()))&#123; throw new IllegalArgumentException(\"验证参数签名失败!\"); &#125; //这里忽略实际的业务逻辑,简单设置返回的data为一个map Map&lt;String, Object&gt; result = new HashMap&lt;&gt;(8); result.put(\"code\", \"200\"); result.put(\"message\", \"success\"); EncryptModel out = new EncryptModel(); out.setTimestamp(System.currentTimeMillis()); out.setData(EncryptUtils.SINGLETON.encryptByAes(objectMapper.writeValueAsString(result))); String rawSign = String.format(\"data=%s&amp;timestamp=%d\", out.getData(), out.getTimestamp()); out.setSign(EncryptUtils.SINGLETON.sha(rawSign)); return ResponseEntity.ok(out); &#125; @PostMapping(value = \"/order/query\", consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_UTF8_VALUE) public ResponseEntity&lt;Order&gt; queryOrder(@RequestBody User user)&#123; Order order = new Order(); //这里忽略实际的业务逻辑 return ResponseEntity.ok(order); &#125;&#125; 这种做法能在短时间完成对应的加解密功能，不需要加解密的接口不用引入相关的代码即可。缺陷十分明显，存在硬编码、代码冗余等问题，一旦接口增多，项目的维护难度大大提高。因此，这种做法是不可取的。 混合方案之Filter和SpringMVC的Http消息转换器 这里先说一点，这里是在SpringMVC中使用Filter。因为要兼容两种contentType，我们需要做到几点： 1、修改请求头的ContentType为application/json。 2、修改请求体中的参数，统一转化为InputStream。 3、定制URL规则，区别需要加解密和不需要加解密的URL。 使用Filter有一个优点：不需要理解SpringMVC的流程，也不需要扩展SpringMVC的相关组件。缺点也比较明显： 1、如果需要区分加解密，只能通过URL规则进行过滤。 2、需要加密的接口的SpringMVC控制器的返回参数必须是加密后的实体类，无法做到加密逻辑和业务逻辑完全拆分，也就是解密逻辑对接收的参数是无感知，但是加密逻辑对返回结果是有感知的。 PS：上面提到的几个需要修改请求参数、请求头等是因为特殊场景的定制，所以如果无此场景可以直接看下面的&quot;单纯的Json请求参数和Json响应结果&quot;小节。流程大致如下： 编写Filter的实现和HttpServletRequestWrapper的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127//CustomEncryptFilter@RequiredArgsConstructorpublic class CustomEncryptFilter extends OncePerRequestFilter &#123; private final ObjectMapper objectMapper; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; //Content-Type String contentType = request.getContentType(); String requestBody = null; boolean shouldEncrypt = false; if (StringUtils.substringMatch(contentType, 0, MediaType.APPLICATION_FORM_URLENCODED_VALUE)) &#123; shouldEncrypt = true; requestBody = convertFormToString(request); &#125; else if (StringUtils.substringMatch(contentType, 0, MediaType.APPLICATION_JSON_VALUE)) &#123; shouldEncrypt = true; requestBody = convertInputStreamToString(request.getInputStream()); &#125; if (!shouldEncrypt) &#123; filterChain.doFilter(request, response); &#125; else &#123; CustomEncryptHttpWrapper wrapper = new CustomEncryptHttpWrapper(request, requestBody); wrapper.putHeader(\"Content-Type\", MediaType.APPLICATION_PROBLEM_JSON_UTF8_VALUE); filterChain.doFilter(wrapper, response); &#125; &#125; private String convertFormToString(HttpServletRequest request) &#123; Map&lt;String, String&gt; result = new HashMap&lt;&gt;(8); Enumeration&lt;String&gt; parameterNames = request.getParameterNames(); while (parameterNames.hasMoreElements()) &#123; String name = parameterNames.nextElement(); result.put(name, request.getParameter(name)); &#125; try &#123; return objectMapper.writeValueAsString(result); &#125; catch (JsonProcessingException e) &#123; throw new IllegalArgumentException(e); &#125; &#125; private String convertInputStreamToString(InputStream inputStream) throws IOException &#123; return StreamUtils.copyToString(inputStream, Charset.forName(\"UTF-8\")); &#125;&#125;//CustomEncryptHttpWrapperpublic class CustomEncryptHttpWrapper extends HttpServletRequestWrapper &#123; private final Map&lt;String, String&gt; headers = new HashMap&lt;&gt;(8); private final byte[] data; public CustomEncryptHttpWrapper(HttpServletRequest request, String content) &#123; super(request); data = content.getBytes(Charset.forName(\"UTF-8\")); Enumeration&lt;String&gt; headerNames = request.getHeaderNames(); while (headerNames.hasMoreElements()) &#123; String key = headerNames.nextElement(); headers.put(key, request.getHeader(key)); &#125; &#125; public void putHeader(String key, String value) &#123; headers.put(key, value); &#125; @Override public String getHeader(String name) &#123; return headers.get(name); &#125; @Override public Enumeration&lt;String&gt; getHeaders(String name) &#123; return Collections.enumeration(Collections.singletonList(headers.get(name))); &#125; @Override public Enumeration&lt;String&gt; getHeaderNames() &#123; return Collections.enumeration(headers.keySet()); &#125; @Override public ServletInputStream getInputStream() throws IOException &#123; ByteArrayInputStream inputStream = new ByteArrayInputStream(data); return new ServletInputStream() &#123; @Override public boolean isFinished() &#123; return !isReady(); &#125; @Override public boolean isReady() &#123; return inputStream.available() &gt; 0; &#125; @Override public void setReadListener(ReadListener listener) &#123; &#125; @Override public int read() throws IOException &#123; return inputStream.read(); &#125; &#125;; &#125; @Override public BufferedReader getReader() throws IOException &#123; return super.getReader(); &#125;&#125;//CustomEncryptConfiguration@Configurationpublic class CustomEncryptConfiguration &#123; @Bean public FilterRegistrationBean&lt;CustomEncryptFilter&gt; customEncryptFilter(ObjectMapper objectMapper)&#123; FilterRegistrationBean&lt;CustomEncryptFilter&gt; bean = new FilterRegistrationBean&lt;&gt;(new CustomEncryptFilter(objectMapper)); bean.addUrlPatterns(\"/e/*\"); return bean; &#125;&#125; 控制器代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344//可加密的，空接口，用于标识解密的模型对象public interface Encryptable &#123;&#125;@Datapublic class Order implements Encryptable&#123; private Long userId;&#125;@Datapublic class EncryptResponse&lt;T&gt; implements Encryptable &#123; private Integer code; private T data;&#125;@RequiredArgsConstructor@RestControllerpublic class Controller &#123; private final ObjectMapper objectMapper; @PostMapping(value = \"/e/order/save\", consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_UTF8_VALUE) public EncryptResponse&lt;Order&gt; saveOrder(@RequestBody Order order) throws Exception &#123; //这里忽略实际的业务逻辑,简单设置返回的data为一个map EncryptResponse&lt;Order&gt; response = new EncryptResponse&lt;&gt;(); response.setCode(200); response.setData(order); return response; &#125; @PostMapping(value = \"/c/order/query\", consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_UTF8_VALUE) public ResponseEntity&lt;Order&gt; queryOrder(@RequestBody User user) &#123; Order order = new Order(); //这里忽略实际的业务逻辑 return ResponseEntity.ok(order); &#125;&#125; 这里可能有人有疑问，为什么不在Filter做加解密的操作？因为考虑到场景太特殊，要兼容两种形式的表单提交参数，如果在Filter做加解密操作，会影响到Controller的编码，这就违反了全局加解密不影响到里层业务代码的目标。上面的Filter只会拦截URL满足/e/*的请求，因此查询接口/c/order/query不会受到影响。这里使用了标识接口用于决定请求参数或者响应结果是否需要加解密，也就是只需要在HttpMessageConverter中判断请求参数的类型或者响应结果的类型是否加解密标识接口的子类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@RequiredArgsConstructorpublic class CustomEncryptHttpMessageConverter extends MappingJackson2HttpMessageConverter &#123; private final ObjectMapper objectMapper; @Override protected Object readInternal(Class&lt;?&gt; clazz, HttpInputMessage inputMessage) throws IOException, HttpMessageNotReadableException &#123; if (Encryptable.class.isAssignableFrom(clazz)) &#123; EncryptModel in = objectMapper.readValue(StreamUtils.copyToByteArray(inputMessage.getBody()), EncryptModel.class); String inRawSign = String.format(\"data=%s&amp;timestamp=%d\", in.getData(), in.getTimestamp()); String inSign; try &#123; inSign = EncryptUtils.SINGLETON.sha(inRawSign); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(\"验证参数签名失败!\"); &#125; if (!inSign.equals(in.getSign())) &#123; throw new IllegalArgumentException(\"验证参数签名失败!\"); &#125; try &#123; return objectMapper.readValue(EncryptUtils.SINGLETON.decryptByAes(in.getData()), clazz); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(\"解密失败!\"); &#125; &#125; else &#123; return super.readInternal(clazz, inputMessage); &#125; &#125; @Override protected void writeInternal(Object object, Type type, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException &#123; Class&lt;?&gt; clazz = (Class) type; if (Encryptable.class.isAssignableFrom(clazz)) &#123; EncryptModel out = new EncryptModel(); out.setTimestamp(System.currentTimeMillis()); try &#123; out.setData(EncryptUtils.SINGLETON.encryptByAes(objectMapper.writeValueAsString(object))); String rawSign = String.format(\"data=%s&amp;timestamp=%d\", out.getData(), out.getTimestamp()); out.setSign(EncryptUtils.SINGLETON.sha(rawSign)); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(\"参数签名失败!\"); &#125; super.writeInternal(out, type, outputMessage); &#125; else &#123; super.writeInternal(object, type, outputMessage); &#125; &#125;&#125; 自实现的HttpMessageConverter主要需要判断请求参数的类型和返回值的类型，从而判断是否需要进行加解密。 单纯的Json请求参数和Json响应结果的加解密处理最佳实践 一般情况下，对接方的请求参数和响应结果是完全规范统一使用Json(ContentType指定为application/json，使用@RequestBody接收参数)，那么所有的事情就会变得简单，因为不需要考虑请求参数由xxx=yyy&amp;aaa=bbb转换为InputStream再交给SpringMVC处理，因此我们只需要提供一个MappingJackson2HttpMessageConverter子类实现(继承它并且覆盖对应方法，添加加解密特性)。我们还是使用标识接口用于决定请求参数或者响应结果是否需要加解密： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@RequiredArgsConstructorpublic class CustomEncryptHttpMessageConverter extends MappingJackson2HttpMessageConverter &#123; private final ObjectMapper objectMapper; @Override protected Object readInternal(Class&lt;?&gt; clazz, HttpInputMessage inputMessage) throws IOException, HttpMessageNotReadableException &#123; if (Encryptable.class.isAssignableFrom(clazz)) &#123; EncryptModel in = objectMapper.readValue(StreamUtils.copyToByteArray(inputMessage.getBody()), EncryptModel.class); String inRawSign = String.format(\"data=%s&amp;timestamp=%d\", in.getData(), in.getTimestamp()); String inSign; try &#123; inSign = EncryptUtils.SINGLETON.sha(inRawSign); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(\"验证参数签名失败!\"); &#125; if (!inSign.equals(in.getSign())) &#123; throw new IllegalArgumentException(\"验证参数签名失败!\"); &#125; try &#123; return objectMapper.readValue(EncryptUtils.SINGLETON.decryptByAes(in.getData()), clazz); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(\"解密失败!\"); &#125; &#125; else &#123; return super.readInternal(clazz, inputMessage); &#125; &#125; @Override protected void writeInternal(Object object, Type type, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException &#123; Class&lt;?&gt; clazz = (Class) type; if (Encryptable.class.isAssignableFrom(clazz)) &#123; EncryptModel out = new EncryptModel(); out.setTimestamp(System.currentTimeMillis()); try &#123; out.setData(EncryptUtils.SINGLETON.encryptByAes(objectMapper.writeValueAsString(object))); String rawSign = String.format(\"data=%s&amp;timestamp=%d\", out.getData(), out.getTimestamp()); out.setSign(EncryptUtils.SINGLETON.sha(rawSign)); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(\"参数签名失败!\"); &#125; super.writeInternal(out, type, outputMessage); &#125; else &#123; super.writeInternal(object, type, outputMessage); &#125; &#125;&#125; 没错，代码是拷贝上一节提供的HttpMessageConverter实现，然后控制器方法的参数使用@RequestBody注解并且类型实现加解密标识接口Encryptable即可，返回值的类型也需要实现加解密标识接口Encryptable。这种做法可以让控制器的代码对加解密完全无感知。当然，也可以不改变原来的MappingJackson2HttpMessageConverter实现，使用RequestBodyAdvice和ResponseBodyAdvice完成相同的功能： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869@RequiredArgsConstructorpublic class CustomRequestBodyAdvice extends RequestBodyAdviceAdapter &#123; private final ObjectMapper objectMapper; @Override public boolean supports(MethodParameter methodParameter, Type targetType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; converterType) &#123; Class&lt;?&gt; clazz = (Class) targetType; return Encryptable.class.isAssignableFrom(clazz); &#125; @Override public HttpInputMessage beforeBodyRead(HttpInputMessage inputMessage, MethodParameter parameter, Type targetType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; converterType) throws IOException &#123; Class&lt;?&gt; clazz = (Class) targetType; if (Encryptable.class.isAssignableFrom(clazz)) &#123; String content = StreamUtils.copyToString(inputMessage.getBody(), Charset.forName(\"UTF-8\")); EncryptModel in = objectMapper.readValue(content, EncryptModel.class); String inRawSign = String.format(\"data=%s&amp;timestamp=%d\", in.getData(), in.getTimestamp()); String inSign; try &#123; inSign = EncryptUtils.SINGLETON.sha(inRawSign); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(\"验证参数签名失败!\"); &#125; if (!inSign.equals(in.getSign())) &#123; throw new IllegalArgumentException(\"验证参数签名失败!\"); &#125; ByteArrayInputStream inputStream = new ByteArrayInputStream(in.getData().getBytes(Charset.forName(\"UTF-8\"))); return new MappingJacksonInputMessage(inputStream, inputMessage.getHeaders()); &#125; else &#123; return super.beforeBodyRead(inputMessage, parameter, targetType, converterType); &#125; &#125;&#125;@RequiredArgsConstructorpublic class CustomResponseBodyAdvice extends JsonViewResponseBodyAdvice &#123; private final ObjectMapper objectMapper; @Override public boolean supports(MethodParameter returnType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; converterType) &#123; Class&lt;?&gt; parameterType = returnType.getParameterType(); return Encryptable.class.isAssignableFrom(parameterType); &#125; @Override protected void beforeBodyWriteInternal(MappingJacksonValue bodyContainer, MediaType contentType, MethodParameter returnType, ServerHttpRequest request, ServerHttpResponse response) &#123; Class&lt;?&gt; parameterType = returnType.getParameterType(); if (Encryptable.class.isAssignableFrom(parameterType)) &#123; EncryptModel out = new EncryptModel(); out.setTimestamp(System.currentTimeMillis()); try &#123; out.setData(EncryptUtils.SINGLETON.encryptByAes(objectMapper.writeValueAsString(bodyContainer.getValue()))); String rawSign = String.format(\"data=%s&amp;timestamp=%d\", out.getData(), out.getTimestamp()); out.setSign(EncryptUtils.SINGLETON.sha(rawSign)); out.setSign(EncryptUtils.SINGLETON.sha(rawSign)); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(\"参数签名失败!\"); &#125; &#125; else &#123; super.beforeBodyWriteInternal(bodyContainer, contentType, returnType, request, response); &#125; &#125;&#125; 单纯的application/x-www-form-urlencoded表单请求参数和Json响应结果的加解密处理最佳实践 一般情况下，对接方的请求参数完全采用application/x-www-form-urlencoded表单请求参数返回结果全部按照Json接收，我们也可以通过一个HttpMessageConverter实现就完成加解密模块。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class FormHttpMessageConverter implements HttpMessageConverter&lt;Object&gt; &#123; private final List&lt;MediaType&gt; mediaTypes; private final ObjectMapper objectMapper; public FormHttpMessageConverter(ObjectMapper objectMapper) &#123; this.objectMapper = objectMapper; this.mediaTypes = new ArrayList&lt;&gt;(1); this.mediaTypes.add(MediaType.APPLICATION_FORM_URLENCODED); &#125; @Override public boolean canRead(Class&lt;?&gt; clazz, MediaType mediaType) &#123; return Encryptable.class.isAssignableFrom(clazz) &amp;&amp; mediaTypes.contains(mediaType); &#125; @Override public boolean canWrite(Class&lt;?&gt; clazz, MediaType mediaType) &#123; return Encryptable.class.isAssignableFrom(clazz) &amp;&amp; mediaTypes.contains(mediaType); &#125; @Override public List&lt;MediaType&gt; getSupportedMediaTypes() &#123; return mediaTypes; &#125; @Override public Object read(Class&lt;?&gt; clazz, HttpInputMessage inputMessage) throws IOException, HttpMessageNotReadableException &#123; if (Encryptable.class.isAssignableFrom(clazz)) &#123; String content = StreamUtils.copyToString(inputMessage.getBody(), Charset.forName(\"UTF-8\")); EncryptModel in = objectMapper.readValue(content, EncryptModel.class); String inRawSign = String.format(\"data=%s&amp;timestamp=%d\", in.getData(), in.getTimestamp()); String inSign; try &#123; inSign = EncryptUtils.SINGLETON.sha(inRawSign); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(\"验证参数签名失败!\"); &#125; if (!inSign.equals(in.getSign())) &#123; throw new IllegalArgumentException(\"验证参数签名失败!\"); &#125; try &#123; return objectMapper.readValue(EncryptUtils.SINGLETON.decryptByAes(in.getData()), clazz); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(\"解密失败!\"); &#125; &#125; else &#123; MediaType contentType = inputMessage.getHeaders().getContentType(); Charset charset = (contentType != null &amp;&amp; contentType.getCharset() != null ? contentType.getCharset() : Charset.forName(\"UTF-8\")); String body = StreamUtils.copyToString(inputMessage.getBody(), charset); String[] pairs = StringUtils.tokenizeToStringArray(body, \"&amp;\"); MultiValueMap&lt;String, String&gt; result = new LinkedMultiValueMap&lt;&gt;(pairs.length); for (String pair : pairs) &#123; int idx = pair.indexOf('='); if (idx == -1) &#123; result.add(URLDecoder.decode(pair, charset.name()), null); &#125; else &#123; String name = URLDecoder.decode(pair.substring(0, idx), charset.name()); String value = URLDecoder.decode(pair.substring(idx + 1), charset.name()); result.add(name, value); &#125; &#125; return result; &#125; &#125; @Override public void write(Object o, MediaType contentType, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException &#123; Class&lt;?&gt; clazz = o.getClass(); if (Encryptable.class.isAssignableFrom(clazz)) &#123; EncryptModel out = new EncryptModel(); out.setTimestamp(System.currentTimeMillis()); try &#123; out.setData(EncryptUtils.SINGLETON.encryptByAes(objectMapper.writeValueAsString(o))); String rawSign = String.format(\"data=%s&amp;timestamp=%d\", out.getData(), out.getTimestamp()); out.setSign(EncryptUtils.SINGLETON.sha(rawSign)); StreamUtils.copy(objectMapper.writeValueAsString(out) .getBytes(Charset.forName(\"UTF-8\")), outputMessage.getBody()); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(\"参数签名失败!\"); &#125; &#125; else &#123; String out = objectMapper.writeValueAsString(o); StreamUtils.copy(out.getBytes(Charset.forName(\"UTF-8\")), outputMessage.getBody()); &#125; &#125;&#125; 上面的HttpMessageConverter的实现可以参考org.springframework.http.converter.FormHttpMessageConverter。 小结 这篇文章强行复杂化了实际的情况(但是在实际中真的碰到过)，一般情况下，现在流行使用Json进行数据传输，在SpringMVC项目中，我们只需要针对性地改造MappingJackson2HttpMessageConverter即可(继承并且添加特性)，如果对SpringMVC的源码相对熟悉的话，直接添加自定义的RequestBodyAdvice(RequestBodyAdviceAdapter)和ResponseBodyAdvice(JsonViewResponseBodyAdvice)实现也可以达到目的。至于为什么使用HttpMessageConverter做加解密功能，这里基于SpringMVC源码的对请求参数处理的过程整理了一张处理流程图： 上面流程最核心的代码可以看AbstractMessageConverterMethodArgumentResolver#readWithMessageConverters和HandlerMethodArgumentResolverComposite#resolveArgument，毕竟源码不会骗人。控制器方法返回值的处理基于是对称的，阅读起来也比较轻松。 参考资料： spring-boot-web-starter:2.0.3.RELEASE源码。 （本文完 c-d-4 e-a-2018-8-14 老文重发）","categories":[{"name":"Spring","slug":"Spring","permalink":"http://throwable.club/blog/categories/Spring/"},{"name":"SpringMVC","slug":"Spring/SpringMVC","permalink":"http://throwable.club/blog/categories/Spring/SpringMVC/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://throwable.club/blog/tags/Spring/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://throwable.club/blog/tags/SpringMVC/"}]},{"title":"初识Redis的数据类型HyperLogLog","slug":"redis-type-hll-introduction","date":"2019-11-17T05:10:16.000Z","updated":"2019-11-28T17:03:45.812Z","comments":true,"path":"2019/11/17/redis-type-hll-introduction/","link":"","permalink":"http://throwable.club/2019/11/17/redis-type-hll-introduction/","excerpt":"前提 未来一段时间开发的项目或者需求会大量使用到Redis，趁着这段时间业务并不太繁忙，抽点时间预习和复习Redis的相关内容。刚好看到博客下面的UV和PV统计，想到了最近看书里面提到的HyperLogLog数据类型，于是花点时间分析一下它的使用方式和使用场景（暂时不探究HyperLogLog的实现原理）。Redis中HyperLogLog数据类型是Redid 2.8.9引入的，使用的时候确保Redis版本&gt;= 2.8.9。","text":"前提 未来一段时间开发的项目或者需求会大量使用到Redis，趁着这段时间业务并不太繁忙，抽点时间预习和复习Redis的相关内容。刚好看到博客下面的UV和PV统计，想到了最近看书里面提到的HyperLogLog数据类型，于是花点时间分析一下它的使用方式和使用场景（暂时不探究HyperLogLog的实现原理）。Redis中HyperLogLog数据类型是Redid 2.8.9引入的，使用的时候确保Redis版本&gt;= 2.8.9。 HyperLogLog简介 基数计数(cardinality counting)，通常用来统计一个集合中不重复的元素个数。一个很常见的例子就是统计某个文章的UV（Unique Visitor，独立访客，一般可以理解为客户端IP）。大数据量背景下，要实现基数计数，多数情况下不会选择存储全量的基数集合的元素，因为可以计算出存储的内存成本，假设一个每个被统计的元素的平均大小为32bit，那么如果统计一亿个数据，占用的内存大小为： 32 * 100000000 / 8 / 1024 / 1024 ≈ 381M。 如果有多个集合，并且允许计算多个集合的合并计数结果，那么这个操作带来的复杂度可能是毁灭性的。因此，不会使用Bitmap、Tree或者HashSet等数据结构直接存储计数元素集合的方式进行计数，而是在不追求绝对准确计数结果的前提之下，使用基数计数的概率算法进行计数，目前常见的有概率算法以下三种： Linear Counting(LC)。 LogLog Counting(LLC)。 HyperLogLog Counting(HLL)。 所以，HyperLogLog其实是一种基数计数概率算法，并不是Redis特有的，Redis基于C语言实现了HyperLogLog并且提供了相关命令API入口。 Redis的作者Antirez为了纪念Philippe Flajolet对组合数学和基数计算算法分析的研究，所以在设计HyperLogLog命令的时候使用了Philippe Flajolet姓名的英文首字母PF作为前缀。也就是说，Philippe Flajolet博士是HLL算法的重大贡献者，但是他其实并不是Redis中HyperLogLog数据类型的开发者。遗憾的是Philippe Flajolet博士于2011年3月22日因病在巴黎辞世。这个是Philippe Flajolet博士的维基百科照片： Redis提供的HyperLogLog数据类型的特征： 基本特征：使用HyperLogLog Counting(HLL)实现，只做基数计算，不会保存元数据。 内存占用：HyperLogLog每个KEY最多占用12K的内存空间，可以计算接近2^64个不同元素的基数，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数基数个数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，转变成稠密矩阵之后才会占用12K的内存空间。 计数误差范围：基数计数的结果是一个标准误差（Standard Error）为0.81%的近似值，当数据量不大的时候，得到的结果也可能是一个准确值。 内存占用小（每个KEY最高占用12K）是HyperLogLog的最大优势，而它存在两个相对明显的限制： 计算结果并不是准确值，存在标准误差，这是由于它本质上是用概率算法导致的。 不保存基数的元数据，这一点对需要使用元数据进行数据分析的场景并不友好。 HyperLogLog命令使用 Redis提供的HyperLogLog数据类型一共有三个命令API：PFADD、PFCOUNT和PFMERGE。 PFADD PFADD命令参数如下： 1PFADD key element [element …] 支持此命令的Redis版本是：&gt;= 2.8.9 时间复杂度：每添加一个元素的复杂度为O(1) 功能：将所有元素参数element添加到键为key的HyperLogLog数据结构中。 PFADD命令的执行流程如下： PFADD命令的使用方式如下： 12345678910127.0.0.1:6379&gt; PFADD food apple fish(integer) 1127.0.0.1:6379&gt; PFADD food apple(integer) 0127.0.0.1:6379&gt; PFADD throwable(integer) 1127.0.0.1:6379&gt; SET name dogeOK127.0.0.1:6379&gt; PFADD name throwable(error) WRONGTYPE Key is not a valid HyperLogLog string value. 虽然HyperLogLog数据结构本质是一个字符串，但是不能在String类型的KEY使用HyperLogLog的相关命令。 PFCOUNT PFCOUNT命令参数如下： 1PFCOUNT key [key …] 支持此命令的Redis版本是：&gt;= 2.8.9 时间复杂度：返回单个HyperLogLog的基数计数值的复杂度为O(1)，平均常数时间比较低。当参数为多个key的时候，复杂度为O(N)，N为key的个数。 当PFCOUNT命令使用单个key的时候，返回储存在给定键的HyperLogLog数据结构的近似基数，如果键不存在， 则返回0。 当PFCOUNT命令使用多个key的时候，返回储存在给定的所有HyperLogLog数据结构的并集的近似基数，也就是会把所有的HyperLogLog数据结构合并到一个临时的HyperLogLog数据结构，然后计算出近似基数。 PFCOUNT命令的使用方式如下： 12345678910127.0.0.1:6379&gt; PFADD POST:1 ip-1 ip-2(integer) 1127.0.0.1:6379&gt; PFADD POST:2 ip-2 ip-3 ip-4(integer) 1127.0.0.1:6379&gt; PFCOUNT POST:1(integer) 2127.0.0.1:6379&gt; PFCOUNT POST:1 POST:2(integer) 4127.0.0.1:6379&gt; PFCOUNT NOT_EXIST_KEY(integer) 0 PFMERGE PFMERGE命令参数如下： 1PFMERGE destkey sourcekey [sourcekey ...] 支持此命令的Redis版本是：&gt;= 2.8.9 时间复杂度：O(N)，其中N为被合并的HyperLogLog数据结构的数量，此命令的常数时间比较高 功能：把多个HyperLogLog数据结构合并为一个新的键为destkey的HyperLogLog数据结构，合并后的HyperLogLog的基数接近于所有输入HyperLogLog的可见集合（Observed Set）的并集的基数。 命令返回值：只会返回字符串OK。 PFMERGE命令的使用方式如下 12345678127.0.0.1:6379&gt; PFADD POST:1 ip-1 ip-2(integer) 1127.0.0.1:6379&gt; PFADD POST:2 ip-2 ip-3 ip-4(integer) 1127.0.0.1:6379&gt; PFMERGE POST:1-2 POST:1 POST:2OK127.0.0.1:6379&gt; PFCOUNT POST:1-2(integer) 4 使用HyperLogLog统计UV的案例 假设现在有个简单的场景，就是统计博客文章的UV，要求UV的计数不需要准确，也不需要保存客户端的IP数据。下面就这个场景，使用HyperLogLog做一个简单的方案和编码实施。 这个流程可能步骤的先后顺序可能会有所调整，但是要做的操作是基本不变的。先简单假设，文章的内容和统计数据都是后台服务返回的，两个接口是分开设计。引入Redis的高级客户端Lettuce依赖： 12345&lt;dependency&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt; &lt;version&gt;5.2.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; 编码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class UvTest &#123; private static RedisCommands&lt;String, String&gt; COMMANDS; @BeforeClass public static void beforeClass() throws Exception &#123; // 初始化Redis客户端 RedisURI uri = RedisURI.builder().withHost(\"localhost\").withPort(6379).build(); RedisClient redisClient = RedisClient.create(uri); StatefulRedisConnection&lt;String, String&gt; connect = redisClient.connect(); COMMANDS = connect.sync(); &#125; @Data public static class PostDetail &#123; private Long id; private String content; &#125; private PostDetail selectPostDetail(Long id) &#123; PostDetail detail = new PostDetail(); detail.setContent(\"content\"); detail.setId(id); return detail; &#125; private PostDetail getPostDetail(String clientIp, Long postId) &#123; PostDetail detail = selectPostDetail(postId); String key = \"puv:\" + postId; COMMANDS.pfadd(key, clientIp); return detail; &#125; private Long getPostUv(Long postId) &#123; String key = \"puv:\" + postId; return COMMANDS.pfcount(key); &#125; @Test public void testViewPost() throws Exception &#123; Long postId = 1L; getPostDetail(\"111.111.111.111\", postId); getPostDetail(\"111.111.111.222\", postId); getPostDetail(\"111.111.111.333\", postId); getPostDetail(\"111.111.111.444\", postId); System.out.println(String.format(\"The uv count of post [%d] is %d\", postId, getPostUv(postId))); &#125;&#125; 输出结果： 1The uv count of post [1] is 4 可以适当使用更多数量的不同客户端IP调用getPostDetail()，然后统计一下误差。 题外话-如何准确地统计UV 如果想要准确统计UV，则需要注意几个点： 内存或者磁盘容量需要准备充足，因为就目前的基数计数算法来看，没有任何算法可以在不保存元数据的前提下进行准确计数。 如果需要做用户行为分析，那么元数据最终需要持久化，这一点应该依托于大数据体系，在这一方面笔者没有经验，所以暂时不多说。 假设在不考虑内存成本的前提下，我们依然可以使用Redis做准确和实时的UV统计，简单就可以使用Set数据类型，增加UV只需要使用SADD命令，统计UV只需要使用SCARD命令（时间复杂度为O(1)，可以放心使用）。举例： 123456127.0.0.1:6379&gt; SADD puv:1 ip-1 ip-2(integer) 2127.0.0.1:6379&gt; SADD puv:1 ip-3 ip-4(integer) 2127.0.0.1:6379&gt; SCARD puv:1(integer) 4 如果这些统计数据仅仅是用户端展示，那么可以采用异步设计： 在体量小的时候，上面的所有应用的功能可以在同一个服务中完成，消息队列可以用线程池的异步方案替代。 小结 这篇文章只是简单介绍了HyperLogLog的使用和统计UV的使用场景。总的来说就是：在（1）原始数据量巨大，（2）内存占用要求尽可能小，（3）允许计数存在一定误差并且（4）不要求存放元数据的场景下，可以优先考虑使用HyperLogLog进行计数。 参考资料： antirez-Redis new data structure: the HyperLogLog Redis Commands 维基百科 （本文完 c-3-d e-a-20191117）","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Redis","slug":"Middleware/Redis","permalink":"http://throwable.club/blog/categories/Middleware/Redis/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Redis","slug":"Redis","permalink":"http://throwable.club/blog/tags/Redis/"}]},{"title":"使用Redis实现UA池","slug":"redis-in-action-ua-pool","date":"2019-11-13T17:02:36.000Z","updated":"2019-11-28T17:00:58.743Z","comments":true,"path":"2019/11/14/redis-in-action-ua-pool/","link":"","permalink":"http://throwable.club/2019/11/14/redis-in-action-ua-pool/","excerpt":"前提 最近忙于业务开发、交接和游戏，加上碰上了不定时出现的犹豫期和困惑期，荒废学业了一段时间。天冷了，要重新拾起开始下阶段的学习了。之前接触到的一些数据搜索项目，涉及到请求模拟，基于反爬需要使用随机的User Agent，于是使用Redis实现了一个十分简易的UA池。","text":"前提 最近忙于业务开发、交接和游戏，加上碰上了不定时出现的犹豫期和困惑期，荒废学业了一段时间。天冷了，要重新拾起开始下阶段的学习了。之前接触到的一些数据搜索项目，涉及到请求模拟，基于反爬需要使用随机的User Agent，于是使用Redis实现了一个十分简易的UA池。 背景 最近的一个需求，有模拟请求的逻辑，要求每次请求的请求头中的User Agent要满足下面几点： 每次获取的User Agent是随机的。 每次获取的User Agent（短时间内）不能重复。 每次获取的User Agent必须带有主流的操作系统信息（可以是Uinux、Windows、IOS和安卓等等）。 这里三点都可以从UA数据的来源解决，实际上我们应该关注具体的实现方案。简单分析一下，流程如下： 在设计UA池的时候，它的数据结构和环形队列十分类似： 上图中，假设不同颜色的UA是完全不同的UA，它们通过洗牌算法打散放进去环形队列中，实际上每次取出一个UA之后，只需要把游标cursor前进或者后退一格即可（甚至可以把游标设置到队列中的任意元素）。最终的实现就是：需要通过中间件实现分布式队列（只是队列，不是消息队列）。 具体实现方案 毫无疑问需要一个分布式数据库类型的中间件才能存放已经准备好的UA，第一印象就感觉Redis会比较合适。接下来需要选用Redis的数据类型，主要考虑几个方面： 具备队列性质。 最好支持随机访问。 元素入队、出队和随机访问的时间复杂度要低，毕竟获取UA的接口访问量会比较大。 支持这几个方面的Redis数据类型就是List，不过注意List本身不能去重，去重的工作可以用代码逻辑实现。然后可以想象客户端获取UA的流程大致如下： 结合前面的分析，编码过程有如下几步： 准备好需要导入的UA数据，可以从数据源读取，也可以直接文件读取。 因为需要导入的UA数据集合一般不会太大，考虑先把这个集合的数据随机打散，如果使用Java开发可以直接使用Collections#shuffle()洗牌算法，当然也可以自行实现这个数据随机分布的算法，这一步对于一些被模拟方会严格检验UA合法性的场景是必须的。 导入UA数据到Redis列表中。 编写RPOP + LPUSH的Lua脚本，实现分布式循环队列。 编码和测试示例 引入Redis的高级客户端Lettuce依赖： 12345&lt;dependency&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt; &lt;version&gt;5.2.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; 编写RPOP + LPUSH的Lua脚本，Lua脚本名字暂称为L_RPOP_LPUSH.lua，放在resources/scripts/lua目录下： 1234local key = KEYS[1]local value = redis.call('RPOP', key)redis.call('LPUSH', key, value)return value 这个脚本十分简单，但是已经实现了循环队列的功能。剩下来的测试代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041public class UaPoolTest &#123; private static RedisCommands&lt;String, String&gt; COMMANDS; private static AtomicReference&lt;String&gt; LUA_SHA = new AtomicReference&lt;&gt;(); private static final String KEY = \"UA_POOL\"; @BeforeClass public static void beforeClass() throws Exception &#123; // 初始化Redis客户端 RedisURI uri = RedisURI.builder().withHost(\"localhost\").withPort(6379).build(); RedisClient redisClient = RedisClient.create(uri); StatefulRedisConnection&lt;String, String&gt; connect = redisClient.connect(); COMMANDS = connect.sync(); // 模拟构建UA池的原始数据,假设有10个UA,分别是UA-0 ... UA-9 List&lt;String&gt; uaList = Lists.newArrayList(); IntStream.range(0, 10).forEach(e -&gt; uaList.add(String.format(\"UA-%d\", e))); // 洗牌 Collections.shuffle(uaList); // 加载Lua脚本 ClassPathResource resource = new ClassPathResource(\"/scripts/lua/L_RPOP_LPUSH.lua\"); String content = StreamUtils.copyToString(resource.getInputStream(), StandardCharsets.UTF_8); String sha = COMMANDS.scriptLoad(content); LUA_SHA.compareAndSet(null, sha); // Redis队列中写入UA数据,数据量多的时候可以考虑分批写入防止长时间阻塞Redis服务 COMMANDS.lpush(KEY, uaList.toArray(new String[0])); &#125; @AfterClass public static void afterClass() throws Exception &#123; COMMANDS.del(KEY); &#125; @Test public void testUaPool() &#123; IntStream.range(1, 21).forEach(e -&gt; &#123; String result = COMMANDS.evalsha(LUA_SHA.get(), ScriptOutputType.VALUE, KEY); System.out.println(String.format(\"第%d次获取到的UA是:%s\", e, result)); &#125;); &#125;&#125; 某次运行结果如下： 1234567891011121314151617181920第1次获取到的UA是:UA-0第2次获取到的UA是:UA-8第3次获取到的UA是:UA-2第4次获取到的UA是:UA-4第5次获取到的UA是:UA-7第6次获取到的UA是:UA-5第7次获取到的UA是:UA-1第8次获取到的UA是:UA-3第9次获取到的UA是:UA-6第10次获取到的UA是:UA-9第11次获取到的UA是:UA-0第12次获取到的UA是:UA-8第13次获取到的UA是:UA-2第14次获取到的UA是:UA-4第15次获取到的UA是:UA-7第16次获取到的UA是:UA-5第17次获取到的UA是:UA-1第18次获取到的UA是:UA-3第19次获取到的UA是:UA-6第20次获取到的UA是:UA-9 可见洗牌算法的效果不差，数据相对分散。 小结 其实UA池的设计难度并不大，需要注意几个要点： 一般主流的移动设备或者桌面设备的系统版本不会太多，所以来源UA数据不会太多，最简单的实现可以使用文件存放，一次读取直接写入Redis中。 注意需要随机打散UA数据，避免同一个设备系统类型的UA数据过于密集，这样可以避免触发模拟某些请求时候的风控规则。 需要熟悉Lua的语法，毕竟Redis的原子指令一定离不开Lua脚本。 （本文完 c-2-d e-a-20191114）","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Redis","slug":"Middleware/Redis","permalink":"http://throwable.club/blog/categories/Middleware/Redis/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Redis","slug":"Redis","permalink":"http://throwable.club/blog/tags/Redis/"}]},{"title":"一文彻底理解Redis序列化协议，你也可以编写Redis客户端","slug":"redis-serialization-protocol-decode-guide","date":"2019-10-09T14:40:13.000Z","updated":"2019-11-28T17:01:03.790Z","comments":true,"path":"2019/10/09/redis-serialization-protocol-decode-guide/","link":"","permalink":"http://throwable.club/2019/10/09/redis-serialization-protocol-decode-guide/","excerpt":"前提 最近学习Netty的时候想做一个基于Redis服务协议的编码解码模块，过程中顺便阅读了Redis服务序列化协议RESP，结合自己的理解对文档进行了翻译并且简单实现了RESP基于Java语言的解析。编写本文的使用使用的JDK版本为[8+]。","text":"前提 最近学习Netty的时候想做一个基于Redis服务协议的编码解码模块，过程中顺便阅读了Redis服务序列化协议RESP，结合自己的理解对文档进行了翻译并且简单实现了RESP基于Java语言的解析。编写本文的使用使用的JDK版本为[8+]。 RESP简介 Redis客户端与Redis服务端基于一个称作RESP的协议进行通信，RESP全称为Redis Serialization Protocol，也就是Redis序列化协议。虽然RESP为Redis设计，但是它也可以应用在其他客户端-服务端（Client-Server）的软件项目中。RESP在设计的时候折中考虑了如下几点： 易于实现。 快速解析。 可读性高。 RESP可以序列化不同的数据类型，如整型、字符串、数组还有一种特殊的Error类型。需要执行的Redis命令会封装为类似于字符串数组的请求然后通过Redis客户端发送到Redis服务端。Redis服务端会基于特定的命令类型选择对应的一种数据类型进行回复（这一句是意译，原文是：Redis replies with a command-specific data type）。 RESP是二进制安全的（binary-safe），并且在RESP下不需要处理从一个进程传输到另一个进程的批量数据，因为它使用了前缀长度（prefixed-length，后面会分析，就是在每个数据块的前缀已经定义好数据块的个数，类似于Netty里面的定长编码解码）来传输批量数据。 注意：此处概述的协议仅仅使用在客户端-服务端通信，Redis Cluster使用不同的二进制协议在多个节点之间交换消息（也就是Redis集群中的节点之间并不使用RESP通信）。 网络层 Redis客户端通过创建一个在6379端口的TCP连接，连接到Redis服务端。 虽然RESP在底层通信协议技术上是非TCP特定的，但在Redis的上下文中，RESP仅用于TCP连接（或类似的面向流的连接，如Unix套接字）。 请求-响应模型 Redis服务端接收由不同参数组成的命令，接收到命令并将其处理之后会把回复发送回Redis客户端。这是最简单的模型，但是有两种例外的情况： Redis支持管道（Pipelining，流水线，多数情况下习惯称为管道）操作。使用管道的情况下，Redis客户端可以一次发送多个命令，然后等待一次性的回复（文中的回复是replies，理解为Redis服务端会一次性返回一个批量回复结果）。 当Redis客户端订阅Pub/Sub信道时，该协议会更改语义并成为推送协议（push protocol），也就是说，客户端不再需要发送命令，因为Redis服务端将自动向客户端（订阅了改信道的客户端）发送新消息（这里的意思是：在订阅/发布模式下，消息是由Redis服务端主动推送给订阅了特定信道的Redis客户端）。 除了上述两个特例之外，Redis协议是一种简单的请求-响应协议。 RESP支持的数据类型 RESP在Redis 1.2中引入，在Redis 2.0，RESP正式成为与Redis服务端通信的标准方案。也就是如果需要编写Redis客户端，你就必须在客户端中实现此协议。 RESP本质上是一种序列化协议，它支持的数据类型如下：单行字符串、错误消息、整型数字、定长字符串和RESP数组。 RESP在Redis中用作请求-响应协议的方式如下： Redis客户端将命令封装为RESP的数组类型（数组元素都是定长字符串类型，注意这一点，很重要）发送到Redis服务器。 Redis服务端根据命令实现选择对应的RESP数据类型之一进行回复。 在RESP中，数据类型取决于数据报的第一个字节： 单行字符串的第一个字节为+。 错误消息的第一个字节为-。 整型数字的第一个字节为:。 定长字符串的第一个字节为$。 RESP数组的第一个字节为*。 另外，在RESP中可以使用定长字符串或者数组的特殊变体来表示Null值，后面会提及。在RESP中，协议的不同部分始终以\\r\\n（CRLF）终止。 目前RESP中5种数据类型的小结如下： 数据类型 本文翻译名称 基本特征 例子 Simple String 单行字符串 第一个字节是+，最后两个字节是\\r\\n，其他字节是字符串内容 +OK\\r\\n Error 错误消息 第一个字节是-，最后两个字节是\\r\\n，其他字节是异常消息的文本内容 -ERR\\r\\n Integer 整型数字 第一个字节是:，最后两个字节是\\r\\n，其他字节是数字的文本内容 :100\\r\\n Bulk String 定长字符串 第一个字节是$，紧接着的字节是内容字符串长度\\r\\n，最后两个字节是\\r\\n，其他字节是字符串内容 $4\\r\\ndoge\\r\\n Array RESP数组 第一个字节是*，紧接着的字节是元素个数\\r\\n，最后两个字节是\\r\\n，其他字节是各个元素的内容，每个元素可以是任意一种数据类型 *2\\r\\n:100\\r\\n$4\\r\\ndoge\\r\\n 下面的小节是对每种数据类型的更细致的分析。 RESP简单字符串-Simple String 简单字符串的编码方式如下： （1）第一个字节为+。 （2）紧接着的是一个不能包含CR或者LF字符的字符串。 （3）以CRLF终止。 简单字符串能够保证在最小开销的前提下传输非二进制安全的字符串。例如很多Redis命令执行成功后服务端需要回复OK字符串，此时通过简单字符串编码为5字节的数据报如下： 1+OK\\r\\n 如果需要发送二进制安全的字符串，那么需要使用定长字符串。 当Redis服务端用简单字符串响应时，Redis客户端库应该向调用者返回一个字符串，该响应到调用者的字符串由+之后直到字符串内容末尾的字符组成（其实就是上面提到的第（2）部分的内容），不包括最后的CRLF字节。 RESP错误消息-Error 错误消息类型是RESP特定的数据类型。实际上，错误消息类型和简单字符串类型基本一致，只是其第一个字节为-。错误消息类型跟简单字符串类型的最大区别是：错误消息作为Redis服务端响应的时候，对于客户端而言应该感知为异常，而错误消息中的字符串内容应该感知为Redis服务端返回的错误信息。错误消息的编码方式如下： （1）第一个字节为-。 （2）紧接着的是一个不能包含CR或者LF字符的字符串。 （3）以CRLF终止。 一个简单的例子如下： 1-Error message\\r\\n Redis服务端只有在真正发生错误或者感知错误的时候才会回复错误消息，例如尝试对错误的数据类型执行操作或者命令不存在等等。Redis客户端接收到错误消息的时候，应该触发异常（一般情况就是直接抛出异常，可以根据错误消息的内容进行异常分类）。下面是错误消息响应的一些例子： 12-ERR unknown command 'foobar'-WRONGTYPE Operation against a key holding the wrong kind of value -之后的第一个单词到第一个空格或换行符之间的内容，代表返回的错误类型。这只是Redis使用的约定，不是RESP错误消息格式的一部分。 例如，ERR是通用错误，WRONGTYPE则是更具体的错误，表示客户端试图针对错误的数据类型执行操作。这种定义方式称为错误前缀，是一种使客户端能够理解服务器返回的错误类型的方法，而不必依赖于所给出的确切消息定义，该消息可能会随时间而变化。 客户端实现可以针对不同的错误类型返回不同种类的异常，或者可以通过将错误类型的名称作为字符串直接提供给调用方来提供捕获错误的通用方法。 但是，不应该将错误消息分类处理的功能视为至关重要的功能，因为它作用并不巨大，并且有些的客户端实现可能会简单地返回特定值去屏蔽错误消息作为通用的异常处理，例如直接返回false。 RESP整型数字-Integer 整型数字的编码方式如下： （1）第一个字节为：。 （2）紧接着的是一个不能包含CR或者LF字符的字符串，也就是数字要先转换为字符序列，最终要输出为字节。 （3）以CRLF终止。 例如： 12:0\\r\\n:1000\\r\\n 许多Redis命令返回整型数字，像INCR，LLEN和LASTSAVE命令等等。 返回的整型数字没有特殊的含义，像INCR返回的是增量的总量，而LASTSAVE是UNIX时间戳。但是Redis服务端保证返回的整型数字在带符号的64位整数范围内。 有些情况下，返回的整型数字会指代true或者false。如EXISTS或者SISMEMBER命令执行返回1代表true，0代表false。 有些情况下，返回的整型数字会指代命令是否真正产生了效果。如SADD，SREM和SETNX命令执行返回1代表命令执行生效，0代表命令执行不生效（等价于命令没有执行）。 下面的一组命令执行后都是返回整型数字：SETNX, DEL, EXISTS, INCR, INCRBY, DECR, DECRBY, DBSIZE, LASTSAVE, RENAMENX, MOVE, LLEN, SADD, SREM, SISMEMBER, SCARD。 RESP定长字符串-Bulk String 定长字符串用于表示一个最大长度为512MB的二进制安全的字符串（Bulk，本身有体积大的含义）。定长字符串的编码方式如下： （1）第一个字节为$。 （2）紧接着的是组成字符串的字节数长度（称为prefixed length，也就是前缀长度），前缀长度分块以CRLF终止。 （3）然后是一个不能包含CR或者LF字符的字符串，也就是数字要先转换为字符序列，最终要输出为字节。 （4）以CRLF终止。 举个例子，doge使用定长字符串编码如下： 第一个字节 前缀长度 CRLF 字符串内容 CRLF 定长字符串 $ 4 \\r\\n doge \\r\\n ===&gt; $4\\r\\ndoge\\r\\n foobar使用定长字符串编码如下： 第一个字节 前缀长度 CRLF 字符串内容 CRLF 定长字符串 $ 6 \\r\\n foobar \\r\\n ===&gt; $6\\r\\nfoobar\\r\\n 表示空字符串（Empty String，对应Java中的&quot;&quot;） 的时候，使用定长字符串编码如下： 第一个字节 前缀长度 CRLF CRLF 定长字符串 $ 0 \\r\\n \\r\\n ===&gt; $0\\r\\n\\r\\n 定长字符串也可以使用特殊的格式来表示Null值，指代值不存在。在这种特殊格式中，前缀长度为-1，并且没有数据，因此使用定长字符串对Null值进行编码如下： 第一个字节 前缀长度 CRLF 定长字符串 $ -1 \\r\\n ===&gt; $-1\\r\\n 当Redis服务端返回定长字符串编码的Null值的时候，客户端不应该返回空字符串，而应该返回对应编程语言中的Null对象。例如Ruby中对应nil，C语言中对应NULL，Java中对应null，以此类推。 RESP数组-Array Redis客户端使用RESP数组发送命令到Redis服务端。与此相似，某些Redis命令执行完毕后服务端需要使用RESP数组类型将元素集合返回给客户端，如返回一个元素列表的LRANGE命令。RESP数组和我们认知中的数组并不完全一致，它的编码格式如下： （1）第一个字节为*。 （2）紧接着的是组成RESP数组的元素个数（十进制数，但是最终需要转换为字节序列，如10需要转换为1和0两个相邻的字节），元素个数分块以CRLF终止。 （3）RESP数组的每个元素内容，每个元素可以是任意的RESP数据类型。 一个空的RESP数组的编码如下： 1*0\\r\\n 一个包含2个定长字符串元素内容分别为foo和bar的RESP数组的编码如下： 1*2\\r\\n$3\\r\\nfoo\\r\\n$3\\r\\nbar\\r\\n 通用格式就是：*&lt;count&gt;CRLF作为RESP数组的前缀部分，而组成RESP数组的其他数据类型的元素只是一个接一个地串联在一起。例如一个包含3个整数类型元素的RESP数组的编码如下： 1*3\\r\\n:1\\r\\n:2\\r\\n:3\\r\\n RESP数组的元素不一定是同一种数据类型，可以包含混合类型的元素。例如下面是一个包含4个整数类型元素和1个定长字符串类型元素（一共有5个元素）的RESP数组的编码（为了看得更清楚，分多行进行编码，实际上不能这样做）： 12345678910111213# 元素个数*5\\r\\n# 第1个整型类型的元素:1\\r\\n# 第2个整型类型的元素:2\\r\\n# 第3个整型类型的元素:3\\r\\n# 第4个整型类型的元素:4\\r\\n# 定长字符串类型的元素$6\\r\\nfoobar\\r\\n Redis服务端响应报的首行*5\\r\\n定义了后面会紧跟着5个回复数据，然后每个回复数据分别作元素项，构成了用于传输的多元素定长回复（Multi Bulk Reply，感觉比较难翻译，这里的大概意思就是每个回复行都是整个回复报中的一个项）。 这里可以类比为Java中的ArrayList（泛型擦除），有点类似于下面的伪代码： 123456789101112131415161718192021222324252627List encode = new ArrayList();// 添加元素个数encode.add(elementCount);encode.add(CRLF);// 添加第1个整型类型的元素 - 1encode.add(':');encode.add(1);encode.add(CRLF);// 添加第2个整型类型的元素 - 2encode.add(':');encode.add(2);encode.add(CRLF);// 添加第3个整型类型的元素 - 3encode.add(':');encode.add(3);encode.add(CRLF);// 添加第4个整型类型的元素 - 4encode.add(':');encode.add(4);encode.add(CRLF);// 添加定长字符串类型的元素encode.add('$');// 前缀长度encode.add(6);// 字符串内容encode.add(\"foobar\");encode.add(CRLF); RESP数组中也存在Null值的概念，下面称为RESP Null Array。处于历史原因，RESP数组中采用了另一种特殊的编码格式定义Null值，区别于定长字符串中的Null值字符串。例如，BLPOP命令执行超时的时候，就会返回一个RESP Null Array类型的响应。RESP Null Array的编码如下： 1*-1\\r\\n 当Redis服务端的回复是RESP Null Array类型的时候，客户端应该返回一个Null对象，而不是一个空数组或者空列表。这一点比较重要，它是区分回复是空数组（也就是命令正确执行完毕，返回结果正常）或者其他原因（如BLPOP命令的超时等）的关键。 RESP数组的元素也可以是RESP数组，下面是一个包含2个RESP数组类型的元素的RESP数组，编码如下（为了看得更清楚，分多行进行编码，实际上不能这样做）： 1234567891011# 元素个数*2\\r\\n# 第1个RESP数组元素*3\\r\\n:1\\r\\n:2\\r\\n:3\\r\\n# 第2个RESP数组元素*2\\r\\n+Foo\\r\\n-Bar\\r\\n 上面的RESP数组的包含2个RESP数组类型的元素，第1个RESP数组元素包含3个整型类型的元素，而第2个RESP数组元素包含1个简单字符串类型的元素和1个错误消息类型的元素。 RESP数组中的Null元素 RESP数组中的单个元素也有Null值的概念，下面称为Null元素。Redis服务端回复如果是RESP数组类型，并且RESP数组中存在Null元素，那么意味着元素丢失，绝对不能用空字符串替代。缺少指定键的前提下，当与GET模式选项一起使用时，SORT命令可能会发生这种情况。 下面是一个包含Null元素的RESP数组的例子（为了看得更清楚，分多行进行编码，实际上不能这样做）： 123456*3\\r\\n$3\\r\\nfoo\\r\\n$-1\\r\\n$3\\r\\nbar\\r\\n RESP数组中的第2个元素是Null元素，客户端API最终返回的内容应该是： 1234# Ruby[\"foo\",nil,\"bar\"]# Java[\"foo\",null,\"bar\"] RESP其他相关内容 主要包括： 将命令发送到Redis服务端的示例。 批量命令与管道。 内联命令（Inline Commands）。 其实文档中还有一节使用C语言编写高性能RESP解析器，这里不做翻译，因为掌握RESP的相关内容后，可以基于任何语言编写解析器。 将命令发送到Redis服务端 如果已经相对熟悉RESP中的序列化格式，那么编写Redis客户端类库就会变得很容易。我们可以进一步指定客户端和服务器之间的交互方式： Redis客户端向Redis服务端发送仅仅包含定长字符串类型元素的RESP数组。 Redis服务端可以采用任意一种RESP数据类型向Redis客户端进行回复，具体的数据类型一般取决于命令类型。 下面是典型的交互例子：Redis客户端发送命令LLEN mylist以获得KEY为mylist的长度，Redis服务端将以整数类型进行回复，如以下示例所示（C是客户端，S服务器），伪代码如下： 1234567C: *2\\r\\nC: $4\\r\\nC: LLEN\\r\\nC: $6\\r\\nC: mylist\\r\\nS: :48293\\r\\n 为了简单起见，我们使用换行符来分隔协议的不同部分（这里指上面的代码分行展示），但是实际交互的时候Redis客户端在发送*2\\r\\n$4\\r\\nLLEN\\r\\n$6\\r\\nmylist\\r\\n的时候是整体发送的。 批量命令与管道 Redis客户端可以使用相同的连接发送批量命令。Redis支持管道特性，因此Redis客户端可以通过一次写操作发送多个命令，而无需在发送下一个命令之前读取Redis服务端对上一个命令的回复。批量发送命令之后，所有的回复可以在最后得到（合并为一个回复）。更多相关信息可以查看Using pipelining to speedup Redis queries。 内联命令 有些场景下，我们可能只有telnet命令可以使用，在这种条件下，我们需要发送命令到Redis服务端。尽管Redis协议易于实现，但在交互式会话中并不理想，并且redis-cli有些情况下不一定可用。处于这类原因，Redis设计了一种专为人类设计的命令格式，称为内联命令（Inline Command格式。 以下是服务器/客户端使用内联命令进行聊天的示例（S代表服务端，C代表客户端）： 12C: PINGS: +PONG 以下是使用内联命令返回整数的另一个示例： 12C: EXISTS somekeyS: :0 基本上只需在telnet会话中编写以空格分隔的参数。由于除了统一的请求协议之外没有命令会以*开头，Redis能够检测到这种情况并解析输入的命令。 基于RESP编写高性能解析器 因为JDK原生提供的字节缓冲区java.nio.ByteBuffer存在不能自动扩容、需要切换读写模式等等问题，这里直接引入Netty并且使用Netty提供的ByteBuf进行RESP数据类型解析。编写本文的时候（2019-10-09）Netty的最新版本为4.1.42.Final。引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-buffer&lt;/artifactId&gt; &lt;version&gt;4.1.42.Final&lt;/version&gt;&lt;/dependency&gt; 定义解码器接口： 1234public interface RespDecoder&lt;V&gt;&#123; V decode(ByteBuf buffer);&#125; 定义常量： 12345678910111213141516171819202122232425262728293031public class RespConstants &#123; public static final Charset ASCII = StandardCharsets.US_ASCII; public static final Charset UTF_8 = StandardCharsets.UTF_8; public static final byte DOLLAR_BYTE = '$'; public static final byte ASTERISK_BYTE = '*'; public static final byte PLUS_BYTE = '+'; public static final byte MINUS_BYTE = '-'; public static final byte COLON_BYTE = ':'; public static final String EMPTY_STRING = \"\"; public static final Long ZERO = 0L; public static final Long NEGATIVE_ONE = -1L; public static final byte CR = (byte) '\\r'; public static final byte LF = (byte) '\\n'; public static final byte[] CRLF = \"\\r\\n\".getBytes(ASCII); public enum ReplyType &#123; SIMPLE_STRING, ERROR, INTEGER, BULK_STRING, RESP_ARRAY &#125;&#125; 下面的章节中解析模块的实现已经忽略第一个字节的解析，因为第一个字节是决定具体的数据类型。 解析简单字符串 简单字符串类型就是单行字符串，它的解析结果对应的就是Java中的String类型。解码器实现如下： 1234567891011121314151617181920212223242526272829303132333435363738// 解析单行字符串public class LineStringDecoder implements RespDecoder&lt;String&gt; &#123; @Override public String decode(ByteBuf buffer) &#123; return CodecUtils.X.readLine(buffer); &#125;&#125;public enum CodecUtils &#123; X; public int findLineEndIndex(ByteBuf buffer) &#123; int index = buffer.forEachByte(ByteProcessor.FIND_LF); return (index &gt; 0 &amp;&amp; buffer.getByte(index - 1) == '\\r') ? index : -1; &#125; public String readLine(ByteBuf buffer) &#123; int lineEndIndex = findLineEndIndex(buffer); if (lineEndIndex &gt; -1) &#123; int lineStartIndex = buffer.readerIndex(); // 计算字节长度 int size = lineEndIndex - lineStartIndex - 1; byte[] bytes = new byte[size]; buffer.readBytes(bytes); // 重置读游标为\\r\\n之后的第一个字节 buffer.readerIndex(lineEndIndex + 1); buffer.markReaderIndex(); return new String(bytes, RespConstants.UTF_8); &#125; return null; &#125;&#125;public class RespSimpleStringDecoder extends LineStringDecoder &#123; &#125; 这里抽取出一个类LineStringDecoder用于解析单行字符串，这样在解析错误消息的时候可以做一次继承即可。测试一下： 123456789public static void main(String[] args) throws Exception &#123; ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(); // +OK\\r\\n buffer.writeBytes(\"+OK\".getBytes(RespConstants.UTF_8)); buffer.writeBytes(RespConstants.CRLF); String value = RespCodec.X.decode(buffer); log.info(\"Decode result:&#123;&#125;\", value);&#125;// Decode result:OK 解析错误消息 错误消息的本质也是单行字符串，所以其解码的实现可以和简单字符串的解码实现一致。错误消息数据类型的解码器如下： 123public class RespErrorDecoder extends LineStringDecoder &#123;&#125; 测试一下： 123456789public static void main(String[] args) throws Exception &#123; ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(); // -ERR unknown command 'foobar'\\r\\n buffer.writeBytes(\"-ERR unknown command 'foobar'\".getBytes(RespConstants.UTF_8)); buffer.writeBytes(RespConstants.CRLF); String value = RespCodec.X.decode(buffer); log.info(\"Decode result:&#123;&#125;\", value);&#125;// Decode result:ERR unknown command 'foobar' 解析整型数字 整型数字类型，本质就是需要从字节序列中还原出带符号的64bit的长整型，因为是带符号的，类型标识位:后的第一个字节需要判断是否负数字符-，因为是从左向右解析，然后每解析出一个新的位，当前的数字值要乘10。其解码器的实现如下： 123456789101112131415161718192021222324252627282930313233public class RespIntegerDecoder implements RespDecoder&lt;Long&gt; &#123; @Override public Long decode(ByteBuf buffer) &#123; int lineEndIndex = CodecUtils.X.findLineEndIndex(buffer); // 没有行尾，异常 if (-1 == lineEndIndex) &#123; return null; &#125; long result = 0L; int lineStartIndex = buffer.readerIndex(); boolean negative = false; byte firstByte = buffer.getByte(lineStartIndex); // 负数 if (RespConstants.MINUS_BYTE == firstByte) &#123; negative = true; &#125; else &#123; int digit = firstByte - '0'; result = result * 10 + digit; &#125; for (int i = lineStartIndex + 1; i &lt; (lineEndIndex - 1); i++) &#123; byte value = buffer.getByte(i); int digit = value - '0'; result = result * 10 + digit; &#125; if (negative) &#123; result = -result; &#125; // 重置读游标为\\r\\n之后的第一个字节 buffer.readerIndex(lineEndIndex + 1); return result; &#125;&#125; 整型数字类型的解析相对复杂，一定要注意负数判断。测试一下： 123456789public static void main(String[] args) throws Exception &#123; ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(); // :-1000\\r\\n buffer.writeBytes(\":-1000\".getBytes(RespConstants.UTF_8)); buffer.writeBytes(RespConstants.CRLF); Long value = RespCodec.X.decode(buffer); log.info(\"Decode result:&#123;&#125;\", value);&#125;// Decode result:-1000 解析定长字符串 定长字符串类型解析的关键是先读取类型标识符$后的第一个字节序列分块解析成64bit带符号的整数，用来确定后面需要解析的字符串内容的字节长度，然后再按照该长度读取后面的字节。其解码器实现如下： 123456789101112131415161718192021222324252627282930313233public class RespBulkStringDecoder implements RespDecoder&lt;String&gt; &#123; @Override public String decode(ByteBuf buffer) &#123; int lineEndIndex = CodecUtils.X.findLineEndIndex(buffer); if (-1 == lineEndIndex) &#123; return null; &#125; // 使用RespIntegerDecoder读取长度 Long length = (Long) DefaultRespCodec.DECODERS.get(ReplyType.INTEGER).decode(buffer); if (null == length) &#123; return null; &#125; // Bulk Null String if (RespConstants.NEGATIVE_ONE.equals(length)) &#123; return null; &#125; // Bulk Empty String if (RespConstants.ZERO.equals(length)) &#123; return RespConstants.EMPTY_STRING; &#125; // 真实字节内容的长度 int readLength = (int) length.longValue(); if (buffer.readableBytes() &gt; readLength) &#123; byte[] bytes = new byte[readLength]; buffer.readBytes(bytes); // 重置读游标为\\r\\n之后的第一个字节 buffer.readerIndex(buffer.readerIndex() + 2); return new String(bytes, RespConstants.UTF_8); &#125; return null; &#125;&#125; 测试一下： 123456789101112public static void main(String[] args) throws Exception&#123; ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(); // $6\\r\\nthrowable\\r\\n buffer = ByteBufAllocator.DEFAULT.buffer(); buffer.writeBytes(\"$9\".getBytes(RespConstants.UTF_8)); buffer.writeBytes(RespConstants.CRLF); buffer.writeBytes(\"throwable\".getBytes(RespConstants.UTF_8)); buffer.writeBytes(RespConstants.CRLF); String value = RespCodec.X.decode(buffer); log.info(\"Decode result:&#123;&#125;\", value);&#125;// Decode result:throwable 解析RESP数组 RESP数组类型解析的关键： 先读取类型标识符*后的第一个字节序列分块解析成64bit带符号的整数，确定数组中的元素个数。 递归解析每个元素。 参考过不少Redis协议解析框架，不少是用栈或者状态机实现，这里先简单点用递归实现，解码器代码如下： 1234567891011121314151617181920212223242526272829public class RespArrayDecoder implements RespDecoder &#123; @Override public Object decode(ByteBuf buffer) &#123; int lineEndIndex = CodecUtils.X.findLineEndIndex(buffer); if (-1 == lineEndIndex) &#123; return null; &#125; // 解析元素个数 Long length = (Long) DefaultRespCodec.DECODERS.get(ReplyType.INTEGER).decode(buffer); if (null == length) &#123; return null; &#125; // Null Array if (RespConstants.NEGATIVE_ONE.equals(length)) &#123; return null; &#125; // Array Empty List if (RespConstants.ZERO.equals(length)) &#123; return Lists.newArrayList(); &#125; List&lt;Object&gt; result = Lists.newArrayListWithCapacity((int) length.longValue()); // 递归 for (int i = 0; i &lt; length; i++) &#123; result.add(DefaultRespCodec.X.decode(buffer)); &#125; return result; &#125;&#125; 测试一下： 123456789101112131415161718public static void main(String[] args) throws Exception &#123; ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(); //*2\\r\\n$3\\r\\nfoo\\r\\n$3\\r\\nbar\\r\\n buffer = ByteBufAllocator.DEFAULT.buffer(); buffer.writeBytes(\"*2\".getBytes(RespConstants.UTF_8)); buffer.writeBytes(RespConstants.CRLF); buffer.writeBytes(\"$3\".getBytes(RespConstants.UTF_8)); buffer.writeBytes(RespConstants.CRLF); buffer.writeBytes(\"foo\".getBytes(RespConstants.UTF_8)); buffer.writeBytes(RespConstants.CRLF); buffer.writeBytes(\"$3\".getBytes(RespConstants.UTF_8)); buffer.writeBytes(RespConstants.CRLF); buffer.writeBytes(\"bar\".getBytes(RespConstants.UTF_8)); buffer.writeBytes(RespConstants.CRLF); List value = RespCodec.X.decode(buffer); log.info(\"Decode result:&#123;&#125;\", value);&#125;// Decode result:[foo, bar] 小结 对RESP的内容和其编码解码的过程有相对深刻的认识后，就可以基于Netty编写Redis服务的编码解码模块，作为Netty入门的十分有意义的例子。本文的最后一节只演示了RESP的解码部分，编码模块和更多细节会在另一篇用Netty实现Redis客户端的文章中展示。 参考资料： Redis Protocol specification 附录 本文涉及的所有代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246public class RespConstants &#123; public static final Charset ASCII = StandardCharsets.US_ASCII; public static final Charset UTF_8 = StandardCharsets.UTF_8; public static final byte DOLLAR_BYTE = '$'; public static final byte ASTERISK_BYTE = '*'; public static final byte PLUS_BYTE = '+'; public static final byte MINUS_BYTE = '-'; public static final byte COLON_BYTE = ':'; public static final String EMPTY_STRING = \"\"; public static final Long ZERO = 0L; public static final Long NEGATIVE_ONE = -1L; public static final byte CR = (byte) '\\r'; public static final byte LF = (byte) '\\n'; public static final byte[] CRLF = \"\\r\\n\".getBytes(ASCII); public enum ReplyType &#123; SIMPLE_STRING, ERROR, INTEGER, BULK_STRING, RESP_ARRAY &#125;&#125;public enum CodecUtils &#123; X; public int findLineEndIndex(ByteBuf buffer) &#123; int index = buffer.forEachByte(ByteProcessor.FIND_LF); return (index &gt; 0 &amp;&amp; buffer.getByte(index - 1) == '\\r') ? index : -1; &#125; public String readLine(ByteBuf buffer) &#123; int lineEndIndex = findLineEndIndex(buffer); if (lineEndIndex &gt; -1) &#123; int lineStartIndex = buffer.readerIndex(); // 计算字节长度 int size = lineEndIndex - lineStartIndex - 1; byte[] bytes = new byte[size]; buffer.readBytes(bytes); // 重置读游标为\\r\\n之后的第一个字节 buffer.readerIndex(lineEndIndex + 1); buffer.markReaderIndex(); return new String(bytes, RespConstants.UTF_8); &#125; return null; &#125;&#125;public interface RespCodec &#123; RespCodec X = DefaultRespCodec.X; &lt;IN, OUT&gt; OUT decode(ByteBuf buffer); &lt;IN, OUT&gt; ByteBuf encode(IN in);&#125;public enum DefaultRespCodec implements RespCodec &#123; X; static final Map&lt;ReplyType, RespDecoder&gt; DECODERS = Maps.newConcurrentMap(); private static final RespDecoder DEFAULT_DECODER = new DefaultRespDecoder(); static &#123; DECODERS.put(ReplyType.SIMPLE_STRING, new RespSimpleStringDecoder()); DECODERS.put(ReplyType.ERROR, new RespErrorDecoder()); DECODERS.put(ReplyType.INTEGER, new RespIntegerDecoder()); DECODERS.put(ReplyType.BULK_STRING, new RespBulkStringDecoder()); DECODERS.put(ReplyType.RESP_ARRAY, new RespArrayDecoder()); &#125; @SuppressWarnings(\"unchecked\") @Override public &lt;IN, OUT&gt; OUT decode(ByteBuf buffer) &#123; return (OUT) DECODERS.getOrDefault(determineReplyType(buffer), DEFAULT_DECODER).decode(buffer); &#125; private ReplyType determineReplyType(ByteBuf buffer) &#123; byte firstByte = buffer.readByte(); ReplyType replyType; switch (firstByte) &#123; case RespConstants.PLUS_BYTE: replyType = ReplyType.SIMPLE_STRING; break; case RespConstants.MINUS_BYTE: replyType = ReplyType.ERROR; break; case RespConstants.COLON_BYTE: replyType = ReplyType.INTEGER; break; case RespConstants.DOLLAR_BYTE: replyType = ReplyType.BULK_STRING; break; case RespConstants.ASTERISK_BYTE: replyType = ReplyType.RESP_ARRAY; break; default: &#123; throw new IllegalArgumentException(\"first byte:\" + firstByte); &#125; &#125; return replyType; &#125; @Override public &lt;IN, OUT&gt; ByteBuf encode(IN in) &#123; // TODO throw new UnsupportedOperationException(\"encode\"); &#125;&#125;public interface RespDecoder&lt;V&gt; &#123; V decode(ByteBuf buffer);&#125;public class DefaultRespDecoder implements RespDecoder &#123; @Override public Object decode(ByteBuf buffer) &#123; throw new IllegalStateException(\"decoder\"); &#125;&#125;public class LineStringDecoder implements RespDecoder&lt;String&gt; &#123; @Override public String decode(ByteBuf buffer) &#123; return CodecUtils.X.readLine(buffer); &#125;&#125;public class RespSimpleStringDecoder extends LineStringDecoder &#123;&#125;public class RespErrorDecoder extends LineStringDecoder &#123;&#125;public class RespIntegerDecoder implements RespDecoder&lt;Long&gt; &#123; @Override public Long decode(ByteBuf buffer) &#123; int lineEndIndex = CodecUtils.X.findLineEndIndex(buffer); // 没有行尾，异常 if (-1 == lineEndIndex) &#123; return null; &#125; long result = 0L; int lineStartIndex = buffer.readerIndex(); boolean negative = false; byte firstByte = buffer.getByte(lineStartIndex); // 负数 if (RespConstants.MINUS_BYTE == firstByte) &#123; negative = true; &#125; else &#123; int digit = firstByte - '0'; result = result * 10 + digit; &#125; for (int i = lineStartIndex + 1; i &lt; (lineEndIndex - 1); i++) &#123; byte value = buffer.getByte(i); int digit = value - '0'; result = result * 10 + digit; &#125; if (negative) &#123; result = -result; &#125; // 重置读游标为\\r\\n之后的第一个字节 buffer.readerIndex(lineEndIndex + 1); return result; &#125;&#125;public class RespBulkStringDecoder implements RespDecoder&lt;String&gt; &#123; @Override public String decode(ByteBuf buffer) &#123; int lineEndIndex = CodecUtils.X.findLineEndIndex(buffer); if (-1 == lineEndIndex) &#123; return null; &#125; Long length = (Long) DefaultRespCodec.DECODERS.get(ReplyType.INTEGER).decode(buffer); if (null == length) &#123; return null; &#125; // Bulk Null String if (RespConstants.NEGATIVE_ONE.equals(length)) &#123; return null; &#125; // Bulk Empty String if (RespConstants.ZERO.equals(length)) &#123; return RespConstants.EMPTY_STRING; &#125; // 真实字节内容的长度 int readLength = (int) length.longValue(); if (buffer.readableBytes() &gt; readLength) &#123; byte[] bytes = new byte[readLength]; buffer.readBytes(bytes); // 重置读游标为\\r\\n之后的第一个字节 buffer.readerIndex(buffer.readerIndex() + 2); return new String(bytes, RespConstants.UTF_8); &#125; return null; &#125;&#125;public class RespArrayDecoder implements RespDecoder &#123; @Override public Object decode(ByteBuf buffer) &#123; int lineEndIndex = CodecUtils.X.findLineEndIndex(buffer); if (-1 == lineEndIndex) &#123; return null; &#125; // 解析元素个数 Long length = (Long) DefaultRespCodec.DECODERS.get(ReplyType.INTEGER).decode(buffer); if (null == length) &#123; return null; &#125; // Null Array if (RespConstants.NEGATIVE_ONE.equals(length)) &#123; return null; &#125; // Array Empty List if (RespConstants.ZERO.equals(length)) &#123; return Lists.newArrayList(); &#125; List&lt;Object&gt; result = Lists.newArrayListWithCapacity((int) length.longValue()); // 递归 for (int i = 0; i &lt; length; i++) &#123; result.add(DefaultRespCodec.X.decode(buffer)); &#125; return result; &#125;&#125; （本文完 e-a-20191009 c-2-d）","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Redis","slug":"Middleware/Redis","permalink":"http://throwable.club/blog/categories/Middleware/Redis/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Redis","slug":"Redis","permalink":"http://throwable.club/blog/tags/Redis/"}]},{"title":"Redis5.x哨兵搭建手记","slug":"redis-server-sentinel-install-guide","date":"2019-10-06T17:48:24.000Z","updated":"2019-11-28T17:01:08.179Z","comments":true,"path":"2019/10/07/redis-server-sentinel-install-guide/","link":"","permalink":"http://throwable.club/2019/10/07/redis-server-sentinel-install-guide/","excerpt":"前提 Redis5.x之后，单机、哨兵、集群搭建的难度已经简化。鉴于目前看到太多文章都是复制粘贴以往一些3.x版本的一些内容，所以打算基于当前Redis的最新版本做一次单机、哨兵和集群的搭建，记录一下过程步骤和遇到的问题。编写本文的时间是2019年10月6日（国庆假期…），当前Redis的最新版本为5.0.5。操作系统用的是虚拟机里面安装的CentOS 7。先确定已经安装好Redis服务，可以参考笔者写的前一篇文章：《Redis5.x单机服务搭建手记》。出于书写习惯，本文有可能把哨兵称为Sentinel、Redis Sentinel、哨兵或者Redis哨兵，这四个名词是等价的。","text":"前提 Redis5.x之后，单机、哨兵、集群搭建的难度已经简化。鉴于目前看到太多文章都是复制粘贴以往一些3.x版本的一些内容，所以打算基于当前Redis的最新版本做一次单机、哨兵和集群的搭建，记录一下过程步骤和遇到的问题。编写本文的时间是2019年10月6日（国庆假期…），当前Redis的最新版本为5.0.5。操作系统用的是虚拟机里面安装的CentOS 7。先确定已经安装好Redis服务，可以参考笔者写的前一篇文章：《Redis5.x单机服务搭建手记》。出于书写习惯，本文有可能把哨兵称为Sentinel、Redis Sentinel、哨兵或者Redis哨兵，这四个名词是等价的。 哨兵简介 一定要有一个概念：哨兵实例也是特殊的Redis实例，也就是哨兵实例是独立的进程，多个哨兵实例可以搭建主从（Master-Slave），它们承担的职责和普通的Redis实例不一样。下面是官方文档中对哨兵的介绍： Redis哨兵为Redis提供了高可用性，意味着可以使用哨兵创建Redis服务部署，该部署可以在无需人工干预的情况下抵御某些类型的故障。Redis哨兵还提供其他功能，如监视、通知，并且为客户端提供配置入口（acts as a configuration provider for clients）。下面是Redis哨兵提供的完整功能列表： 监控（Monitoring）：Sentinel会不断检查Master实例和Slave实例是否按预期工作。 通知（Notification）：Sentinel可以通过API进行通知受监控的Redis实例出现问题。 自动故障转移（Automatic Failover）：如果Master实例未按预期工作，则Sentinel可以启动故障转移程序，在该过程中，会将一个Slave实例提升为Master实例，将其他Slave实例重新配置为使用新的Master实例，并且会通知使用Redis实例的应用程序获取新的地址、连接信息。 提供配置入口（Configuration provider）：Sentinel充当客户端服务发现的授权来源（a source of authority）：客户端连接到Sentinel，可以询问Redis服务群中的Master实例的地址。如果发生故障转移，Sentinel将通知客户端新的Master实例的地址。 Sentinel的分布式性质 Redis Sentinel是一个分布式系统，Sentinel采用同一份配置多个Sentinel进程共同协作运行的设计，多Sentinel进程协作的优势如下： 多个Sentinel实例就给定的主机不再可用这一事实达成共识时，将执行故障检测，从而降低了误报的可能性。 Sentinel群中即使不是所有Sentinel处于可用状态，Sentinel群仍然能够正常工作，进行故障转移。 哨兵搭建 当前的Redis哨兵版本称为哨兵2，哨兵版本1是Redis 2.6的时候引入，现在已经过期，不推荐使用。官方文档中部署哨兵的示例中指出：一个健壮的部署至少需要三个Sentinel实例。再加上一般情况下，普通的Redis服务实例为了保证健壮性需要搭建树状主从，至少建议部署三个实例。这里的部署拓扑图如下： 环境配置 按照部署拓扑图，一共部署6个Redis实例，3个普通的Redis实例组成Master-Slave，并且是树状主从，3个Redis哨兵实例。为了简单起见，6个Redis实例部署在同一个虚拟机中，注意在生产或者测试环境要分散机器部署，避免所有鸡蛋放在同一个篮子出现机器单点故障。具体信息如下： 实例标识 角色 主机IP 端口 备注 Sentinel-1 - 192.168.56.200 26379 - Sentinel-2 - 192.168.56.200 26380 - Sentinel-3 - 192.168.56.200 26381 - Redis-1 Master 192.168.56.200 6380 - Redis-11 Slave 192.168.56.200 6381 Redis-1的从节点 Redis-111 Slave 192.168.56.200 6382 Redis-11的从节点 Sentinel配置和配置文件创建 先看样板配置文件sentinel.conf的内容： 12345678910111213port 26379daemonize nopidfile /var/run/redis-sentinel.pidlogfile \"\"dir /tmpsentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 30000sentinel parallel-syncs mymaster 1sentinel failover-timeout mymaster 180000sentinel deny-scripts-reconfig yes# sentinel auth-pass mymaster 123456# bind 127.0.0.1# ...... 完整的配置属性列表比较少，而port、daemonize、pidfile、logfile、dir、bind等属性上一篇文章已经分析过，这里不再复述。 sentinel monitor &lt;master-group-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt; master-group-name：被监控的目标Master实例的名称，这个值可以自定义。 ip：被监控的目标Master实例的服务器地址。 port：被监控的目标Master实例的端口。 quorum：仲裁参数，设置需要多少个Sentinel实例同意才能判断一个被监控的Redis实例失效。换言之，一个 Sentinel群需要获得系统中多数Sentinel的支持， 才能发起一次自动故障迁移。如果我们使用3个Sentinel实例，那么这个值可以定义为2。 sentinel monitor配置项比较特殊，主要用来指定Master角色Redis服务的链接信息。其他5个配置项采用下面的格式： 1sentinel &lt;option_name&gt; &lt;master-group-name&gt; &lt;option_value&gt; down-after-milliseconds：定了Sentinel认为被监控的Redis服务已经断线的总毫秒数。如果在指定的毫秒数之内，被监控的Redis服务没有向Sentinel回复PING信息或者回复了Error信息，那么Sentinel会开始认为被监控的Redis服务下线（其实这里是主观下线（subjectively down，简称SDOWN）。 parallel-syncs：指定了在执行故障转移时，最多可以有多少Slave实例同时对新的Master实例进行同步，这个数字越小，完成故障转移所需的时间就越长。这里建议参考样板配置中的值，设置为1。 failover-timeout：故障转移超时时间，单位为毫秒。 deny-scripts-reconfig：是否禁用SENTINEL SET命令运行时修改notification-script和client-reconfig-script，默认值为yes。 auth-pass：配置连接Master实例的认证密码，如果Master实例没有设置密码，可以不配置此项属性。 创建3份Sentinel配置文件26379.conf、26380.conf、26381.conf，它们的内容十分相似，这里只列出26379.conf的内容（192.168.56.200是笔者虚拟机的主机地址）： 1234567891011port 26379daemonize yesbind 0.0.0.0protected-mode nopidfile /var/run/sentinel-26379.pidlogfile \"/data/redis/sentinel-26379.log\"dir /data/redissentinel monitor doge-master 192.168.56.200 6380 2sentinel down-after-milliseconds doge-master 30000sentinel parallel-syncs doge-master 1sentinel failover-timeout doge-master 180000 另外，创建3份Redis服务的配置文件6380.conf、6381.conf、6382.conf，它们的内容十分相似，这里只列出6380.conf（主节点）的内容： 12345678port 6380daemonize yesbind 0.0.0.0protected-mode nopidfile /var/run/redis-6380.pidlogfile \"/data/redis/redis-6380.log\"dir /data/redisdbfilename \"dump-6380.rdb\" 6381.conf（从节点）尾部添加额外配置： 1slaveof 192.168.56.200 6380 6382.conf（从节点）尾部添加额外配置： 1slaveof 192.168.56.200 6381 每份配置记得替换好对应的端口号，都准备好了之后，依次启动主节点、两个从节点和3个Sentinel（可以把命令写成一个start.sh，调用sh start.sh）： 1234567/data/redis/redis-5.0.5/src/redis-server /data/redis/6380.conf/data/redis/redis-5.0.5/src/redis-server /data/redis/6381.conf/data/redis/redis-5.0.5/src/redis-server /data/redis/6382.conf/data/redis/redis-5.0.5/src/redis-sentinel /data/redis/26379.conf/data/redis/redis-5.0.5/src/redis-sentinel /data/redis/26380.conf/data/redis/redis-5.0.5/src/redis-sentinel /data/redis/26381.conf 此时查看哨兵的配置，发现被Redis修改，新增了发现的主从信息和哨兵实例信息： 查看一下哨兵实例的日志： 目前哨兵和Redis服务都正常运作。 模拟故障转移 官方文档中建议使用测试命令让Redis实例Sleep一个时间，从而触发故障转移： 1redis-cli -p [port] DEBUG sleep 30 先查看当前的Master实例： 1234[root@localhost ~]# redis-cli -p 26379 127.0.0.1:26379&gt; SENTINEL get-master-addr-by-name doge-master1) \"127.0.0.1\"2) \"6380\" 再对Master实例执行Sleep命令： 1redis-cli -p 6380 DEBUG sleep 40 该命令会阻塞直到40秒后，控制台释放后，再查看当前的Master实例： 1234127.0.0.1:26379&gt; SENTINEL get-master-addr-by-name doge-master1) \"127.0.0.1\"2) \"6381\"127.0.0.1:26379&gt; 可见，已经成功切换Master实例为6381。那么，当前的Master-Slave的拓扑关系到底是怎么样的？这个时候先看一下Sentinel的日志： 这里可以看出了，恢复后的6380实例重新成为了Slave角色，感觉有点翻车了，原来的树状主从部署变回了一主多从，笔者开始不相信，于是从当前的Master实例查看了一下主从信息： 确实如此，再检查了一下旧的主节点6380的配置： 12345678910port 6380daemonize yesbind 0.0.0.0protected-mode nopidfile \"/var/run/redis-6380.pid\"logfile \"/data/redis/redis-6380.log\"dir \"/data/redis\"dbfilename \"dump-6380.rdb\"# Generated by CONFIG REWRITEreplicaof 192.168.56.200 6381 发现，最后一行被新增了内容，它成为了从节点。这一点如果不实践，恐怕不知道会衍生出这种结果。画了个图表明一下整个过程： 这个问题暂时不深入探究，目前知道结果如此即可。 客户端代码测试 既然哨兵搭建完了，可以用Java客户端连接进行一些简单的操作。使用的是Lettuce驱动： 12345&lt;dependency&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt; &lt;version&gt;5.1.8.RELEASE&lt;/version&gt;&lt;/dependency&gt; 测试代码： 123456789101112131415161718@Testpublic void testSentinel() throws Exception &#123; RedisURI uri = RedisURI.builder() .withSentinelMasterId(\"doge-master\") .withSentinel(\"192.168.56.200\", 26379) .build(); RedisClient redisClient = RedisClient.create(uri); StatefulRedisMasterSlaveConnection&lt;String, String&gt; connection = MasterSlave.connect(redisClient, new Utf8StringCodec(), uri); connection.setReadFrom(ReadFrom.SLAVE_PREFERRED); RedisCommands&lt;String, String&gt; commands = connection.sync(); String result = commands.ping(); log.info(\"PING:&#123;&#125;\", result); commands.setex(\"name\", 5, \"throwable\"); result = commands.get(\"name\"); log.info(\"Get value:&#123;&#125;\", result); connection.close(); redisClient.shutdown();&#125; 输出结果： 12PING:PONGGet value:throwable 小结 Redis哨兵搭建相对简单，但是需要注意Redis主从配置和Sentinel配置，一些命令可以直接写成shell脚本方便一键shutdown或者重启。在测试故障转移的时候发现了树状主从会变成一主多从，这个问题后面会分析。 参考资料： Redis Sentinel Documentation （本文完 c-1-d e-a-20191007）","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Redis","slug":"Middleware/Redis","permalink":"http://throwable.club/blog/categories/Middleware/Redis/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Redis","slug":"Redis","permalink":"http://throwable.club/blog/tags/Redis/"}]},{"title":"Redis5.x单机服务搭建手记","slug":"redis-server-single-install-guide","date":"2019-10-06T01:58:53.000Z","updated":"2019-11-28T17:01:12.773Z","comments":true,"path":"2019/10/06/redis-server-single-install-guide/","link":"","permalink":"http://throwable.club/2019/10/06/redis-server-single-install-guide/","excerpt":"Redis5.x之后，单机、哨兵、集群搭建的难度已经简化。鉴于目前看到太多文章都是复制粘贴以往一些3.x版本的一些内容，所以打算基于当前Redis的最新版本做一次单机、哨兵和集群的搭建，记录一下过程步骤和遇到的问题。编写本文的时间是2019年10月5日（国庆假期…），当前Redis的最新版本为5.0.5。操作系统用的是虚拟机里面安装的CentOS 7。","text":"Redis5.x之后，单机、哨兵、集群搭建的难度已经简化。鉴于目前看到太多文章都是复制粘贴以往一些3.x版本的一些内容，所以打算基于当前Redis的最新版本做一次单机、哨兵和集群的搭建，记录一下过程步骤和遇到的问题。编写本文的时间是2019年10月5日（国庆假期…），当前Redis的最新版本为5.0.5。操作系统用的是虚拟机里面安装的CentOS 7。 单机版安装和启动 编译过程依赖于gcc，记得先提前安装gcc： 1yum install -y gcc 预先建一个目录/data/redis，下载并且解压安装包： 1234mkdir /data/rediscd /data/rediswget http://download.redis.io/releases/redis-5.0.5.tar.gztar zxvf redis-5.0.5.tar.gz 接着进入解压后的目录/data/redis/redis-5.0.5，进行编译： 123cd /data/redis/redis-5.0.5# 这里的MALLOC=libc不能少make MALLOC=libc 编译完成之后，可以看到类似如下的日志： 可选安装项：可以使用下面的命令把/data/redis/redis-5.0.5/src目录下的编译完成后的文件添加到系统的/usr/local/bin目录： 1cd /data/redis/redis-5.0.5/src &amp;&amp; make install 编译完成之后，注意/data/redis/redis-5.0.5/src目录下的几个重要的可执行脚本： 123456789......redis-benchmark - benchmark测试相关redis-check-aof - AOE相关redis-check-rdb - RDB相关redis-cli - 命令行提示符入口redis-sentinel - 哨兵相关redis-server - Redis服务端指令redis-trib.rb - Ruby脚本，集群相关...... 单机启动需要使用redis-server脚本，它会读取/data/redis/redis-5.0.5目录下的redis.conf配置文件，在/data/redis/redis-5.0.5目录下有两个样板配置文件： 12redis.conf - 单机配置文件sentinel.conf - 哨兵配置文件 还有一点需要重点提示一下：/data/redis/redis-5.0.5/utils目录下自带了一些十分有用的Redis服务安装、管理、集群创建等等的相关脚本，有使用场景的时候可以直接从里面拿出来使用。 非后台启动Redis服务： 1234567891011# 使用默认配置/data/redis/redis-5.0.5/src/redis-server# 已经进入了 /data/redis/redis-5.0.5/src目录下./redis-server# 或者指定配置如下/data/redis/redis-5.0.5/src/redis-server /配置目录/你的配置文件.conf# 已经进入了 /data/redis/redis-5.0.5/src目录下./redis-server /配置目录/你的配置文件.conf 非后台启动Redis服务，窗口需要一直打开，需要退出进程则按Ctrl + C，显然不是太方便。 后台启动Redis服务： 1234# 修改redis.conf文件的daemonize配置，笔者修改和使用/data/redis/redis-5.0.5/redis.conf把daemonize no 修改为 daemonize yes保存# 启动Redis服务./redis-server /data/redis/redis-5.0.5/redis.conf 查看Redis服务进程信息： 1ps -ef | grep redis 强杀Redis服务进程 12# 一般情况下，请勿使用kill -9，否则有可能造成数据丢失kill -9 5365 安装Redis作为系统服务（可以使用系统命令管理，设置自启动等等）： 123456789101112131415# 注意：这里要先把../redis-5.0.5/src目录下的文件加到/usr/local/bin目录，如果已经添加过可以忽略这一步cd /data/redis/redis-5.0.5/src/ &amp;&amp; make install# 预先建立/etc/redis目录mkdir /etc/redis# 依赖redis_init_script脚本，里面会读取/etc/redis/$&#123;PORT&#125;.conf配置，需要提前建好cp /data/redis/redis-5.0.5/utils/redis_init_script /etc/init.d/redis-doge# 拷贝配置文件cp /data/redis/redis-5.0.5/redis.conf /etc/redis/6379.conf# 配置系统应用cd /etc/init.dchkconfig redis-doge on 这里的redis-doge命名是笔者随意自定义，在个人开发环境可以这样做，测试或者生产环境尽量规范命名为redis或者redisd。做好上面的设置之后，就可以用系统服务的形式启动和关闭Redis服务： 配置文件redis.conf的常用配置项 解压目录下的样板配置文件redis.conf里面已经列举了Redis服务启动配置支持的全量配置项，里面的内容太多，这里暂时挑几个相对重要和常用的项做分析： 配置项 描述 默认值 port Redis服务的启动端口 6379 daemoniz Redis服务是否后台运行 no pidfile Redis服务PID寄存文件 /var/run/redis_6379.pid logfile Redis服务输出日志文件 &quot;&quot;，指向/dev/null dbfilename Redis服务数据库dump文件的名称 dump.rdb dir Redis服务数据库dump文件的输出目录，也就是工作目录 ./，也就是当前目录 appendonly 是否启用AOF no appendfilename 启用AOF后输出的文件名称 appendonly.aof appendfsync AOF策略 everysec requirepass Redis服务数访问认证密码 - 还有两个比较难理解的bind和protected-mode配置。 bind：默认值为127.0.0.1。 bind配置的注释比较长，这里翻译和浓缩一下：默认情况下，如果没有指定bind配置，则Redis服务监听来自服务器上所有可用网络接口（Network Interface） 的连接。可以使用bind配置指令来监听一个或多个选定的网络接口，在bind后拼接一个或多个IP地址即可，如bind 127.0.0.1 192.168.56.101。bind参数配置里面绑定的是网络接口而不是具体的外部IP地址，这一点很重要，不能错误认为这个配置项的功能类似于防护墙或者白名单提供的功能。127.0.0.1其实对应的网络接口是本地的回环网卡，下面是笔者虚拟机的网卡信息： protected-mode：默认值为yes。 protected-mode配置表示保护模式是否开启，指定为yes表示为开启保护模式，指定为no表示关闭。开启保护模式之后，如果bind配置项没有绑定一些列的地址并且没有配置认证密码requirepass，那么Redis服务只允许通过本地回环地址127.0.0.1(IPV4)和::1(IPV6)访问。 在个人开发环境中，为了方便起见，可以不设置密码，去掉网络限制和保护模式： 12protected-mode nobind 0.0.0.0 上面的配置切勿在生产环境使用。 上面的配置切勿在生产环境使用。 上面的配置切勿在生产环境使用。 小结 如果属性Linux的相关命令，Redis单机服务搭建是比较简单的。Redis服务的配置文件中配置项极多，一时间不可能全部列出，但是常用的配置必须清楚其的作用。下一篇文章会详细介绍Redis5.x的哨兵搭建过程以及遇到的问题。 （本文完 c-1-d e-a-20191005）","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Redis","slug":"Middleware/Redis","permalink":"http://throwable.club/blog/categories/Middleware/Redis/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Redis","slug":"Redis","permalink":"http://throwable.club/blog/tags/Redis/"}]},{"title":"钢铁宅的国庆老广州小食之旅","slug":"national-day-2019-travel","date":"2019-10-03T11:07:12.000Z","updated":"2019-10-06T02:00:23.808Z","comments":true,"path":"2019/10/03/national-day-2019-travel/","link":"","permalink":"http://throwable.club/2019/10/03/national-day-2019-travel/","excerpt":"背景 国庆长假算是过半，宅了两天感觉没什么作为，天天睡到中午，然后吃午饭（不出门，吃外卖），午饭后又睡到晚餐时间吃第二顿外卖。心里感觉有点咸鱼。 想了下，这样下去不行，必须出去走走，做一条活动的不那么咸的咸鱼。于是2019年10月2日凌晨找了一些老广州小食攻略，从里面挑出一些想吃的或者新奇的东东（咸鱼对玩的和看的提不起兴趣，而对吃的兴趣比较大）。参考了下面两个帖子： 史上最强广州老字号攻略，务必带上你256G的胃 广州西华路荔枝湾探店7次以上美食攻略 整理了几个突然想去试试的店： 早上起来临时写的备忘录，准备了一下就随缘出发。","text":"背景 国庆长假算是过半，宅了两天感觉没什么作为，天天睡到中午，然后吃午饭（不出门，吃外卖），午饭后又睡到晚餐时间吃第二顿外卖。心里感觉有点咸鱼。 想了下，这样下去不行，必须出去走走，做一条活动的不那么咸的咸鱼。于是2019年10月2日凌晨找了一些老广州小食攻略，从里面挑出一些想吃的或者新奇的东东（咸鱼对玩的和看的提不起兴趣，而对吃的兴趣比较大）。参考了下面两个帖子： 史上最强广州老字号攻略，务必带上你256G的胃 广州西华路荔枝湾探店7次以上美食攻略 整理了几个突然想去试试的店： 早上起来临时写的备忘录，准备了一下就随缘出发。 出发 2019年10月3日睡到接近自然醒，早上9点多记录了几个小食店的坐标之后，10点左右开始出发。 发两张钢铁宅所住小区风景照，天气很好，出门的时候比较凉快，光照强度舒适。直奔地铁站上车，刚好目的地都在1号线，三个站的是相连的。 第一站：无名鸡杂汤 从广州地铁1号线陈家祠地铁站C出口走出来，再用地图软件搜一下小店的具体地址。印象中是穿过一个红绿灯，再沿着一个围墙走几百米左转到一个小巷子就到了。第一站选无名鸡杂汤是因为传闻该店一天只煮一锅鸡杂汤，一锅猪红汤，早上11点开店，卖完就收摊。所以，最好赶在中午之前到店去觅食。 无名鸡杂汤，一般又叫夫妻档鸡什猪红汤，其实该小店是没有店名的。小店经营20多年，十平的小屋，上了年纪的两夫妻，传闻夫负责熬汤，妻负责卖汤。 咸鱼刚转入小巷，就看到小店门口放着很多塑料凳子，很少男女老少就坐在门口的塑料凳上，不顾形象地喝汤。 走到店里准备点单，发现了小店只收现金，不能网银、微信或者支付宝支付。看了看墙上贴着的纸皮，发现运气比较好，明天和后天小店休息。 排队的时候，身后的热心阿姨帮我用微信支付兑换了10块钱的现金，于是买了一碗鸡杂汤（咸鱼不喜欢猪红…）。 鸡杂汤足料，鸡味和药材味十分浓郁，主要用料是鸡内脏、鸡子、红枣、党参等等。一碗汤管饱。说实话，现在广州很少地方能10块钱吃到这么足料美味的补品。 店名：无名 地址：中山七路220号（广州地铁1号线陈家祠C出口再步行200米） 特色：20年老字号店，只卖两款汤，10块钱的鸡杂汤和3块钱的猪红汤 备注：小店只能现金支付；每天限量；2019年10月4 - 5日休息 消费：咸鱼用了10块钱 下单的时候，整锅鸡杂汤剩下四分之一，吃完走的时候，后面还排着很长的队伍（估计后面来的人都没机会了…）。 第二站：食盈碗仔翅 说实话，吃完鸡杂汤，已经有六成饱。于是，咸鱼故意走慢点绕远路去找碗仔翅的店面，路上顺便消消肚子。从广州地铁1号线西安门口站D出口出来，走几百米就能看到金平大厦。食盈碗仔翅店面就在金平大厦1楼的角落处，比较不显眼，面向西华路和金花直街的交界处十字路口。 店铺门口比较小，里面的空间还算比较宽敞。刚好点单的时候是中午，人不算多。菜品主要有：人比花胶翅、椰皇冻、蛋黄粽、咖啡等等。其中，人比花胶翅算是明星产品，于是点了个26块的人比花胶翅 + 柠七套餐。 上菜的时候用的是一次性的塑料碗。第一口吃下去感觉是十分浓郁的鲜味，实际上整碗是用蟹子、花胶、瑶柱、鱼翅、蹄筋、桂圆等熬出来的浓汤，所有食材熬的时间都比较长，入口感觉比较丝滑。可能美中不足的是，感觉放了太多调味料，调味料的味道有点掩盖了食材本身的鲜味，而且吃起来感觉很腻。如果你没吃过碗仔翅，第一口应该会被惊艳到。 店名：食盈碗仔翅 地址：西华路金平大厦星玺广场1152铺（广州地铁1号线西门口站D出口走几百米） 特色：镇店碗仔翅，特色椰皇冻（还没试过椰皇冻，下次去试试） 备注：无 消费：咸鱼用了26块钱 中场休息闲逛 吃完碗仔翅感觉有点腻，暂时不去下一站，先逛一下西华路。西华路很有老广州的特色，街道不宽广，整街不长，而且两旁的建筑都比较低矮，楼龄应该都比较大。小食店比较多，一间挨着一间的。例如街头就有一间比较大的粥铺，中午了还很多人在店里吃粥。街头还看到一间比较出名的生煎店： 门口的应该就是组队专门过来吃生煎的。在路的中段还有一家比较出名的芝麻糊店铺： 在街尾还有很出名的芳记小食店： 整条街的生活节奏很慢，广场有席地而坐下棋的老大爷，还有在地上摆摊卖菜的大妈，有推着手推车叫卖的小伙，还有很多像我这样慕名而来觅食、不是咸鱼的少男少女。生活节奏慢才适合生活，在这里游荡吃喝，可以暂时忘记工作日或者双休匆匆忙忙买早餐挤地铁的日子，真是挺舒适愉快的。 第三站：牛佬牛杂汤 牛佬牛杂汤的店面其实就在食盈碗仔翅的附近。弄一张灵魂画图： 正午时分，吃客很多，又要排队。 排了接近20分钟，点了一份萝卜牛杂，19块。很多食客直接在这里吃午餐，其他菜品有牛三星（本来应该点这个才对，传闻中是招牌）和牛杂汤粉面等等。 首先，萝卜牛杂中牛肚居多（我这份好像只有一块牛肉，其他全是牛肚和萝卜），吃一口感觉翻车了。咸鱼口味偏向于清淡，牛杂偏咸，不过口感比较嫩和软，应该是熬足时间。不知道是不是之前吃得太饱，这一家的牛杂个人感觉没有让人眼前一亮的感觉，建议尝试一下牛三星和牛杂汤粉。 店名：牛佬牛杂汤 地址：西华路与金花直街交界口处金花庙后街3号（广州地铁1号线西门口站D出口走几百米） 特色：萝卜牛杂19块一份，其他菜品10几块一份 备注：口味偏咸，吃惯清淡的可能不适应 消费：咸鱼用了19块钱 第四站：顺记冰室 吃完牛杂，上地铁向长寿路进发，要吃点甜品消消腻气。旧时候，老广东人一般称喝糖水或者吃甜品为饮冰，那个时候地道的甜品店一般叫做冰室。而长寿路的顺记冰室就是一间老字号的甜品店，印象中几年前还在读大学的时候就去过一次。先附上一张灵魂画图的地图： 天气炎热，饮冰的人特别多。另外，宝华路的风格和西华路完全不一样，简直是动如脱兔和静如处子的区别，整条街都塞满了年轻的男女，路况比较复杂，出游的时候需要尽量注意安全。走了不久就到了顺记冰室的店面： 说实话，店里里面也塞满了人，很多人站着等位置（情侣居多）。由于咸鱼单身，挤进去店里面很快就让店员安排拼桌。先看看菜牌如下： 款式十分丰富。想了下小时候经常吃双色雪球，加上天气燥热，点了个榴莲椰子双色雪球（25块）和一个炼奶龟苓膏（9块）。等了很长时间才上菜： 味道很好，雪糕软滑，榴莲和椰子的香味浓郁，龟苓膏的味道算是正宗。不过感觉甜度不够，毕竟咸鱼平时点喜茶必须勾选多糖的选项，可能和个体对甜度的耐受性有关。 店名：顺记冰室 地址：宝华路中段（广州地铁1号线长寿路站D2出口走几百米） 特色：种类丰富的甜品，还有粥粉面饭等正餐 备注：人太多，需要拼座 消费：咸鱼用了34块钱 最后一站：陈添记 陈添记就在顺记冰室附近，在一个小巷子拐进去就能看到。有个很大的问题就是食客太太太多了，咸鱼当时在排队，拍了照看看排队的长龙： 一位疑似老板的大叔还要出来维持秩序。鉴于室外天气炎热，人员太密集，咸鱼选择打包一份凉拌鱼皮（25块）。 不得不说，陈添记的鱼皮确实爽脆弹牙，口感比较独特，芝麻油特别香，加上爆炒的花生仁和配料，多吃也不会腻，难怪这么多人排队。 店名：陈添记 地址：宝华路中段小巷子（广州地铁1号线长寿路站D2出口走几百米） 特色：特色凉拌鱼皮和其他小食 备注：人太太太多，堂食环境比较一般 消费：咸鱼用了25块钱 结束 带着鼓起的肚子回到家里已经接近傍晚，吃足一天的花销不超过200块，既能满足胃口，品尝一下老广州的特色美食，又可能放松一下做一条活跃的咸鱼，暂时忘记紧张的工作生活，真是很开心。这里做一个简单的表格，仅仅代表个人的角度（咸鱼没必要为这些店打广告，只在乎自己的感受）： 地点 无名鸡杂汤 食盈碗仔翅 牛佬牛杂汤 顺记冰室 陈添记 人均消费（元） 10 20+ 20 30+ 25+ 推荐指数（假设满为5） 5 4 3 4.5 5 及时行乐，何不快哉？ （本文完 c-1-d e-a-20191003 国庆快乐(*^▽^*)）","categories":[{"name":"Life","slug":"Life","permalink":"http://throwable.club/blog/categories/Life/"}],"tags":[{"name":"Life","slug":"Life","permalink":"http://throwable.club/blog/tags/Life/"}]},{"title":"一个低级错误引发Netty编码解码中文异常","slug":"netty-codec-chinese-exception","date":"2019-10-03T01:05:34.000Z","updated":"2019-10-03T01:34:15.489Z","comments":true,"path":"2019/10/03/netty-codec-chinese-exception/","link":"","permalink":"http://throwable.club/2019/10/03/netty-codec-chinese-exception/","excerpt":"前言 最近在调研Netty的使用，在编写编码解码模块的时候遇到了一个中文字符串编码和解码异常的情况，后来发现是笔者犯了个低级错误。这里做一个小小的回顾。","text":"前言 最近在调研Netty的使用，在编写编码解码模块的时候遇到了一个中文字符串编码和解码异常的情况，后来发现是笔者犯了个低级错误。这里做一个小小的回顾。 错误重现 在设计Netty的自定义协议的时候，发现了字符串类型的属性，一旦出现中文就会出现解码异常的现象，这个异常并不一定出现了Exception，而是出现了解码之后字符截断出现了人类不可读的字符。编码和解码器的实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041// 实体@Datapublic class ChineseMessage implements Serializable &#123; private long id; private String message;&#125;// 编码器 - &lt;错误示范，不要拷贝&gt;public class ChineseMessageEncoder extends MessageToByteEncoder&lt;ChineseMessage&gt; &#123; @Override protected void encode(ChannelHandlerContext ctx, ChineseMessage target, ByteBuf out) throws Exception &#123; // 写入ID out.writeLong(target.getId()); String message = target.getMessage(); int length = message.length(); // 写入Message长度 out.writeInt(length); // 写入Message字符序列 out.writeCharSequence(message, StandardCharsets.UTF_8); &#125;&#125;// 解码器public class ChineseMessageDecoder extends ByteToMessageDecoder &#123; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; // 读取ID long id = in.readLong(); // 读取Message长度 int length = in.readInt(); // 读取Message字符序列 CharSequence charSequence = in.readCharSequence(length, StandardCharsets.UTF_8); ChineseMessage message = new ChineseMessage(); message.setId(id); message.setMessage(charSequence.toString()); out.add(message); &#125;&#125; 简单地编写客户端和服务端代码，然后用客户端服务端发送一条带中文的消息： 123456// 服务端日志接收到客户端的请求:ChineseMessage(id=1, message=张)io.netty.handler.codec.DecoderException: java.lang.IndexOutOfBoundsException: readerIndex(15) + length(8) exceeds writerIndex(21) ......// 客户端日志接收到服务端的响应:ChineseMessage(id=2, message=张)io.netty.handler.codec.DecoderException: java.lang.IndexOutOfBoundsException: readerIndex(15) + length(8) exceeds writerIndex(21) ...... 其实，问题就隐藏在编码解码模块中。由于笔者前两个月一直996，在疯狂编写CRUD代码，业余在看Netty的时候，有一些基础知识一时短路没有回忆起来。笔者带着这个问题在各大搜索引擎中搜索，有可能是姿势不对或者关键字不准，没有得到答案，加之，很多博客文章都是照搬其他人的Demo，而这些Demo里面恰好都是用英文编写消息体例子，所以这个问题一时陷入了困局（2019年国庆假期之前卡住了大概几天，业务忙也没有花时间去想）。 灵光一现 2019年国庆假期前夕，由于团队一直在赶进度做一个前后端不分离的CRUD后台管理系统，当时有几个同事在做一个页面的时候讨论一个乱码的问题。在他们讨论的过程中，无意蹦出了两个让笔者突然清醒的词语：乱码和UTF-8。笔者第一时间想到的是刚用Cnblogs的时候写过的一篇文章：《小伙子又乱码了吧-Java字符编码原理总结》（现在看起来标题起得挺二的）。当时有对字符编码的原理做过一些探究，想想有点惭愧，1年多前看过的东西差不多忘记得一干二净。 直接说原因：UTF-8编码的中文，大部分情况下一个中文字符长度占据3个字节（3 byte，也就是32 x 3或者32 x 4个位），而Java中字符串长度的获取方法String#length()是返回String实例中的Char数组的长度。但是我们多数情况下会使用Netty的字节缓冲区ByteBuf，而ByteBuf读取字符序列的方法需要预先指定读取的长度ByteBuf#readCharSequence(int length, Charset charset);，因此，在编码的时候需要预先写入字符串序列的长度。但是有一个隐藏的问题是：ByteBuf#readCharSequence(int length, Charset charset)方法底层会创建一个length长度的byte数组作为缓冲区读取数据，由于UTF-8中1 char = 3 or 4 byte，因此ChineseMessageEncoder在写入字符序列长度的时候虽然字符个数是对的，但是每个字符总是丢失2个-3个byte的长度，而ChineseMessageDecoder在读取字符序列长度的时候总是读到一个比原来短的长度，也就是最终会拿到一个不完整或者错误的字符串序列。 解决方案 UTF-8编码的中文在大多数情况下占3个字节，在一些有生僻字的情况下可能占4个字节。可以暴力点直接让写入字节缓冲区的字符序列长度扩大三倍，只需修改编码器的代码： 1234567891011121314public class ChineseMessageEncoder extends MessageToByteEncoder&lt;ChineseMessage&gt; &#123; @Override protected void encode(ChannelHandlerContext ctx, ChineseMessage target, ByteBuf out) throws Exception &#123; // 写入ID out.writeLong(target.getId()); String message = target.getMessage(); int length = message.length() * 3; // &lt;1&gt; 直接扩大字节序列的预读长度 // 写入Message长度 out.writeInt(length); // 写入Message字符序列 out.writeCharSequence(message, StandardCharsets.UTF_8); &#125;&#125; 当然，这样做太暴力，硬编码的做法既不规范也不友好。其实Netty已经提供了内置的工具类io.netty.buffer.ByteBufUtil： 12345// 获取UTF-8字符的最大字节序列长度public static int utf8MaxBytes(CharSequence seq)&#123;&#125;// 写入UTF-8字符序列，返回写入的字节长度 - 建议使用此方法public static int writeUtf8(ByteBuf buf, CharSequence seq)&#123;&#125; 我们可以先记录一下writerIndex，先写一个假的值（例如0），再使用ByteBufUtil#writeUtf8()写字符序列，然后根据返回的写入的字节长度，通过writerIndex覆盖之前写入的假值： 12345678910111213141516public class ChineseMessageEncoder extends MessageToByteEncoder&lt;ChineseMessage&gt; &#123; @Override protected void encode(ChannelHandlerContext ctx, ChineseMessage target, ByteBuf out) throws Exception &#123; out.writeLong(target.getId()); String message = target.getMessage(); // 记录写入游标 int writerIndex = out.writerIndex(); // 预写入一个假的length out.writeInt(0); // 写入UTF-8字符序列 int length = ByteBufUtil.writeUtf8(out, message); // 覆盖length out.setInt(writerIndex, length); &#125;&#125; 至此，问题解决。如果遇到其他Netty编码解码问题，解决的思路是一致的。 小结 Netty学习过程中，编码解码占一半，网络协议知识和调优占另一半。 Netty的源码很优秀，很有美感，阅读起来很舒适。 Netty真好玩。 附录 引入依赖： 1234567891011&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.41.Final&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.10&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123// 实体@Datapublic class ChineseMessage implements Serializable &#123; private long id; private String message;&#125;// 编码器public class ChineseMessageEncoder extends MessageToByteEncoder&lt;ChineseMessage&gt; &#123; @Override protected void encode(ChannelHandlerContext ctx, ChineseMessage target, ByteBuf out) throws Exception &#123; out.writeLong(target.getId()); String message = target.getMessage(); int writerIndex = out.writerIndex(); out.writeInt(0); int length = ByteBufUtil.writeUtf8(out, message); out.setInt(writerIndex, length); &#125;&#125;// 解码器public class ChineseMessageDecoder extends ByteToMessageDecoder &#123; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; long id = in.readLong(); int length = in.readInt(); CharSequence charSequence = in.readCharSequence(length, StandardCharsets.UTF_8); ChineseMessage message = new ChineseMessage(); message.setId(id); message.setMessage(charSequence.toString()); out.add(message); &#125;&#125;// 客户端@Slf4jpublic class ChineseNettyClient &#123; public static void main(String[] args) throws Exception &#123; EventLoopGroup workerGroup = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); try &#123; bootstrap.group(workerGroup); bootstrap.channel(NioSocketChannel.class); bootstrap.option(ChannelOption.SO_KEEPALIVE, true); bootstrap.option(ChannelOption.TCP_NODELAY, Boolean.TRUE); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new LengthFieldBasedFrameDecoder(1024, 0, 4, 0, 4)); ch.pipeline().addLast(new LengthFieldPrepender(4)); ch.pipeline().addLast(new ChineseMessageEncoder()); ch.pipeline().addLast(new ChineseMessageDecoder()); ch.pipeline().addLast(new SimpleChannelInboundHandler&lt;ChineseMessage&gt;() &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, ChineseMessage message) throws Exception &#123; log.info(\"接收到服务端的响应:&#123;&#125;\", message); &#125; &#125;); &#125; &#125;); ChannelFuture future = bootstrap.connect(\"localhost\", 9092).sync(); System.out.println(\"客户端启动成功...\"); Channel channel = future.channel(); ChineseMessage message = new ChineseMessage(); message.setId(1L); message.setMessage(\"张大狗\"); channel.writeAndFlush(message); future.channel().closeFuture().sync(); &#125; finally &#123; workerGroup.shutdownGracefully(); &#125; &#125;&#125;// 服务端@Slf4jpublic class ChineseNettyServer &#123; public static void main(String[] args) throws Exception &#123; int port = 9092; ServerBootstrap bootstrap = new ServerBootstrap(); EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new LengthFieldBasedFrameDecoder(1024, 0, 4, 0, 4)); ch.pipeline().addLast(new LengthFieldPrepender(4)); ch.pipeline().addLast(new ChineseMessageEncoder()); ch.pipeline().addLast(new ChineseMessageDecoder()); ch.pipeline().addLast(new SimpleChannelInboundHandler&lt;ChineseMessage&gt;() &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, ChineseMessage message) throws Exception &#123; log.info(\"接收到客户端的请求:&#123;&#125;\", message); ChineseMessage chineseMessage = new ChineseMessage(); chineseMessage.setId(message.getId() + 1L); chineseMessage.setMessage(\"张小狗\"); ctx.writeAndFlush(chineseMessage); &#125; &#125;); &#125; &#125;); ChannelFuture future = bootstrap.bind(port).sync(); log.info(\"启动Server成功...\"); future.channel().closeFuture().sync(); &#125; finally &#123; workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125;&#125; （本文完 c-2-d e-a-20191003 国庆快乐(*^▽^*)）","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Netty","slug":"Java/Netty","permalink":"http://throwable.club/blog/categories/Java/Netty/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Netty","slug":"Netty","permalink":"http://throwable.club/blog/tags/Netty/"}]},{"title":"Redis高级客户端Lettuce详解","slug":"redis-client-driver-lettuce-usage","date":"2019-09-28T01:24:22.000Z","updated":"2019-11-28T17:00:33.282Z","comments":true,"path":"2019/09/28/redis-client-driver-lettuce-usage/","link":"","permalink":"http://throwable.club/2019/09/28/redis-client-driver-lettuce-usage/","excerpt":"前提 Lettuce是一个Redis的Java驱动包，初识她的时候是使用RedisTemplate的时候遇到点问题Debug到底层的一些源码，发现spring-data-redis的驱动包在某个版本之后替换为Lettuce。Lettuce翻译为生菜，没错，就是吃的那种生菜，所以它的Logo长这样： 既然能被Spring生态所认可，Lettuce想必有过人之处，于是笔者花时间阅读她的官方文档，整理测试示例，写下这篇文章。编写本文时所使用的版本为Lettuce 5.1.8.RELEASE，SpringBoot 2.1.8.RELEASE，JDK [8,11]。超长警告：这篇文章断断续续花了两周完成，超过4万字…","text":"前提 Lettuce是一个Redis的Java驱动包，初识她的时候是使用RedisTemplate的时候遇到点问题Debug到底层的一些源码，发现spring-data-redis的驱动包在某个版本之后替换为Lettuce。Lettuce翻译为生菜，没错，就是吃的那种生菜，所以它的Logo长这样： 既然能被Spring生态所认可，Lettuce想必有过人之处，于是笔者花时间阅读她的官方文档，整理测试示例，写下这篇文章。编写本文时所使用的版本为Lettuce 5.1.8.RELEASE，SpringBoot 2.1.8.RELEASE，JDK [8,11]。超长警告：这篇文章断断续续花了两周完成，超过4万字… Lettuce简介 Lettuce是一个高性能基于Java编写的Redis驱动框架，底层集成了Project Reactor提供天然的反应式编程，通信框架集成了Netty使用了非阻塞IO，5.x版本之后融合了JDK1.8的异步编程特性，在保证高性能的同时提供了十分丰富易用的API，5.1版本的新特性如下： 支持Redis的新增命令ZPOPMIN, ZPOPMAX, BZPOPMIN, BZPOPMAX。 支持通过Brave模块跟踪Redis命令执行。 支持Redis Streams。 支持异步的主从连接。 支持异步连接池。 新增命令最多执行一次模式（禁止自动重连）。 全局命令超时设置（对异步和反应式命令也有效）。 …等等 注意一点：Redis的版本至少需要2.6，当然越高越好，API的兼容性比较强大。 只需要引入单个依赖就可以开始愉快地使用Lettuce： Maven 12345&lt;dependency&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt; &lt;version&gt;5.1.8.RELEASE&lt;/version&gt;&lt;/dependency&gt; Gradle 123dependencies &#123; compile 'io.lettuce:lettuce-core:5.1.8.RELEASE'&#125; 连接Redis 单机、哨兵、集群模式下连接Redis需要一个统一的标准去表示连接的细节信息，在Lettuce中这个统一的标准是RedisURI。可以通过三种方式构造一个RedisURI实例： 定制的字符串URI语法： 1RedisURI uri = RedisURI.create(\"redis://localhost/\"); 使用建造器（RedisURI.Builder）： 1RedisURI uri = RedisURI.builder().withHost(\"localhost\").withPort(6379).build(); 直接通过构造函数实例化： 1RedisURI uri = new RedisURI(\"localhost\", 6379, 60, TimeUnit.SECONDS); 定制的连接URI语法 单机（前缀为redis://） 123格式：redis://[password@]host[:port][/databaseNumber][?[timeout=timeout[d|h|m|s|ms|us|ns]]完整：redis://mypassword@127.0.0.1:6379/0?timeout=10s简单：redis://localhost 单机并且使用SSL（前缀为rediss://） &lt;== 注意后面多了个s 123格式：rediss://[password@]host[:port][/databaseNumber][?[timeout=timeout[d|h|m|s|ms|us|ns]]完整：rediss://mypassword@127.0.0.1:6379/0?timeout=10s简单：rediss://localhost 单机Unix Domain Sockets模式（前缀为redis-socket://） 12格式：redis-socket://path[?[timeout=timeout[d|h|m|s|ms|us|ns]][&amp;_database=database_]]完整：redis-socket:///tmp/redis?timeout=10s&amp;_database=0 哨兵（前缀为redis-sentinel://） 12格式：redis-sentinel://[password@]host[:port][,host2[:port2]][/databaseNumber][?[timeout=timeout[d|h|m|s|ms|us|ns]]#sentinelMasterId完整：redis-sentinel://mypassword@127.0.0.1:6379,127.0.0.1:6380/0?timeout=10s#mymaster 超时时间单位： d 天 h 小时 m 分钟 s 秒钟 ms 毫秒 us 微秒 ns 纳秒 个人建议使用RedisURI提供的建造器，毕竟定制的URI虽然简洁，但是比较容易出现人为错误。鉴于笔者没有SSL和Unix Domain Socket的使用场景，下面不对这两种连接方式进行列举。 基本使用 Lettuce使用的时候依赖于四个主要组件： RedisURI：连接信息。 RedisClient：Redis客户端，特殊地，集群连接有一个定制的RedisClusterClient。 Connection：Redis连接，主要是StatefulConnection或者StatefulRedisConnection的子类，连接的类型主要由连接的具体方式（单机、哨兵、集群、订阅发布等等）选定，比较重要。 RedisCommands：Redis命令API接口，基本上覆盖了Redis发行版本的所有命令，提供了同步（sync）、异步（async）、反应式（reative）的调用方式，对于使用者而言，会经常跟RedisCommands系列接口打交道。 一个基本使用例子如下： 12345678910111213141516171819@Testpublic void testSetGet() throws Exception &#123; RedisURI redisUri = RedisURI.builder() // &lt;1&gt; 创建单机连接的连接信息 .withHost(\"localhost\") .withPort(6379) .withTimeout(Duration.of(10, ChronoUnit.SECONDS)) .build(); RedisClient redisClient = RedisClient.create(redisUri); // &lt;2&gt; 创建客户端 StatefulRedisConnection&lt;String, String&gt; connection = redisClient.connect(); // &lt;3&gt; 创建线程安全的连接 RedisCommands&lt;String, String&gt; redisCommands = connection.sync(); // &lt;4&gt; 创建同步命令 SetArgs setArgs = SetArgs.Builder.nx().ex(5); String result = redisCommands.set(\"name\", \"throwable\", setArgs); Assertions.assertThat(result).isEqualToIgnoringCase(\"OK\"); result = redisCommands.get(\"name\"); Assertions.assertThat(result).isEqualTo(\"throwable\"); // ... 其他操作 connection.close(); // &lt;5&gt; 关闭连接 redisClient.shutdown(); // &lt;6&gt; 关闭客户端&#125; 注意： &lt;5&gt;：关闭连接一般在应用程序停止之前操作，一个应用程序中的一个Redis驱动实例不需要太多的连接（一般情况下只需要一个连接实例就可以，如果有多个连接的需要可以考虑使用连接池，其实Redis目前处理命令的模块是单线程，在客户端多个连接多线程调用理论上没有效果）。 &lt;6&gt;：关闭客户端一般应用程序停止之前操作，如果条件允许的话，基于后开先闭原则，客户端关闭应该在连接关闭之后操作。 API Lettuce主要提供三种API： 同步（sync）：RedisCommands。 异步（async）：RedisAsyncCommands。 反应式（reactive）：RedisReactiveCommands。 先准备好一个单机Redis连接备用： 12345678910111213141516171819private static StatefulRedisConnection&lt;String, String&gt; CONNECTION;private static RedisClient CLIENT;@BeforeClasspublic static void beforeClass() &#123; RedisURI redisUri = RedisURI.builder() .withHost(\"localhost\") .withPort(6379) .withTimeout(Duration.of(10, ChronoUnit.SECONDS)) .build(); CLIENT = RedisClient.create(redisUri); CONNECTION = CLIENT.connect();&#125;@AfterClasspublic static void afterClass() throws Exception &#123; CONNECTION.close(); CLIENT.shutdown();&#125; Redis命令API的具体实现可以直接从StatefulRedisConnection实例获取，见其接口定义： 12345678910public interface StatefulRedisConnection&lt;K, V&gt; extends StatefulConnection&lt;K, V&gt; &#123; boolean isMulti(); RedisCommands&lt;K, V&gt; sync(); RedisAsyncCommands&lt;K, V&gt; async(); RedisReactiveCommands&lt;K, V&gt; reactive();&#125; 值得注意的是，在不指定编码解码器RedisCodec的前提下，RedisClient创建的StatefulRedisConnection实例一般是泛型实例StatefulRedisConnection&lt;String,String&gt;，也就是所有命令API的KEY和VALUE都是String类型，这种使用方式能满足大部分的使用场景。当然，必要的时候可以定制编码解码器RedisCodec&lt;K,V&gt;。 同步API 先构建RedisCommands实例： 123456private static RedisCommands&lt;String, String&gt; COMMAND;@BeforeClasspublic static void beforeClass() &#123; COMMAND = CONNECTION.sync();&#125; 基本使用： 12345678910111213141516@Testpublic void testSyncPing() throws Exception &#123; String pong = COMMAND.ping(); Assertions.assertThat(pong).isEqualToIgnoringCase(\"PONG\");&#125;@Testpublic void testSyncSetAndGet() throws Exception &#123; SetArgs setArgs = SetArgs.Builder.nx().ex(5); COMMAND.set(\"name\", \"throwable\", setArgs); String value = COMMAND.get(\"name\"); log.info(\"Get value: &#123;&#125;\", value);&#125;// Get value: throwable 同步API在所有命令调用之后会立即返回结果。如果熟悉Jedis的话，RedisCommands的用法其实和它相差不大。 异步API 先构建RedisAsyncCommands实例： 123456private static RedisAsyncCommands&lt;String, String&gt; ASYNC_COMMAND;@BeforeClasspublic static void beforeClass() &#123; ASYNC_COMMAND = CONNECTION.async();&#125; 基本使用： 123456@Testpublic void testAsyncPing() throws Exception &#123; RedisFuture&lt;String&gt; redisFuture = ASYNC_COMMAND.ping(); log.info(\"Ping result:&#123;&#125;\", redisFuture.get());&#125;// Ping result:PONG RedisAsyncCommands所有方法执行返回结果都是RedisFuture实例，而RedisFuture接口的定义如下： 123456public interface RedisFuture&lt;V&gt; extends CompletionStage&lt;V&gt;, Future&lt;V&gt; &#123; String getError(); boolean await(long timeout, TimeUnit unit) throws InterruptedException;&#125; 也就是，RedisFuture可以无缝使用Future或者JDK1.8中引入的CompletableFuture提供的方法。举个例子： 12345678910111213141516171819202122232425@Testpublic void testAsyncSetAndGet1() throws Exception &#123; SetArgs setArgs = SetArgs.Builder.nx().ex(5); RedisFuture&lt;String&gt; future = ASYNC_COMMAND.set(\"name\", \"throwable\", setArgs); // CompletableFuture#thenAccept() future.thenAccept(value -&gt; log.info(\"Set命令返回:&#123;&#125;\", value)); // Future#get() future.get();&#125;// Set命令返回:OK@Testpublic void testAsyncSetAndGet2() throws Exception &#123; SetArgs setArgs = SetArgs.Builder.nx().ex(5); CompletableFuture&lt;Void&gt; result = (CompletableFuture&lt;Void&gt;) ASYNC_COMMAND.set(\"name\", \"throwable\", setArgs) .thenAcceptBoth(ASYNC_COMMAND.get(\"name\"), (s, g) -&gt; &#123; log.info(\"Set命令返回:&#123;&#125;\", s); log.info(\"Get命令返回:&#123;&#125;\", g); &#125;); result.get();&#125;// Set命令返回:OK// Get命令返回:throwable 如果能熟练使用CompletableFuture和函数式编程技巧，可以组合多个RedisFuture完成一些列复杂的操作。 反应式API Lettuce引入的反应式编程框架是Project Reactor，如果没有反应式编程经验可以先自行了解一下Project Reactor。 构建RedisReactiveCommands实例： 123456private static RedisReactiveCommands&lt;String, String&gt; REACTIVE_COMMAND;@BeforeClasspublic static void beforeClass() &#123; REACTIVE_COMMAND = CONNECTION.reactive();&#125; 根据Project Reactor，RedisReactiveCommands的方法如果返回的结果只包含0或1个元素，那么返回值类型是Mono，如果返回的结果包含0到N（N大于0）个元素，那么返回值是Flux。举个例子： 12345678910111213141516171819202122232425262728@Testpublic void testReactivePing() throws Exception &#123; Mono&lt;String&gt; ping = REACTIVE_COMMAND.ping(); ping.subscribe(v -&gt; log.info(\"Ping result:&#123;&#125;\", v)); Thread.sleep(1000);&#125;// Ping result:PONG@Testpublic void testReactiveSetAndGet() throws Exception &#123; SetArgs setArgs = SetArgs.Builder.nx().ex(5); REACTIVE_COMMAND.set(\"name\", \"throwable\", setArgs).block(); REACTIVE_COMMAND.get(\"name\").subscribe(value -&gt; log.info(\"Get命令返回:&#123;&#125;\", value)); Thread.sleep(1000);&#125;// Get命令返回:throwable@Testpublic void testReactiveSet() throws Exception &#123; REACTIVE_COMMAND.sadd(\"food\", \"bread\", \"meat\", \"fish\").block(); Flux&lt;String&gt; flux = REACTIVE_COMMAND.smembers(\"food\"); flux.subscribe(log::info); REACTIVE_COMMAND.srem(\"food\", \"bread\", \"meat\", \"fish\").block(); Thread.sleep(1000);&#125;// meat// bread// fish 举个更加复杂的例子，包含了事务、函数转换等： 12345678910111213@Testpublic void testReactiveFunctional() throws Exception &#123; REACTIVE_COMMAND.multi().doOnSuccess(r -&gt; &#123; REACTIVE_COMMAND.set(\"counter\", \"1\").doOnNext(log::info).subscribe(); REACTIVE_COMMAND.incr(\"counter\").doOnNext(c -&gt; log.info(String.valueOf(c))).subscribe(); &#125;).flatMap(s -&gt; REACTIVE_COMMAND.exec()) .doOnNext(transactionResult -&gt; log.info(\"Discarded:&#123;&#125;\", transactionResult.wasDiscarded())) .subscribe(); Thread.sleep(1000);&#125;// OK// 2// Discarded:false 这个方法开启一个事务，先把counter设置为1，再将counter自增1。 发布和订阅 非集群模式下的发布订阅依赖于定制的连接StatefulRedisPubSubConnection，集群模式下的发布订阅依赖于定制的连接StatefulRedisClusterPubSubConnection，两者分别来源于RedisClient#connectPubSub()系列方法和RedisClusterClient#connectPubSub()： 非集群模式： 123456789101112131415161718// 可能是单机、普通主从、哨兵等非集群模式的客户端RedisClient client = ...StatefulRedisPubSubConnection&lt;String, String&gt; connection = client.connectPubSub();connection.addListener(new RedisPubSubListener&lt;String, String&gt;() &#123; ... &#125;);// 同步命令RedisPubSubCommands&lt;String, String&gt; sync = connection.sync();sync.subscribe(\"channel\");// 异步命令RedisPubSubAsyncCommands&lt;String, String&gt; async = connection.async();RedisFuture&lt;Void&gt; future = async.subscribe(\"channel\");// 反应式命令RedisPubSubReactiveCommands&lt;String, String&gt; reactive = connection.reactive();reactive.subscribe(\"channel\").subscribe();reactive.observeChannels().doOnNext(patternMessage -&gt; &#123;...&#125;).subscribe() 集群模式： 1234567// 使用方式其实和非集群模式基本一致RedisClusterClient clusterClient = ...StatefulRedisClusterPubSubConnection&lt;String, String&gt; connection = clusterClient.connectPubSub();connection.addListener(new RedisPubSubListener&lt;String, String&gt;() &#123; ... &#125;);RedisPubSubCommands&lt;String, String&gt; sync = connection.sync();sync.subscribe(\"channel\");// ... 这里用单机同步命令的模式举一个Redis键空间通知（Redis Keyspace Notifications）的例子： 12345678910111213141516171819202122232425262728293031323334353637@Testpublic void testSyncKeyspaceNotification() throws Exception &#123; RedisURI redisUri = RedisURI.builder() .withHost(\"localhost\") .withPort(6379) // 注意这里只能是0号库 .withDatabase(0) .withTimeout(Duration.of(10, ChronoUnit.SECONDS)) .build(); RedisClient redisClient = RedisClient.create(redisUri); StatefulRedisConnection&lt;String, String&gt; redisConnection = redisClient.connect(); RedisCommands&lt;String, String&gt; redisCommands = redisConnection.sync(); // 只接收键过期的事件 redisCommands.configSet(\"notify-keyspace-events\", \"Ex\"); StatefulRedisPubSubConnection&lt;String, String&gt; connection = redisClient.connectPubSub(); connection.addListener(new RedisPubSubAdapter&lt;&gt;() &#123; @Override public void psubscribed(String pattern, long count) &#123; log.info(\"pattern:&#123;&#125;,count:&#123;&#125;\", pattern, count); &#125; @Override public void message(String pattern, String channel, String message) &#123; log.info(\"pattern:&#123;&#125;,channel:&#123;&#125;,message:&#123;&#125;\", pattern, channel, message); &#125; &#125;); RedisPubSubCommands&lt;String, String&gt; commands = connection.sync(); commands.psubscribe(\"__keyevent@0__:expired\"); redisCommands.setex(\"name\", 2, \"throwable\"); Thread.sleep(10000); redisConnection.close(); connection.close(); redisClient.shutdown();&#125;// pattern:__keyevent@0__:expired,count:1// pattern:__keyevent@0__:expired,channel:__keyevent@0__:expired,message:name 实际上，在实现RedisPubSubListener的时候可以单独抽离，尽量不要设计成匿名内部类的形式。 事务和批量命令执行 事务相关的命令就是WATCH、UNWATCH、EXEC、MULTI和DISCARD，在RedisCommands系列接口中有对应的方法。举个例子： 123456789101112131415// 同步模式@Testpublic void testSyncMulti() throws Exception &#123; COMMAND.multi(); COMMAND.setex(\"name-1\", 2, \"throwable\"); COMMAND.setex(\"name-2\", 2, \"doge\"); TransactionResult result = COMMAND.exec(); int index = 0; for (Object r : result) &#123; log.info(\"Result-&#123;&#125;:&#123;&#125;\", index, r); index++; &#125;&#125;// Result-0:OK// Result-1:OK Redis的Pipeline也就是管道机制可以理解为把多个命令打包在一次请求发送到Redis服务端，然后Redis服务端把所有的响应结果打包好一次性返回，从而节省不必要的网络资源（最主要是减少网络请求次数）。Redis对于Pipeline机制如何实现并没有明确的规定，也没有提供特殊的命令支持Pipeline机制。Jedis中底层采用BIO（阻塞IO）通讯，所以它的做法是客户端缓存将要发送的命令，最后需要触发然后同步发送一个巨大的命令列表包，再接收和解析一个巨大的响应列表包。Pipeline在Lettuce中对使用者是透明的，由于底层的通讯框架是Netty，所以网络通讯层面的优化Lettuce不需要过多干预，换言之可以这样理解：Netty帮Lettuce从底层实现了Redis的Pipeline机制。但是，Lettuce的异步API也提供了手动Flush的方法： 12345678910111213141516171819@Testpublic void testAsyncManualFlush() &#123; // 取消自动flush ASYNC_COMMAND.setAutoFlushCommands(false); List&lt;RedisFuture&lt;?&gt;&gt; redisFutures = Lists.newArrayList(); int count = 5000; for (int i = 0; i &lt; count; i++) &#123; String key = \"key-\" + (i + 1); String value = \"value-\" + (i + 1); redisFutures.add(ASYNC_COMMAND.set(key, value)); redisFutures.add(ASYNC_COMMAND.expire(key, 2)); &#125; long start = System.currentTimeMillis(); ASYNC_COMMAND.flushCommands(); boolean result = LettuceFutures.awaitAll(10, TimeUnit.SECONDS, redisFutures.toArray(new RedisFuture[0])); Assertions.assertThat(result).isTrue(); log.info(\"Lettuce cost:&#123;&#125; ms\", System.currentTimeMillis() - start);&#125;// Lettuce cost:1302 ms 上面只是从文档看到的一些理论术语，但是现实是骨感的，对比了下Jedis的Pipeline提供的方法，发现了Jedis的Pipeline执行耗时比较低： 12345678910111213141516@Testpublic void testJedisPipeline() throws Exception &#123; Jedis jedis = new Jedis(); Pipeline pipeline = jedis.pipelined(); int count = 5000; for (int i = 0; i &lt; count; i++) &#123; String key = \"key-\" + (i + 1); String value = \"value-\" + (i + 1); pipeline.set(key, value); pipeline.expire(key, 2); &#125; long start = System.currentTimeMillis(); pipeline.syncAndReturnAll(); log.info(\"Jedis cost:&#123;&#125; ms\", System.currentTimeMillis() - start);&#125;// Jedis cost:9 ms 个人猜测Lettuce可能底层并非合并所有命令一次发送（甚至可能是单条发送），具体可能需要抓包才能定位。依此来看，如果真的有大量执行Redis命令的场景，不妨可以使用Jedis的Pipeline。 注意：由上面的测试推断RedisTemplate的executePipelined()方法是假的Pipeline执行方法，使用RedisTemplate的时候请务必注意这一点。 Lua脚本执行 Lettuce中执行Redis的Lua命令的同步接口如下： 1234567891011121314151617181920public interface RedisScriptingCommands&lt;K, V&gt; &#123; &lt;T&gt; T eval(String var1, ScriptOutputType var2, K... var3); &lt;T&gt; T eval(String var1, ScriptOutputType var2, K[] var3, V... var4); &lt;T&gt; T evalsha(String var1, ScriptOutputType var2, K... var3); &lt;T&gt; T evalsha(String var1, ScriptOutputType var2, K[] var3, V... var4); List&lt;Boolean&gt; scriptExists(String... var1); String scriptFlush(); String scriptKill(); String scriptLoad(V var1); String digest(V var1);&#125; 异步和反应式的接口方法定义差不多，不同的地方就是返回值类型，一般我们常用的是eval()、evalsha()和scriptLoad()方法。举个简单的例子： 123456789101112131415161718private static RedisCommands&lt;String, String&gt; COMMANDS;private static String RAW_LUA = \"local key = KEYS[1]\\n\" + \"local value = ARGV[1]\\n\" + \"local timeout = ARGV[2]\\n\" + \"redis.call('SETEX', key, tonumber(timeout), value)\\n\" + \"local result = redis.call('GET', key)\\n\" + \"return result;\";private static AtomicReference&lt;String&gt; LUA_SHA = new AtomicReference&lt;&gt;();@Testpublic void testLua() throws Exception &#123; LUA_SHA.compareAndSet(null, COMMANDS.scriptLoad(RAW_LUA)); String[] keys = new String[]&#123;\"name\"&#125;; String[] args = new String[]&#123;\"throwable\", \"5000\"&#125;; String result = COMMANDS.evalsha(LUA_SHA.get(), ScriptOutputType.VALUE, keys, args); log.info(\"Get value:&#123;&#125;\", result);&#125;// Get value:throwable 高可用和分片 为了Redis的高可用，一般会采用普通主从（Master/Replica，这里笔者称为普通主从模式，也就是仅仅做了主从复制，故障需要手动切换）、哨兵和集群。普通主从模式可以独立运行，也可以配合哨兵运行，只是哨兵提供自动故障转移和主节点提升功能。普通主从和哨兵都可以使用MasterSlave，通过入参包括RedisClient、编码解码器以及一个或者多个RedisURI获取对应的Connection实例。 这里注意一点，MasterSlave中提供的方法如果只要求传入一个RedisURI实例，那么Lettuce会进行拓扑发现机制，自动获取Redis主从节点信息；如果要求传入一个RedisURI集合，那么对于普通主从模式来说所有节点信息是静态的，不会进行发现和更新。 拓扑发现的规则如下： 对于普通主从（Master/Replica）模式，不需要感知RedisURI指向从节点还是主节点，只会进行一次性的拓扑查找所有节点信息，此后节点信息会保存在静态缓存中，不会更新。 对于哨兵模式，会订阅所有哨兵实例并侦听订阅/发布消息以触发拓扑刷新机制，更新缓存的节点信息，也就是哨兵天然就是动态发现节点信息，不支持静态配置。 拓扑发现机制的提供API为TopologyProvider，需要了解其原理的可以参考具体的实现。 对于集群（Cluster）模式，Lettuce提供了一套独立的API。 另外，如果Lettuce连接面向的是非单个Redis节点，连接实例提供了数据读取节点偏好（ReadFrom）设置，可选值有： MASTER：只从Master节点中读取。 MASTER_PREFERRED：优先从Master节点中读取。 SLAVE_PREFERRED：优先从Slavor节点中读取。 SLAVE：只从Slavor节点中读取。 NEAREST：使用最近一次连接的Redis实例读取。 普通主从模式 假设现在有三个Redis服务形成树状主从关系如下： 节点一：localhost:6379，角色为Master。 节点二：localhost:6380，角色为Slavor，节点一的从节点。 节点三：localhost:6381，角色为Slavor，节点二的从节点。 首次动态节点发现主从模式的节点信息需要如下构建连接： 123456789101112@Testpublic void testDynamicReplica() throws Exception &#123; // 这里只需要配置一个节点的连接信息，不一定需要是主节点的信息，从节点也可以 RedisURI uri = RedisURI.builder().withHost(\"localhost\").withPort(6379).build(); RedisClient redisClient = RedisClient.create(uri); StatefulRedisMasterSlaveConnection&lt;String, String&gt; connection = MasterSlave.connect(redisClient, new Utf8StringCodec(), uri); // 只从从节点读取数据 connection.setReadFrom(ReadFrom.SLAVE); // 执行其他Redis命令 connection.close(); redisClient.shutdown();&#125; 如果需要指定静态的Redis主从节点连接属性，那么可以这样构建连接： 123456789101112131415161718@Testpublic void testStaticReplica() throws Exception &#123; List&lt;RedisURI&gt; uris = new ArrayList&lt;&gt;(); RedisURI uri1 = RedisURI.builder().withHost(\"localhost\").withPort(6379).build(); RedisURI uri2 = RedisURI.builder().withHost(\"localhost\").withPort(6380).build(); RedisURI uri3 = RedisURI.builder().withHost(\"localhost\").withPort(6381).build(); uris.add(uri1); uris.add(uri2); uris.add(uri3); RedisClient redisClient = RedisClient.create(); StatefulRedisMasterSlaveConnection&lt;String, String&gt; connection = MasterSlave.connect(redisClient, new Utf8StringCodec(), uris); // 只从主节点读取数据 connection.setReadFrom(ReadFrom.MASTER); // 执行其他Redis命令 connection.close(); redisClient.shutdown();&#125; 哨兵模式 由于Lettuce自身提供了哨兵的拓扑发现机制，所以只需要随便配置一个哨兵节点的RedisURI实例即可： 123456789101112131415161718@Testpublic void testDynamicSentinel() throws Exception &#123; RedisURI redisUri = RedisURI.builder() .withPassword(\"你的密码\") .withSentinel(\"localhost\", 26379) .withSentinelMasterId(\"哨兵Master的ID\") .build(); RedisClient redisClient = RedisClient.create(); StatefulRedisMasterSlaveConnection&lt;String, String&gt; connection = MasterSlave.connect(redisClient, new Utf8StringCodec(), redisUri); // 只允许从从节点读取数据 connection.setReadFrom(ReadFrom.SLAVE); RedisCommands&lt;String, String&gt; command = connection.sync(); SetArgs setArgs = SetArgs.Builder.nx().ex(5); command.set(\"name\", \"throwable\", setArgs); String value = command.get(\"name\"); log.info(\"Get value:&#123;&#125;\", value);&#125;// Get value:throwable 集群模式 鉴于笔者对Redis集群模式并不熟悉，Cluster模式下的API使用本身就有比较多的限制，所以这里只简单介绍一下怎么用。先说几个特性： 下面的API提供跨槽位（Slot）调用的功能： RedisAdvancedClusterCommands。 RedisAdvancedClusterAsyncCommands。 RedisAdvancedClusterReactiveCommands。 静态节点选择功能： masters：选择所有主节点执行命令。 slaves：选择所有从节点执行命令，其实就是只读模式。 all nodes：命令可以在所有节点执行。 集群拓扑视图动态更新功能： 手动更新，主动调用RedisClusterClient#reloadPartitions()。 后台定时更新。 自适应更新，基于连接断开和MOVED/ASK命令重定向自动更新。 Redis集群搭建详细过程可以参考官方文档，假设已经搭建好集群如下（192.168.56.200是笔者的虚拟机Host）： 192.168.56.200:7001 =&gt; 主节点，槽位0-5460。 192.168.56.200:7002 =&gt; 主节点，槽位5461-10922。 192.168.56.200:7003 =&gt; 主节点，槽位10923-16383。 192.168.56.200:7004 =&gt; 7001的从节点。 192.168.56.200:7005 =&gt; 7002的从节点。 192.168.56.200:7006 =&gt; 7003的从节点。 简单的集群连接和使用方式如下： 1234567891011@Testpublic void testSyncCluster()&#123; RedisURI uri = RedisURI.builder().withHost(\"192.168.56.200\").build(); RedisClusterClient redisClusterClient = RedisClusterClient.create(uri); StatefulRedisClusterConnection&lt;String, String&gt; connection = redisClusterClient.connect(); RedisAdvancedClusterCommands&lt;String, String&gt; commands = connection.sync(); commands.setex(\"name\",10, \"throwable\"); String value = commands.get(\"name\"); log.info(\"Get value:&#123;&#125;\", value);&#125;// Get value:throwable 节点选择： 1234567891011121314151617@Testpublic void testSyncNodeSelection() &#123; RedisURI uri = RedisURI.builder().withHost(\"192.168.56.200\").withPort(7001).build(); RedisClusterClient redisClusterClient = RedisClusterClient.create(uri); StatefulRedisClusterConnection&lt;String, String&gt; connection = redisClusterClient.connect(); RedisAdvancedClusterCommands&lt;String, String&gt; commands = connection.sync();// commands.all(); // 所有节点// commands.masters(); // 主节点 // 从节点只读 NodeSelection&lt;String, String&gt; replicas = commands.slaves(); NodeSelectionCommands&lt;String, String&gt; nodeSelectionCommands = replicas.commands(); // 这里只是演示,一般应该禁用keys *命令 Executions&lt;List&lt;String&gt;&gt; keys = nodeSelectionCommands.keys(\"*\"); keys.forEach(key -&gt; log.info(\"key: &#123;&#125;\", key)); connection.close(); redisClusterClient.shutdown();&#125; 定时更新集群拓扑视图（每隔十分钟更新一次，这个时间自行考量，不能太频繁）： 123456789101112131415161718@Testpublic void testPeriodicClusterTopology() throws Exception &#123; RedisURI uri = RedisURI.builder().withHost(\"192.168.56.200\").withPort(7001).build(); RedisClusterClient redisClusterClient = RedisClusterClient.create(uri); ClusterTopologyRefreshOptions options = ClusterTopologyRefreshOptions .builder() .enablePeriodicRefresh(Duration.of(10, ChronoUnit.MINUTES)) .build(); redisClusterClient.setOptions(ClusterClientOptions.builder().topologyRefreshOptions(options).build()); StatefulRedisClusterConnection&lt;String, String&gt; connection = redisClusterClient.connect(); RedisAdvancedClusterCommands&lt;String, String&gt; commands = connection.sync(); commands.setex(\"name\", 10, \"throwable\"); String value = commands.get(\"name\"); log.info(\"Get value:&#123;&#125;\", value); Thread.sleep(Integer.MAX_VALUE); connection.close(); redisClusterClient.shutdown();&#125; 自适应更新集群拓扑视图： 123456789101112131415161718192021@Testpublic void testAdaptiveClusterTopology() throws Exception &#123; RedisURI uri = RedisURI.builder().withHost(\"192.168.56.200\").withPort(7001).build(); RedisClusterClient redisClusterClient = RedisClusterClient.create(uri); ClusterTopologyRefreshOptions options = ClusterTopologyRefreshOptions.builder() .enableAdaptiveRefreshTrigger( ClusterTopologyRefreshOptions.RefreshTrigger.MOVED_REDIRECT, ClusterTopologyRefreshOptions.RefreshTrigger.PERSISTENT_RECONNECTS ) .adaptiveRefreshTriggersTimeout(Duration.of(30, ChronoUnit.SECONDS)) .build(); redisClusterClient.setOptions(ClusterClientOptions.builder().topologyRefreshOptions(options).build()); StatefulRedisClusterConnection&lt;String, String&gt; connection = redisClusterClient.connect(); RedisAdvancedClusterCommands&lt;String, String&gt; commands = connection.sync(); commands.setex(\"name\", 10, \"throwable\"); String value = commands.get(\"name\"); log.info(\"Get value:&#123;&#125;\", value); Thread.sleep(Integer.MAX_VALUE); connection.close(); redisClusterClient.shutdown();&#125; 动态命令和自定义命令 自定义命令是Redis命令有限集，不过可以更细粒度指定KEY、ARGV、命令类型、编码解码器和返回值类型，依赖于dispatch()方法： 123456789101112131415161718192021222324252627282930313233343536373839// 自定义实现PING方法@Testpublic void testCustomPing() throws Exception &#123; RedisURI redisUri = RedisURI.builder() .withHost(\"localhost\") .withPort(6379) .withTimeout(Duration.of(10, ChronoUnit.SECONDS)) .build(); RedisClient redisClient = RedisClient.create(redisUri); StatefulRedisConnection&lt;String, String&gt; connect = redisClient.connect(); RedisCommands&lt;String, String&gt; sync = connect.sync(); RedisCodec&lt;String, String&gt; codec = StringCodec.UTF8; String result = sync.dispatch(CommandType.PING, new StatusOutput&lt;&gt;(codec)); log.info(\"PING:&#123;&#125;\", result); connect.close(); redisClient.shutdown();&#125;// PING:PONG// 自定义实现Set方法@Testpublic void testCustomSet() throws Exception &#123; RedisURI redisUri = RedisURI.builder() .withHost(\"localhost\") .withPort(6379) .withTimeout(Duration.of(10, ChronoUnit.SECONDS)) .build(); RedisClient redisClient = RedisClient.create(redisUri); StatefulRedisConnection&lt;String, String&gt; connect = redisClient.connect(); RedisCommands&lt;String, String&gt; sync = connect.sync(); RedisCodec&lt;String, String&gt; codec = StringCodec.UTF8; sync.dispatch(CommandType.SETEX, new StatusOutput&lt;&gt;(codec), new CommandArgs&lt;&gt;(codec).addKey(\"name\").add(5).addValue(\"throwable\")); String result = sync.get(\"name\"); log.info(\"Get value:&#123;&#125;\", result); connect.close(); redisClient.shutdown();&#125;// Get value:throwable 动态命令是基于Redis命令有限集，并且通过注解和动态代理完成一些复杂命令组合的实现。主要注解在io.lettuce.core.dynamic.annotation包路径下。简单举个例子： 123456789101112131415161718192021222324252627282930313233343536373839404142public interface CustomCommand extends Commands &#123; // SET [key] [value] @Command(\"SET ?0 ?1\") String setKey(String key, String value); // SET [key] [value] @Command(\"SET :key :value\") String setKeyNamed(@Param(\"key\") String key, @Param(\"value\") String value); // MGET [key1] [key2] @Command(\"MGET ?0 ?1\") List&lt;String&gt; mGet(String key1, String key2); /** * 方法名作为命令 */ @CommandNaming(strategy = CommandNaming.Strategy.METHOD_NAME) String mSet(String key1, String value1, String key2, String value2);&#125;@Testpublic void testCustomDynamicSet() throws Exception &#123; RedisURI redisUri = RedisURI.builder() .withHost(\"localhost\") .withPort(6379) .withTimeout(Duration.of(10, ChronoUnit.SECONDS)) .build(); RedisClient redisClient = RedisClient.create(redisUri); StatefulRedisConnection&lt;String, String&gt; connect = redisClient.connect(); RedisCommandFactory commandFactory = new RedisCommandFactory(connect); CustomCommand commands = commandFactory.getCommands(CustomCommand.class); commands.setKey(\"name\", \"throwable\"); commands.setKeyNamed(\"throwable\", \"doge\"); log.info(\"MGET ===&gt; \" + commands.mGet(\"name\", \"throwable\")); commands.mSet(\"key1\", \"value1\",\"key2\", \"value2\"); log.info(\"MGET ===&gt; \" + commands.mGet(\"key1\", \"key2\")); connect.close(); redisClient.shutdown();&#125;// MGET ===&gt; [throwable, doge]// MGET ===&gt; [value1, value2] 高阶特性 Lettuce有很多高阶使用特性，这里只列举个人认为常用的两点： 配置客户端资源。 使用连接池。 更多其他特性可以自行参看官方文档。 配置客户端资源 客户端资源的设置与Lettuce的性能、并发和事件处理相关。线程池或者线程组相关配置占据客户端资源配置的大部分（EventLoopGroups和EventExecutorGroup），这些线程池或者线程组是连接程序的基础组件。一般情况下，客户端资源应该在多个Redis客户端之间共享，并且在不再使用的时候需要自行关闭。笔者认为，客户端资源是面向Netty的。注意：除非特别熟悉或者花长时间去测试调整下面提到的参数，否则在没有经验的前提下凭直觉修改默认值，有可能会踩坑。 客户端资源接口是ClientResources，实现类是DefaultClientResources。 构建DefaultClientResources实例： 12345678// 默认ClientResources resources = DefaultClientResources.create();// 建造器ClientResources resources = DefaultClientResources.builder() .ioThreadPoolSize(4) .computationThreadPoolSize(4) .build() 使用： 12345678910ClientResources resources = DefaultClientResources.create();// 非集群RedisClient client = RedisClient.create(resources, uri);// 集群RedisClusterClient clusterClient = RedisClusterClient.create(resources, uris);// ......client.shutdown();clusterClient.shutdown();// 关闭资源resources.shutdown(); 客户端资源基本配置： 属性 描述 默认值 ioThreadPoolSize I/O线程数 Runtime.getRuntime().availableProcessors() computationThreadPoolSize 任务线程数 Runtime.getRuntime().availableProcessors() 客户端资源高级配置： 属性 描述 默认值 eventLoopGroupProvider EventLoopGroup提供商 - eventExecutorGroupProvider EventExecutorGroup提供商 - eventBus 事件总线 DefaultEventBus commandLatencyCollectorOptions 命令延时收集器配置 DefaultCommandLatencyCollectorOptions commandLatencyCollector 命令延时收集器 DefaultCommandLatencyCollector commandLatencyPublisherOptions 命令延时发布器配置 DefaultEventPublisherOptions dnsResolver DNS处理器 JDK或者Netty提供 reconnectDelay 重连延时配置 Delay.exponential() nettyCustomizer Netty自定义配置器 - tracing 轨迹记录器 - 非集群客户端RedisClient的属性配置： Redis非集群客户端RedisClient本身提供了配置属性方法： 12345RedisClient client = RedisClient.create(uri);client.setOptions(ClientOptions.builder() .autoReconnect(false) .pingBeforeActivateConnection(true) .build()); 非集群客户端的配置属性列表： 属性 描述 默认值 pingBeforeActivateConnection 连接激活之前是否执行PING命令 false autoReconnect 是否自动重连 true cancelCommandsOnReconnectFailure 重连失败是否拒绝命令执行 false suspendReconnectOnProtocolFailure 底层协议失败是否挂起重连操作 false requestQueueSize 请求队列容量 2147483647(Integer#MAX_VALUE) disconnectedBehavior 失去连接时候的行为 DEFAULT sslOptions SSL配置 - socketOptions Socket配置 10 seconds Connection-Timeout, no keep-alive, no TCP noDelay timeoutOptions 超时配置 - publishOnScheduler 发布反应式信号数据的调度器 使用I/O线程 集群客户端属性配置： Redis集群客户端RedisClusterClient本身提供了配置属性方法： 123456789RedisClusterClient client = RedisClusterClient.create(uri);ClusterTopologyRefreshOptions topologyRefreshOptions = ClusterTopologyRefreshOptions.builder() .enablePeriodicRefresh(refreshPeriod(10, TimeUnit.MINUTES)) .enableAllAdaptiveRefreshTriggers() .build();client.setOptions(ClusterClientOptions.builder() .topologyRefreshOptions(topologyRefreshOptions) .build()); 集群客户端的配置属性列表： 属性 描述 默认值 enablePeriodicRefresh 是否允许周期性更新集群拓扑视图 false refreshPeriod 更新集群拓扑视图周期 60秒 enableAdaptiveRefreshTrigger 设置自适应更新集群拓扑视图触发器RefreshTrigger - adaptiveRefreshTriggersTimeout 自适应更新集群拓扑视图触发器超时设置 30秒 refreshTriggersReconnectAttempts 自适应更新集群拓扑视图触发重连次数 5 dynamicRefreshSources 是否允许动态刷新拓扑资源 true closeStaleConnections 是否允许关闭陈旧的连接 true maxRedirects 集群重定向次数上限 5 validateClusterNodeMembership 是否校验集群节点的成员关系 true 使用连接池 引入连接池依赖commons-pool2： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency 基本使用如下： 123456789101112131415161718192021@Testpublic void testUseConnectionPool() throws Exception &#123; RedisURI redisUri = RedisURI.builder() .withHost(\"localhost\") .withPort(6379) .withTimeout(Duration.of(10, ChronoUnit.SECONDS)) .build(); RedisClient redisClient = RedisClient.create(redisUri); GenericObjectPoolConfig poolConfig = new GenericObjectPoolConfig(); GenericObjectPool&lt;StatefulRedisConnection&lt;String, String&gt;&gt; pool = ConnectionPoolSupport.createGenericObjectPool(redisClient::connect, poolConfig); try (StatefulRedisConnection&lt;String, String&gt; connection = pool.borrowObject()) &#123; RedisCommands&lt;String, String&gt; command = connection.sync(); SetArgs setArgs = SetArgs.Builder.nx().ex(5); command.set(\"name\", \"throwable\", setArgs); String n = command.get(\"name\"); log.info(\"Get value:&#123;&#125;\", n); &#125; pool.close(); redisClient.shutdown();&#125; 其中，同步连接的池化支持需要用ConnectionPoolSupport，异步连接的池化支持需要用AsyncConnectionPoolSupport（Lettuce5.1之后才支持）。 几个常见的渐进式删除例子 渐进式删除Hash中的域-属性： 1234567891011121314151617181920212223242526272829303132@Testpublic void testDelBigHashKey() throws Exception &#123; // SCAN参数 ScanArgs scanArgs = ScanArgs.Builder.limit(2); // TEMP游标 ScanCursor cursor = ScanCursor.INITIAL; // 目标KEY String key = \"BIG_HASH_KEY\"; prepareHashTestData(key); log.info(\"开始渐进式删除Hash的元素...\"); int counter = 0; do &#123; MapScanCursor&lt;String, String&gt; result = COMMAND.hscan(key, cursor, scanArgs); // 重置TEMP游标 cursor = ScanCursor.of(result.getCursor()); cursor.setFinished(result.isFinished()); Collection&lt;String&gt; fields = result.getMap().values(); if (!fields.isEmpty()) &#123; COMMAND.hdel(key, fields.toArray(new String[0])); &#125; counter++; &#125; while (!(ScanCursor.FINISHED.getCursor().equals(cursor.getCursor()) &amp;&amp; ScanCursor.FINISHED.isFinished() == cursor.isFinished())); log.info(\"渐进式删除Hash的元素完毕,迭代次数:&#123;&#125; ...\", counter);&#125;private void prepareHashTestData(String key) throws Exception &#123; COMMAND.hset(key, \"1\", \"1\"); COMMAND.hset(key, \"2\", \"2\"); COMMAND.hset(key, \"3\", \"3\"); COMMAND.hset(key, \"4\", \"4\"); COMMAND.hset(key, \"5\", \"5\");&#125; 渐进式删除集合中的元素： 123456789101112131415161718192021222324252627@Testpublic void testDelBigSetKey() throws Exception &#123; String key = \"BIG_SET_KEY\"; prepareSetTestData(key); // SCAN参数 ScanArgs scanArgs = ScanArgs.Builder.limit(2); // TEMP游标 ScanCursor cursor = ScanCursor.INITIAL; log.info(\"开始渐进式删除Set的元素...\"); int counter = 0; do &#123; ValueScanCursor&lt;String&gt; result = COMMAND.sscan(key, cursor, scanArgs); // 重置TEMP游标 cursor = ScanCursor.of(result.getCursor()); cursor.setFinished(result.isFinished()); List&lt;String&gt; values = result.getValues(); if (!values.isEmpty()) &#123; COMMAND.srem(key, values.toArray(new String[0])); &#125; counter++; &#125; while (!(ScanCursor.FINISHED.getCursor().equals(cursor.getCursor()) &amp;&amp; ScanCursor.FINISHED.isFinished() == cursor.isFinished())); log.info(\"渐进式删除Set的元素完毕,迭代次数:&#123;&#125; ...\", counter);&#125;private void prepareSetTestData(String key) throws Exception &#123; COMMAND.sadd(key, \"1\", \"2\", \"3\", \"4\", \"5\");&#125; 渐进式删除有序集合中的元素： 1234567891011121314151617181920212223242526272829303132@Testpublic void testDelBigZSetKey() throws Exception &#123; // SCAN参数 ScanArgs scanArgs = ScanArgs.Builder.limit(2); // TEMP游标 ScanCursor cursor = ScanCursor.INITIAL; // 目标KEY String key = \"BIG_ZSET_KEY\"; prepareZSetTestData(key); log.info(\"开始渐进式删除ZSet的元素...\"); int counter = 0; do &#123; ScoredValueScanCursor&lt;String&gt; result = COMMAND.zscan(key, cursor, scanArgs); // 重置TEMP游标 cursor = ScanCursor.of(result.getCursor()); cursor.setFinished(result.isFinished()); List&lt;ScoredValue&lt;String&gt;&gt; scoredValues = result.getValues(); if (!scoredValues.isEmpty()) &#123; COMMAND.zrem(key, scoredValues.stream().map(ScoredValue&lt;String&gt;::getValue).toArray(String[]::new)); &#125; counter++; &#125; while (!(ScanCursor.FINISHED.getCursor().equals(cursor.getCursor()) &amp;&amp; ScanCursor.FINISHED.isFinished() == cursor.isFinished())); log.info(\"渐进式删除ZSet的元素完毕,迭代次数:&#123;&#125; ...\", counter);&#125;private void prepareZSetTestData(String key) throws Exception &#123; COMMAND.zadd(key, 0, \"1\"); COMMAND.zadd(key, 0, \"2\"); COMMAND.zadd(key, 0, \"3\"); COMMAND.zadd(key, 0, \"4\"); COMMAND.zadd(key, 0, \"5\");&#125; 在SpringBoot中使用Lettuce 个人认为，spring-data-redis中的API封装并不是很优秀，用起来比较重，不够灵活，这里结合前面的例子和代码，在SpringBoot脚手架项目中配置和整合Lettuce。先引入依赖： 12345678910111213141516171819202122232425262728&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt; &lt;version&gt;5.1.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.10&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 一般情况下，每个应用应该使用单个Redis客户端实例和单个连接实例，这里设计一个脚手架，适配单机、普通主从、哨兵和集群四种使用场景。对于客户端资源，采用默认的实现即可。对于Redis的连接属性，比较主要的有Host、Port和Password，其他可以暂时忽略。基于约定大于配置的原则，先定制一系列属性配置类（其实有些配置是可以完全共用，但是考虑到要清晰描述类之间的关系，这里拆分多个配置属性类和多个配置方法）： 12345678910111213141516171819202122232425262728293031323334353637@Data@ConfigurationProperties(prefix = \"lettuce\")public class LettuceProperties &#123; private LettuceSingleProperties single; private LettuceReplicaProperties replica; private LettuceSentinelProperties sentinel; private LettuceClusterProperties cluster;&#125;@Datapublic class LettuceSingleProperties &#123; private String host; private Integer port; private String password;&#125;@EqualsAndHashCode(callSuper = true)@Datapublic class LettuceReplicaProperties extends LettuceSingleProperties &#123;&#125;@EqualsAndHashCode(callSuper = true)@Datapublic class LettuceSentinelProperties extends LettuceSingleProperties &#123; private String masterId;&#125;@EqualsAndHashCode(callSuper = true)@Datapublic class LettuceClusterProperties extends LettuceSingleProperties &#123;&#125; 配置类如下，主要使用@ConditionalOnProperty做隔离，一般情况下，很少有人会在一个应用使用一种以上的Redis连接场景： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107@RequiredArgsConstructor@Configuration@ConditionalOnClass(name = \"io.lettuce.core.RedisURI\")@EnableConfigurationProperties(value = LettuceProperties.class)public class LettuceAutoConfiguration &#123; private final LettuceProperties lettuceProperties; @Bean(destroyMethod = \"shutdown\") public ClientResources clientResources() &#123; return DefaultClientResources.create(); &#125; @Bean @ConditionalOnProperty(name = \"lettuce.single.host\") public RedisURI singleRedisUri() &#123; LettuceSingleProperties singleProperties = lettuceProperties.getSingle(); return RedisURI.builder() .withHost(singleProperties.getHost()) .withPort(singleProperties.getPort()) .withPassword(singleProperties.getPassword()) .build(); &#125; @Bean(destroyMethod = \"shutdown\") @ConditionalOnProperty(name = \"lettuce.single.host\") public RedisClient singleRedisClient(ClientResources clientResources, @Qualifier(\"singleRedisUri\") RedisURI redisUri) &#123; return RedisClient.create(clientResources, redisUri); &#125; @Bean(destroyMethod = \"close\") @ConditionalOnProperty(name = \"lettuce.single.host\") public StatefulRedisConnection&lt;String, String&gt; singleRedisConnection(@Qualifier(\"singleRedisClient\") RedisClient singleRedisClient) &#123; return singleRedisClient.connect(); &#125; @Bean @ConditionalOnProperty(name = \"lettuce.replica.host\") public RedisURI replicaRedisUri() &#123; LettuceReplicaProperties replicaProperties = lettuceProperties.getReplica(); return RedisURI.builder() .withHost(replicaProperties.getHost()) .withPort(replicaProperties.getPort()) .withPassword(replicaProperties.getPassword()) .build(); &#125; @Bean(destroyMethod = \"shutdown\") @ConditionalOnProperty(name = \"lettuce.replica.host\") public RedisClient replicaRedisClient(ClientResources clientResources, @Qualifier(\"replicaRedisUri\") RedisURI redisUri) &#123; return RedisClient.create(clientResources, redisUri); &#125; @Bean(destroyMethod = \"close\") @ConditionalOnProperty(name = \"lettuce.replica.host\") public StatefulRedisMasterSlaveConnection&lt;String, String&gt; replicaRedisConnection(@Qualifier(\"replicaRedisClient\") RedisClient replicaRedisClient, @Qualifier(\"replicaRedisUri\") RedisURI redisUri) &#123; return MasterSlave.connect(replicaRedisClient, new Utf8StringCodec(), redisUri); &#125; @Bean @ConditionalOnProperty(name = \"lettuce.sentinel.host\") public RedisURI sentinelRedisUri() &#123; LettuceSentinelProperties sentinelProperties = lettuceProperties.getSentinel(); return RedisURI.builder() .withPassword(sentinelProperties.getPassword()) .withSentinel(sentinelProperties.getHost(), sentinelProperties.getPort()) .withSentinelMasterId(sentinelProperties.getMasterId()) .build(); &#125; @Bean(destroyMethod = \"shutdown\") @ConditionalOnProperty(name = \"lettuce.sentinel.host\") public RedisClient sentinelRedisClient(ClientResources clientResources, @Qualifier(\"sentinelRedisUri\") RedisURI redisUri) &#123; return RedisClient.create(clientResources, redisUri); &#125; @Bean(destroyMethod = \"close\") @ConditionalOnProperty(name = \"lettuce.sentinel.host\") public StatefulRedisMasterSlaveConnection&lt;String, String&gt; sentinelRedisConnection(@Qualifier(\"sentinelRedisClient\") RedisClient sentinelRedisClient, @Qualifier(\"sentinelRedisUri\") RedisURI redisUri) &#123; return MasterSlave.connect(sentinelRedisClient, new Utf8StringCodec(), redisUri); &#125; @Bean @ConditionalOnProperty(name = \"lettuce.cluster.host\") public RedisURI clusterRedisUri() &#123; LettuceClusterProperties clusterProperties = lettuceProperties.getCluster(); return RedisURI.builder() .withHost(clusterProperties.getHost()) .withPort(clusterProperties.getPort()) .withPassword(clusterProperties.getPassword()) .build(); &#125; @Bean(destroyMethod = \"shutdown\") @ConditionalOnProperty(name = \"lettuce.cluster.host\") public RedisClusterClient redisClusterClient(ClientResources clientResources, @Qualifier(\"clusterRedisUri\") RedisURI redisUri) &#123; return RedisClusterClient.create(clientResources, redisUri); &#125; @Bean(destroyMethod = \"close\") @ConditionalOnProperty(name = \"lettuce.cluster\") public StatefulRedisClusterConnection&lt;String, String&gt; clusterConnection(RedisClusterClient clusterClient) &#123; return clusterClient.connect(); &#125;&#125; 最后为了让IDE识别我们的配置，可以添加IDE亲缘性，/META-INF文件夹下新增一个文件spring-configuration-metadata.json，内容如下： 12345678910111213141516171819202122232425262728&#123; \"properties\": [ &#123; \"name\": \"lettuce.single\", \"type\": \"club.throwable.spring.lettuce.LettuceSingleProperties\", \"description\": \"单机配置\", \"sourceType\": \"club.throwable.spring.lettuce.LettuceProperties\" &#125;, &#123; \"name\": \"lettuce.replica\", \"type\": \"club.throwable.spring.lettuce.LettuceReplicaProperties\", \"description\": \"主从配置\", \"sourceType\": \"club.throwable.spring.lettuce.LettuceProperties\" &#125;, &#123; \"name\": \"lettuce.sentinel\", \"type\": \"club.throwable.spring.lettuce.LettuceSentinelProperties\", \"description\": \"哨兵配置\", \"sourceType\": \"club.throwable.spring.lettuce.LettuceProperties\" &#125;, &#123; \"name\": \"lettuce.single\", \"type\": \"club.throwable.spring.lettuce.LettuceClusterProperties\", \"description\": \"集群配置\", \"sourceType\": \"club.throwable.spring.lettuce.LettuceProperties\" &#125; ]&#125; 如果想IDE亲缘性做得更好，可以添加/META-INF/additional-spring-configuration-metadata.json进行更多细节定义。简单使用如下： 12345678910111213141516@Slf4j@Componentpublic class RedisCommandLineRunner implements CommandLineRunner &#123; @Autowired @Qualifier(\"singleRedisConnection\") private StatefulRedisConnection&lt;String, String&gt; connection; @Override public void run(String... args) throws Exception &#123; RedisCommands&lt;String, String&gt; redisCommands = connection.sync(); redisCommands.setex(\"name\", 5, \"throwable\"); log.info(\"Get value:&#123;&#125;\", redisCommands.get(\"name\")); &#125;&#125;// Get value:throwable 小结 本文算是基于Lettuce的官方文档，对它的使用进行全方位的分析，包括主要功能、配置都做了一些示例，限于篇幅部分特性和配置细节没有分析。Lettuce已经被spring-data-redis接纳作为官方的Redis客户端驱动，所以值得信赖，它的一些API设计确实比较合理，扩展性高的同时灵活性也高。个人建议，基于Lettuce包自行添加配置到SpringBoot应用用起来会得心应手，毕竟RedisTemplate实在太笨重，而且还屏蔽了Lettuce一些高级特性和灵活的API。 参考资料： Lettuce Reference Guide （本文完 c-14-d e-a-20190928 最近事太多…）","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Redis","slug":"Middleware/Redis","permalink":"http://throwable.club/blog/categories/Middleware/Redis/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Redis","slug":"Redis","permalink":"http://throwable.club/blog/tags/Redis/"}]},{"title":"使用Redis实现延时任务(二)","slug":"redis-delay-task-second","date":"2019-09-01T12:50:09.000Z","updated":"2019-11-28T17:00:53.907Z","comments":true,"path":"2019/09/01/redis-delay-task-second/","link":"","permalink":"http://throwable.club/2019/09/01/redis-delay-task-second/","excerpt":"前提 前一篇文章通过Redis的有序集合Sorted Set和调度框架Quartz实例一版简单的延时任务，但是有两个相对重要的问题没有解决： 分片。 监控。 这篇文章的内容就是要完善这两个方面的功能。前置文章：使用Redis实现延时任务(一)。","text":"前提 前一篇文章通过Redis的有序集合Sorted Set和调度框架Quartz实例一版简单的延时任务，但是有两个相对重要的问题没有解决： 分片。 监控。 这篇文章的内容就是要完善这两个方面的功能。前置文章：使用Redis实现延时任务(一)。 为什么需要分片 这里重新贴一下查询脚本dequeue.lua的内容： 12345678910111213141516171819202122-- 参考jesque的部分Lua脚本实现local zset_key = KEYS[1]local hash_key = KEYS[2]local min_score = ARGV[1]local max_score = ARGV[2]local offset = ARGV[3]local limit = ARGV[4]-- TYPE命令的返回结果是&#123;'ok':'zset'&#125;这样子,这里利用next做一轮迭代local status, type = next(redis.call('TYPE', zset_key))if status ~= nil and status == 'ok' then if type == 'zset' then local list = redis.call('ZREVRANGEBYSCORE', zset_key, max_score, min_score, 'LIMIT', offset, limit) if list ~= nil and #list &gt; 0 then -- unpack函数能把table转化为可变参数 redis.call('ZREM', zset_key, unpack(list)) local result = redis.call('HMGET', hash_key, unpack(list)) redis.call('HDEL', hash_key, unpack(list)) return result end endendreturn nil 这个脚本一共用到了四个命令ZREVRANGEBYSCORE、ZREM、HMGET和HDEL（TYPE命令的时间复杂度可以忽略）： 命令 时间复杂度 参数说明 ZREVRANGEBYSCORE O(log(N)+M) N是有序集合中的元素总数，M是返回的元素的数量 ZREM O(M*log(N)) N是有序集合中的元素总数，M是成功移除的元素的数量 HMGET O(L) L是成功返回的域的数量 HDEL O(L) L是要删除的域的数量 接下来需要结合场景和具体参数分析，假如在生产环境，有序集合的元素总量维持在10000每小时（也就是说业务量是每小时下单1万笔），由于查询Sorted Set和Hash的数据同时做了删除，那么30分钟内常驻在这两个集合中的数据有5000条，也就是上面表中的N = 5000。假设我们初步定义查询的LIMIT值为100，也就是上面的M值为100，假设Redis中每个操作单元的耗时简单认为是T，那么分析一下5000条数据处理的耗时： 序号 集合基数 ZREVRANGEBYSCORE ZREM HMGET HDEL 1 5000 log(5000T) + 100T log(5000T) * 100 100T 100T 2 4900 log(4900T) + 100T log(4900T) * 100 100T 100T 3 4800 log(4800T) + 100T log(4800T) * 100 100T 100T … … … … … … 理论上，脚本用到的四个命令中，ZREM命令的耗时是最大的，而ZREVRANGEBYSCORE和ZREM的时间复杂度函数都是M * log(N)，因此控制集合元素基数N对于降低Lua脚本运行的耗时是有一定帮助的。 分片 上面分析了dequeue.lua的时间复杂度，准备好的分片方案有两个： 方案一：单Redis实例，对Sorted Set和Hash两个集合的数据进行分片。 方案二：基于多个Redis实例（可以是哨兵或者集群），实施方案一的分片操作。 为了简单起见，后面的例子中分片的数量（shardingCount）设计为2，生产中分片数量应该根据实际情况定制。预设使用长整型的用户ID字段userId取模进行分片，假定测试数据中的userId是均匀分布的。 通用实体： 12345678@Datapublic class OrderMessage &#123; private String orderId; private BigDecimal amount; private Long userId; private String timestamp;&#125; 延迟队列接口： 123456789101112public interface OrderDelayQueue &#123; void enqueue(OrderMessage message); List&lt;OrderMessage&gt; dequeue(String min, String max, String offset, String limit, int index); List&lt;OrderMessage&gt; dequeue(int index); String enqueueSha(); String dequeueSha();&#125; 单Redis实例分片 单Redis实例分片比较简单，示意图如下： 编写队列实现代码如下（部分参数写死，仅供参考，切勿照搬到生产中）： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495@RequiredArgsConstructor@Componentpublic class RedisOrderDelayQueue implements OrderDelayQueue, InitializingBean &#123; private static final String MIN_SCORE = \"0\"; private static final String OFFSET = \"0\"; private static final String LIMIT = \"10\"; /** * 分片数量 */ private static final long SHARDING_COUNT = 2L; private static final String ORDER_QUEUE_PREFIX = \"ORDER_QUEUE_\"; private static final String ORDER_DETAIL_QUEUE_PREFIX = \"ORDER_DETAIL_QUEUE_\"; private static final String ENQUEUE_LUA_SCRIPT_LOCATION = \"/lua/enqueue.lua\"; private static final String DEQUEUE_LUA_SCRIPT_LOCATION = \"/lua/dequeue.lua\"; private static final AtomicReference&lt;String&gt; ENQUEUE_LUA_SHA = new AtomicReference&lt;&gt;(); private static final AtomicReference&lt;String&gt; DEQUEUE_LUA_SHA = new AtomicReference&lt;&gt;(); private final JedisProvider jedisProvider; @Override public void enqueue(OrderMessage message) &#123; List&lt;String&gt; args = Lists.newArrayList(); args.add(message.getOrderId()); args.add(String.valueOf(System.currentTimeMillis())); args.add(message.getOrderId()); args.add(JSON.toJSONString(message)); List&lt;String&gt; keys = Lists.newArrayList(); long index = message.getUserId() % SHARDING_COUNT; keys.add(ORDER_QUEUE_PREFIX + index); keys.add(ORDER_DETAIL_QUEUE_PREFIX + index); try (Jedis jedis = jedisProvider.provide()) &#123; jedis.evalsha(ENQUEUE_LUA_SHA.get(), keys, args); &#125; &#125; @Override public List&lt;OrderMessage&gt; dequeue(int index) &#123; // 30分钟之前 String maxScore = String.valueOf(System.currentTimeMillis() - 30 * 60 * 1000); return dequeue(MIN_SCORE, maxScore, OFFSET, LIMIT, index); &#125; @SuppressWarnings(\"unchecked\") @Override public List&lt;OrderMessage&gt; dequeue(String min, String max, String offset, String limit, int index) &#123; List&lt;String&gt; args = new ArrayList&lt;&gt;(); args.add(min); args.add(max); args.add(offset); args.add(limit); List&lt;OrderMessage&gt; result = Lists.newArrayList(); List&lt;String&gt; keys = Lists.newArrayList(); keys.add(ORDER_QUEUE_PREFIX + index); keys.add(ORDER_DETAIL_QUEUE_PREFIX + index); try (Jedis jedis = jedisProvider.provide()) &#123; List&lt;String&gt; eval = (List&lt;String&gt;) jedis.evalsha(DEQUEUE_LUA_SHA.get(), keys, args); if (null != eval) &#123; for (String e : eval) &#123; result.add(JSON.parseObject(e, OrderMessage.class)); &#125; &#125; &#125; return result; &#125; @Override public String enqueueSha() &#123; return ENQUEUE_LUA_SHA.get(); &#125; @Override public String dequeueSha() &#123; return DEQUEUE_LUA_SHA.get(); &#125; @Override public void afterPropertiesSet() throws Exception &#123; // 加载Lua脚本 loadLuaScript(); &#125; private void loadLuaScript() throws Exception &#123; try (Jedis jedis = jedisProvider.provide()) &#123; ClassPathResource resource = new ClassPathResource(ENQUEUE_LUA_SCRIPT_LOCATION); String luaContent = StreamUtils.copyToString(resource.getInputStream(), StandardCharsets.UTF_8); String sha = jedis.scriptLoad(luaContent); ENQUEUE_LUA_SHA.compareAndSet(null, sha); resource = new ClassPathResource(DEQUEUE_LUA_SCRIPT_LOCATION); luaContent = StreamUtils.copyToString(resource.getInputStream(), StandardCharsets.UTF_8); sha = jedis.scriptLoad(luaContent); DEQUEUE_LUA_SHA.compareAndSet(null, sha); &#125; &#125;&#125; 消费者定时任务的实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859DisallowConcurrentExecution@Componentpublic class OrderMessageConsumer implements Job &#123; private static final Logger LOGGER = LoggerFactory.getLogger(OrderMessageConsumer.class); private static final AtomicInteger COUNTER = new AtomicInteger(); /** * 初始化业务线程池 */ private static final ExecutorService BUSINESS_WORKER_POOL = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors(), r -&gt; &#123; Thread thread = new Thread(r); thread.setDaemon(true); thread.setName(\"OrderMessageConsumerWorker-\" + COUNTER.getAndIncrement()); return thread; &#125;); @Autowired private OrderDelayQueue orderDelayQueue; @Override public void execute(JobExecutionContext context) throws JobExecutionException &#123; // 这里为了简单起见，分片的下标暂时使用Quartz的任务执行上下文存放 int shardingIndex = context.getMergedJobDataMap().getInt(\"shardingIndex\"); LOGGER.info(\"订单消息消费者定时任务开始执行,shardingIndex:[&#123;&#125;]...\", shardingIndex); List&lt;OrderMessage&gt; dequeue = orderDelayQueue.dequeue(shardingIndex); if (null != dequeue) &#123; final CountDownLatch latch = new CountDownLatch(1); BUSINESS_WORKER_POOL.execute(new ConsumeTask(latch, dequeue, shardingIndex)); try &#123; latch.await(); &#125; catch (InterruptedException ignore) &#123; //ignore &#125; &#125; LOGGER.info(\"订单消息消费者定时任务执行完毕,shardingIndex:[&#123;&#125;]...\", shardingIndex); &#125; @RequiredArgsConstructor private static class ConsumeTask implements Runnable &#123; private final CountDownLatch latch; private final List&lt;OrderMessage&gt; messages; private final int shardingIndex; @Override public void run() &#123; try &#123; for (OrderMessage message : messages) &#123; LOGGER.info(\"shardingIndex:[&#123;&#125;],处理订单消息,内容:&#123;&#125;\", shardingIndex, JSON.toJSONString(message)); // 模拟耗时 TimeUnit.MILLISECONDS.sleep(50); &#125; &#125; catch (Exception ignore) &#123; &#125; finally &#123; latch.countDown(); &#125; &#125; &#125;&#125; 启动定时任务和写入测试数据的CommandLineRunner实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@Componentpublic class QuartzJobStartCommandLineRunner implements CommandLineRunner &#123; @Autowired private Scheduler scheduler; @Autowired private JedisProvider jedisProvider; @Override public void run(String... args) throws Exception &#123; int shardingCount = 2; // 准备测试数据 prepareOrderMessageData(shardingCount); for (ConsumerTask task : prepareConsumerTasks(shardingCount)) &#123; scheduler.scheduleJob(task.getJobDetail(), task.getTrigger()); &#125; &#125; private void prepareOrderMessageData(int shardingCount) throws Exception &#123; DateTimeFormatter f = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss.SSS\"); try (Jedis jedis = jedisProvider.provide()) &#123; List&lt;OrderMessage&gt; messages = Lists.newArrayList(); for (int i = 0; i &lt; 100; i++) &#123; OrderMessage message = new OrderMessage(); message.setAmount(BigDecimal.valueOf(i)); message.setOrderId(\"ORDER_ID_\" + i); message.setUserId((long) i); message.setTimestamp(LocalDateTime.now().format(f)); messages.add(message); &#125; for (OrderMessage message : messages) &#123; // 30分钟前 Double score = Double.valueOf(String.valueOf(System.currentTimeMillis() - 30 * 60 * 1000)); long index = message.getUserId() % shardingCount; jedis.hset(\"ORDER_DETAIL_QUEUE_\" + index, message.getOrderId(), JSON.toJSONString(message)); jedis.zadd(\"ORDER_QUEUE_\" + index, score, message.getOrderId()); &#125; &#125; &#125; private List&lt;ConsumerTask&gt; prepareConsumerTasks(int shardingCount) &#123; List&lt;ConsumerTask&gt; tasks = Lists.newArrayList(); for (int i = 0; i &lt; shardingCount; i++) &#123; JobDetail jobDetail = JobBuilder.newJob(OrderMessageConsumer.class) .withIdentity(\"OrderMessageConsumer-\" + i, \"DelayTask\") .usingJobData(\"shardingIndex\", i) .build(); Trigger trigger = TriggerBuilder.newTrigger() .withIdentity(\"OrderMessageConsumerTrigger-\" + i, \"DelayTask\") .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(10).repeatForever()) .build(); tasks.add(new ConsumerTask(jobDetail, trigger)); &#125; return tasks; &#125; @Getter @RequiredArgsConstructor private static class ConsumerTask &#123; private final JobDetail jobDetail; private final Trigger trigger; &#125;&#125; 启动应用，输出如下： 12345678910112019-08-28 00:13:20.648 INFO 50248 --- [ main] c.t.s.s.NoneJdbcSpringApplication : Started NoneJdbcSpringApplication in 1.35 seconds (JVM running for 5.109)2019-08-28 00:13:20.780 INFO 50248 --- [ryBean_Worker-1] c.t.s.sharding.OrderMessageConsumer : 订单消息消费者定时任务开始执行,shardingIndex:[0]...2019-08-28 00:13:20.781 INFO 50248 --- [ryBean_Worker-2] c.t.s.sharding.OrderMessageConsumer : 订单消息消费者定时任务开始执行,shardingIndex:[1]...2019-08-28 00:13:20.788 INFO 50248 --- [onsumerWorker-1] c.t.s.sharding.OrderMessageConsumer : shardingIndex:[1],处理订单消息,内容:&#123;\"amount\":99,\"orderId\":\"ORDER_ID_99\",\"timestamp\":\"2019-08-28 00:13:20.657\",\"userId\":99&#125;2019-08-28 00:13:20.788 INFO 50248 --- [onsumerWorker-0] c.t.s.sharding.OrderMessageConsumer : shardingIndex:[0],处理订单消息,内容:&#123;\"amount\":98,\"orderId\":\"ORDER_ID_98\",\"timestamp\":\"2019-08-28 00:13:20.657\",\"userId\":98&#125;2019-08-28 00:13:20.840 INFO 50248 --- [onsumerWorker-1] c.t.s.sharding.OrderMessageConsumer : shardingIndex:[1],处理订单消息,内容:&#123;\"amount\":97,\"orderId\":\"ORDER_ID_97\",\"timestamp\":\"2019-08-28 00:13:20.657\",\"userId\":97&#125;2019-08-28 00:13:20.840 INFO 50248 --- [onsumerWorker-0] c.t.s.sharding.OrderMessageConsumer : shardingIndex:[0],处理订单消息,内容:&#123;\"amount\":96,\"orderId\":\"ORDER_ID_96\",\"timestamp\":\"2019-08-28 00:13:20.657\",\"userId\":96&#125;// ... 省略大量输出2019-08-28 00:13:21.298 INFO 50248 --- [ryBean_Worker-1] c.t.s.sharding.OrderMessageConsumer : 订单消息消费者定时任务执行完毕,shardingIndex:[0]...2019-08-28 00:13:21.298 INFO 50248 --- [ryBean_Worker-2] c.t.s.sharding.OrderMessageConsumer : 订单消息消费者定时任务执行完毕,shardingIndex:[1]...// ... 省略大量输出 多Redis实例分片 单Redis实例分片其实存在一个问题，就是Redis实例总是单线程处理客户端的命令，即使客户端是多个线程执行Redis命令，示意图如下： 这种情况下，虽然通过分片降低了Lua脚本命令的复杂度，但是Redis的命令处理模型（单线程）也有可能成为另一个性能瓶颈隐患。因此，可以考虑基于多Redis实例进行分片。 这里为了简单起见，用两个单点的Redis实例做编码示例。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296// Jedis提供者@Componentpublic class JedisProvider implements InitializingBean &#123; private final Map&lt;Long, JedisPool&gt; pools = Maps.newConcurrentMap(); private JedisPool defaultPool; @Override public void afterPropertiesSet() throws Exception &#123; JedisPool pool = new JedisPool(\"localhost\"); defaultPool = pool; pools.put(0L, pool); // 这个是虚拟机上的redis实例 pool = new JedisPool(\"192.168.56.200\"); pools.put(1L, pool); &#125; public Jedis provide(Long index) &#123; return pools.getOrDefault(index, defaultPool).getResource(); &#125;&#125;// 订单消息@Datapublic class OrderMessage &#123; private String orderId; private BigDecimal amount; private Long userId;&#125;// 订单延时队列接口public interface OrderDelayQueue &#123; void enqueue(OrderMessage message); List&lt;OrderMessage&gt; dequeue(String min, String max, String offset, String limit, long index); List&lt;OrderMessage&gt; dequeue(long index); String enqueueSha(long index); String dequeueSha(long index);&#125;// 延时队列实现@RequiredArgsConstructor@Componentpublic class RedisOrderDelayQueue implements OrderDelayQueue, InitializingBean &#123; private static final String MIN_SCORE = \"0\"; private static final String OFFSET = \"0\"; private static final String LIMIT = \"10\"; private static final long SHARDING_COUNT = 2L; private static final String ORDER_QUEUE = \"ORDER_QUEUE\"; private static final String ORDER_DETAIL_QUEUE = \"ORDER_DETAIL_QUEUE\"; private static final String ENQUEUE_LUA_SCRIPT_LOCATION = \"/lua/enqueue.lua\"; private static final String DEQUEUE_LUA_SCRIPT_LOCATION = \"/lua/dequeue.lua\"; private static final ConcurrentMap&lt;Long, String&gt; ENQUEUE_LUA_SHA = Maps.newConcurrentMap(); private static final ConcurrentMap&lt;Long, String&gt; DEQUEUE_LUA_SHA = Maps.newConcurrentMap(); private final JedisProvider jedisProvider; @Override public void enqueue(OrderMessage message) &#123; List&lt;String&gt; args = Lists.newArrayList(); args.add(message.getOrderId()); args.add(String.valueOf(System.currentTimeMillis() - 30 * 60 * 1000)); args.add(message.getOrderId()); args.add(JSON.toJSONString(message)); List&lt;String&gt; keys = Lists.newArrayList(); long index = message.getUserId() % SHARDING_COUNT; keys.add(ORDER_QUEUE); keys.add(ORDER_DETAIL_QUEUE); try (Jedis jedis = jedisProvider.provide(index)) &#123; jedis.evalsha(ENQUEUE_LUA_SHA.get(index), keys, args); &#125; &#125; @Override public List&lt;OrderMessage&gt; dequeue(long index) &#123; // 30分钟之前 String maxScore = String.valueOf(System.currentTimeMillis() - 30 * 60 * 1000); return dequeue(MIN_SCORE, maxScore, OFFSET, LIMIT, index); &#125; @SuppressWarnings(\"unchecked\") @Override public List&lt;OrderMessage&gt; dequeue(String min, String max, String offset, String limit, long index) &#123; List&lt;String&gt; args = new ArrayList&lt;&gt;(); args.add(min); args.add(max); args.add(offset); args.add(limit); List&lt;OrderMessage&gt; result = Lists.newArrayList(); List&lt;String&gt; keys = Lists.newArrayList(); keys.add(ORDER_QUEUE); keys.add(ORDER_DETAIL_QUEUE); try (Jedis jedis = jedisProvider.provide(index)) &#123; List&lt;String&gt; eval = (List&lt;String&gt;) jedis.evalsha(DEQUEUE_LUA_SHA.get(index), keys, args); if (null != eval) &#123; for (String e : eval) &#123; result.add(JSON.parseObject(e, OrderMessage.class)); &#125; &#125; &#125; return result; &#125; @Override public String enqueueSha(long index) &#123; return ENQUEUE_LUA_SHA.get(index); &#125; @Override public String dequeueSha(long index) &#123; return DEQUEUE_LUA_SHA.get(index); &#125; @Override public void afterPropertiesSet() throws Exception &#123; // 加载Lua脚本 loadLuaScript(); &#125; private void loadLuaScript() throws Exception &#123; for (long i = 0; i &lt; SHARDING_COUNT; i++) &#123; try (Jedis jedis = jedisProvider.provide(i)) &#123; ClassPathResource resource = new ClassPathResource(ENQUEUE_LUA_SCRIPT_LOCATION); String luaContent = StreamUtils.copyToString(resource.getInputStream(), StandardCharsets.UTF_8); String sha = jedis.scriptLoad(luaContent); ENQUEUE_LUA_SHA.put(i, sha); resource = new ClassPathResource(DEQUEUE_LUA_SCRIPT_LOCATION); luaContent = StreamUtils.copyToString(resource.getInputStream(), StandardCharsets.UTF_8); sha = jedis.scriptLoad(luaContent); DEQUEUE_LUA_SHA.put(i, sha); &#125; &#125; &#125;&#125;// 消费者public class OrderMessageConsumer implements Job &#123; private static final Logger LOGGER = LoggerFactory.getLogger(OrderMessageConsumer.class); private static final AtomicInteger COUNTER = new AtomicInteger(); // 初始化业务线程池 private final ExecutorService businessWorkerPool = Executors.newSingleThreadExecutor(r -&gt; &#123; Thread thread = new Thread(r); thread.setDaemon(true); thread.setName(\"OrderMessageConsumerWorker-\" + COUNTER.getAndIncrement()); return thread; &#125;); @Autowired private OrderDelayQueue orderDelayQueue; @Override public void execute(JobExecutionContext context) throws JobExecutionException &#123; long shardingIndex = context.getMergedJobDataMap().getLong(\"shardingIndex\"); LOGGER.info(\"订单消息消费者定时任务开始执行,shardingIndex:[&#123;&#125;]...\", shardingIndex); List&lt;OrderMessage&gt; dequeue = orderDelayQueue.dequeue(shardingIndex); if (null != dequeue) &#123; // 这里的倒数栅栏，在线程池资源充足的前提下可以去掉 final CountDownLatch latch = new CountDownLatch(1); businessWorkerPool.execute(new ConsumeTask(latch, dequeue, shardingIndex)); try &#123; latch.await(); &#125; catch (InterruptedException ignore) &#123; //ignore &#125; &#125; LOGGER.info(\"订单消息消费者定时任务执行完毕,shardingIndex:[&#123;&#125;]...\", shardingIndex); &#125; @RequiredArgsConstructor private static class ConsumeTask implements Runnable &#123; private final CountDownLatch latch; private final List&lt;OrderMessage&gt; messages; private final long shardingIndex; @Override public void run() &#123; try &#123; for (OrderMessage message : messages) &#123; LOGGER.info(\"shardingIndex:[&#123;&#125;],处理订单消息,内容:&#123;&#125;\", shardingIndex, JSON.toJSONString(message)); // 模拟处理耗时50毫秒 TimeUnit.MILLISECONDS.sleep(50); &#125; &#125; catch (Exception ignore) &#123; &#125; finally &#123; latch.countDown(); &#125; &#125; &#125;&#125;// 配置@Configurationpublic class QuartzConfiguration &#123; @Bean public AutowiredSupportQuartzJobFactory autowiredSupportQuartzJobFactory() &#123; return new AutowiredSupportQuartzJobFactory(); &#125; @Bean public SchedulerFactoryBean schedulerFactoryBean(AutowiredSupportQuartzJobFactory autowiredSupportQuartzJobFactory) &#123; SchedulerFactoryBean factory = new SchedulerFactoryBean(); factory.setSchedulerName(\"RamScheduler\"); factory.setAutoStartup(true); factory.setJobFactory(autowiredSupportQuartzJobFactory); return factory; &#125; public static class AutowiredSupportQuartzJobFactory extends AdaptableJobFactory implements BeanFactoryAware &#123; private AutowireCapableBeanFactory autowireCapableBeanFactory; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.autowireCapableBeanFactory = (AutowireCapableBeanFactory) beanFactory; &#125; @Override protected Object createJobInstance(@Nonnull TriggerFiredBundle bundle) throws Exception &#123; Object jobInstance = super.createJobInstance(bundle); autowireCapableBeanFactory.autowireBean(jobInstance); return jobInstance; &#125; &#125;&#125;// CommandLineRunner@Componentpublic class QuartzJobStartCommandLineRunner implements CommandLineRunner &#123; @Autowired private Scheduler scheduler; @Autowired private JedisProvider jedisProvider; @Override public void run(String... args) throws Exception &#123; long shardingCount = 2; prepareData(shardingCount); for (ConsumerTask task : prepareConsumerTasks(shardingCount)) &#123; scheduler.scheduleJob(task.getJobDetail(), task.getTrigger()); &#125; &#125; private void prepareData(long shardingCount) &#123; for (long i = 0L; i &lt; shardingCount; i++) &#123; Map&lt;String, Double&gt; z = Maps.newHashMap(); Map&lt;String, String&gt; h = Maps.newHashMap(); for (int k = 0; k &lt; 100; k++) &#123; OrderMessage message = new OrderMessage(); message.setAmount(BigDecimal.valueOf(k)); message.setUserId((long) k); message.setOrderId(\"ORDER_ID_\" + k); // 30 min ago z.put(message.getOrderId(), Double.valueOf(String.valueOf(System.currentTimeMillis() - 30 * 60 * 1000))); h.put(message.getOrderId(), JSON.toJSONString(message)); &#125; Jedis jedis = jedisProvider.provide(i); jedis.hmset(\"ORDER_DETAIL_QUEUE\", h); jedis.zadd(\"ORDER_QUEUE\", z); &#125; &#125; private List&lt;ConsumerTask&gt; prepareConsumerTasks(long shardingCount) &#123; List&lt;ConsumerTask&gt; tasks = Lists.newArrayList(); for (long i = 0; i &lt; shardingCount; i++) &#123; JobDetail jobDetail = JobBuilder.newJob(OrderMessageConsumer.class) .withIdentity(\"OrderMessageConsumer-\" + i, \"DelayTask\") .usingJobData(\"shardingIndex\", i) .build(); Trigger trigger = TriggerBuilder.newTrigger() .withIdentity(\"OrderMessageConsumerTrigger-\" + i, \"DelayTask\") .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(10).repeatForever()) .build(); tasks.add(new ConsumerTask(jobDetail, trigger)); &#125; return tasks; &#125; @Getter @RequiredArgsConstructor private static class ConsumerTask &#123; private final JobDetail jobDetail; private final Trigger trigger; &#125;&#125; 新增一个启动函数并且启动，控制台输出如下： 123456789101112// ...省略大量输出2019-09-01 14:08:27.664 INFO 13056 --- [ main] c.t.multi.NoneJdbcSpringApplication : Started NoneJdbcSpringApplication in 1.333 seconds (JVM running for 5.352)2019-09-01 14:08:27.724 INFO 13056 --- [eduler_Worker-2] c.throwable.multi.OrderMessageConsumer : 订单消息消费者定时任务开始执行,shardingIndex:[1]...2019-09-01 14:08:27.724 INFO 13056 --- [eduler_Worker-1] c.throwable.multi.OrderMessageConsumer : 订单消息消费者定时任务开始执行,shardingIndex:[0]...2019-09-01 14:08:27.732 INFO 13056 --- [onsumerWorker-1] c.throwable.multi.OrderMessageConsumer : shardingIndex:[1],处理订单消息,内容:&#123;\"amount\":99,\"orderId\":\"ORDER_ID_99\",\"userId\":99&#125;2019-09-01 14:08:27.732 INFO 13056 --- [onsumerWorker-0] c.throwable.multi.OrderMessageConsumer : shardingIndex:[0],处理订单消息,内容:&#123;\"amount\":99,\"orderId\":\"ORDER_ID_99\",\"userId\":99&#125;2019-09-01 14:08:27.782 INFO 13056 --- [onsumerWorker-0] c.throwable.multi.OrderMessageConsumer : shardingIndex:[0],处理订单消息,内容:&#123;\"amount\":98,\"orderId\":\"ORDER_ID_98\",\"userId\":98&#125;2019-09-01 14:08:27.782 INFO 13056 --- [onsumerWorker-1] c.throwable.multi.OrderMessageConsumer : shardingIndex:[1],处理订单消息,内容:&#123;\"amount\":98,\"orderId\":\"ORDER_ID_98\",\"userId\":98&#125;// ...省略大量输出2019-09-01 14:08:28.239 INFO 13056 --- [eduler_Worker-2] c.throwable.multi.OrderMessageConsumer : 订单消息消费者定时任务执行完毕,shardingIndex:[1]...2019-09-01 14:08:28.240 INFO 13056 --- [eduler_Worker-1] c.throwable.multi.OrderMessageConsumer : 订单消息消费者定时任务执行完毕,shardingIndex:[0]...// ...省略大量输出 生产中应该避免Redis服务单点，一般常用哨兵配合树状主从的部署方式（参考《Redis开发与运维》），2套Redis哨兵的部署示意图如下： 需要什么监控项 我们需要相对实时地知道Redis中的延时队列集合有多少积压数据，每次出队的耗时大概是多少等等监控项参数，这样我们才能更好地知道延时队列模块是否正常运行、是否存在性能瓶颈等等。具体的监控项，需要按需定制，这里为了方便举例，只做两个监控项的监控： 有序集合Sorted Set中积压的元素数量。 每次调用dequeue.lua的耗时。 采用的是应用实时上报数据的方式，依赖于spring-boot-starter-actuator、Prometheus、Grafana搭建的监控体系，如果并不熟悉这个体系可以看两篇前置文章： JVM应用度量框架Micrometer实战 通过micrometer实时监控线程池的各项指标 监控 引入依赖： 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt;&lt;/dependency&gt; 这里选用Gauge的Meter进行监控数据收集，添加监控类OrderDelayQueueMonitor：。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// OrderDelayQueueMonitor@Componentpublic class OrderDelayQueueMonitor implements InitializingBean &#123; private static final long SHARDING_COUNT = 2L; private final ConcurrentMap&lt;Long, AtomicLong&gt; remain = Maps.newConcurrentMap(); private final ConcurrentMap&lt;Long, AtomicLong&gt; lua = Maps.newConcurrentMap(); private ScheduledExecutorService executor; @Autowired private JedisProvider jedisProvider; @Override public void afterPropertiesSet() throws Exception &#123; executor = Executors.newSingleThreadScheduledExecutor(r -&gt; &#123; Thread thread = new Thread(r, \"OrderDelayQueueMonitor\"); thread.setDaemon(true); return thread; &#125;); for (long i = 0L; i &lt; SHARDING_COUNT; i++) &#123; AtomicLong l = new AtomicLong(); Metrics.gauge(\"order.delay.queue.lua.cost\", Collections.singleton(Tag.of(\"index\", String.valueOf(i))), l, AtomicLong::get); lua.put(i, l); AtomicLong r = new AtomicLong(); Metrics.gauge(\"order.delay.queue.remain\", Collections.singleton(Tag.of(\"index\", String.valueOf(i))), r, AtomicLong::get); remain.put(i, r); &#125; // 每五秒上报一次集合中的剩余数据 executor.scheduleWithFixedDelay(new MonitorTask(jedisProvider), 0, 5, TimeUnit.SECONDS); &#125; public void recordRemain(Long index, long count) &#123; remain.get(index).set(count); &#125; public void recordLuaCost(Long index, long count) &#123; lua.get(index).set(count); &#125; @RequiredArgsConstructor private class MonitorTask implements Runnable &#123; private final JedisProvider jedisProvider; @Override public void run() &#123; for (long i = 0L; i &lt; SHARDING_COUNT; i++) &#123; try (Jedis jedis = jedisProvider.provide(i)) &#123; recordRemain(i, jedis.zcount(\"ORDER_QUEUE\", \"-inf\", \"+inf\")); &#125; &#125; &#125; &#125;&#125; 原来的RedisOrderDelayQueue#dequeue()进行改造： 1234567891011121314151617181920212223242526272829303132333435363738@RequiredArgsConstructor@Componentpublic class RedisOrderDelayQueue implements OrderDelayQueue, InitializingBean &#123; // ... 省略没有改动的代码 private final OrderDelayQueueMonitor orderDelayQueueMonitor; // ... 省略没有改动的代码 @Override public List&lt;OrderMessage&gt; dequeue(String min, String max, String offset, String limit, long index) &#123; List&lt;String&gt; args = new ArrayList&lt;&gt;(); args.add(min); args.add(max); args.add(offset); args.add(limit); List&lt;OrderMessage&gt; result = Lists.newArrayList(); List&lt;String&gt; keys = Lists.newArrayList(); keys.add(ORDER_QUEUE); keys.add(ORDER_DETAIL_QUEUE); try (Jedis jedis = jedisProvider.provide(index)) &#123; long start = System.nanoTime(); List&lt;String&gt; eval = (List&lt;String&gt;) jedis.evalsha(DEQUEUE_LUA_SHA.get(index), keys, args); long end = System.nanoTime(); // 添加dequeue的耗时监控-单位微秒 orderDelayQueueMonitor.recordLuaCost(index, TimeUnit.NANOSECONDS.toMicros(end - start)); if (null != eval) &#123; for (String e : eval) &#123; result.add(JSON.parseObject(e, OrderMessage.class)); &#125; &#125; &#125; return result; &#125; // ... 省略没有改动的代码&#125; 其他配置这里简单说一下。 application.yaml要开放prometheus端点的访问权限： 1234567server: port: 9091management: endpoints: web: exposure: include: 'prometheus' Prometheus服务配置尽量减少查询的间隔时间，暂定为5秒： 12345678910111213141516171819202122232425262728# my global configglobal: scrape_interval: 5s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s).# Alertmanager configurationalerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.rule_files: # - \"first_rules.yml\" # - \"second_rules.yml\"# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: 'prometheus' metrics_path: '/actuator/prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['localhost:9091'] Grafana的基本配置项如下： 12出队耗时 order_delay_queue_lua_cost 分片编号-&#123;&#123;index&#125;&#125;订单延时队列积压量 order_delay_queue_remain 分片编号-&#123;&#123;index&#125;&#125; 最终可以在Grafana配置每5秒刷新，见效果如下： 这里的监控项更多时候应该按需定制，说实话，监控的工作往往是最复杂和繁琐的。 小结 全文相对详细地介绍了基于Redis实现延时任务的分片和监控的具体实施过程，核心代码仅供参考，还有一些具体的细节例如Prometheus、Grafana的一些应用，这里限于篇幅不会详细地展开。说实话，基于实际场景做一次中间件和架构的选型并不是一件简单的事，而且往往初期的实施并不是最大的难点，更大的难题在后面的优化以及监控。 附件 Markdown原件：https://github.com/zjcscut/blog-article-file/tree/master/20190901/redis-delay-task-second （本文完 c-3-d 20190901 身体不适，拖了一下）","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Redis","slug":"Middleware/Redis","permalink":"http://throwable.club/blog/categories/Middleware/Redis/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Redis","slug":"Redis","permalink":"http://throwable.club/blog/tags/Redis/"}]},{"title":"使用Redis实现延时任务(一)","slug":"redis-delay-task-first","date":"2019-08-21T15:32:30.000Z","updated":"2019-11-28T17:00:48.265Z","comments":true,"path":"2019/08/21/redis-delay-task-first/","link":"","permalink":"http://throwable.club/2019/08/21/redis-delay-task-first/","excerpt":"前提 最近在生产环境刚好遇到了延时任务的场景，调研了一下目前主流的方案，分析了一下优劣并且敲定了最终的方案。这篇文章记录了调研的过程，以及初步方案的实现。","text":"前提 最近在生产环境刚好遇到了延时任务的场景，调研了一下目前主流的方案，分析了一下优劣并且敲定了最终的方案。这篇文章记录了调研的过程，以及初步方案的实现。 候选方案对比 下面是想到的几种实现延时任务的方案，总结了一下相应的优势和劣势。 方案 优势 劣势 选用场景 JDK内置的延迟队列DelayQueue 实现简单 数据内存态，不可靠 一致性相对低的场景 调度框架和MySQL进行短间隔轮询 实现简单，可靠性高 存在明显的性能瓶颈 数据量较少实时性相对低的场景 RabbitMQ的DLX和TTL，一般称为死信队列方案 异步交互可以削峰 延时的时间长度不可控，如果数据需要持久化则性能会降低 - 调度框架和Redis进行短间隔轮询 数据持久化，高性能 实现难度大 常见于支付结果回调方案 时间轮 实时性高 实现难度大，内存消耗大 实时性高的场景 如果应用的数据量不高，实时性要求比较低，选用调度框架和MySQL进行短间隔轮询这个方案是最优的方案。但是笔者遇到的场景数据量相对比较大，实时性并不高，采用扫库的方案一定会对MySQL实例造成比较大的压力。记得很早之前，看过一个PPT叫《盒子科技聚合支付系统演进》，其中里面有一张图片给予笔者一点启发： 里面刚好用到了调度框架和Redis进行短间隔轮询实现延时任务的方案，不过为了分摊应用的压力，图中的方案还做了分片处理。鉴于笔者当前业务紧迫，所以在第一期的方案暂时不考虑分片，只做了一个简化版的实现。 由于PPT中没有任何的代码或者框架贴出，有些需要解决的技术点需要自行思考，下面会重现一次整个方案实现的详细过程。 场景设计 实际的生产场景是笔者负责的某个系统需要对接一个外部的资金方，每一笔资金下单后需要延时30分钟推送对应的附件。这里简化为一个订单信息数据延迟处理的场景，就是每一笔下单记录一条订单消息(暂时叫做OrderMessage)，订单消息需要延迟5到15秒后进行异步处理。 否决的候选方案实现思路 下面介绍一下其它四个不选用的候选方案，结合一些伪代码和流程分析一下实现过程。 JDK内置延迟队列 DelayQueue是一个阻塞队列的实现，它的队列元素必须是Delayed的子类，这里做个简单的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109public class DelayQueueMain &#123; private static final Logger LOGGER = LoggerFactory.getLogger(DelayQueueMain.class); public static void main(String[] args) throws Exception &#123; DelayQueue&lt;OrderMessage&gt; queue = new DelayQueue&lt;&gt;(); // 默认延迟5秒 OrderMessage message = new OrderMessage(\"ORDER_ID_10086\"); queue.add(message); // 延迟6秒 message = new OrderMessage(\"ORDER_ID_10087\", 6); queue.add(message); // 延迟10秒 message = new OrderMessage(\"ORDER_ID_10088\", 10); queue.add(message); ExecutorService executorService = Executors.newSingleThreadExecutor(r -&gt; &#123; Thread thread = new Thread(r); thread.setName(\"DelayWorker\"); thread.setDaemon(true); return thread; &#125;); LOGGER.info(\"开始执行调度线程...\"); executorService.execute(() -&gt; &#123; while (true) &#123; try &#123; OrderMessage task = queue.take(); LOGGER.info(\"延迟处理订单消息,&#123;&#125;\", task.getDescription()); &#125; catch (Exception e) &#123; LOGGER.error(e.getMessage(), e); &#125; &#125; &#125;); Thread.sleep(Integer.MAX_VALUE); &#125; private static class OrderMessage implements Delayed &#123; private static final DateTimeFormatter F = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"); /** * 默认延迟5000毫秒 */ private static final long DELAY_MS = 1000L * 5; /** * 订单ID */ private final String orderId; /** * 创建时间戳 */ private final long timestamp; /** * 过期时间 */ private final long expire; /** * 描述 */ private final String description; public OrderMessage(String orderId, long expireSeconds) &#123; this.orderId = orderId; this.timestamp = System.currentTimeMillis(); this.expire = this.timestamp + expireSeconds * 1000L; this.description = String.format(\"订单[%s]-创建时间为:%s,超时时间为:%s\", orderId, LocalDateTime.ofInstant(Instant.ofEpochMilli(timestamp), ZoneId.systemDefault()).format(F), LocalDateTime.ofInstant(Instant.ofEpochMilli(expire), ZoneId.systemDefault()).format(F)); &#125; public OrderMessage(String orderId) &#123; this.orderId = orderId; this.timestamp = System.currentTimeMillis(); this.expire = this.timestamp + DELAY_MS; this.description = String.format(\"订单[%s]-创建时间为:%s,超时时间为:%s\", orderId, LocalDateTime.ofInstant(Instant.ofEpochMilli(timestamp), ZoneId.systemDefault()).format(F), LocalDateTime.ofInstant(Instant.ofEpochMilli(expire), ZoneId.systemDefault()).format(F)); &#125; public String getOrderId() &#123; return orderId; &#125; public long getTimestamp() &#123; return timestamp; &#125; public long getExpire() &#123; return expire; &#125; public String getDescription() &#123; return description; &#125; @Override public long getDelay(TimeUnit unit) &#123; return unit.convert(this.expire - System.currentTimeMillis(), TimeUnit.MILLISECONDS); &#125; @Override public int compareTo(Delayed o) &#123; return (int) (this.getDelay(TimeUnit.MILLISECONDS) - o.getDelay(TimeUnit.MILLISECONDS)); &#125; &#125;&#125; 注意一下，OrderMessage实现Delayed接口，关键是需要实现Delayed#getDelay()和Delayed#compareTo()。运行一下main()方法： 123410:16:08.240 [main] INFO club.throwable.delay.DelayQueueMain - 开始执行调度线程...10:16:13.224 [DelayWorker] INFO club.throwable.delay.DelayQueueMain - 延迟处理订单消息,订单[ORDER_ID_10086]-创建时间为:2019-08-20 10:16:08,超时时间为:2019-08-20 10:16:1310:16:14.237 [DelayWorker] INFO club.throwable.delay.DelayQueueMain - 延迟处理订单消息,订单[ORDER_ID_10087]-创建时间为:2019-08-20 10:16:08,超时时间为:2019-08-20 10:16:1410:16:18.237 [DelayWorker] INFO club.throwable.delay.DelayQueueMain - 延迟处理订单消息,订单[ORDER_ID_10088]-创建时间为:2019-08-20 10:16:08,超时时间为:2019-08-20 10:16:18 调度框架 + MySQL 使用调度框架对MySQL表进行短间隔轮询是实现难度比较低的方案，通常服务刚上线，表数据不多并且实时性不高的情况下应该首选这个方案。不过要注意以下几点： 注意轮询间隔不能太短，否则会对MySQL实例产生影响。 注意每次查询的数量，结果集数量太多有可能会导致调度阻塞和占用应用大量内存，从而影响时效性。 注意要设计状态值和最大重试次数，这样才能尽量避免大量数据积压和重复查询的问题。 最好通过时间列做索引，查询指定时间范围内的数据。 引入Quartz、MySQL的Java驱动包和spring-boot-starter-jdbc（这里只是为了方便用相对轻量级的框架实现，生产中可以按场景按需选择其他更合理的框架）： 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.48&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;version&gt;2.1.7.RELEASE&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.3.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 假设表设计如下： 123456789101112131415161718CREATE DATABASE `delayTask` CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_520_ci;USE `delayTask`;CREATE TABLE `t_order_message`( id BIGINT UNSIGNED PRIMARY KEY AUTO_INCREMENT, order_id VARCHAR(50) NOT NULL COMMENT '订单ID', create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建日期时间', edit_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改日期时间', retry_times TINYINT NOT NULL DEFAULT 0 COMMENT '重试次数', order_status TINYINT NOT NULL DEFAULT 0 COMMENT '订单状态', INDEX idx_order_id (order_id), INDEX idx_create_time (create_time)) COMMENT '订单信息表';# 写入两条测试数据INSERT INTO t_order_message(order_id) VALUES ('10086'),('10087'); 编写代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149// 常量public class OrderConstants &#123; public static final int MAX_RETRY_TIMES = 5; public static final int PENDING = 0; public static final int SUCCESS = 1; public static final int FAIL = -1; public static final int LIMIT = 10;&#125;// 实体@Builder@Datapublic class OrderMessage &#123; private Long id; private String orderId; private LocalDateTime createTime; private LocalDateTime editTime; private Integer retryTimes; private Integer orderStatus;&#125;// DAO@RequiredArgsConstructorpublic class OrderMessageDao &#123; private final JdbcTemplate jdbcTemplate; private static final ResultSetExtractor&lt;List&lt;OrderMessage&gt;&gt; M = r -&gt; &#123; List&lt;OrderMessage&gt; list = Lists.newArrayList(); while (r.next()) &#123; list.add(OrderMessage.builder() .id(r.getLong(\"id\")) .orderId(r.getString(\"order_id\")) .createTime(r.getTimestamp(\"create_time\").toLocalDateTime()) .editTime(r.getTimestamp(\"edit_time\").toLocalDateTime()) .retryTimes(r.getInt(\"retry_times\")) .orderStatus(r.getInt(\"order_status\")) .build()); &#125; return list; &#125;; public List&lt;OrderMessage&gt; selectPendingRecords(LocalDateTime start, LocalDateTime end, List&lt;Integer&gt; statusList, int maxRetryTimes, int limit) &#123; StringJoiner joiner = new StringJoiner(\",\"); statusList.forEach(s -&gt; joiner.add(String.valueOf(s))); return jdbcTemplate.query(\"SELECT * FROM t_order_message WHERE create_time &gt;= ? AND create_time &lt;= ? \" + \"AND order_status IN (?) AND retry_times &lt; ? LIMIT ?\", p -&gt; &#123; p.setTimestamp(1, Timestamp.valueOf(start)); p.setTimestamp(2, Timestamp.valueOf(end)); p.setString(3, joiner.toString()); p.setInt(4, maxRetryTimes); p.setInt(5, limit); &#125;, M); &#125; public int updateOrderStatus(Long id, int status) &#123; return jdbcTemplate.update(\"UPDATE t_order_message SET order_status = ?,edit_time = ? WHERE id =?\", p -&gt; &#123; p.setInt(1, status); p.setTimestamp(2, Timestamp.valueOf(LocalDateTime.now())); p.setLong(3, id); &#125;); &#125;&#125;// Service@RequiredArgsConstructorpublic class OrderMessageService &#123; private static final Logger LOGGER = LoggerFactory.getLogger(OrderMessageService.class); private final OrderMessageDao orderMessageDao; private static final List&lt;Integer&gt; STATUS = Lists.newArrayList(); static &#123; STATUS.add(OrderConstants.PENDING); STATUS.add(OrderConstants.FAIL); &#125; public void executeDelayJob() &#123; LOGGER.info(\"订单处理定时任务开始执行......\"); LocalDateTime end = LocalDateTime.now(); // 一天前 LocalDateTime start = end.minusDays(1); List&lt;OrderMessage&gt; list = orderMessageDao.selectPendingRecords(start, end, STATUS, OrderConstants.MAX_RETRY_TIMES, OrderConstants.LIMIT); if (!list.isEmpty()) &#123; for (OrderMessage m : list) &#123; LOGGER.info(\"处理订单[&#123;&#125;],状态由&#123;&#125;更新为&#123;&#125;\", m.getOrderId(), m.getOrderStatus(), OrderConstants.SUCCESS); // 这里其实可以优化为批量更新 orderMessageDao.updateOrderStatus(m.getId(), OrderConstants.SUCCESS); &#125; &#125; LOGGER.info(\"订单处理定时任务开始完毕......\"); &#125;&#125;// Job@DisallowConcurrentExecutionpublic class OrderMessageDelayJob implements Job &#123; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; OrderMessageService service = (OrderMessageService) jobExecutionContext.getMergedJobDataMap().get(\"orderMessageService\"); service.executeDelayJob(); &#125; public static void main(String[] args) throws Exception &#123; HikariConfig config = new HikariConfig(); config.setJdbcUrl(\"jdbc:mysql://localhost:3306/delayTask?useSSL=false&amp;characterEncoding=utf8\"); config.setDriverClassName(Driver.class.getName()); config.setUsername(\"root\"); config.setPassword(\"root\"); HikariDataSource dataSource = new HikariDataSource(config); OrderMessageDao orderMessageDao = new OrderMessageDao(new JdbcTemplate(dataSource)); OrderMessageService service = new OrderMessageService(orderMessageDao); // 内存模式的调度器 StdSchedulerFactory factory = new StdSchedulerFactory(); Scheduler scheduler = factory.getScheduler(); // 这里没有用到IOC容器,直接用Quartz数据集合传递服务引用 JobDataMap jobDataMap = new JobDataMap(); jobDataMap.put(\"orderMessageService\", service); // 新建Job JobDetail job = JobBuilder.newJob(OrderMessageDelayJob.class) .withIdentity(\"orderMessageDelayJob\", \"delayJob\") .usingJobData(jobDataMap) .build(); // 新建触发器,10秒执行一次 Trigger trigger = TriggerBuilder.newTrigger() .withIdentity(\"orderMessageDelayTrigger\", \"delayJob\") .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(10).repeatForever()) .build(); scheduler.scheduleJob(job, trigger); // 启动调度器 scheduler.start(); Thread.sleep(Integer.MAX_VALUE); &#125;&#125; 这个例子里面用了create_time做轮询，实际上可以添加一个调度时间schedule_time列做轮询，这样子才能更容易定制空闲时和忙碌时候的调度策略。上面的示例的运行效果如下： 12345678910111213141516171819202122232425262728293031323334353637383911:58:27.202 [main] INFO org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED' Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally. NOT STARTED. Currently in standby mode. Number of jobs executed: 0 Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads. Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.11:58:27.202 [main] INFO org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'11:58:27.202 [main] INFO org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.111:58:27.209 [main] INFO org.quartz.core.QuartzScheduler - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.11:58:27.212 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 1 triggers11:58:27.217 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.simpl.PropertySettingJobFactory - Producing instance of Job 'delayJob.orderMessageDelayJob', class=club.throwable.jdbc.OrderMessageDelayJob11:58:27.219 [HikariPool-1 connection adder] DEBUG com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Added connection com.mysql.jdbc.JDBC4Connection@10eb8c5311:58:27.220 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 0 triggers11:58:27.221 [DefaultQuartzScheduler_Worker-1] DEBUG org.quartz.core.JobRunShell - Calling execute on job delayJob.orderMessageDelayJob11:58:34.440 [DefaultQuartzScheduler_Worker-1] INFO club.throwable.jdbc.OrderMessageService - 订单处理定时任务开始执行......11:58:34.451 [HikariPool-1 connection adder] DEBUG com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Added connection com.mysql.jdbc.JDBC4Connection@3d27ece411:58:34.459 [HikariPool-1 connection adder] DEBUG com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Added connection com.mysql.jdbc.JDBC4Connection@64e808af11:58:34.470 [HikariPool-1 connection adder] DEBUG com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Added connection com.mysql.jdbc.JDBC4Connection@79c8c2b711:58:34.477 [HikariPool-1 connection adder] DEBUG com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Added connection com.mysql.jdbc.JDBC4Connection@19a6236911:58:34.485 [HikariPool-1 connection adder] DEBUG com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Added connection com.mysql.jdbc.JDBC4Connection@1673d01711:58:34.485 [HikariPool-1 connection adder] DEBUG com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - After adding stats (total=10, active=0, idle=10, waiting=0)11:58:34.559 [DefaultQuartzScheduler_Worker-1] DEBUG org.springframework.jdbc.core.JdbcTemplate - Executing prepared SQL query11:58:34.565 [DefaultQuartzScheduler_Worker-1] DEBUG org.springframework.jdbc.core.JdbcTemplate - Executing prepared SQL statement [SELECT * FROM t_order_message WHERE create_time &gt;= ? AND create_time &lt;= ? AND order_status IN (?) AND retry_times &lt; ? LIMIT ?]11:58:34.645 [DefaultQuartzScheduler_Worker-1] DEBUG org.springframework.jdbc.datasource.DataSourceUtils - Fetching JDBC Connection from DataSource11:58:35.210 [DefaultQuartzScheduler_Worker-1] DEBUG org.springframework.jdbc.core.JdbcTemplate - SQLWarning ignored: SQL state '22007', error code '1292', message [Truncated incorrect DOUBLE value: '0,-1']11:58:35.335 [DefaultQuartzScheduler_Worker-1] INFO club.throwable.jdbc.OrderMessageService - 处理订单[10086],状态由0更新为111:58:35.342 [DefaultQuartzScheduler_Worker-1] DEBUG org.springframework.jdbc.core.JdbcTemplate - Executing prepared SQL update11:58:35.346 [DefaultQuartzScheduler_Worker-1] DEBUG org.springframework.jdbc.core.JdbcTemplate - Executing prepared SQL statement [UPDATE t_order_message SET order_status = ?,edit_time = ? WHERE id =?]11:58:35.347 [DefaultQuartzScheduler_Worker-1] DEBUG org.springframework.jdbc.datasource.DataSourceUtils - Fetching JDBC Connection from DataSource11:58:35.354 [DefaultQuartzScheduler_Worker-1] INFO club.throwable.jdbc.OrderMessageService - 处理订单[10087],状态由0更新为111:58:35.355 [DefaultQuartzScheduler_Worker-1] DEBUG org.springframework.jdbc.core.JdbcTemplate - Executing prepared SQL update11:58:35.355 [DefaultQuartzScheduler_Worker-1] DEBUG org.springframework.jdbc.core.JdbcTemplate - Executing prepared SQL statement [UPDATE t_order_message SET order_status = ?,edit_time = ? WHERE id =?]11:58:35.355 [DefaultQuartzScheduler_Worker-1] DEBUG org.springframework.jdbc.datasource.DataSourceUtils - Fetching JDBC Connection from DataSource11:58:35.361 [DefaultQuartzScheduler_Worker-1] INFO club.throwable.jdbc.OrderMessageService - 订单处理定时任务开始完毕......11:58:35.363 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 1 triggers11:58:37.206 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.simpl.PropertySettingJobFactory - Producing instance of Job 'delayJob.orderMessageDelayJob', class=club.throwable.jdbc.OrderMessageDelayJob11:58:37.206 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 0 triggers RabbitMQ死信队列 使用RabbitMQ死信队列依赖于RabbitMQ的两个特性：TTL和DLX。 TTL：Time To Live，消息存活时间，包括两个维度：队列消息存活时间和消息本身的存活时间。 DLX：Dead Letter Exchange，死信交换器。 画个图描述一下这两个特性： 下面为了简单起见，TTL使用了针对队列的维度。引入RabbitMQ的Java驱动： 123456&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.7.3&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public class DlxMain &#123; private static final DateTimeFormatter F = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"); private static final Logger LOGGER = LoggerFactory.getLogger(DlxMain.class); public static void main(String[] args) throws Exception &#123; ConnectionFactory factory = new ConnectionFactory(); Connection connection = factory.newConnection(); Channel producerChannel = connection.createChannel(); Channel consumerChannel = connection.createChannel(); // dlx交换器名称为dlx.exchange,类型是direct,绑定键为dlx.key,队列名为dlx.queue producerChannel.exchangeDeclare(\"dlx.exchange\", \"direct\"); producerChannel.queueDeclare(\"dlx.queue\", false, false, false, null); producerChannel.queueBind(\"dlx.queue\", \"dlx.exchange\", \"dlx.key\"); Map&lt;String, Object&gt; queueArgs = new HashMap&lt;&gt;(); // 设置队列消息过期时间,5秒 queueArgs.put(\"x-message-ttl\", 5000); // 指定DLX相关参数 queueArgs.put(\"x-dead-letter-exchange\", \"dlx.exchange\"); queueArgs.put(\"x-dead-letter-routing-key\", \"dlx.key\"); // 声明业务队列 producerChannel.queueDeclare(\"business.queue\", false, false, false, queueArgs); ExecutorService executorService = Executors.newSingleThreadExecutor(r -&gt; &#123; Thread thread = new Thread(r); thread.setDaemon(true); thread.setName(\"DlxConsumer\"); return thread; &#125;); // 启动消费者 executorService.execute(() -&gt; &#123; try &#123; consumerChannel.basicConsume(\"dlx.queue\", true, new DlxConsumer(consumerChannel)); &#125; catch (IOException e) &#123; LOGGER.error(e.getMessage(), e); &#125; &#125;); OrderMessage message = new OrderMessage(\"10086\"); producerChannel.basicPublish(\"\", \"business.queue\", MessageProperties.TEXT_PLAIN, message.getDescription().getBytes(StandardCharsets.UTF_8)); LOGGER.info(\"发送消息成功,订单ID:&#123;&#125;\", message.getOrderId()); message = new OrderMessage(\"10087\"); producerChannel.basicPublish(\"\", \"business.queue\", MessageProperties.TEXT_PLAIN, message.getDescription().getBytes(StandardCharsets.UTF_8)); LOGGER.info(\"发送消息成功,订单ID:&#123;&#125;\", message.getOrderId()); message = new OrderMessage(\"10088\"); producerChannel.basicPublish(\"\", \"business.queue\", MessageProperties.TEXT_PLAIN, message.getDescription().getBytes(StandardCharsets.UTF_8)); LOGGER.info(\"发送消息成功,订单ID:&#123;&#125;\", message.getOrderId()); Thread.sleep(Integer.MAX_VALUE); &#125; private static class DlxConsumer extends DefaultConsumer &#123; DlxConsumer(Channel channel) &#123; super(channel); &#125; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; LOGGER.info(\"处理消息成功:&#123;&#125;\", new String(body, StandardCharsets.UTF_8)); &#125; &#125; private static class OrderMessage &#123; private final String orderId; private final long timestamp; private final String description; OrderMessage(String orderId) &#123; this.orderId = orderId; this.timestamp = System.currentTimeMillis(); this.description = String.format(\"订单[%s],订单创建时间为:%s\", orderId, LocalDateTime.ofInstant(Instant.ofEpochMilli(timestamp), ZoneId.systemDefault()).format(F)); &#125; public String getOrderId() &#123; return orderId; &#125; public long getTimestamp() &#123; return timestamp; &#125; public String getDescription() &#123; return description; &#125; &#125;&#125; 运行main()方法结果如下： 12345616:35:58.638 [main] INFO club.throwable.dlx.DlxMain - 发送消息成功,订单ID:1008616:35:58.641 [main] INFO club.throwable.dlx.DlxMain - 发送消息成功,订单ID:1008716:35:58.641 [main] INFO club.throwable.dlx.DlxMain - 发送消息成功,订单ID:1008816:36:03.646 [pool-1-thread-4] INFO club.throwable.dlx.DlxMain - 处理消息成功:订单[10086],订单创建时间为:2019-08-20 16:35:5816:36:03.670 [pool-1-thread-5] INFO club.throwable.dlx.DlxMain - 处理消息成功:订单[10087],订单创建时间为:2019-08-20 16:35:5816:36:03.670 [pool-1-thread-6] INFO club.throwable.dlx.DlxMain - 处理消息成功:订单[10088],订单创建时间为:2019-08-20 16:35:58 时间轮 时间轮TimingWheel是一种高效、低延迟的调度数据结构，底层采用数组实现存储任务列表的环形队列，示意图如下： 这里暂时不对时间轮和其实现作分析，只简单举例说明怎么使用时间轮实现延时任务。这里使用Netty提供的HashedWheelTimer，引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-common&lt;/artifactId&gt; &lt;version&gt;4.1.39.Final&lt;/version&gt;&lt;/dependency&gt; 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142public class HashedWheelTimerMain &#123; private static final DateTimeFormatter F = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss.SSS\"); public static void main(String[] args) throws Exception &#123; AtomicInteger counter = new AtomicInteger(); ThreadFactory factory = r -&gt; &#123; Thread thread = new Thread(r); thread.setDaemon(true); thread.setName(\"HashedWheelTimerWorker-\" + counter.getAndIncrement()); return thread; &#125;; // tickDuration - 每tick一次的时间间隔, 每tick一次就会到达下一个槽位 // unit - tickDuration的时间单位 // ticksPerWhee - 时间轮中的槽位数 Timer timer = new HashedWheelTimer(factory, 1, TimeUnit.SECONDS, 60); TimerTask timerTask = new DefaultTimerTask(\"10086\"); timer.newTimeout(timerTask, 5, TimeUnit.SECONDS); timerTask = new DefaultTimerTask(\"10087\"); timer.newTimeout(timerTask, 10, TimeUnit.SECONDS); timerTask = new DefaultTimerTask(\"10088\"); timer.newTimeout(timerTask, 15, TimeUnit.SECONDS); Thread.sleep(Integer.MAX_VALUE); &#125; private static class DefaultTimerTask implements TimerTask &#123; private final String orderId; private final long timestamp; public DefaultTimerTask(String orderId) &#123; this.orderId = orderId; this.timestamp = System.currentTimeMillis(); &#125; @Override public void run(Timeout timeout) throws Exception &#123; System.out.println(String.format(\"任务执行时间:%s,订单创建时间:%s,订单ID:%s\", LocalDateTime.now().format(F), LocalDateTime.ofInstant(Instant.ofEpochMilli(timestamp), ZoneId.systemDefault()).format(F), orderId)); &#125; &#125;&#125; 运行结果： 123任务执行时间:2019-08-20 17:19:49.310,订单创建时间:2019-08-20 17:19:43.294,订单ID:10086任务执行时间:2019-08-20 17:19:54.297,订单创建时间:2019-08-20 17:19:43.301,订单ID:10087任务执行时间:2019-08-20 17:19:59.297,订单创建时间:2019-08-20 17:19:43.301,订单ID:10088 一般来说，任务执行的时候应该使用另外的业务线程池，以免阻塞时间轮本身的运动。 选用的方案实现过程 最终选用了基于Redis的有序集合Sorted Set和Quartz短轮询进行实现。具体方案是： 订单创建的时候，订单ID和当前时间戳分别作为Sorted Set的member和score添加到订单队列Sorted Set中。 订单创建的时候，订单ID和推送内容JSON字符串分别作为field和value添加到订单队列内容Hash中。 第1步和第2步操作的时候用Lua脚本保证原子性。 使用一个异步线程通过Sorted Set的命令ZREVRANGEBYSCORE弹出指定数量的订单ID对应的订单队列内容Hash中的订单推送内容数据进行处理。 对于第4点处理有两种方案： 方案一：弹出订单内容数据的同时进行数据删除，也就是ZREVRANGEBYSCORE、ZREM和HDEL命令要在同一个Lua脚本中执行，这样的话Lua脚本的编写难度大，并且由于弹出数据已经在Redis中删除，如果数据处理失败则可能需要从数据库重新查询补偿。 方案二：弹出订单内容数据之后，在数据处理完成的时候再主动删除订单队列Sorted Set和订单队列内容Hash中对应的数据，这样的话需要控制并发，有重复执行的可能性。 最终暂时选用了方案一，也就是从Sorted Set弹出订单ID并且从Hash中获取完推送数据之后马上删除这两个集合中对应的数据。方案的流程图大概是这样： 这里先详细说明一下用到的Redis命令。 Sorted Set相关命令 ZADD命令 - 将一个或多个成员元素及其分数值加入到有序集当中。 ZADD KEY SCORE1 VALUE1.. SCOREN VALUEN ZREVRANGEBYSCORE命令 - 返回有序集中指定分数区间内的所有的成员。有序集成员按分数值递减(从大到小)的次序排列。 ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] max：分数区间 - 最大分数。 min：分数区间 - 最小分数。 WITHSCORES：可选参数，是否返回分数值，指定则会返回得分值。 LIMIT：可选参数，offset和count原理和MySQL的LIMIT offset,size一致，如果不指定此参数则返回整个集合的数据。 ZREM命令 - 用于移除有序集中的一个或多个成员，不存在的成员将被忽略。 ZREM key member [member ...] Hash相关命令 HMSET命令 - 同时将多个field-value(字段-值)对设置到哈希表中。 HMSET KEY_NAME FIELD1 VALUE1 ...FIELDN VALUEN HDEL命令 - 删除哈希表key中的一个或多个指定字段，不存在的字段将被忽略。 HDEL KEY_NAME FIELD1.. FIELDN Lua相关 加载Lua脚本并且返回脚本的SHA-1字符串：SCRIPT LOAD script。 执行已经加载的Lua脚本：EVALSHA sha1 numkeys key [key ...] arg [arg ...]。 unpack函数可以把table类型的参数转化为可变参数，不过需要注意的是unpack函数必须使用在非变量定义的函数调用的最后一个参数，否则会失效，详细见Stackoverflow的提问table.unpack() only returns the first element。 PS：如果不熟悉Lua语言，建议系统学习一下，因为想用好Redis，一定离不开Lua。 引入依赖： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.7.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;5.1.9.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.8&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.59&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 编写Lua脚本/lua/enqueue.lua和/lua/dequeue.lua： 12345678910111213141516171819202122232425262728293031323334-- /lua/enqueue.lualocal zset_key = KEYS[1]local hash_key = KEYS[2]local zset_value = ARGV[1]local zset_score = ARGV[2]local hash_field = ARGV[3]local hash_value = ARGV[4]redis.call('ZADD', zset_key, zset_score, zset_value)redis.call('HSET', hash_key, hash_field, hash_value)return nil-- /lua/dequeue.lua-- 参考jesque的部分Lua脚本实现local zset_key = KEYS[1]local hash_key = KEYS[2]local min_score = ARGV[1]local max_score = ARGV[2]local offset = ARGV[3]local limit = ARGV[4]-- TYPE命令的返回结果是&#123;'ok':'zset'&#125;这样子,这里利用next做一轮迭代local status, type = next(redis.call('TYPE', zset_key))if status ~= nil and status == 'ok' then if type == 'zset' then local list = redis.call('ZREVRANGEBYSCORE', zset_key, max_score, min_score, 'LIMIT', offset, limit) if list ~= nil and #list &gt; 0 then -- unpack函数能把table转化为可变参数 redis.call('ZREM', zset_key, unpack(list)) local result = redis.call('HMGET', hash_key, unpack(list)) redis.call('HDEL', hash_key, unpack(list)) return result end endendreturn nil 编写核心API代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155// Jedis提供者@Componentpublic class JedisProvider implements InitializingBean &#123; private JedisPool jedisPool; @Override public void afterPropertiesSet() throws Exception &#123; jedisPool = new JedisPool(); &#125; public Jedis provide()&#123; return jedisPool.getResource(); &#125;&#125;// OrderMessage@Datapublic class OrderMessage &#123; private String orderId; private BigDecimal amount; private Long userId;&#125;// 延迟队列接口public interface OrderDelayQueue &#123; void enqueue(OrderMessage message); List&lt;OrderMessage&gt; dequeue(String min, String max, String offset, String limit); List&lt;OrderMessage&gt; dequeue(); String enqueueSha(); String dequeueSha();&#125;// 延迟队列实现类@RequiredArgsConstructor@Componentpublic class RedisOrderDelayQueue implements OrderDelayQueue, InitializingBean &#123; private static final String MIN_SCORE = \"0\"; private static final String OFFSET = \"0\"; private static final String LIMIT = \"10\"; private static final String ORDER_QUEUE = \"ORDER_QUEUE\"; private static final String ORDER_DETAIL_QUEUE = \"ORDER_DETAIL_QUEUE\"; private static final String ENQUEUE_LUA_SCRIPT_LOCATION = \"/lua/enqueue.lua\"; private static final String DEQUEUE_LUA_SCRIPT_LOCATION = \"/lua/dequeue.lua\"; private static final AtomicReference&lt;String&gt; ENQUEUE_LUA_SHA = new AtomicReference&lt;&gt;(); private static final AtomicReference&lt;String&gt; DEQUEUE_LUA_SHA = new AtomicReference&lt;&gt;(); private static final List&lt;String&gt; KEYS = Lists.newArrayList(); private final JedisProvider jedisProvider; static &#123; KEYS.add(ORDER_QUEUE); KEYS.add(ORDER_DETAIL_QUEUE); &#125; @Override public void enqueue(OrderMessage message) &#123; List&lt;String&gt; args = Lists.newArrayList(); args.add(message.getOrderId()); args.add(String.valueOf(System.currentTimeMillis())); args.add(message.getOrderId()); args.add(JSON.toJSONString(message)); try (Jedis jedis = jedisProvider.provide()) &#123; jedis.evalsha(ENQUEUE_LUA_SHA.get(), KEYS, args); &#125; &#125; @Override public List&lt;OrderMessage&gt; dequeue() &#123; // 30分钟之前 String maxScore = String.valueOf(System.currentTimeMillis() - 30 * 60 * 1000); return dequeue(MIN_SCORE, maxScore, OFFSET, LIMIT); &#125; @SuppressWarnings(\"unchecked\") @Override public List&lt;OrderMessage&gt; dequeue(String min, String max, String offset, String limit) &#123; List&lt;String&gt; args = new ArrayList&lt;&gt;(); args.add(min); args.add(max); args.add(offset); args.add(limit); List&lt;OrderMessage&gt; result = Lists.newArrayList(); try (Jedis jedis = jedisProvider.provide()) &#123; List&lt;String&gt; eval = (List&lt;String&gt;) jedis.evalsha(DEQUEUE_LUA_SHA.get(), KEYS, args); if (null != eval) &#123; for (String e : eval) &#123; result.add(JSON.parseObject(e, OrderMessage.class)); &#125; &#125; &#125; return result; &#125; @Override public String enqueueSha() &#123; return ENQUEUE_LUA_SHA.get(); &#125; @Override public String dequeueSha() &#123; return DEQUEUE_LUA_SHA.get(); &#125; @Override public void afterPropertiesSet() throws Exception &#123; // 加载Lua脚本 loadLuaScript(); &#125; private void loadLuaScript() throws Exception &#123; try (Jedis jedis = jedisProvider.provide()) &#123; ClassPathResource resource = new ClassPathResource(ENQUEUE_LUA_SCRIPT_LOCATION); String luaContent = StreamUtils.copyToString(resource.getInputStream(), StandardCharsets.UTF_8); String sha = jedis.scriptLoad(luaContent); ENQUEUE_LUA_SHA.compareAndSet(null, sha); resource = new ClassPathResource(DEQUEUE_LUA_SCRIPT_LOCATION); luaContent = StreamUtils.copyToString(resource.getInputStream(), StandardCharsets.UTF_8); sha = jedis.scriptLoad(luaContent); DEQUEUE_LUA_SHA.compareAndSet(null, sha); &#125; &#125; public static void main(String[] as) throws Exception &#123; DateTimeFormatter f = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss.SSS\"); JedisProvider jedisProvider = new JedisProvider(); jedisProvider.afterPropertiesSet(); RedisOrderDelayQueue queue = new RedisOrderDelayQueue(jedisProvider); queue.afterPropertiesSet(); // 写入测试数据 OrderMessage message = new OrderMessage(); message.setAmount(BigDecimal.valueOf(10086)); message.setOrderId(\"ORDER_ID_10086\"); message.setUserId(10086L); message.setTimestamp(LocalDateTime.now().format(f)); List&lt;String&gt; args = Lists.newArrayList(); args.add(message.getOrderId()); // 测试需要,score设置为30分钟之前 args.add(String.valueOf(System.currentTimeMillis() - 30 * 60 * 1000)); args.add(message.getOrderId()); args.add(JSON.toJSONString(message)); try (Jedis jedis = jedisProvider.provide()) &#123; jedis.evalsha(ENQUEUE_LUA_SHA.get(), KEYS, args); &#125; List&lt;OrderMessage&gt; dequeue = queue.dequeue(); System.out.println(dequeue); &#125;&#125; 这里先执行一次main()方法验证一下延迟队列是否生效： 1[OrderMessage(orderId=ORDER_ID_10086, amount=10086, userId=10086, timestamp=2019-08-21 08:32:22.885)] 确定延迟队列的代码没有问题，接着编写一个Quartz的Job类型的消费者OrderMessageConsumer： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@DisallowConcurrentExecution@Componentpublic class OrderMessageConsumer implements Job &#123; private static final AtomicInteger COUNTER = new AtomicInteger(); private static final ExecutorService BUSINESS_WORKER_POOL = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors(), r -&gt; &#123; Thread thread = new Thread(r); thread.setDaemon(true); thread.setName(\"OrderMessageConsumerWorker-\" + COUNTER.getAndIncrement()); return thread; &#125;); private static final Logger LOGGER = LoggerFactory.getLogger(OrderMessageConsumer.class); @Autowired private OrderDelayQueue orderDelayQueue; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); LOGGER.info(\"订单消息处理定时任务开始执行......\"); List&lt;OrderMessage&gt; messages = orderDelayQueue.dequeue(); if (!messages.isEmpty()) &#123; // 简单的列表等分放到线程池中执行 List&lt;List&lt;OrderMessage&gt;&gt; partition = Lists.partition(messages, 2); int size = partition.size(); final CountDownLatch latch = new CountDownLatch(size); for (List&lt;OrderMessage&gt; p : partition) &#123; BUSINESS_WORKER_POOL.execute(new ConsumeTask(p, latch)); &#125; try &#123; latch.await(); &#125; catch (InterruptedException ignore) &#123; //ignore &#125; &#125; stopWatch.stop(); LOGGER.info(\"订单消息处理定时任务执行完毕,耗时:&#123;&#125; ms......\", stopWatch.getTotalTimeMillis()); &#125; @RequiredArgsConstructor private static class ConsumeTask implements Runnable &#123; private final List&lt;OrderMessage&gt; messages; private final CountDownLatch latch; @Override public void run() &#123; try &#123; // 实际上这里应该单条捕获异常 for (OrderMessage message : messages) &#123; LOGGER.info(\"处理订单信息,内容:&#123;&#125;\", message); &#125; &#125; finally &#123; latch.countDown(); &#125; &#125; &#125;&#125; 上面的消费者设计的时候需要有以下考量： 使用@DisallowConcurrentExecution注解不允许Job并发执行，其实多个Job并发执行意义不大，因为我们采用的是短间隔的轮询，而Redis是单线程处理命令，在客户端做多线程其实效果不佳。 线程池BUSINESS_WORKER_POOL的线程容量或者队列应该综合LIMIT值、等分订单信息列表中使用的size值以及ConsumeTask里面具体的执行时间进行考虑，这里只是为了方便使用了固定容量的线程池。 ConsumeTask中应该对每一条订单信息的处理单独捕获异常和吞并异常，或者把处理单个订单信息的逻辑封装成一个不抛出异常的方法。 其他Quartz相关的代码： 1234567891011121314151617181920212223242526272829303132333435// Quartz配置类@Configurationpublic class QuartzAutoConfiguration &#123; @Bean public SchedulerFactoryBean schedulerFactoryBean(QuartzAutowiredJobFactory quartzAutowiredJobFactory) &#123; SchedulerFactoryBean factory = new SchedulerFactoryBean(); factory.setAutoStartup(true); factory.setJobFactory(quartzAutowiredJobFactory); return factory; &#125; @Bean public QuartzAutowiredJobFactory quartzAutowiredJobFactory() &#123; return new QuartzAutowiredJobFactory(); &#125; public static class QuartzAutowiredJobFactory extends AdaptableJobFactory implements BeanFactoryAware &#123; private AutowireCapableBeanFactory autowireCapableBeanFactory; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.autowireCapableBeanFactory = (AutowireCapableBeanFactory) beanFactory; &#125; @Override protected Object createJobInstance(TriggerFiredBundle bundle) throws Exception &#123; Object jobInstance = super.createJobInstance(bundle); // 这里利用AutowireCapableBeanFactory从新建的Job实例做一次自动装配,得到一个原型(prototype)的JobBean实例 autowireCapableBeanFactory.autowireBean(jobInstance); return jobInstance; &#125; &#125;&#125; 这里暂时使用了内存态的RAMJobStore去存放任务和触发器的相关信息，如果在生产环境最好替换成基于MySQL也就是JobStoreTX进行集群化，最后是启动函数和CommandLineRunner的实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@SpringBootApplication(exclude = &#123;DataSourceAutoConfiguration.class, TransactionAutoConfiguration.class&#125;)public class Application implements CommandLineRunner &#123; @Autowired private Scheduler scheduler; @Autowired private JedisProvider jedisProvider; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; @Override public void run(String... args) throws Exception &#123; // 准备一些测试数据 prepareOrderMessageData(); JobDetail job = JobBuilder.newJob(OrderMessageConsumer.class) .withIdentity(\"OrderMessageConsumer\", \"DelayTask\") .build(); // 触发器5秒触发一次 Trigger trigger = TriggerBuilder.newTrigger() .withIdentity(\"OrderMessageConsumerTrigger\", \"DelayTask\") .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(5).repeatForever()) .build(); scheduler.scheduleJob(job, trigger); &#125; private void prepareOrderMessageData() throws Exception &#123; DateTimeFormatter f = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss.SSS\"); try (Jedis jedis = jedisProvider.provide()) &#123; List&lt;OrderMessage&gt; messages = Lists.newArrayList(); for (int i = 0; i &lt; 100; i++) &#123; OrderMessage message = new OrderMessage(); message.setAmount(BigDecimal.valueOf(i)); message.setOrderId(\"ORDER_ID_\" + i); message.setUserId((long) i); message.setTimestamp(LocalDateTime.now().format(f)); messages.add(message); &#125; // 这里暂时不使用Lua Map&lt;String, Double&gt; map = Maps.newHashMap(); Map&lt;String, String&gt; hash = Maps.newHashMap(); for (OrderMessage message : messages) &#123; // 故意把score设计成30分钟前 map.put(message.getOrderId(), Double.valueOf(String.valueOf(System.currentTimeMillis() - 30 * 60 * 1000))); hash.put(message.getOrderId(), JSON.toJSONString(message)); &#125; jedis.zadd(\"ORDER_QUEUE\", map); jedis.hmset(\"ORDER_DETAIL_QUEUE\", hash); &#125; &#125;&#125; 输出结果如下： 123456789101112131415161718192021222324252019-08-21 22:45:59.518 INFO 33000 --- [ryBean_Worker-1] club.throwable.OrderMessageConsumer : 订单消息处理定时任务开始执行......2019-08-21 22:45:59.525 INFO 33000 --- [onsumerWorker-4] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_91, amount=91, userId=91, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:45:59.525 INFO 33000 --- [onsumerWorker-2] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_95, amount=95, userId=95, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:45:59.525 INFO 33000 --- [onsumerWorker-1] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_97, amount=97, userId=97, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:45:59.525 INFO 33000 --- [onsumerWorker-0] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_99, amount=99, userId=99, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:45:59.525 INFO 33000 --- [onsumerWorker-3] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_93, amount=93, userId=93, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:45:59.539 INFO 33000 --- [onsumerWorker-2] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_94, amount=94, userId=94, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:45:59.539 INFO 33000 --- [onsumerWorker-1] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_96, amount=96, userId=96, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:45:59.539 INFO 33000 --- [onsumerWorker-3] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_92, amount=92, userId=92, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:45:59.539 INFO 33000 --- [onsumerWorker-0] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_98, amount=98, userId=98, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:45:59.539 INFO 33000 --- [onsumerWorker-4] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_90, amount=90, userId=90, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:45:59.540 INFO 33000 --- [ryBean_Worker-1] club.throwable.OrderMessageConsumer : 订单消息处理定时任务执行完毕,耗时:22 ms......2019-08-21 22:46:04.515 INFO 33000 --- [ryBean_Worker-2] club.throwable.OrderMessageConsumer : 订单消息处理定时任务开始执行......2019-08-21 22:46:04.516 INFO 33000 --- [onsumerWorker-5] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_89, amount=89, userId=89, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:46:04.516 INFO 33000 --- [onsumerWorker-6] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_87, amount=87, userId=87, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:46:04.516 INFO 33000 --- [onsumerWorker-7] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_85, amount=85, userId=85, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:46:04.516 INFO 33000 --- [onsumerWorker-5] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_88, amount=88, userId=88, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:46:04.516 INFO 33000 --- [onsumerWorker-2] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_83, amount=83, userId=83, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:46:04.516 INFO 33000 --- [onsumerWorker-1] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_81, amount=81, userId=81, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:46:04.516 INFO 33000 --- [onsumerWorker-6] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_86, amount=86, userId=86, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:46:04.516 INFO 33000 --- [onsumerWorker-2] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_82, amount=82, userId=82, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:46:04.516 INFO 33000 --- [onsumerWorker-7] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_84, amount=84, userId=84, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:46:04.516 INFO 33000 --- [onsumerWorker-1] club.throwable.OrderMessageConsumer : 处理订单信息,内容:OrderMessage(orderId=ORDER_ID_80, amount=80, userId=80, timestamp=2019-08-21 22:45:59.475)2019-08-21 22:46:04.516 INFO 33000 --- [ryBean_Worker-2] club.throwable.OrderMessageConsumer : 订单消息处理定时任务执行完毕,耗时:1 ms............ 首次执行的时候涉及到一些组件的初始化，会比较慢，后面看到由于我们只是简单打印订单信息，所以定时任务执行比较快。如果在不调整当前架构的情况下，生产中需要注意： 切换JobStore为JDBC模式，Quartz官方有完整教程，或者看笔者之前翻译的Quartz文档。 需要监控或者收集任务的执行状态，添加预警等等。 这里其实有一个性能隐患，命令ZREVRANGEBYSCORE的时间复杂度可以视为为O(N)，N是集合的元素个数，由于这里把所有的订单信息都放进了同一个Sorted Set(ORDER_QUEUE)中，所以在一直有新增数据的时候，dequeue脚本的时间复杂度一直比较高，后续订单量升高之后会此处一定会成为性能瓶颈，后面会给出解决的方案。 小结 这篇文章主要从一个实际生产案例的仿真例子入手，分析了当前延时任务的一些实现方案，还基于Redis和Quartz给出了一个完整的示例。当前的示例只是处于可运行的状态，有些问题尚未解决。下一篇文章会着眼于解决两个方面的问题： 分片。 监控。 还有一点，架构是基于业务形态演进出来的，很多东西需要结合场景进行方案设计和改进，思路仅供参考，切勿照搬代码。 附件 Markdown和PPT原件： （本文完 c-5-d e-a-20190821 顺便开通了RSS插件，见主页的图标，欢迎订阅 r-a-20190904）","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Redis","slug":"Middleware/Redis","permalink":"http://throwable.club/blog/categories/Middleware/Redis/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Redis","slug":"Redis","permalink":"http://throwable.club/blog/tags/Redis/"}]},{"title":"Redis的复合SET命令和简易的分布式锁优化","slug":"middleware-redis-set-command-distributed-lock","date":"2019-08-14T16:36:32.000Z","updated":"2019-08-14T16:42:42.590Z","comments":true,"path":"2019/08/15/middleware-redis-set-command-distributed-lock/","link":"","permalink":"http://throwable.club/2019/08/15/middleware-redis-set-command-distributed-lock/","excerpt":"前提 最近在跟进一个比较老的系统的时候，发现了所有调度任务使用了spring-context里面的@Scheduled注解和自行基于Redis封装的简易分布式锁控制任务不并发执行。为了不引入其他框架的情况下做一些简单优化，笔者花点时间去研读了一下Redis的SET命令的相关文档。","text":"前提 最近在跟进一个比较老的系统的时候，发现了所有调度任务使用了spring-context里面的@Scheduled注解和自行基于Redis封装的简易分布式锁控制任务不并发执行。为了不引入其他框架的情况下做一些简单优化，笔者花点时间去研读了一下Redis的SET命令的相关文档。 场景还原 使用@Scheduled注解实现定时任务，使用spring-data-redis提供的API实现简易的Redis分布式锁的伪代码如下： 123456789101112// 每30分钟跑一次@Scheduled(cron = \"* */30 * * * ? \")public void scheduledMethod()&#123; // 判断KEY存在性并且设置KEY，带超时时间5分钟 if (StringRedisTemplate#opsForValue()#hasKey(\"定时任务唯一字符串标识\"))&#123; StringRedisTemplate#opsForValue()#set(\"定时任务唯一字符串标识\", \"1[这里暂时可以使用任何值]\", 5 , TimeUnit.MINUTES); &#125; // 这里做调度正常业务逻辑 doBusiness(); // 删除KEY StringRedisTemplate#opsForValue()#delete(\"定时任务唯一字符串标识\");&#125; 上面的代码存在如下显然的缺陷： 如果应用部署多个节点，由于判断KEY的存在性和SET操作是两个操作（非原子操作），该定时任务有可能在同一个时刻并发执行多次。 如果业务逻辑执行方法doBusiness()抛出了异常，会导致删除KEY的操作无法执行，KEY会到达超时时间后被删除，这个时候相当于加锁时间长达5分钟，显然是无法接受的。 但是实际上，以上两个问题在生产环境中并没有出现过，分析一下具体原因是： 对于第1点，该应用在生产环境只部署了2个节点，节点的重启时间并不相同，所以从天然上避免了重复执行的问题，如果CRON表达式设计为0 */30 * * * ? （0秒开始每30分钟执行一次）就有可能出现并发问题。 对于第2点，开发者在处理业务方法里面全局捕获异常并且没有外抛，所以调度方法总是会执行到删除KEY的逻辑。 以上仅仅是巧合的情况下规避了问题出现的因子，但是从编码规范的角度来看显然是存在问题。基于Redis实现的分布式锁的方案在Redis官方文档中有一篇文章做了详细的分析-Distributed locks with Redis，对于Java语言来说，有现成的类库Redisson提供对应的实现。但是在解决这个问题的时候，为了简易起见并没有引入Redisson，而是想办法通过原来的SET和DEL两个操作的相关思路进行优化。 SET复合命令 自从Redis的2.6.12版本起，SET命令已经提供了可选的复合操作符： 1SET key value [expiration EX seconds|PX milliseconds] [NX|XX] 时间复杂度：O(1)。 可选参数： EX：设置超时时间，单位是秒。 PX：设置超时时间，单位是毫秒。 NX：IF NOT EXIST的缩写，只有KEY不存在的前提下才会设置值。 XX：IF EXIST的缩写，只有在KEY存在的前提下才会设置值。 列举一些等价的命令： 原始命令 等价命令 SETEX KEY_1 1 SET KEY_1 EX 1 SETNX KEY_1 SET KEY_1 NX SETNX KEY_1 &amp;&amp; EXPIRE KEY_1 1 SET KEY_1 EX 1 NX SETNX KEY_1 &amp;&amp; PEXPIRE KEY_1 1000 SET KEY_1 PX 1000 NX 对比一下，发现SET复合命令十分简便，可以把两个命令合并成一个原子命令。不过注意一下，spring-data-redis里面的封装做得不太好，ValueOperations并没有提供相关的方法，因此最好还是使用Redis的Java客户端Jedis。 简易的分布式锁实现 其实官方文档里面已经有很详细的Redis分布式锁方案（尽管这个方案在某些论文里面被热烈讨论它存在的问题，但是生产中它已经被广泛使用），获取锁的伪代码如下： 1SET RESOURCE_NAME RANDOM_VALUE NX PX 30000 释放锁的伪代码（Lua脚本）如下： 12345if redis.call(\"get\",KEYS[1]) == ARGV[1] then return redis.call(\"del\",KEYS[1])else return 0end 改造前文中提及到的例子： 123456789101112131415// 每30分钟跑一次@Scheduled(cron = \"* */30 * * * ? \")public void scheduledMethod()&#123; try (Jedis jedis = getJedis())&#123; SetParams params = new SetParams().ex(300).nx(); String code = jedis.set(\"定时任务唯一字符串标识\", \"1\", params); // 加锁成功 if (\"OK\".equals(code))&#123; // 这里做调度正常业务逻辑 doBusiness(); &#125; &#125;finally&#123; jedis.del(\"定时任务唯一字符串标识\"); &#125;&#125; 这里直接在finally代码块中进行KEY的删除，实际上，我们不需要关注这个删除动作是否成功（假如在最后阶段删除KEY出现Redis服务故障，无论使用Lua还是直接删除导致的结果都是一样的）。为了避免多余的DEL操作，可以简单优化为： 12345678910111213141516171819// 每30分钟跑一次@Scheduled(cron = \"* */30 * * * ? \")public void scheduledMethod()&#123; boolean lock = false; try (Jedis jedis = getJedis())&#123; SetParams params = new SetParams().ex(300).nx(); String code = jedis.set(\"定时任务唯一字符串标识\", \"1\", params); // 加锁成功 if (\"OK\".equals(code))&#123; lock = true; // 这里做调度正常业务逻辑 doBusiness(); &#125; &#125;finally&#123; if (lock)&#123; jedis.del(\"定时任务唯一字符串标识\"); &#125; &#125;&#125; 通过SET RESOURCE_NAME RANDOM_VALUE NX PX 30000和Redis单线程处理的特性，就能避免定时任务重复执行。其实这里还存在一些隐患： 如果一个线程加锁时候指定的超时时间很长，并且在跑到finally代码块之前由于不可抗因素（例如很多人喜欢提到的断电）中断导致锁没有释放，那么这个锁就相当于一个僵尸锁。 锁的持有和锁的释放应该由同一个操作者进行，否则操作者A进行了加锁，如果有恶意操作者B进行解锁，那么会导致锁并不安全。 上面这些隐患在Redisson中都有对应的解决方案，迟点分析一下Redisson的源码实现。 小结 本文在改造一个老系统的时候尝试使用改动最小的方式进行简易的基于Redis实现的分布式锁优化，实际生产环境中应该尽量使用主流的可靠的类库，如Redisson（编写本文的时候Github的星星数已经超过10200，提交和Issue都比较活跃，遇到坑了比较容易找到解决方案，值得信赖）。如果需要造轮子，那么就需要熟练使用中间件提供的API，同时注意一下编码规范，尽可能避免因为规范和使用方式不当带来的问题。 附件 Markdown文件：https://github.com/zjcscut/blog-article-file/tree/master/20190815/middleware-redis-set-command-distributed-lock （本文完 c-1-d e-a-20190815）","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Redis","slug":"Middleware/Redis","permalink":"http://throwable.club/blog/categories/Middleware/Redis/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Redis","slug":"Redis","permalink":"http://throwable.club/blog/tags/Redis/"}]},{"title":"使用Redis的HSCAN命令遇到的一个问题","slug":"middleware-redis-hash-problem-first","date":"2019-08-12T13:59:52.000Z","updated":"2019-08-12T14:12:21.984Z","comments":true,"path":"2019/08/12/middleware-redis-hash-problem-first/","link":"","permalink":"http://throwable.club/2019/08/12/middleware-redis-hash-problem-first/","excerpt":"前提 笔者最近在做一个项目时候使用Redis存放客户端展示的订单列表，列表需要进行分页。由于笔者先前对Redis的各种数据类型的使用场景并不是十分熟悉，于是先入为主地看到Hash类型： 123USER_ID:1 ORDER_ID:ORDER_XX: &#123;\"amount\": \"100\",\"orderId\":\"ORDER_XX\"&#125; ORDER_ID:ORDER_YY: &#123;\"amount\": \"200\",\"orderId\":\"ORDER_YY\"&#125; 感觉Hash类型完全满足需求实现的场景。然后想当然地考虑使用HSCAN命令进行分页，引发了后面遇到的问题。","text":"前提 笔者最近在做一个项目时候使用Redis存放客户端展示的订单列表，列表需要进行分页。由于笔者先前对Redis的各种数据类型的使用场景并不是十分熟悉，于是先入为主地看到Hash类型： 123USER_ID:1 ORDER_ID:ORDER_XX: &#123;\"amount\": \"100\",\"orderId\":\"ORDER_XX\"&#125; ORDER_ID:ORDER_YY: &#123;\"amount\": \"200\",\"orderId\":\"ORDER_YY\"&#125; 感觉Hash类型完全满足需求实现的场景。然后想当然地考虑使用HSCAN命令进行分页，引发了后面遇到的问题。 SCAN和HSCAN命令 SCAN命令如下： 1234SCAN cursor [MATCH pattern] [COUNT count] [TYPE type]// 返回值如下：// 1. cursor，数值类型，下一轮的起始游标值，0代表遍历结束// 2. 遍历的结果集合，列表 SCAN命令在Redis2.8.0版本中新增，时间复杂度计算如下：每一轮遍历的时间复杂度为O(1)，所有元素遍历完毕直到游标cursor返回0的时间复杂度为O(N)，其中N为集合内元素的数量。SCAN是针对整个Database内的所有KEY进行渐进式的遍历，它不会阻塞Redis，也就是使用SCAN命令遍历KEY的性能会优于KEY *命令。对于Hash类型有一个衍生的命令HSCAN专门用于遍历Hash类型及其相关属性(Field)的字段： 1234HSCAN key cursor [MATCH pattern] [COUNT count]// 返回值如下：// 1. cursor，数值类型，下一轮的起始游标值，0代表遍历结束// 2. 遍历的结果集合，是一个映射 笔者当时没有详细查阅Redis的官方文档，想当然地认为Hash类型的分页简单如下（假设每页数据只有1条）： 1234// 第一页HSCAN USER_ID:1 0 COUNT 1 &lt;= 这里认为返回的游标值为1// 第二页HSCAN USER_ID:1 1 COUNT 1 &lt;= 这里认为返回的游标值为0，结束迭代 实际上，执行的结果如下： 12345678HSCAN USER_ID:1 0 COUNT 1// 结果0 ORDER_ID:ORDER_XX &#123;\"amount\": \"100\",\"orderId\":\"ORDER_XX\"&#125; ORDER_ID:ORDER_YY &#123;\"amount\": \"200\",\"orderId\":\"ORDER_YY\"&#125; 也就是在第一轮遍历的时候，KEY对应的所有Field-Value已经全量返回。笔者尝试增加哈希集合KEY = USER_ID:1里面的元素，但是数据量相对较大的时候，依然没有达到预期的分页效果；另一个方面，尝试修改命令中的COUNT值，发现无论如何修改COUNT值都不会对遍历的结果产生任何影响（也就是还是在第一轮迭代返回全部结果）。百思不得其解的情况下，只能仔细翻阅官方文档寻找解决方案。在SCAN命令的COUNT属性描述中找到了原因： 简单翻译理解一下： SCAN命令以及其衍生命令并不保证每一轮迭代返回的元素数量，但是可以使用COUNT属性凭经验调整SCAN命令的行为。COUNT指定每次调用应该完成遍历的元素的数量，以便于遍历集合，本质只是一个提示值。 COUNT默认值为10。 当遍历的目标Set、Hash、Sorted Set或者Key空间足够大可以使用一个哈希表表示并且不使用MATCH属性的前提下，Redis服务端会返回COUNT或者比COUNT大的遍历元素结果集合。 当遍历只包含Integer值的Set集合（也称为intsets），或者ziplists类型编码的Hash或者Sorted Set集合（说明这些集合里面的元素占用的空间足够小），那么SCAN命令会返回集合中的所有元素，直接忽略COUNT属性。 注意第3点，这个就是在Hash集合中使用HSCAN命令COUNT属性失效的根本原因。Redis配置中有两个和Hash类型ziplist编码的相关配置值： 12hash-max-ziplist-entries 512hash-max-ziplist-value 64 在如下两个条件之一满足的时候，Hash集合的编码会由ziplist会转成dict： 当Hash集合中的数据项（即Field-Value对）的数目超过512的时候。 当Hash集合中插入的任意一个Field-Value对中的Value长度超过64。 当Hash集合的编码会由ziplist会转成dict，Redis为Hash类型的内存空间占用优化相当于失败了，降级为相对消耗更多内存的字典类型编码，这个时候，HSCAN命令COUNT属性才会起效。 案例验证 简单验证一下上一节得出的结论，写入一个测试数据如下： 1234// 70个XHSET USER_ID:2 ORDER_ID:ORDER_XXX XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX // 70个YHSET USER_ID:2 ORDER_ID:ORDER_YYY YYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY 接着开始测试一下HSCAN命令： 1234567891011121314151617// 查看编码object encoding USER_ID:2// 编码结果hashtable// 第一轮迭代HSCAN USER_ID:2 0 COUNT 1// 第一轮迭代返回结果2 ORDER_ID:ORDER_YYY YYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY// 第二轮迭代 HSCAN USER_ID:2 2 COUNT 10 ORDER_ID:ORDER_XXX XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX 测试案例中故意让两个值的长度为70，大于64，也就是让Hash集合转变为dict(hashtable)类型，使得COUNT属性生效。但是，这种做法是放弃了Redis为Hash集合的内存优化。显然，HSCAN命令天然不是为了做数据分页而设计的，而是为了渐进式的迭代（也就是如果需要迭代的集合很大，也不会阻塞Redis服务）。所以笔者最后放弃了使用HSCAN命令，寻找更适合做数据分页查询的其他Redis命令。 小结 通过这简单的踩坑案例，笔者得到一些经验： 切忌先入为主，使用中间件的时候要结合实际的场景。 使用工具的之前要仔细阅读工具的使用手册。 要通过一些案例验证自己的猜想或者推导的结果。 Redis提供的API十分丰富，后面应该还会遇到更多的踩坑经验。 附件 Markdown文件：https://github.com/zjcscut/blog-article-file/tree/master/20190812/middleware-redis-hash-problem-first （本文完 e-a-20190812 c-1-d）","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Redis","slug":"Middleware/Redis","permalink":"http://throwable.club/blog/categories/Middleware/Redis/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Redis","slug":"Redis","permalink":"http://throwable.club/blog/tags/Redis/"}]},{"title":"Java函数式编程之Optional","slug":"java-functional-programming-optional","date":"2019-08-07T00:15:24.000Z","updated":"2019-08-11T15:22:56.528Z","comments":true,"path":"2019/08/07/java-functional-programming-optional/","link":"","permalink":"http://throwable.club/2019/08/07/java-functional-programming-optional/","excerpt":"前提 java.util.Optional是JDK8中引入的类，它是JDK从著名的Java工具包Guava中移植过来。本文编写的时候使用的是JDK11。Optional是一个包含了NULL值或者非NULL值的对象容器，它常用作明确表明没有结果（其实明确表明存在结果也可以用Optional表示）的方法返回类型，这样可以避免NULL值带来的可能的异常（一般是NullPointerException）。也就是说，一个方法的返回值类型是Optional，则应该避免返回NULL，而应该让返回值指向一个包含NULL对象的Optional实例。Optional的出现为NULL判断、过滤操作、映射操作等提供了函数式适配入口，它算是Java引入函数式编程的一个重要的里程碑。 本文新增一个Asciidoc的预览模式，可以体验一下Spring官方文档的感觉： Github Page：http://www.throwable.club/adoc/20190807/java-functional-programming-optional Coding Page：http://throwable.coding.me/adoc/20190807/java-functional-programming-optional","text":"前提 java.util.Optional是JDK8中引入的类，它是JDK从著名的Java工具包Guava中移植过来。本文编写的时候使用的是JDK11。Optional是一个包含了NULL值或者非NULL值的对象容器，它常用作明确表明没有结果（其实明确表明存在结果也可以用Optional表示）的方法返回类型，这样可以避免NULL值带来的可能的异常（一般是NullPointerException）。也就是说，一个方法的返回值类型是Optional，则应该避免返回NULL，而应该让返回值指向一个包含NULL对象的Optional实例。Optional的出现为NULL判断、过滤操作、映射操作等提供了函数式适配入口，它算是Java引入函数式编程的一个重要的里程碑。 本文新增一个Asciidoc的预览模式，可以体验一下Spring官方文档的感觉： Github Page：http://www.throwable.club/adoc/20190807/java-functional-programming-optional Coding Page：http://throwable.coding.me/adoc/20190807/java-functional-programming-optional Optional各个方法源码分析和使用场景 Optional的源码比较简单，归根于它是一个简单的对象容器。下面会结合源码分析它的所有构造、属性、方法和对应的使用场景。 Optional属性和构造 Optional的属性和构造如下： 12345678910111213141516171819202122232425262728293031323334353637public final class Optional&lt;T&gt; &#123; // 这个是通用的代表NULL值的Optional实例 private static final Optional&lt;?&gt; EMPTY = new Optional&lt;&gt;(); // 泛型类型的对象实例 private final T value; // 实例化Optional，注意是私有修饰符，value置为NULL private Optional() &#123; this.value = null; &#125; // 直接返回内部的EMPTY实例 public static&lt;T&gt; Optional&lt;T&gt; empty() &#123; @SuppressWarnings(\"unchecked\") Optional&lt;T&gt; t = (Optional&lt;T&gt;) EMPTY; return t; &#125; // 通过value实例化Optional，如果value为NULL则抛出NPE private Optional(T value) &#123; this.value = Objects.requireNonNull(value); &#125; // 通过value实例化Optional，如果value为NULL则抛出NPE，实际上就是使用Optional(T value) public static &lt;T&gt; Optional&lt;T&gt; of(T value) &#123; return new Optional&lt;&gt;(value); &#125; // 如果value为NULL则返回EMPTY实例，否则调用Optional#of(value) public static &lt;T&gt; Optional&lt;T&gt; ofNullable(T value) &#123; return value == null ? empty() : of(value); &#125; // 暂时省略其他代码&#125; 如果明确一个对象实例不为NULL的时候，应该使用Optional#of()，例如： 123Order o = selectByOrderId(orderId);assert null != oOptional op = Optional.of(o); 如果无法明确一个对象实例是否为NULL的时候，应该使用Optional#ofNullable()，例如： 1Optional op = Optional.ofNullable(selectByOrderId(orderId)); 明确表示一个持有NULL值的Optional实例可以使用Optional.empty()。 get()方法 1234567// 如果value为空，则抛出NPE，否则直接返回valuepublic T get() &#123; if (value == null) &#123; throw new NoSuchElementException(\"No value present\"); &#125; return value;&#125; get()方法一般是需要明确value不为NULL的时候使用，它做了先验value的存在性。例如： 1234Order o = selectByOrderId(orderId);assert null != oOptional op = Optional.of(o);Order value = op.get(); isPresent()方法 1234// 判断value是否存在，不为NULL则返回true，如果为NULL则返回falsepublic boolean isPresent() &#123; return value != null;&#125; 举个例子： 12Order o = selectByOrderId(orderId);boolean existed = Optional.ofNullable(o).isPresent(); isEmpty()方法 isEmpty()是JDK11引入的方法，是isPresent()的反向判断： 1234// 判断value是否存在，为NULL则返回true，为非NULL则返回falsepublic boolean isEmpty() &#123; return value == null;&#125; ifPresent()方法 ifPresent()方法的作用是：如果value不为NULL，则使用value调用消费者函数式接口的消费方法Consumer#accept()： 12345public void ifPresent(Consumer&lt;? super T&gt; action) &#123; if (value != null) &#123; action.accept(value); &#125;&#125; 例如： 1Optional.ofNullable(selectByOrderId(orderId)).ifPresent(o-&gt; LOGGER.info(\"订单ID:&#123;&#125;\",o.getOrderId()); ifPresentOrElse()方法 ifPresentOrElse()方法是JDK9新增的方法，它是ifPresent()方法的加强版，如果value不为NULL，则使用value调用消费者函数式接口的消费方法Consumer#accept()，如果value为NULL则执行Runnable#run()： 1234567public void ifPresentOrElse(Consumer&lt;? super T&gt; action, Runnable emptyAction) &#123; if (value != null) &#123; action.accept(value); &#125; else &#123; emptyAction.run(); &#125;&#125; 例如： 12String orderId = \"xxxx\"; Optional.ofNullable(selectByOrderId(orderId)).ifPresentOrElse(o-&gt; LOGGER.info(\"订单ID:&#123;&#125;\",o.getOrderId()), ()-&gt; LOGGER.info(\"订单&#123;&#125;不存在\",o.getOrderId())); filter()方法 1234567891011public Optional&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate) &#123; // 判断predicate不能为NULL Objects.requireNonNull(predicate); // value为NULL，说明是空实例，则直接返回自身 if (!isPresent()) &#123; return this; &#125; else &#123; // value不为NULL，则通过predicate判断，命中返回自身，不命中则返回空实例empty return predicate.test(value) ? this : empty(); &#125;&#125; 这个方法的功能是简单的过滤功能，容器持有对象value非NULL会做一次判断，决定返回自身实例还是empty()。例如： 1Optional.ofNullable(selectByOrderId(orderId)).filter(o -&gt; o.getStatus() == 1).ifPresent(o-&gt; LOGGER.info(\"订单&#123;&#125;的状态为1\",o.getOrderId)); map()方法 map()是简单的值映射操作： 1234567891011public &lt;U&gt; Optional&lt;U&gt; map(Function&lt;? super T, ? extends U&gt; mapper) &#123; // 判断mapper不能为NULL Objects.requireNonNull(mapper); // value为NULL，说明是空实例，则直接返回empty() if (!isPresent()) &#123; return empty(); &#125; else &#123; // value不为NULL，通过mapper转换类型，重新封装为可空的Optional实例 return Optional.ofNullable(mapper.apply(value)); &#125;&#125; API注释里面的一个例子： 123List&lt;URI&gt; uris = ...;// 找到URI列表中未处理的URI对应的路径Optional&lt;Path&gt; p = uris.stream().filter(uri -&gt; !isProcessedYet(uri)).findFirst().map(Paths::get); flatMap()方法 flatMap()方法也是一个映射操作，不过映射的Optional类型返回值直接由外部决定，不需要通过值重新封装为Optional实例： 12345678910111213public &lt;U&gt; Optional&lt;U&gt; flatMap(Function&lt;? super T, ? extends Optional&lt;? extends U&gt;&gt; mapper) &#123; // mapper存在性判断 Objects.requireNonNull(mapper); // value为NULL，说明是空实例，则直接返回empty() if (!isPresent()) &#123; return empty(); &#125; else &#123; // value不为NULL，通过mapper转换，直接返回mapper的返回值，做一次空判断 @SuppressWarnings(\"unchecked\") Optional&lt;U&gt; r = (Optional&lt;U&gt;) mapper.apply(value); return Objects.requireNonNull(r); &#125;&#125; 例如： 123456789class OptionalOrderFactory&#123; static Optional&lt;Order&gt; create(String id)&#123; //省略... &#125;&#125;String orderId = \"xxx\";Optional&lt;Order&gt; op = Optional.of(orderId).flatMap(id -&gt; OptionalOrderFactory.create(id)); or()方法 12345678910111213public Optional&lt;T&gt; or(Supplier&lt;? extends Optional&lt;? extends T&gt;&gt; supplier) &#123; // supplier存在性判断 Objects.requireNonNull(supplier); // value不为NULL，则直接返回自身 if (isPresent()) &#123; return this; &#125; else &#123; // value为NULL，则返回supplier提供的Optional实例，做一次空判断 @SuppressWarnings(\"unchecked\") Optional&lt;T&gt; r = (Optional&lt;T&gt;) supplier.get(); return Objects.requireNonNull(r); &#125;&#125; 例如： 1234Order a = null;Order b = select();// 拿到的就是b订单实例包装的OptionalOptional&lt;Order&gt; op = Optional.ofNullable(a).or(b); stream()方法 12345678// 对value做NULL判断，转换为Stream类型public Stream&lt;T&gt; stream() &#123; if (!isPresent()) &#123; return Stream.empty(); &#125; else &#123; return Stream.of(value); &#125;&#125; orElse()方法 1234// 值不为NULL则直接返回value，否则返回otherpublic T orElse(T other) &#123; return value != null ? value : other;&#125; orElse()就是常见的提供默认值兜底的方法，例如： 1234String v1 = null;String v2 = \"default\";// 拿到的就是v2对应的\"default\"值String value = Optional.ofNullable(v1).orElse(v2); orElseGet()方法 1234// 值不为NULL则直接返回value，否则返回Supplier#get()public T orElseGet(Supplier&lt;? extends T&gt; supplier) &#123; return value != null ? value : supplier.get();&#125; orElseGet()只是orElse()方法的升级版，例如： 1234String v1 = null;Supplier&lt;String&gt; v2 = () -&gt; \"default\";// 拿到的就是v2对应的\"default\"值String value = Optional.ofNullable(v1).orElseGet(v2); orElseThrow()方法 12345678910111213141516// 如果值为NULL，则抛出NoSuchElementException，否则直接返回valuepublic T orElseThrow() &#123; if (value == null) &#123; throw new NoSuchElementException(\"No value present\"); &#125; return value;&#125;// 如果值不为NULL，则直接返回value，否则返回Supplier#get()提供的异常实例public &lt;X extends Throwable&gt; T orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier) throws X &#123; if (value != null) &#123; return value; &#125; else &#123; throw exceptionSupplier.get(); &#125;&#125; 例如： 1Optional.ofNullable(orderInfoVo.getAmount()).orElseThrow(()-&gt; new IllegalArgumentException(String.format(\"%s订单的amount不能为NULL\",orderInfoVo.getOrderId()))); equals()和hashCode()方法 12345678910111213141516public boolean equals(Object obj) &#123; if (this == obj) &#123; return true; &#125; if (!(obj instanceof Optional)) &#123; return false; &#125; Optional&lt;?&gt; other = (Optional&lt;?&gt;) obj; return Objects.equals(value, other.value);&#125;public int hashCode() &#123; return Objects.hashCode(value);&#125; 这两个方法都是比较value，说明了Optional实例如果使用于HashMap的KEY，只要value相同，对于HashMap就是同一个KEY。如： 1234567Map&lt;Optional,Boolean&gt; map = new HashMap&lt;&gt;();Optional&lt;String&gt; op1 = Optional.of(\"throwable\");map.put(op1, true);Optional&lt;String&gt; op2 = Optional.of(\"throwable\");map.put(op2, false);// 输出falseSystem.out.println(map.get(op1)); Optional实战 下面展示一下Optional的一些常见的使用场景。 空判断 空判断主要是用于不知道当前对象是否为NULL的时候，需要设置对象的属性。不使用Optional时候的代码如下： 123if(null != order)&#123; order.setAmount(orderInfoVo.getAmount());&#125; 使用Optional时候的代码如下： 123456Optional.ofNullable(order).ifPresent(o -&gt; o.setAmount(orderInfoVo.getAmount()));// 如果判断空的对象是OrderInfoVo如下Order o = select();OrderInfoVo vo = ...Optional.ofNullable(vo).ifPresent(v -&gt; o.setAmount(v.getAmount())); 使用Optional实现空判断的好处是只有一个属性设值的时候可以压缩代码为一行，这样做的话，代码会相对简洁。 断言 在维护一些老旧的系统的时候，很多情况下外部的传参没有做空判断，因此需要写一些断言代码如： 123456if (null == orderInfoVo.getAmount())&#123; throw new IllegalArgumentException(String.format(\"%s订单的amount不能为NULL\",orderInfoVo.getOrderId()));&#125;if (StringUtils.isBlank(orderInfoVo.getAddress())&#123; throw new IllegalArgumentException(String.format(\"%s订单的address不能为空\",orderInfoVo.getOrderId()));&#125; 使用Optional后的断言代码如下： 12Optional.ofNullable(orderInfoVo.getAmount()).orElseThrow(()-&gt; new IllegalArgumentException(String.format(\"%s订单的amount不能为NULL\",orderInfoVo.getOrderId())));Optional.ofNullable(orderInfoVo.getAddress()).orElseThrow(()-&gt; new IllegalArgumentException(String.format(\"%s订单的address不能为空\",orderInfoVo.getOrderId()))); 综合仿真案例 下面是一个仿真案例，模拟的步骤如下： 给出客户ID列表查询客户列表。 基于存在的客户列表中的客户ID查询订单列表。 基于订单列表转换为订单DTO视图列表。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Datastatic class Customer &#123; private Long id;&#125;@Datastatic class Order &#123; private Long id; private String orderId; private Long customerId;&#125;@Datastatic class OrderDto &#123; private String orderId;&#125;// 模拟客户查询private static List&lt;Customer&gt; selectCustomers(List&lt;Long&gt; ids) &#123; return null;&#125;// 模拟订单查询private static List&lt;Order&gt; selectOrders(List&lt;Long&gt; customerIds) &#123; return null;&#125;// main方法public static void main(String[] args) throws Exception &#123; List&lt;Long&gt; ids = new ArrayList&lt;&gt;(); List&lt;OrderDto&gt; view = Optional.ofNullable(selectCustomers(ids)) .filter(cs -&gt; !cs.isEmpty()) .map(cs -&gt; selectOrders(cs.stream().map(Customer::getId).collect(Collectors.toList()))) .map(orders -&gt; &#123; List&lt;OrderDto&gt; dtoList = new ArrayList&lt;&gt;(); orders.forEach(o -&gt; &#123; OrderDto dto = new OrderDto(); dto.setOrderId(o.getOrderId()); dtoList.add(dto); &#125;); return dtoList; &#125;).orElse(Collections.emptyList());&#125; 小结 Optional本质是一个对象容器，它的特征如下： Optional作为一个容器承载对象，提供方法适配部分函数式接口，结合部分函数式接口提供方法实现NULL判断、过滤操作、安全取值、映射操作等等。 Optional一般使用场景是用于方法返回值的包装，当然也可以作为临时变量从而享受函数式接口的便捷功能。 Optional只是一个简化操作的工具，可以解决多层嵌套代码的节点空判断问题（例如简化箭头型代码）。 Optional并非银弹。 这里提到箭头型代码，下面尝试用常规方法和Optional分别解决： 12345678910111213141516171819202122232425262728// 假设VO有多个层级，每个层级都不知道父节点是否为NULL，如下// - OrderInfoVo// - UserInfoVo// - AddressInfoVo// - address(属性)// 假设我要为address属性赋值，那么就会产生箭头型代码。// 常规方法String address = \"xxx\";OrderInfoVo o = ...;if(null != o)&#123; UserInfoVo uiv = o.getUserInfoVo(); if (null != uiv)&#123; AddressInfoVo aiv = uiv.getAddressInfoVo(); if (null != aiv)&#123; aiv.setAddress(address); &#125; &#125;&#125;// 使用OptionalString address = \"xxx\";OrderInfoVo o = null;Optional.ofNullable(o) .map(OrderInfoVo::getUserInfoVo) .map(UserInfoVo::getAddressInfoVo) .ifPresent(a -&gt; a.setAddress(address)); 使用Optional解决箭头型代码，通过映射操作map()能减少大量的if和NULL判断分支，使得代码更加简洁。 有些开发者提议把DAO方法的返回值类型定义为Optional，笔者对此持中立态度，原因是： Optional是JDK1.8引入，低版本的JDK并不能使用，不是所有的系统都能平滑迁移到JDK1.8+。 并不是所有人都热衷于函数式编程，因为它带来了便捷的同时转变了代码的阅读逻辑（有些人甚至会认为降低了代码的可读性）。 附件 Github Page：http://www.throwable.club/2019/08/07/java-functional-programming-optional Coding Page：http://throwable.coding.me/2019/08/07/java-functional-programming-optional Markdown或Asciidoc文件：https://github.com/zjcscut/blog-article-file/tree/master/20190807/java-functional-programming-optional （本文完 c-2-d e-a-20190805 by throwable）","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Functional Programming","slug":"Java/Functional-Programming","permalink":"http://throwable.club/blog/categories/Java/Functional-Programming/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Optional","slug":"Optional","permalink":"http://throwable.club/blog/tags/Optional/"}]},{"title":"JUC线程池服务ExecutorService接口实现源码分析","slug":"java-concurrency-executor-service","date":"2019-07-27T02:05:15.000Z","updated":"2019-07-27T02:10:11.616Z","comments":true,"path":"2019/07/27/java-concurrency-executor-service/","link":"","permalink":"http://throwable.club/2019/07/27/java-concurrency-executor-service/","excerpt":"前提 之前的一篇文章JUC线程池ThreadPoolExecutor源码分析深入分析了JUC线程池的源码实现，特别对Executor#execute()接口的实现做了行级别的源码分析。这篇文章主要分析一下线程池扩展服务ExecutorService接口的实现源码，同时会重点分析Future的底层实现。ThreadPoolExecutor和其抽象父类AbstractExecutorService的源码从JDK8到JDK11基本没有变化，本文编写的时候使用的是JDK11，由于ExecutorService接口的定义在JDK[8,11]都没有变化，本文的分析适用于这个JDK版本范围的任意版本。最近尝试找Hexo可以渲染Asciidoc的插件，但是没有找到，于是就先移植了Asciidoc中的五种Tip。","text":"前提 之前的一篇文章JUC线程池ThreadPoolExecutor源码分析深入分析了JUC线程池的源码实现，特别对Executor#execute()接口的实现做了行级别的源码分析。这篇文章主要分析一下线程池扩展服务ExecutorService接口的实现源码，同时会重点分析Future的底层实现。ThreadPoolExecutor和其抽象父类AbstractExecutorService的源码从JDK8到JDK11基本没有变化，本文编写的时候使用的是JDK11，由于ExecutorService接口的定义在JDK[8,11]都没有变化，本文的分析适用于这个JDK版本范围的任意版本。最近尝试找Hexo可以渲染Asciidoc的插件，但是没有找到，于是就先移植了Asciidoc中的五种Tip。 ExecutorService接口简介 ExecutorService接口是线程池扩展功能服务接口，它的定义如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public interface ExecutorService extends Executor &#123; // 停止线程池 void shutdown(); // 立即停止线程池，返回尚未执行的任务列表 List&lt;Runnable&gt; shutdownNow(); // 线程池是否停止 boolean isShutdown(); // 线程池是否终结 boolean isTerminated(); // 等待线程池终结 boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; // 提交Callable类型任务 &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); // 提交Runnable类型任务，预先知道返回值 &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); // 提交Runnable类型任务，对返回值无感知 Future&lt;?&gt; submit(Runnable task); // 永久阻塞 - 提交和执行一个任务列表的所有任务 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; // 带超时阻塞 - 提交和执行一个任务列表的所有任务 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; // 永久阻塞 - 提交和执行一个任务列表的某一个任务 &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; // 带超时阻塞 - 提交和执行一个任务列表的某一个任务 &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; ExecutorService继承自Executor，主要提供了线程池的关闭、状态查询查询、可获取返回值的任务提交、整个任务列表或者执行任务列表中任意一个任务（返回执行最快的任务的结果）等功能。 Future实现的通俗原理 ExecutorService接口的扩展方法都是返回Future相关的实例。java.util.concurrent.Future（中文翻译就是未来，还是挺有意思的），代表着一次异步计算的结果，它提供了检查计算是否已经完成、等待计算完成、获取计算结果等一系列方法。笔者之前强调过：线程池ThreadPoolExecutor的顶级接口Executor只提供了一个无状态的返回值类型为void的execute(Runnable command)方法，无法感知异步任务执行的完成时间和获取任务计算结果。如果我们需要感知异步任务执行的返回值或者计算结果，就必须提供带返回值的接口方法去承载计算结果的操作。这些方法上一节已经介绍过，而Future就是一个担任了承载计算结果（包括结果值、状态、阻塞等待获取结果操作等）的工具。这里举一个模拟Future实现过程的例子，例子是伪代码和真实代码的混合实现，不需要太较真。 首先，假设我们定义了一个动作函数式接口Action： 12345// 带泛型的动作接口，可以返回一个泛型结果public interface Action&lt;V&gt;&#123; V doAction();&#125; 我们可以尝试实现一下Action接口： 12345678910111213// 假设1个动作做的是一个十分复杂的运算，返回一个BigDecimal类型的结果Action&lt;BigDecimal&gt; action1 = () -&gt; &#123; // 模拟随机耗时 sleep(x秒); return BigDecimal.valueOf(result);&#125;;// 假设1个动作做的是制作一个面包的过程，返回一个Bread面包实例Action&lt;Bread&gt; action2 = () -&gt; &#123; // 模拟随机耗时 sleep(x秒); return new Bread();&#125;; 由于Action没有实现Runnable接口，上面的两个动作无法通过Executor#execute()方法提交异步任务，所以我们需要添加一个适配器ActionAdapter： 1234567891011121314151617public class ActionAdapter&lt;V&gt; implements Runnable &#123; private Action&lt;V&gt; action; private ActionAdapter(Action&lt;V&gt; action) &#123; this.action = action; &#125; public static &lt;V&gt; ActionAdapter&lt;V&gt; newActionAdapter(Action&lt;V&gt; action) &#123; return new ActionAdapter&lt;&gt;(action); &#125; @Override public void run() &#123; action.doAction(); &#125;&#125; 这里只做了简单粗暴的适配，虽然可以提交到线程池中执行，但是功能太过简陋。很多时候，我们还需要添加任务执行状态判断和获取结果的功能，于是新增一个接口ActionFuture： 123456public interface ActionFuture&lt;V&gt; extends Runnable&#123; V get() throws Exception; boolean isDone();&#125; 然后ActionAdapter实现ActionFuture接口，内部添加简单的状态控制： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class ActionAdapter&lt;V&gt; implements Runnable, ActionFuture&lt;V&gt; &#123; private static final int NEW = 0; private static final int DONE = 1; private int state; private final Action&lt;V&gt; action; private Object result; private ActionAdapter(Action&lt;V&gt; action) &#123; this.action = action; this.state = NEW; &#125; public static &lt;V&gt; ActionAdapter&lt;V&gt; newActionAdapter(Action&lt;V&gt; action) &#123; return new ActionAdapter&lt;&gt;(action); &#125; @Override public void run() &#123; try &#123; result = action.doAction(); &#125; catch (Throwable e) &#123; result = e; &#125; finally &#123; state = DONE; &#125; &#125; @Override public V get() throws Exception&#123; while (state &lt; DONE)&#123; // 这个等待方法没有实现，只是表明逻辑 currentThreadWaitForResult(); &#125; if (result instanceof Throwable)&#123; throw new ExecutionException((Throwable) result); &#125;else &#123; return (V) result; &#125; &#125; @Override public boolean isDone() &#123; return state == DONE; &#125;&#125; 这里有个技巧是用Object类型的对象存放Action执行的结果或者抛出的异常实例，这样可以在ActionFuture#get()方法中进行判断和处理。最后一步，依赖Executor#execute()新增一个提交异步任务的方法： 123456789101112131415161718192021222324252627282930public class ActionPool &#123; private final Executor executor; public ActionPool(Executor executor) &#123; this.executor = executor; &#125; public &lt;V&gt; ActionFuture&lt;V&gt; submit(Action&lt;V&gt; action) &#123; ActionFuture&lt;V&gt; actionFuture = ActionAdapter.newActionAdapter(action); executor.execute(actionFuture); return actionFuture; &#125; public static void main(String[] args) throws Exception&#123; ActionPool pool = new ActionPool(Executors.newSingleThreadExecutor()); Action&lt;BigDecimal&gt; action1 = () -&gt; &#123; // 模拟随机耗时 sleep(x秒); return BigDecimal.valueOf(result); &#125;; pool.submit(action1); Action&lt;Bread&gt; action2 = () -&gt; &#123; // 模拟随机耗时 sleep(x秒); return new Bread(); &#125;; pool.submit(action2); &#125;&#125; 上面例子提到的虚拟核心组件，在JUC包中有对应的实现（当时，JUC包对逻辑和状态控制会比虚拟例子更加严谨），对应关系如下： 虚拟组件 JUC中的组件 Action Callable ActionFuture RunnableFuture ActionAdapter FutureTask ActionPool ExecutorService(ThreadPoolExecutor) 其中大部分实现逻辑都由FutureTask和ThreadPoolExecutor的抽象父类AbstractExecutorService承担，下面会重点分析这两个类核心功能的源码实现。 Tip实际上，Future的实现使用的是Promise模式，具体可以查阅相关的资料。 FutureTask源码实现 提供回调的Runnable类型任务实际最终都会包装为FutureTask再提交到线程池中执行，而FutureTask是Runnable、Future和Callable三者的桥梁。先看FutureTask的类继承关系： 利用接口可以多继承的特性，RunnableFuture接口继承自Runnable和Future接口： 1234567891011121314151617181920212223242526272829public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125;@FunctionalInterfacepublic interface Runnable &#123; public abstract void run();&#125; public interface Future&lt;V&gt; &#123; // 取消，mayInterruptIfRunning用于控制是否中断，实际上这个方法并不能终止已经提交的任务，后面会详细说明 boolean cancel(boolean mayInterruptIfRunning); // 是否取消 boolean isCancelled(); // 是否完成，包括正常和异常的情况 boolean isDone(); // 永久阻塞获取结果，响应中断 V get() throws InterruptedException, ExecutionException; // 带超时的阻塞获取结果，响应中断 V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 而FutureTask实现了RunnableFuture接口，本质就是实现Runnable和Future接口的方法。先看FutureTask的重要属性： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 状态private volatile int state;// 初始化状态private static final int NEW = 0;// 完成中状态private static final int COMPLETING = 1;// 正常情况下的完成状态private static final int NORMAL = 2;// 异常情况下的完成状态private static final int EXCEPTIONAL = 3;// 取消状态private static final int CANCELLED = 4;// 中断中状态private static final int INTERRUPTING = 5;// 已中断状态private static final int INTERRUPTED = 6;// 底层的Callable实现，执行完毕后需要置为nullprivate Callable&lt;V&gt; callable;// 输出结果，如果是正常执行完成，get()方法会返回此结果，如果是异常执行完成，get()方法会抛出outcome包装为ExecutionException的异常private Object outcome; // 真正的执行Callable对象的线程实例，运行期间通过CAS操作此线程实例private volatile Thread runner;// 等待线程集合，Treiber Stack实现private volatile WaitNode waiters;// 下面是变量句柄，底层是基于Unsafe实现，通过相对顶层的操作原语，如CAS等private static final VarHandle STATE;private static final VarHandle RUNNER;private static final VarHandle WAITERS;static &#123; try &#123; MethodHandles.Lookup l = MethodHandles.lookup(); STATE = l.findVarHandle(FutureTask.class, \"state\", int.class); RUNNER = l.findVarHandle(FutureTask.class, \"runner\", Thread.class); WAITERS = l.findVarHandle(FutureTask.class, \"waiters\", WaitNode.class); &#125; catch (ReflectiveOperationException e) &#123; throw new ExceptionInInitializerError(e); &#125; // Reduce the risk of rare disastrous classloading in first call to // LockSupport.park: https://bugs.openjdk.java.net/browse/JDK-8074773 Class&lt;?&gt; ensureLoaded = LockSupport.class;&#125;// ... 省略其他代码 上面的主要属性中，有两点比较复杂，但却是最重要的： FutureTask生命周期的状态管理或者跃迁。 等待（获取结果）线程集合WaitNode基于Treiber Stack实现，需要彻底弄清楚Treiber Stack的工作原理。 FutureTask的状态管理 FutureTask的内建状态包括了七种，也就是属性state有七种可选状态值，总结成表格如下： 状态 状态值 描述 NEW 0 初始化状态，FutureTask实例创建时候在构造函数中标记为此状态 COMPLETING 1 完成中状态，这个是中间状态，执行完成后设置outcome之前标记为此状态 NORMAL 2 正常执行完成，通过调用get()方法能够获取正确的计算结果 EXCEPTIONAL 3 异常执行完成，通过调用get()方法会抛出包装后的ExecutionException异常 CANCELLED 4 取消状态 INTERRUPTING 5 中断中状态，执行线程实例Thread#interrupt()之前会标记为此状态 INTERRUPTED 6 中断完成状态 这些状态之间的跃迁流程图如下： 每一种状态跃迁都是由于调用或者触发了某个方法，下文的一个小节会分析这些方法的实现。 等待线程集合数据结构Treiber Stack的原理 Treiber Stack，中文翻译是驱动栈，听起来比较怪。实际上，Treiber Stack算法是R. Kent Treiber在其1986年的论文Systems Programming: Coping with Parallelism中首次提出，这种算法提供了一种可扩展的无锁栈，基于细粒度的并发原语CAS(Compare And Swap)实现。笔者并没有花时间去研读Treiber的论文，因为在Doug Lea大神参与编写的《Java Concurrency in Practice（Java并发编程实战）》中的第15.4.1小节中有简单分析非阻塞算法中的非阻塞栈。 在实现相同功能的前提下，非阻塞算法通常比基于锁的算法更加复杂。创建非阻塞算法的关键在于，找出如何将原子修改的范围缩小到单个变量上，同时还要维护数据的一致性。下面的ConcurrentStack是基于Java语言实现的Treiber算法： 123456789101112131415161718192021222324252627282930313233343536public class ConcurrentStack&lt;E&gt; &#123; private AtomicReference&lt;Node&lt;E&gt;&gt; top = new AtomicReference&lt;&gt;(); public void push(E item) &#123; Node&lt;E&gt; newHead = new Node&lt;&gt;(item); Node&lt;E&gt; oldHead; do &#123; oldHead = top.get(); newHead.next = oldHead; &#125; while (!top.compareAndSet(oldHead, newHead)); &#125; public E pop() &#123; Node&lt;E&gt; oldHead; Node&lt;E&gt; newHead; do &#123; oldHead = top.get(); if (null == oldHead) &#123; return null; &#125; newHead = oldHead.next; &#125; while (!top.compareAndSet(oldHead, newHead)); return oldHead.item; &#125; private static class Node&lt;E&gt; &#123; final E item; Node&lt;E&gt; next; Node(E item) &#123; this.item = item; &#125; &#125;&#125; ConcurrentStack是一个栈，它是由Node元素构成的一个链表，其中栈顶作为根节点，并且每个元素都包含了一个值以及指向下一个元素的链接。push()方法创建一个新的节点，该节点的next域指向了当前的栈顶，然后通过CAS把这个新节点放入栈顶。如果在开始插入节点时，位于栈顶的节点没有发生变化，那么CAS就会成功，如果栈顶节点发生变化（例如由于其他线程在当前线程开始之前插入或者移除了元素），那么CAS就会失败，而push()方法会根据栈的当前状态来更新节点（其实就是while循环会进入下一轮），并且再次尝试。无论哪种情况，在CAS执行完成之后，栈仍然回处于一致的状态。这里通过一个图来模拟一下push()方法的流程： 而pop()方法可以简单理解为push()方法的逆向操作，具体流程是： 创建一个引用newHead指向当前top的下一个节点，也就是top.next，top所在引用称为oldHead。 通过CAS更新top的值，伪代码是CAS(expect=oldHead,update=newHead)，如果更新成功，那么top就指向top.next，也就是newHead。 Warning这里可以看出Treiber Stack算法有个比较大的问题是有可能产生无效的节点，所以FutureTask也存在可能产生无效的等待节点的问题。 FutureTask方法源码分析 先看FutureTask提供的非阻塞栈节点的实现： 12345678// 等待获取结果的线程节点（集合），实际上是一个单链表，实现了一个非阻塞栈static final class WaitNode &#123; // 记录等待线程实例 volatile Thread thread; // 指向下一个节点的引用 volatile WaitNode next; WaitNode() &#123; thread = Thread.currentThread(); &#125;&#125; 和我们上面分析Treiber Stack时候使用的单链表如出一辙。接着看FutureTask的构造函数： 12345678910111213141516171819202122232425262728293031323334353637// 适配使用Callable类型任务的场景public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; &#125;// 适配使用Runnable类型任务和已经提供了最终计算结果的场景public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = NEW; &#125;// Executors中public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;T&gt;(task, result);&#125;// Runnable和Callable的适配器，设计十分巧妙，实际上run()方法委托给传入的Runnable实例执行，实现了Callable的call()方法，使用的是外部传入的值作为返回结果private static final class RunnableAdapter&lt;T&gt; implements Callable&lt;T&gt; &#123; private final Runnable task; private final T result; RunnableAdapter(Runnable task, T result) &#123; this.task = task; this.result = result; &#125; public T call() &#123; task.run(); return result; &#125; public String toString() &#123; return super.toString() + \"[Wrapped task = \" + task + \"]\"; &#125;&#125; 主要是针对两种不同场景的任务类型进行适配，构造函数中直接设置状态state = NEW(0)。因为FutureTask是最终的任务包装类，它的核心功能都在其实现的Runnable#run()方法中，这里重点分析一下run()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110// FutureTask实现的Runnable#run()方法public void run() &#123; // 如果状态不为NEW(0)或者CAS(null,当前线程实例)更新runner-真正的执行Callable对象的线程实例失败，那么直接返回，不执行任务 if (state != NEW || !RUNNER.compareAndSet(this, null, Thread.currentThread())) return; try &#123; // 获取Callable任务实例赋值到临时变量c Callable&lt;V&gt; c = callable; // 判断任务不能为空，二次校验状态必须为NEW(0) if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; // 调用任务实例Callable#call()方法，正常情况下的执行完毕，没有抛出异常，则记录执行结果 result = c.call(); // 记录正常执行完毕 ran = true; &#125; catch (Throwable ex) &#123; // 异常情况下的执行完毕，执行结果记录为null result = null; // 记录异常执行完毕 ran = false; // 设置异常实例 setException(ex); &#125; // 正常执行完毕设置结果 if (ran) set(result); &#125; &#125; finally &#123; // runner更新为null，防止并发执行run()方法 runner = null; // 记录新的状态值，因为run()方法执行的时候，状态值有可能被其他方法更新了 int s = state; if (s &gt;= INTERRUPTING) // 处理run()方法执行期间调用了cancel(true)方法的情况 handlePossibleCancellationInterrupt(s); &#125;&#125;// 异常执行挖鼻的情况下，设置异常实例protected void setException(Throwable t) &#123; // CAS更新状态state，由NEW(0)更新为COMPLETING(1) if (STATE.compareAndSet(this, NEW, COMPLETING)) &#123; // 设置异常实例到outcome属性中 outcome = t; // 设置最终状态state = EXCEPTIONAL(3)，意味着任务最终异常执行完毕 STATE.setRelease(this, EXCEPTIONAL); // final state // 完成后的通知方法 finishCompletion(); &#125;&#125;// 完成任务后的通知方法，最要作用是移除和唤醒所有的等待结果线程，调用钩子方法done()和设置任务实例callable为nullprivate void finishCompletion() &#123; // 遍历栈，终止条件是下一个元素为null for (WaitNode q; (q = waiters) != null;) &#123; // CAS设置栈顶为null if (WAITERS.weakCompareAndSet(this, q, null)) &#123; // 遍历栈中的所有节点，唤醒节点中的线程，这是一个十分常规的遍历单链表的方法，注意几点： // 1. 使用LockSupport.unpark()唤醒线程，因为后面会分析，线程阻塞等待的时候使用的是LockSupport.park()方法 // 2. 断开链表节点的时候后继节点需要置为null，这样游离节点才能更容易被JVM回收 for (;;) &#123; Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t); &#125; WaitNode next = q.next; if (next == null) break; q.next = null; q = next; &#125; break; &#125; &#125; // 回调钩子方法done()，这个可以通过子类进行扩展 done(); // 置任务实例callable为null，从而减少JVM memory footprint（这个东西有兴趣可以自行扩展阅读） callable = null; // to reduce footprint&#125;// 正常执行完毕的情况下设置执行结果protected void set(V v) &#123; // CAS更新状态state，由NEW(0)更新为COMPLETING(1) if (STATE.compareAndSet(this, NEW, COMPLETING)) &#123; // 最终执行结果值更新到outcome中 outcome = v; // 设置最终状态state = NORMAL(2)，意味着任务最终正常执行完毕 STATE.setRelease(this, NORMAL); // 完成后的通知方法 finishCompletion(); &#125;&#125;// 处理run()方法执行期间调用了cancel(true)方法的情况// 这里还没分析cancel()方法，但是可以提前告知：它会先把状态更新为INTERRUPTING，再进行线程中断，最后更新状态为INTERRUPTED// 所以如果发现当前状态为INTERRUPTING，当前线程需要让出CPU控制权等待到状态更变为INTERRUPTED即可，这个时间应该十分短暂private void handlePossibleCancellationInterrupt(int s) &#123; if (s == INTERRUPTING) while (state == INTERRUPTING) Thread.yield(); &#125;// 钩子方法，可以通过子类扩展此方法，方法回调的时机是任务已经执行完毕，阻塞获取结果的线程被唤醒之后protected void done() &#123; &#125; run()方法的执行流程比较直观，这里提供一个简单的流程图： FutureTask还提供了一个能够重置状态（准确来说是保持状态）的runAndReset()方法，这个方法专门提供给ScheduledThreadPoolExecutor使用： 123456789101112131415161718192021222324252627282930// 执行任务并且重置状态// 由于没有执行set()方法设置执行结果，这个方法除了执行过程中抛出异常或者主动取消会到导致state由NEW更变为其他值，正常执行完毕一个任务之后，state是保持为NEW不变protected boolean runAndReset() &#123; // 如果状态不为NEW(0)或者CAS(null,当前线程实例)更新runner-真正的执行Callable对象的线程实例失败，那么直接返回false，不执行任务 if (state != NEW || !RUNNER.compareAndSet(this, null, Thread.currentThread())) return false; boolean ran = false; int s = state; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; s == NEW) &#123; try &#123; // 这里会忽略执行结果，只记录是否正常执行 c.call(); ran = true; &#125; catch (Throwable ex) &#123; // 记录执行异常结果 setException(ex); &#125; &#125; &#125; finally &#123; runner = null; s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125; // 正常情况下的执行完毕，ran会更新为true，state此时也保持为NEW，这个时候方法返回true return ran &amp;&amp; s == NEW;&#125; runAndReset()方法保证了在任务正常执行完成之后返回true，此时FutureTask的状态state保持为NEW，由于没有调用set()方法，也就是没有调用finishCompletion()方法，它内部持有的Callable任务引用不会置为null，等待获取结果的线程集合也不会解除阻塞。这种设计方案专门针对可以周期性重复执行的任务。异常执行情况和取消的情况导致的最终结果和run()方法是一致的。接下来分析一下获取执行结果的get()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137// 获取执行结果 - 永久阻塞public V get() throws InterruptedException, ExecutionException &#123; int s = state; // 如果状态小于等于COMPLETING(1)，也就是COMPLETING(1)和NEW(0)，那么就需要等待任务完成 if (s &lt;= COMPLETING) // 注意这里调用awaitDone方法的参数为永久阻塞参数，也就是没有超时期限，返回最新的状态值 s = awaitDone(false, 0L); // 根据状态值报告结果 return report(s);&#125;// 获取执行结果 - 带超时的阻塞public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; if (unit == null) throw new NullPointerException(); int s = state; // 如果状态小于等于COMPLETING(1)，也就是COMPLETING(1)和NEW(0)，那么就需要等待任务完成 // 注意这里调用awaitDone方法的参数为带超时上限的阻塞参数 // 如果超过了指定的等待期限（注意会把时间转化为纳秒），返回的最新状态依然为COMPLETING(1)或者NEW(0)，那么抛出TimeoutException异常 if (s &lt;= COMPLETING &amp;&amp; (s = awaitDone(true, unit.toNanos(timeout))) &lt;= COMPLETING) throw new TimeoutException(); // 根据状态值报告结果 return report(s);&#125;// 等待任务完成，区分永久阻塞等待和带超时上限的阻塞等待两种场景private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; long startTime = 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; int s = state; // 如果状态值已经大于COMPLETING(1)，说明任务已经执行完毕，可以直接返回，如果等待节点已经初始化，则置空其线程实例引用，便于GC回收 if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; else if (s == COMPLETING) // 状态值等于COMPLETING(1)，说明任务执行到达尾声，在执行set()或者setException()，只需让出CPU控制权等待完成即可等待下一轮循环重试即可 Thread.yield(); else if (Thread.interrupted()) &#123; // 如果线程被中断，则清除其中断状态，并且断开超时或中断的等待节点的链接 removeWaiter(q); // 抛出InterruptedException异常 throw new InterruptedException(); &#125; else if (q == null) &#123; // 等待节点尚未初始化，如果设置了超时期限并且超时时间小于等于0，则直接返回状态并且终止等待，说明已经超时了 // 这里的逻辑属于先行校验，如果命中了就不用进行超时阻塞 if (timed &amp;&amp; nanos &lt;= 0L) return s; // 初始化等待节点 q = new WaitNode(); &#125; else if (!queued) //如果等待节点尚未加入到栈中，则把当前线程所在的节点压入栈中，top引用指向当前等待节点 // 这里就是Treiber Stack算法的入栈操作 queued = WAITERS.weakCompareAndSet(this, q.next = waiters, q); else if (timed) &#123; // 计算开始时间等待时间于当前时间的相差值作为阻塞的时间parkNanos，因为这里涉及到循环，startTime就是第一轮循环时候的当前系统纳秒 final long parkNanos; if (startTime == 0L) &#123; startTime = System.nanoTime(); if (startTime == 0L) startTime = 1L; parkNanos = nanos; &#125; else &#123; long elapsed = System.nanoTime() - startTime; if (elapsed &gt;= nanos) &#123; removeWaiter(q); return state; &#125; parkNanos = nanos - elapsed; &#125; // 如果状态为NEW(0)，则进行超时阻塞，阻塞的是当前的线程 if (state &lt; COMPLETING) LockSupport.parkNanos(this, parkNanos); &#125; else // 这种就是最后一个if分支，就是不命中任何条件的永久阻塞，阻塞的是当前的线程 LockSupport.park(this); &#125;&#125;// 移除等待节点，这个方法有两次使用的地方：// 1. 获取结果的线程进行阻塞等待的时候被中断的场景（处理中断）// 2. 获取结果的线程采用带超时的阻塞等待并且在进行阻塞之前已经判断到超时时间已经到期（处理不小心进栈的无效节点）// 实际上，这个方法就是Treiber Stack算法的出栈操作private void removeWaiter(WaitNode node) &#123; // 只有目标等待节点不空时候才处理 if (node != null) &#123; // 目标等待节点的线程引用置为空 node.thread = null; // 这里循环标记用于因为此方法执行的竞态条件需要重试的起点 retry: for (;;) &#123; // 遍历的终止条件：q != null，由于变化条件是q = s，并且每轮循环s = q.next，因此终止条件是栈节点的后继节点next为null for (WaitNode pred = null, q = waiters, s; q != null; q = s) &#123; // 第一轮循环，q其实就是栈顶节点，栈顶节点的后继节点为s，获取说q是当前需要处理的节点，s是其后继节点 s = q.next; // 如果当前节点时有效（持有的线程引用非空）的节点，则前驱节点pred更新为当前节点，进行下一轮遍历 if (q.thread != null) pred = q; // 如果当前节点已经无效，并且它存在前驱节点，那么前驱节点pred的后继节点引用连接到当前节点的后继节点s，实现当前节点的删除 // 这个是单链表删除中间某一个节点的常规操作 else if (pred != null) &#123; pred.next = s; // 如果在当前节点已经无效，并且它存在前驱节点，但是前驱节点二次判断为无效，说明出现了竞态，需要重新进行栈waiters的遍历 if (pred.thread == null) // check for race continue retry; &#125; // 当前节点已经无效，它不存在前驱节点，则直接把当前节点的后继节点s通过CAS更新栈顶节点 // 类比前面分析过的ConcurrentStack的pop()方法，这里的q就是oldHead，s就是newHead。 // CAS更新失败说明存在竞态，则需要重新进行栈waiters的遍历 else if (!WAITERS.compareAndSet(this, q, s)) continue retry; &#125; break; &#125; &#125;&#125;// 报告结果的方法，入参是awaitDone()方法返回的状态值private V report(int s) throws ExecutionException &#123; Object x = outcome; // 如果状态值为NORMAL(2)正常执行完毕，则直接基于outcome强转为目标类型实例 if (s == NORMAL) return (V)x; // 如果状态值大于等于CANCELLED(4)，则抛出CancellationException异常 if (s &gt;= CANCELLED) throw new CancellationException(); // 其他情况，实际上只剩下状态值为EXCEPTIONAL(3)，则基于outcome强转为Throwable类型，则包装成ExecutionException抛出 throw new ExecutionException((Throwable)x);&#125; 上面的方法中，removeWaiter()方法相对复杂，它涉及到单链表移除中间节点、考虑多种竞态情况进行重试等设计，需要花大量心思去理解。接着看cancel()方法： 123456789101112131415161718192021222324public boolean cancel(boolean mayInterruptIfRunning) &#123; // 状态必须为NEW(0) // 如果mayInterruptIfRunning为true，则把状态通过CAS更新为INTERRUPTING(5) // 如果mayInterruptIfRunning为false，则把状态通过CAS更新为CANCELLED(4) // 如果状态不为NEW(0)或者CAS更新失败，直接返回false，说明任务已经执行到set()或setException()，无法取消 if (!(state == NEW &amp;&amp; STATE.compareAndSet(this, NEW, mayInterruptIfRunning ? INTERRUPTING : CANCELLED))) return false; try &#123; // mayInterruptIfRunning为true，调用执行任务的线程实例的Thread#interrupt()进行中断，更新最终状态为INTERRUPTED(6) if (mayInterruptIfRunning) &#123; try &#123; Thread t = runner; if (t != null) t.interrupt(); &#125; finally &#123; // final state STATE.setRelease(this, INTERRUPTED); &#125; &#125; &#125; finally &#123; // 完成后的通知方法 finishCompletion(); &#125; return true;&#125; cancel()方法只能够中断状态为NEW(0)的线程，并且由于线程只在某些特殊情况下（例如阻塞在同步代码块或者同步方法中阻塞在Object#wait()方法、主动判断线程的中断状态等等）才能响应中断，所以需要思考这个方法是否可以达到预想的目的。最后看剩下的状态判断方法： 123456789// 判断是否取消状态，包括CANCELLED(4)、INTERRUPTING(5)、INTERRUPTED(6)三种状态public boolean isCancelled() &#123; return state &gt;= CANCELLED;&#125;// 判断是否已经完成，这里只是简单判断状态值不为NEW(0)，原因是所有的中间状态都是十分短暂的public boolean isDone() &#123; return state != NEW;&#125; AbstractExecutorService源码实现 AbstractExecutorService虽然只是ThreadPoolExecutor的抽象父类，但是它已经实现了ExecutorService接口中除了shutdown()、shutdownNow()、isShutdown()、isTerminated()和awaitTermination()五个方法之外的其他所有方法（这五个方法在ThreadPoolExecutor实现，因为它们是和线程池的状态相关的）。它的源码体积比较小，下面全量贴出分析： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213public abstract class AbstractExecutorService implements ExecutorService &#123; // 静态工厂方法，通过Runnable和具体的返回结果创建FutureTask实例 protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value); &#125; // 静态工厂方法，通过Callable实例创建FutureTask实例 protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable); &#125; // 提交Runnable类型任务 public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); // 适配任务为FutureTask实例，注意最终计算结果已经提前设置为null RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); // 提交到线程池 execute(ftask); return ftask; &#125; // 提交Runnable类型任务，同时传入最终计算结果 public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); // 适配任务为FutureTask实例 RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); // 提交到线程池 execute(ftask); return ftask; &#125; // 提交Callable类型任务 public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); // 适配任务为FutureTask实例 RunnableFuture&lt;T&gt; ftask = newTaskFor(task); // 提交到线程池 execute(ftask); return ftask; &#125; // 执行任务列表中的任意一个任务（实际上有可能会执行多个任务，确保最先完成的任务对应的结果返回） private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException &#123; if (tasks == null) throw new NullPointerException(); int ntasks = tasks.size(); if (ntasks == 0) throw new IllegalArgumentException(); ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;&gt;(ntasks); // 通过当前的线程池实例构建ExecutorCompletionService实例 ExecutorCompletionService&lt;T&gt; ecs = new ExecutorCompletionService&lt;T&gt;(this); try &#123; ExecutionException ee = null; // 计算deadline final long deadline = timed ? System.nanoTime() + nanos : 0L; Iterator&lt;? extends Callable&lt;T&gt;&gt; it = tasks.iterator(); // 提交任务列表的第一个任务实例 futures.add(ecs.submit(it.next())); --ntasks; int active = 1; for (;;) &#123; // 这里获取上一轮（或者第一个任务）任务执行的Future实例 Future&lt;T&gt; f = ecs.poll(); // 如果拿到Future实例为null说明上一轮的任务尚未执行完毕 if (f == null) &#123; // 如果任务队列中还有任务任务，则添加到线程池中执行 if (ntasks &gt; 0) &#123; --ntasks; futures.add(ecs.submit(it.next())); ++active; &#125; // 活跃计算任务为0，说明至少有一个任务成功返回了Future实例 else if (active == 0) break; else if (timed) &#123; // 允许超时的模式下用超时阻塞获取Future实例 f = ecs.poll(nanos, NANOSECONDS); if (f == null) throw new TimeoutException(); nanos = deadline - System.nanoTime(); &#125; // 非超时的模式下永久阻塞获取Future实例 else f = ecs.take(); &#125; // 获取到的Future实例不为null，说明已经有至少一个任务执行完毕 if (f != null) &#123; --active; try &#123; return f.get(); &#125; catch (ExecutionException eex) &#123; ee = eex; &#125; catch (RuntimeException rex) &#123; ee = new ExecutionException(rex); &#125; &#125; &#125; if (ee == null) ee = new ExecutionException(); throw ee; &#125; finally &#123; // 取消所有任务，确保至少有一个任务完成，即使取消所有任务，由于状态管理，成功的任务不受干扰 cancelAll(futures); &#125; &#125; // 永久阻塞 - 执行任务列表中的任意一个任务（实际上有可能会执行多个任务，确保最先完成的任务对应的结果返回） public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123; try &#123; return doInvokeAny(tasks, false, 0); &#125; catch (TimeoutException cannotHappen) &#123; assert false; return null; &#125; &#125; // 带超时阻塞 - 执行任务列表中的任意一个任务（实际上有可能会执行多个任务，确保最先完成的任务对应的结果返回） public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; return doInvokeAny(tasks, true, unit.toNanos(timeout)); &#125; // 永久阻塞 - 执行任务列表中的所有任务 public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123; if (tasks == null) throw new NullPointerException(); ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;&gt;(tasks.size()); try &#123; // 遍历任务列表进行FutureTask并且提交到线程池，FutureTask实例添加到futures列表中 for (Callable&lt;T&gt; t : tasks) &#123; RunnableFuture&lt;T&gt; f = newTaskFor(t); futures.add(f); execute(f); &#125; // 遍历futures列表调用get()方法获取结果，注意会忽略所有的CancellationException、ExecutionException for (int i = 0, size = futures.size(); i &lt; size; i++) &#123; Future&lt;T&gt; f = futures.get(i); if (!f.isDone()) &#123; try &#123; f.get(); &#125; catch (CancellationException | ExecutionException ignore) &#123;&#125; &#125; &#125; return futures; &#125; catch (Throwable t) &#123; // 只要出现非CancellationException或者ExecutionException异常，则取消所有任务，尚未执行或者尚未执行完毕的任务有可能受到影响 cancelAll(futures); throw t; &#125; &#125; // 带超时阻塞 - 执行任务列表中的所有任务 public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException &#123; if (tasks == null) throw new NullPointerException(); // 转换超时时间单位为纳秒 final long nanos = unit.toNanos(timeout); // 计算deadline final long deadline = System.nanoTime() + nanos; ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;&gt;(tasks.size()); int j = 0; timedOut: try &#123; // 遍历任务列表进行FutureTask，FutureTask实例添加到futures列表中 for (Callable&lt;T&gt; t : tasks) futures.add(newTaskFor(t)); final int size = futures.size(); // 遍历futures列表，进行一次超时先验，如果已经超时，则直接跳出，无须执行任务 for (int i = 0; i &lt; size; i++) &#123; // 这里有个特殊处理，第一个任务只要timeout不为0，必定会进行提交第二个任务起才判断deadline if (((i == 0) ? nanos : deadline - System.nanoTime()) &lt;= 0L) break timedOut; // 提交FutureTask到线程池 execute((Runnable)futures.get(i)); &#125; // j记录了超时的那个任务的Future的索引值，遍历futures列表进行超时阻塞的get()方法调用 for (; j &lt; size; j++) &#123; Future&lt;T&gt; f = futures.get(j); if (!f.isDone()) &#123; try &#123; f.get(deadline - System.nanoTime(), NANOSECONDS); &#125; catch (CancellationException | ExecutionException ignore) &#123;&#125; catch (TimeoutException timedOut) &#123; break timedOut; &#125; &#125; &#125; return futures; &#125; catch (Throwable t) &#123; cancelAll(futures); throw t; &#125; // 所有任务完成之前发现已经超时，则取消超时任务索引之后的所有任务，已经完成的不受影响 cancelAll(futures, j); return futures; &#125; // 取消所有的Future实例 private static &lt;T&gt; void cancelAll(ArrayList&lt;Future&lt;T&gt;&gt; futures) &#123; cancelAll(futures, 0); &#125; // 遍历所有的Future实例调用其cancel方法，因为参数为true，所以会响应中断 // j参数是决定遍历的起点，0表示整个列表遍历 private static &lt;T&gt; void cancelAll(ArrayList&lt;Future&lt;T&gt;&gt; futures, int j) &#123; for (int size = futures.size(); j &lt; size; j++) futures.get(j).cancel(true); &#125;&#125; 整个类的源码并不复杂，注意到Callable和Runnable的任务最重都会包装为适配器FutureTask的实例，然后通过execute()方法提交包装好的FutureTask任务实例，返回值是Future或者Future的集合时候，实际上是RunnableFuture或者RunnableFuture的集合，只因为RunnableFuture是Future的子接口，这种设计遵循了设计模式原则里面的依赖倒置原则。这里小结一下分析过的几个方法的特征： 方法 特征 submit(Runnable task) 异步执行，执行结果无感知，通过get()方法虽然返回null但是可以确定执行完毕的时刻 submit(Runnable task, T result) 异步执行，预先传入执行结果，最终通过get()方法返回的就是初始传入的结果 submit(Callable&lt;T&gt; task) 异步执行，最终通过get()方法返回的是Callable#call()的结果 invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) 异步执行任务列表中的任意一个任务（实际上有可能会执行多个任务，确保最先完成的任务对应的结果返回），永久阻塞同步返回结果 invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) 功能同上，获取结果的时候是超时阻塞获取 invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) 异步执行任务列表中的所有任务，必须等待所有Future#get()永久阻塞方法都返回了结果才返回Future列表 invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) 异步执行任务列表中的所有任务，只要其中一个任务Future#get()超时阻塞方法超时就会取消该任务索引之后的所有任务并且返回Future列表 小结 ExecutorService提供了一系列便捷的异步任务提交方法，它使用到多种技术： 相对底层的CAS原语。 基于CAS实现的无锁并发栈。 依赖于线程池实现的execute()方法进行异步任务提交。 使用适配器模式设计FutureTask适配Futrue、Runnable和Callable，提供了状态的生命周期管理。 下一篇文章将会分析一下调度线程池ScheduledThreadPoolExecutor的底层实现和源码。 （本文完 c-7-d e-a-20190727）","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Concurrency","slug":"Java/Concurrency","permalink":"http://throwable.club/blog/categories/Java/Concurrency/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"ExecutorService","slug":"ExecutorService","permalink":"http://throwable.club/blog/tags/ExecutorService/"}]},{"title":"JUC线程池ThreadPoolExecutor源码分析","slug":"java-concurrency-thread-pool-executor","date":"2019-07-15T15:58:25.000Z","updated":"2019-07-21T15:56:36.342Z","comments":true,"path":"2019/07/15/java-concurrency-thread-pool-executor/","link":"","permalink":"http://throwable.club/2019/07/15/java-concurrency-thread-pool-executor/","excerpt":"前提 很早之前就打算看一次JUC线程池ThreadPoolExecutor的源码实现，由于近段时间比较忙，一直没有时间整理出源码分析的文章。之前在分析扩展线程池实现可回调的Future时候曾经提到并发大师Doug Lea在设计线程池ThreadPoolExecutor的提交任务的顶层接口Executor只有一个无状态的执行方法： 1234public interface Executor &#123; void execute(Runnable command);&#125; 而ExecutorService提供了很多扩展方法底层基本上是基于Executor#execute()方法进行扩展。本文着重分析ThreadPoolExecutor#execute()的实现，笔者会从实现原理、源码实现等角度结合简化例子进行详细的分析。ThreadPoolExecutor的源码从JDK8到JDK11基本没有变化，本文编写的时候使用的是JDK11。","text":"前提 很早之前就打算看一次JUC线程池ThreadPoolExecutor的源码实现，由于近段时间比较忙，一直没有时间整理出源码分析的文章。之前在分析扩展线程池实现可回调的Future时候曾经提到并发大师Doug Lea在设计线程池ThreadPoolExecutor的提交任务的顶层接口Executor只有一个无状态的执行方法： 1234public interface Executor &#123; void execute(Runnable command);&#125; 而ExecutorService提供了很多扩展方法底层基本上是基于Executor#execute()方法进行扩展。本文着重分析ThreadPoolExecutor#execute()的实现，笔者会从实现原理、源码实现等角度结合简化例子进行详细的分析。ThreadPoolExecutor的源码从JDK8到JDK11基本没有变化，本文编写的时候使用的是JDK11。 ThreadPoolExecutor的原理 ThreadPoolExecutor里面使用到JUC同步器框架AbstractQueuedSynchronizer（俗称AQS）、大量的位操作、CAS操作。ThreadPoolExecutor提供了固定活跃线程（核心线程）、额外的线程（线程池容量 - 核心线程数这部分额外创建的线程，下面称为非核心线程）、任务队列以及拒绝策略这几个重要的功能。 JUC同步器框架 ThreadPoolExecutor里面使用到JUC同步器框架，主要用于四个方面： 全局锁mainLock成员属性，是可重入锁ReentrantLock类型，主要是用于访问工作线程Worker集合和进行数据统计记录时候的加锁操作。 条件变量termination，Condition类型，主要用于线程进行等待终结awaitTermination()方法时的带期限阻塞。 任务队列workQueue，BlockingQueue&lt;Runnable&gt;类型，任务队列，用于存放待执行的任务。 工作线程，内部类Worker类型，是线程池中真正的工作线程对象。 关于AQS笔者之前写过一篇相关源码分析的文章：JUC同步器框架AbstractQueuedSynchronizer源码图文分析。 核心线程 这里先参考ThreadPoolExecutor的实现并且进行简化，实现一个只有核心线程的线程池，要求如下： 暂时不考虑任务执行异常情况下的处理。 任务队列为无界队列。 线程池容量固定为核心线程数量。 暂时不考虑拒绝策略。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class CoreThreadPool implements Executor &#123; private BlockingQueue&lt;Runnable&gt; workQueue; private static final AtomicInteger COUNTER = new AtomicInteger(); private int coreSize; private int threadCount = 0; public CoreThreadPool(int coreSize) &#123; this.coreSize = coreSize; this.workQueue = new LinkedBlockingQueue&lt;&gt;(); &#125; @Override public void execute(Runnable command) &#123; if (++threadCount &lt;= coreSize) &#123; new Worker(command).start(); &#125; else &#123; try &#123; workQueue.put(command); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(e); &#125; &#125; &#125; private class Worker extends Thread &#123; private Runnable firstTask; public Worker(Runnable runnable) &#123; super(String.format(\"Worker-%d\", COUNTER.getAndIncrement())); this.firstTask = runnable; &#125; @Override public void run() &#123; Runnable task = this.firstTask; while (null != task || null != (task = getTask())) &#123; try &#123; task.run(); &#125; finally &#123; task = null; &#125; &#125; &#125; &#125; private Runnable getTask() &#123; try &#123; return workQueue.take(); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(e); &#125; &#125; public static void main(String[] args) throws Exception &#123; CoreThreadPool pool = new CoreThreadPool(5); IntStream.range(0, 10) .forEach(i -&gt; pool.execute(() -&gt; System.out.println(String.format(\"Thread:%s,value:%d\", Thread.currentThread().getName(), i)))); Thread.sleep(Integer.MAX_VALUE); &#125;&#125; 某次运行结果如下： 12345678910Thread:Worker-0,value:0Thread:Worker-3,value:3Thread:Worker-2,value:2Thread:Worker-1,value:1Thread:Worker-4,value:4Thread:Worker-1,value:5Thread:Worker-2,value:8Thread:Worker-4,value:7Thread:Worker-0,value:6Thread:Worker-3,value:9 设计此线程池的时候，核心线程是懒创建的，如果线程空闲的时候则阻塞在任务队列的take()方法，其实对于ThreadPoolExecutor也是类似这样实现，只是如果使用了keepAliveTime并且允许核心线程超时（allowCoreThreadTimeOut设置为true）则会使用BlockingQueue#poll(keepAliveTime)进行轮询代替永久阻塞。 其他附加功能 构建ThreadPoolExecutor实例的时候，需要定义maximumPoolSize（线程池最大线程数）和corePoolSize（核心线程数）。当任务队列是有界的阻塞队列，核心线程满负载，任务队列已经满的情况下，会尝试创建额外的maximumPoolSize - corePoolSize个线程去执行新提交的任务。当ThreadPoolExecutor这里实现的两个主要附加功能是： 一定条件下会创建非核心线程去执行任务，非核心线程的回收周期（线程生命周期终结时刻）是keepAliveTime，线程生命周期终结的条件是：下一次通过任务队列获取任务的时候并且存活时间超过keepAliveTime。 提供拒绝策略，也就是在核心线程满负载、任务队列已满、非核心线程满负载的条件下会触发拒绝策略。 源码分析 先分析线程池的关键属性，接着分析其状态控制，最后重点分析ThreadPoolExecutor#execute()方法。 关键属性 12345678910111213141516171819202122232425262728293031323334353637383940414243public class ThreadPoolExecutor extends AbstractExecutorService &#123; // 控制变量-存放状态和线程数 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); // 任务队列，必须是阻塞队列 private final BlockingQueue&lt;Runnable&gt; workQueue; // 工作线程集合，存放线程池中所有的（活跃的）工作线程，只有在持有全局锁mainLock的前提下才能访问此集合 private final HashSet&lt;Worker&gt; workers = new HashSet&lt;&gt;(); // 全局锁 private final ReentrantLock mainLock = new ReentrantLock(); // awaitTermination方法使用的等待条件变量 private final Condition termination = mainLock.newCondition(); // 记录峰值线程数 private int largestPoolSize; // 记录已经成功执行完毕的任务数 private long completedTaskCount; // 线程工厂，用于创建新的线程实例 private volatile ThreadFactory threadFactory; // 拒绝执行处理器，对应不同的拒绝策略 private volatile RejectedExecutionHandler handler; // 空闲线程等待任务的时间周期，单位是纳秒 private volatile long keepAliveTime; // 是否允许核心线程超时，如果为true则keepAliveTime对核心线程也生效 private volatile boolean allowCoreThreadTimeOut; // 核心线程数 private volatile int corePoolSize; // 线程池容量 private volatile int maximumPoolSize; // 省略其他代码&#125; 下面看参数列表最长的构造函数： 123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 可以自定义核心线程数、线程池容量（最大线程数）、空闲线程等待任务周期、任务队列、线程工厂、拒绝策略。下面简单分析一下每个参数的含义和作用： corePoolSize：int类型，核心线程数量。 maximumPoolSize：int类型，最大线程数量，也就是线程池的容量。 keepAliveTime：long类型，线程空闲等待时间，也和工作线程的生命周期有关，下文会分析。 unit：TimeUnit类型，keepAliveTime参数的时间单位，实际上keepAliveTime最终会转化为纳秒。 workQueue：BlockingQueue&lt;Runnable&gt;类型，等待队列或者叫任务队列。 threadFactory：ThreadFactory类型，线程工厂，用于创建工作线程（包括核心线程和非核心线程），默认使用Executors.defaultThreadFactory()作为内建线程工厂实例，一般自定义线程工厂才能更好地跟踪工作线程。 handler：RejectedExecutionHandler类型，线程池的拒绝执行处理器，更多时候称为拒绝策略，拒绝策略执行的时机是当阻塞队列已满、没有空闲的线程（包括核心线程和非核心线程）并且继续提交任务。提供了4种内建的拒绝策略实现： AbortPolicy：直接拒绝策略，也就是不会执行任务，直接抛出RejectedExecutionException，这是默认的拒绝策略。 DiscardPolicy：抛弃策略，也就是直接忽略提交的任务（通俗来说就是空实现）。 DiscardOldestPolicy：抛弃最老任务策略，也就是通过poll()方法取出任务队列队头的任务抛弃，然后执行当前提交的任务。 CallerRunsPolicy：调用者执行策略，也就是当前调用Executor#execute()的线程直接调用任务Runnable#run()，一般不希望任务丢失会选用这种策略，但从实际角度来看，原来的异步调用意图会退化为同步调用。 状态控制 状态控制主要围绕原子整型成员变量ctl： 1234567891011121314151617181920212223242526272829303132333435363738394041424344private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int COUNT_MASK = (1 &lt;&lt; COUNT_BITS) - 1;private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;// 通过ctl值获取运行状态private static int runStateOf(int c) &#123; return c &amp; ~COUNT_MASK; &#125;// 通过ctl值获取工作线程数private static int workerCountOf(int c) &#123; return c &amp; COUNT_MASK; &#125;// 通过运行状态和工作线程数计算ctl的值，或运算private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;private static boolean runStateLessThan(int c, int s) &#123; return c &lt; s;&#125;private static boolean runStateAtLeast(int c, int s) &#123; return c &gt;= s;&#125;private static boolean isRunning(int c) &#123; return c &lt; SHUTDOWN;&#125;// CAS操作线程数增加1private boolean compareAndIncrementWorkerCount(int expect) &#123; return ctl.compareAndSet(expect, expect + 1);&#125;// CAS操作线程数减少1private boolean compareAndDecrementWorkerCount(int expect) &#123; return ctl.compareAndSet(expect, expect - 1);&#125;// 线程数直接减少1private void decrementWorkerCount() &#123; ctl.addAndGet(-1);&#125; 接下来分析一下线程池的状态变量，工作线程上限数量位的长度是COUNT_BITS，它的值是Integer.SIZE - 3，也就是正整数29： 我们知道，整型包装类型Integer实例的大小是4 byte，一共32 bit，也就是一共有32个位用于存放0或者1。 在ThreadPoolExecutor实现中，使用32位的整型包装类型存放工作线程数和线程池状态。 其中，低29位用于存放工作线程数，而高3位用于存放线程池状态，所以线程池的状态最多只能有2^3种。 工作线程上限数量为2^29 - 1，超过5亿，这个数量在短时间内不用考虑会超限。 接着看工作线程上限数量掩码COUNT_MASK，它的值是(1 &lt; COUNT_BITS) - l，也就是1左移29位，再减去1，如果补全32位，它的位视图如下： 然后就是线程池的状态常量，这里只详细分析其中一个，其他类同，这里看RUNNING状态： 12345// -1的补码为：111-11111111111111111111111111111// 左移29位后：111-00000000000000000000000000000// 10进制值为：-536870912 // 高3位111的值就是表示线程池正在处于运行状态private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; 控制变量ctl的组成就是通过线程池运行状态rs和工作线程数wc通过或运算得到的： 1234567// rs=RUNNING值为：111-00000000000000000000000000000// wc的值为0：000-00000000000000000000000000000// rs | wc的结果为：111-00000000000000000000000000000private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 那么我们怎么从ctl中取出高3位的线程池状态？上面源码中提供的runStateOf()方法就是提取运行状态： 123456// 先把COUNT_MASK取反(~COUNT_MASK)，得到：111-00000000000000000000000000000// ctl位图特点是：xxx-yyyyyyyyyyyyyyyyyyyyyyyyyyyyyy// 两者做一次与运算即可得到高3位xxxprivate static int runStateOf(int c)&#123; return c &amp; ~COUNT_MASK; &#125; 同理，取出低29位的工作线程数量只需要把ctl和COUNT_MASK(000-11111111111111111111111111111)做一次与运算即可。 工作线程数为0的前提下，小结一下线程池的运行状态常量： 状态名称 位图 十进制值 描述 RUNNING 111-00000000000000000000000000000 -536870912 运行中状态，可以接收新的任务和执行任务队列中的任务 SHUTDOWN 000-00000000000000000000000000000 0 shutdown状态，不再接收新的任务，但是会执行任务队列中的任务 STOP 001-00000000000000000000000000000 536870912 停止状态，不再接收新的任务，也不会执行任务队列中的任务，中断所有执行中的任务 TIDYING 010-00000000000000000000000000000 1073741824 整理中状态，所有任务已经终结，工作线程数为0，过渡到此状态的工作线程会调用钩子方法terminated() TERMINATED 011-00000000000000000000000000000 1610612736 终结状态，钩子方法terminated()执行完毕 这里有一个比较特殊的技巧，由于运行状态值存放在高3位，所以可以直接通过十进制值（甚至可以忽略低29位，直接用ctl进行比较，或者使用ctl和线程池状态常量进行比较）来比较和判断线程池的状态： 工作线程数为0的前提下：RUNNING(-536870912) &lt; SHUTDOWN(0) &lt; STOP(536870912) &lt; TIDYING(1073741824) &lt; TERMINATED(1610612736) 下面这三个方法就是使用这种技巧： 1234567891011121314// ctl和状态常量比较，判断是否小于private static boolean runStateLessThan(int c, int s) &#123; return c &lt; s;&#125;// ctl和状态常量比较，判断是否小于或等于private static boolean runStateAtLeast(int c, int s) &#123; return c &gt;= s;&#125;// ctl和状态常量SHUTDOWN比较，判断是否处于RUNNING状态private static boolean isRunning(int c) &#123; return c &lt; SHUTDOWN;&#125; 最后是线程池状态的跃迁图： PS：线程池源码中有很多中间变量用了简单的单字母表示，例如c就是表示ctl、wc就是表示worker count、rs就是表示running status。 execute方法源码分析 线程池异步执行任务的方法实现是ThreadPoolExecutor#execute()，源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 执行命令，其中命令（下面称任务）对象是Runnable的实例public void execute(Runnable command) &#123; // 判断命令（任务）对象非空 if (command == null) throw new NullPointerException(); // 获取ctl的值 int c = ctl.get(); // 判断如果当前工作线程数小于核心线程数，则创建新的核心线程并且执行传入的任务 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) // 如果创建新的核心线程成功则直接返回 return; // 这里说明创建核心线程失败，需要更新ctl的临时变量c c = ctl.get(); &#125; // 走到这里说明创建新的核心线程失败，也就是当前工作线程数大于等于corePoolSize // 判断线程池是否处于运行中状态，同时尝试用非阻塞方法向任务队列放入任务（放入任务失败返回false） if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 这里是向任务队列投放任务成功，对线程池的运行中状态做二次检查 // 如果线程池二次检查状态是非运行中状态，则从任务队列移除当前的任务调用拒绝策略处理之（也就是移除前面成功入队的任务实例） if (! isRunning(recheck) &amp;&amp; remove(command)) // 调用拒绝策略处理任务 - 返回 reject(command); // 走到下面的else if分支，说明有以下的前提： // 0、待执行的任务已经成功加入任务队列 // 1、线程池可能是RUNNING状态 // 2、传入的任务可能从任务队列中移除失败（移除失败的唯一可能就是任务已经被执行了） // 如果当前工作线程数量为0，则创建一个非核心线程并且传入的任务对象为null - 返回 // 也就是创建的非核心线程不会马上运行，而是等待获取任务队列的任务去执行 // 如果前工作线程数量不为0，原来应该是最后的else分支，但是可以什么也不做，因为任务已经成功入队列，总会有合适的时机分配其他空闲线程去执行它 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 走到这里说明有以下的前提： // 0、线程池中的工作线程总数已经大于等于corePoolSize（简单来说就是核心线程已经全部懒创建完毕） // 1、线程池可能不是RUNNING状态 // 2、线程池可能是RUNNING状态同时任务队列已经满了 // 如果向任务队列投放任务失败，则会尝试创建非核心线程传入任务执行 // 创建非核心线程失败，此时需要拒绝执行任务 else if (!addWorker(command, false)) // 调用拒绝策略处理任务 - 返回 reject(command);&#125; 这里简单分析一下整个流程： 如果当前工作线程总数小于corePoolSize，则直接创建核心线程执行任务（任务实例会传入直接用于构造工作线程实例）。 如果当前工作线程总数大于等于corePoolSize，判断线程池是否处于运行中状态，同时尝试用非阻塞方法向任务队列放入任务，这里会二次检查线程池运行状态，如果当前工作线程数量为0，则创建一个非核心线程并且传入的任务对象为null。 如果向任务队列投放任务失败（任务队列已经满了），则会尝试创建非核心线程传入任务实例执行。 如果创建非核心线程失败，此时需要拒绝执行任务，调用拒绝策略处理任务。 这里是一个疑惑点：为什么需要二次检查线程池的运行状态，当前工作线程数量为0，尝试创建一个非核心线程并且传入的任务对象为null？这个可以看API注释： 如果一个任务成功加入任务队列，我们依然需要二次检查是否需要添加一个工作线程（因为所有存活的工作线程有可能在最后一次检查之后已经终结）或者执行当前方法的时候线程池是否已经shutdown了。所以我们需要二次检查线程池的状态，必须时把任务从任务队列中移除或者在没有可用的工作线程的前提下新建一个工作线程。 任务提交流程从调用者的角度来看如下： addWorker方法源码分析 boolean addWorker(Runnable firstTask, boolean core)方法的第一的参数可以用于直接传入任务实例，第二个参数用于标识将要创建的工作线程是否核心线程。方法源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105// 添加工作线程，如果返回false说明没有新创建工作线程，如果返回true说明创建和启动工作线程成功private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: // 注意这是一个死循环 - 最外层循环 for (int c = ctl.get();;) &#123; // 这个是十分复杂的条件，这里先拆分多个与（&amp;&amp;）条件： // 1. 线程池状态至少为SHUTDOWN状态，也就是rs &gt;= SHUTDOWN(0) // 2. 线程池状态至少为STOP状态，也就是rs &gt;= STOP(1)，或者传入的任务实例firstTask不为null，或者任务队列为空 // 其实这个判断的边界是线程池状态为shutdown状态下，不会再接受新的任务，在此前提下如果状态已经到了STOP、或者传入任务不为空、或者任务队列为空（已经没有积压任务）都不需要添加新的线程 if (runStateAtLeast(c, SHUTDOWN) &amp;&amp; (runStateAtLeast(c, STOP) || firstTask != null || workQueue.isEmpty())) return false; // 注意这也是一个死循环 - 二层循环 for (;;) &#123; // 这里每一轮循环都会重新获取工作线程数wc // 1. 如果传入的core为true，表示将要创建核心线程，通过wc和corePoolSize判断，如果wc &gt;= corePoolSize，则返回false表示创建核心线程失败 // 1. 如果传入的core为false，表示将要创非建核心线程，通过wc和maximumPoolSize判断，如果wc &gt;= maximumPoolSize，则返回false表示创建非核心线程失败 if (workerCountOf(c) &gt;= ((core ? corePoolSize : maximumPoolSize) &amp; COUNT_MASK)) return false; // 成功通过CAS更新工作线程数wc，则break到最外层的循环 if (compareAndIncrementWorkerCount(c)) break retry; // 走到这里说明了通过CAS更新工作线程数wc失败，这个时候需要重新判断线程池的状态是否由RUNNING已经变为SHUTDOWN c = ctl.get(); // Re-read ctl // 如果线程池状态已经由RUNNING已经变为SHUTDOWN，则重新跳出到外层循环继续执行 if (runStateAtLeast(c, SHUTDOWN)) continue retry; // 如果线程池状态依然是RUNNING，CAS更新工作线程数wc失败说明有可能是并发更新导致的失败，则在内层循环重试即可 // else CAS failed due to workerCount change; retry inner loop &#125; &#125; // 标记工作线程是否启动成功 boolean workerStarted = false; // 标记工作线程是否创建成功 boolean workerAdded = false; Worker w = null; try &#123; // 传入任务实例firstTask创建Worker实例，Worker构造里面会通过线程工厂创建新的Thread对象，所以下面可以直接操作Thread t = w.thread // 这一步Worker实例已经创建，但是没有加入工作线程集合或者启动它持有的线程Thread实例 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; // 这里需要全局加锁，因为会改变一些指标值和非线程安全的集合 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int c = ctl.get(); // 这里主要在加锁的前提下判断ThreadFactory创建的线程是否存活或者判断获取锁成功之后线程池状态是否已经更变为SHUTDOWN // 1. 如果线程池状态依然为RUNNING，则只需要判断线程实例是否存活，需要添加到工作线程集合和启动新的Worker // 2. 如果线程池状态小于STOP，也就是RUNNING或者SHUTDOWN状态下，同时传入的任务实例firstTask为null，则需要添加到工作线程集合和启动新的Worker // 对于2，换言之，如果线程池处于SHUTDOWN状态下，同时传入的任务实例firstTask不为null，则不会添加到工作线程集合和启动新的Worker // 这一步其实有可能创建了新的Worker实例但是并不启动（临时对象，没有任何强引用），这种Worker有可能成功下一轮GC被收集的垃圾对象 if (isRunning(c) || (runStateLessThan(c, STOP) &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 把创建的工作线程实例添加到工作线程集合 workers.add(w); int s = workers.size(); // 尝试更新历史峰值工作线程数，也就是线程池峰值容量 if (s &gt; largestPoolSize) largestPoolSize = s; // 这里更新工作线程是否启动成功标识为true，后面才会调用Thread#start()方法启动真实的线程实例 workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // 如果成功添加工作线程，则调用Worker内部的线程实例t的Thread#start()方法启动真实的线程实例 if (workerAdded) &#123; t.start(); // 标记线程启动成功 workerStarted = true; &#125; &#125; &#125; finally &#123; // 线程启动失败，需要从工作线程集合移除对应的Worker if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125;// 添加Worker失败private void addWorkerFailed(Worker w) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 从工作线程集合移除之 if (w != null) workers.remove(w); // wc数量减1 decrementWorkerCount(); // 基于状态判断尝试终结线程池 tryTerminate(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; 笔者发现了Doug Lea大神十分喜欢复杂的条件判断，而且单行复杂判断不喜欢加花括号，像下面这种代码在他编写的很多类库中都比较常见： 123456789101112if (runStateAtLeast(c, SHUTDOWN) &amp;&amp; (runStateAtLeast(c, STOP) || firstTask != null || workQueue.isEmpty())) return false;// ....// 代码拆分一下如下 boolean atLeastShutdown = runStateAtLeast(c, SHUTDOWN); # rs &gt;= SHUTDOWN(0)boolean atLeastStop = runStateAtLeast(c, STOP) || firstTask != null || workQueue.isEmpty(); if (atLeastShutdown &amp;&amp; atLeastStop)&#123; return false;&#125; 上面的分析逻辑中需要注意一点，Worker实例创建的同时，在其构造函数中会通过ThreadFactory创建一个Java线程Thread实例，后面会加锁后二次检查是否需要把Worker实例添加到工作线程集合workers中和是否需要启动Worker中持有的Thread实例，只有启动了Thread实例实例，Worker才真正开始运作，否则只是一个无用的临时对象。Worker本身也实现了Runnable接口，它可以看成是一个Runnable的适配器。 工作线程内部类Worker源码分析 线程池中的每一个具体的工作线程被包装为内部类Worker实例，Worker继承于AbstractQueuedSynchronizer(AQS)，实现了Runnable接口： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; // 保存ThreadFactory创建的线程实例，如果ThreadFactory创建线程失败则为null final Thread thread; // 保存传入的Runnable任务实例 Runnable firstTask; // 记录每个线程完成的任务总数 volatile long completedTasks; // 唯一的构造函数，传入任务实例firstTask，注意可以为null Worker(Runnable firstTask) &#123; // 禁止线程中断，直到runWorker()方法执行 setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; // 通过ThreadFactory创建线程实例，注意一下Worker实例自身作为Runnable用于创建新的线程实例 this.thread = getThreadFactory().newThread(this); &#125; // 委托到外部的runWorker()方法，注意runWorker()方法是线程池的方法，而不是Worker的方法 public void run() &#123; runWorker(this); &#125; // Lock methods // // The value 0 represents the unlocked state. // The value 1 represents the locked state. // 是否持有独占锁，state值为1的时候表示持有锁，state值为0的时候表示已经释放锁 protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; // 独占模式下尝试获取资源，这里没有判断传入的变量，直接CAS判断0更新为1是否成功，成功则设置独占线程为当前线程 protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; // 独占模式下尝试是否资源，这里没有判断传入的变量，直接把state设置为0 protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; // 加锁 public void lock() &#123; acquire(1); &#125; // 尝试加锁 public boolean tryLock() &#123; return tryAcquire(1); &#125; // 解锁 public void unlock() &#123; release(1); &#125; // 是否锁定 public boolean isLocked() &#123; return isHeldExclusively(); &#125; // 启动后进行线程中断，注意这里会判断线程实例的中断标志位是否为false，只有中断标志位为false才会中断 void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125;&#125; Worker的构造函数里面的逻辑十分重要，通过ThreadFactory创建的Thread实例同时传入Worker实例，因为Worker本身实现了Runnable，所以可以作为任务提交到线程中执行。只要Worker持有的线程实例w调用Thread#start()方法就能在合适时机执行Worker#run()。简化一下逻辑如下： 12345678// addWorker()方法中构造Worker worker = createWorker();// 通过线程池构造时候传入ThreadFactory threadFactory = getThreadFactory();// Worker构造函数中Thread thread = threadFactory.newThread(worker);// addWorker()方法中启动thread.start(); Worker继承自AQS，这里使用了AQS的独占模式，有个技巧是构造Worker的时候，把AQS的资源（状态）通过setState(-1)设置为-1，这是因为Worker实例刚创建时AQS中state的默认值为0，此时线程尚未启动，不能在这个时候进行线程中断，见Worker#interruptIfStarted()方法。Worker中两个覆盖AQS的方法tryAcquire()和tryRelease()都没有判断外部传入的变量，前者直接CAS(0,1)，后者直接setState(0)。接着看核心方法ThreadPoolExecutor#runWorker()： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556final void runWorker(Worker w) &#123; // 获取当前线程，实际上和Worker持有的线程实例是相同的 Thread wt = Thread.currentThread(); // 获取Worker中持有的初始化时传入的任务对象，这里注意存放在临时变量task中 Runnable task = w.firstTask; // 设置Worker中持有的初始化时传入的任务对象为null w.firstTask = null; // 由于Worker初始化时AQS中state设置为-1，这里要先做一次解锁把state更新为0，允许线程中断 w.unlock(); // allow interrupts // 记录线程是否因为用户异常终结，默认是true boolean completedAbruptly = true; try &#123; // 初始化任务对象不为null，或者从任务队列获取任务不为空（从任务队列获取到的任务会更新到临时变量task中） // getTask()由于使用了阻塞队列，这个while循环如果命中后半段会处于阻塞或者超时阻塞状态，getTask()返回为null会导致线程跳出死循环使线程终结 while (task != null || (task = getTask()) != null) &#123; // Worker加锁，本质是AQS获取资源并且尝试CAS更新state由0更变为1 w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt // 如果线程池正在停止（也就是由RUNNING或者SHUTDOWN状态向STOP状态变更），那么要确保当前工作线程是中断状态 // 否则，要保证当前线程不是中断状态 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; // 钩子方法，任务执行前 beforeExecute(wt, task); try &#123; task.run(); // 钩子方法，任务执行后 - 正常情况 afterExecute(task, null); &#125; catch (Throwable ex) &#123; // 钩子方法，任务执行后 - 异常情况 afterExecute(task, ex); throw ex; &#125; &#125; finally &#123; // 清空task临时变量，这个很重要，否则while会死循环执行同一个task task = null; // 累加Worker完成的任务数 w.completedTasks++; // Worker解锁，本质是AQS释放资源，设置state为0 w.unlock(); &#125; &#125; // 走到这里说明某一次getTask()返回为null，线程正常退出 completedAbruptly = false; &#125; finally &#123; // 处理线程退出，completedAbruptly为true说明由于用户异常导致线程非正常退出 processWorkerExit(w, completedAbruptly); &#125;&#125; 这里重点拆解分析一下判断当前工作线程中断状态的代码： 12345678910111213if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt();// 先简化一下判断逻辑，如下// 判断线程池状态是否至少为STOP，rs &gt;= STOP(1)boolean atLeastStop = runStateAtLeast(ctl.get(), STOP);// 判断线程池状态是否至少为STOP，同时判断当前线程的中断状态并且清空当前线程的中断状态boolean interruptedAndAtLeastStop = Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP);if (atLeastStop || interruptedAndAtLeastStop &amp;&amp; !wt.isInterrupted())&#123; wt.interrupt();&#125; Thread.interrupted()方法获取线程的中断状态同时会清空该中断状态，这里之所以会调用这个方法是因为在执行上面这个if逻辑同时外部有可能调用shutdownNow()方法，shutdownNow()方法中也存在中断所有Worker线程的逻辑，但是由于shutdownNow()方法中会遍历所有Worker做线程中断，有可能无法及时在任务提交到Worker执行之前进行中断，所以这个中断逻辑会在Worker内部执行，就是if代码块的逻辑。这里还要注意的是：STOP状态下会拒绝所有新提交的任务，不会再执行任务队列中的任务，同时会中断所有Worker线程。也就是，即使任务Runnable已经runWorker()中前半段逻辑取出，只要还没走到调用其Runnable#run()，都有可能被中断。假设刚好发生了进入if代码块的逻辑同时外部调用了shutdownNow()方法，那么if逻辑内会判断线程中断状态并且重置，那么shutdownNow()方法中调用的interruptWorkers()就不会因为中断状态判断出现问题导致二次中断线程（会导致异常）。 小结一下上面runWorker()方法的核心流程： Worker先执行一次解锁操作，用于解除不可中断状态。 通过while循环调用getTask()方法从任务队列中获取任务（当然，首轮循环也有可能是外部传入的firstTask任务实例）。 如果线程池更变为STOP状态，则需要确保工作线程是中断状态并且进行中断处理，否则要保证工作线程必须不是中断状态。 执行任务实例Runnale#run()方法，任务实例执行之前和之后（包括正常执行完毕和异常执行情况）分别会调用钩子方法beforeExecute()和afterExecute()。 while循环跳出意味着runWorker()方法结束和工作线程生命周期结束（Worker#run()生命周期完结），会调用processWorkerExit()处理工作线程退出的后续工作。 接下来分析一下从任务队列中获取任务的getTask()方法和处理线程退出的后续工作的processWorkerExit()方法。 getTask方法源码分析 getTask()方法是工作线程在while死循环中获取任务队列中的任务对象的方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253private Runnable getTask() &#123; // 记录上一次从队列中拉取的时候是否超时 boolean timedOut = false; // Did the last poll() time out? // 注意这是死循环 for (;;) &#123; int c = ctl.get(); // Check if queue empty only if necessary. // 第一个if：如果线程池状态至少为SHUTDOWN，也就是rs &gt;= SHUTDOWN(0)，则需要判断两种情况（或逻辑）： // 1. 线程池状态至少为STOP(1)，也就是线程池正在停止，一般是调用了shutdownNow()方法 // 2. 任务队列为空 // 如果在线程池至少为SHUTDOWN状态并且满足上面两个条件之一，则工作线程数wc减去1，然后直接返回null if (runStateAtLeast(c, SHUTDOWN) &amp;&amp; (runStateAtLeast(c, STOP) || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; // 跑到这里说明线程池还处于RUNNING状态，重新获取一次工作线程数 int wc = workerCountOf(c); // Are workers subject to culling? // timed临时变量勇于线程超时控制，决定是否需要通过poll()此带超时的非阻塞方法进行任务队列的任务拉取 // 1.allowCoreThreadTimeOut默认值为false，如果设置为true，则允许核心线程也能通过poll()方法从任务队列中拉取任务 // 2.工作线程数大于核心线程数的时候，说明线程池中创建了额外的非核心线程，这些非核心线程一定是通过poll()方法从任务队列中拉取任务 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; // 第二个if： // 1.wc &gt; maximumPoolSize说明当前的工作线程总数大于maximumPoolSize，说明了通过setMaximumPoolSize()方法减少了线程池容量 // 或者 2.timed &amp;&amp; timedOut说明了线程命中了超时控制并且上一轮循环通过poll()方法从任务队列中拉取任务为null // 并且 3. 工作线程总数大于1或者任务队列为空，则通过CAS把线程数减去1，同时返回null， // CAS把线程数减去1失败会进入下一轮循环做重试 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; // 如果timed为true，通过poll()方法做超时拉取，keepAliveTime时间内没有等待到有效的任务，则返回null // 如果timed为false，通过take()做阻塞拉取，会阻塞到有下一个有效的任务时候再返回（一般不会是null） Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); // 这里很重要，只有非null时候才返回，null的情况下会进入下一轮循环 if (r != null) return r; // 跑到这里说明上一次从任务队列中获取到的任务为null，一般是workQueue.poll()方法超时返回null timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; 这个方法中，有两处十分庞大的if逻辑，对于第一处if可能导致工作线程数减去1直接返回null的场景有： 线程池状态为SHUTDOWN，一般是调用了shutdown()方法，并且任务队列为空。 线程池状态为STOP。 对于第二处if，逻辑有点复杂，先拆解一下： 12345678910111213141516// 工作线程总数大于maximumPoolSize，说明了通过setMaximumPoolSize()方法减少了线程池容量boolean b1 = wc &gt; maximumPoolSize;// 允许线程超时同时上一轮通过poll()方法从任务队列中拉取任务为nullboolean b2 = timed &amp;&amp; timedOut;// 工作线程总数大于1boolean b3 = wc &gt; 1;// 任务队列为空boolean b4 = workQueue.isEmpty();boolean r = (b1 || b2) &amp;&amp; (b3 || b4);if (r) &#123; if (compareAndDecrementWorkerCount(c))&#123; return null; &#125;else&#123; continue; &#125;&#125; 这段逻辑大多数情况下是针对非核心线程。在execute()方法中，当线程池总数已经超过了corePoolSize并且还小于maximumPoolSize时，当任务队列已经满了的时候，会通过addWorker(task,false)添加非核心线程。而这里的逻辑恰好类似于addWorker(task,false)的反向操作，用于减少非核心线程，使得工作线程总数趋向于corePoolSize。如果对于非核心线程，上一轮循环获取任务对象为null，这一轮循环很容易满足timed &amp;&amp; timedOut为true，这个时候getTask()返回null会导致Worker#runWorker()方法跳出死循环，之后执行processWorkerExit()方法处理后续工作，而该非核心线程对应的Worker则变成“游离对象”，等待被JVM回收。当allowCoreThreadTimeOut设置为true的时候，这里分析的非核心线程的生命周期终结逻辑同时会适用于核心线程。那么可以总结出keepAliveTime的意义： 当允许核心线程超时，也就是allowCoreThreadTimeOut设置为true的时候，此时keepAliveTime表示空闲的工作线程的存活周期。 默认情况下不允许核心线程超时，此时keepAliveTime表示空闲的非核心线程的存活周期。 在一些特定的场景下，配置合理的keepAliveTime能够更好地利用线程池的工作线程资源。 processWorkerExit方法源码分析 processWorkerExit()方法是为将要终结的Worker做一次清理和数据记录工作（因为processWorkerExit()方法也包裹在runWorker()方法finally代码块中，其实工作线程在执行完processWorkerExit()方法才算真正的终结）。 1234567891011121314151617181920212223242526272829303132333435363738private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 因为抛出用户异常导致线程终结，直接使工作线程数减1即可 // 如果没有任何异常抛出的情况下是通过getTask()返回null引导线程正常跳出runWorker()方法的while死循环从而正常终结，这种情况下，在getTask()中已经把线程数减1 if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 全局的已完成任务记录数加上此将要终结的Worker中的已完成任务数 completedTaskCount += w.completedTasks; // 工作线程集合中移除此将要终结的Worker workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; // 见下一小节分析，用于根据当前线程池的状态判断是否需要进行线程池terminate处理 tryTerminate(); int c = ctl.get(); // 如果线程池的状态小于STOP，也就是处于RUNNING或者SHUTDOWN状态的前提下： // 1.如果线程不是由于抛出用户异常终结，如果允许核心线程超时，则保持线程池中至少存在一个工作线程 // 2.如果线程由于抛出用户异常终结，或者当前工作线程数，那么直接添加一个新的非核心线程 if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; // 如果允许核心线程超时，最小值为0，否则为corePoolSize int min = allowCoreThreadTimeOut ? 0 : corePoolSize; // 如果最小值为0，同时任务队列不空，则更新最小值为1 if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; // 工作线程数大于等于最小值，直接返回不新增非核心线程 if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; addWorker(null, false); &#125;&#125; 代码的后面部分区域，会判断线程池的状态，如果线程池是RUNNING或者SHUTDOWN状态的前提下，如果当前的工作线程由于抛出用户异常被终结，那么会新创建一个非核心线程。如果当前的工作线程并不是抛出用户异常被终结（正常情况下的终结），那么会这样处理： allowCoreThreadTimeOut为true，也就是允许核心线程超时的前提下，如果任务队列空，则会通过创建一个非核心线程保持线程池中至少有一个工作线程。 allowCoreThreadTimeOut为false，如果工作线程总数大于corePoolSize则直接返回，否则创建一个非核心线程，也就是会趋向于保持线程池中的工作线程数量趋向于corePoolSize。 processWorkerExit()执行完毕之后，意味着该工作线程的生命周期已经完结。 tryTerminate方法源码分析 每个工作线程终结的时候都会调用tryTerminate()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); // 判断线程池的状态，如果是下面三种情况下的任意一种则直接返回： // 1.线程池处于RUNNING状态 // 2.线程池至少为TIDYING状态，也就是TIDYING或者TERMINATED状态，意味着已经走到了下面的步骤，线程池即将终结 // 3.线程池至少为STOP状态并且任务队列不为空 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateLessThan(c, STOP) &amp;&amp; ! workQueue.isEmpty())) return; // 工作线程数不为0，则中断工作线程集合中的第一个空闲的工作线程 if (workerCountOf(c) != 0) &#123; // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; &#125; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // CAS设置线程池状态为TIDYING，如果设置成功则执行钩子方法terminated() if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; terminated(); &#125; finally &#123; // 最后更新线程池状态为TERMINATED ctl.set(ctlOf(TERMINATED, 0)); // 唤醒阻塞在termination条件的所有线程，这个变量的await()方法在awaitTermination()中调用 termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS &#125;&#125;// 中断空闲的工作线程，onlyOne为true的时候，只会中断工作线程集合中的某一个线程private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) &#123; Thread t = w.thread; // 这里判断线程不是中断状态并且尝试获取锁成功的时候才进行线程中断 if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; // 这里跳出循环，也就是只中断集合中第一个工作线程 if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125; 这里有疑惑的地方是tryTerminate()方法的第二个if代码逻辑：工作线程数不为0，则中断工作线程集合中的第一个空闲的工作线程。方法API注释中有这样一段话： If otherwise eligible to terminate but workerCount is nonzero, interrupts an idle worker to ensure that shutdown signals propagate. 当满足终结线程池的条件但是工作线程数不为0，这个时候需要中断一个空闲的工作线程去确保线程池关闭的信号得以传播。 下面将会分析的shutdown()方法中会通过interruptIdleWorkers()中断所有的空闲线程，这个时候有可能有非空闲的线程在执行某个任务，执行任务完毕之后，如果它刚好是核心线程，就会在下一轮循环阻塞在任务队列的take()方法，如果不做额外的干预，它甚至会在线程池关闭之后永久阻塞在任务队列的take()方法中。为了避免这种情况，每个工作线程退出的时候都会尝试中断工作线程集合中的某一个空闲的线程，确保所有空闲的线程都能够正常退出。 interruptIdleWorkers()方法中会对每一个工作线程先进行tryLock()判断，只有返回true才有可能进行线程中断。我们知道runWorker()方法中，工作线程在每次从任务队列中获取到非null的任务之后，会先进行加锁Worker#lock()操作，这样就能避免线程在执行任务的过程中被中断，保证被中断的一定是空闲的工作线程。 shutdown方法源码分析 线程池关闭操作有几个相关的变体方法，先看shutdown()： 1234567891011121314151617181920212223242526272829303132333435public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 权限校验，安全策略相关判断 checkShutdownAccess(); // 设置SHUTDOWN状态 advanceRunState(SHUTDOWN); // 中断所有的空闲的工作线程 interruptIdleWorkers(); // 钩子方法 onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; // 调用上面分析果敢的尝试terminate方法，使状态更变为TIDYING，执行钩子方法terminated()后，最终状态更新为TERMINATED tryTerminate();&#125;// 升提状态private void advanceRunState(int targetState) &#123; // assert targetState == SHUTDOWN || targetState == STOP; for (;;) &#123; int c = ctl.get(); // 线程池状态至少为targetState或者CAS设置状态为targetState则跳出循环 if (runStateAtLeast(c, targetState) || ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c)))) break; &#125;&#125;// 中断所有的空闲的工作线程private void interruptIdleWorkers() &#123; interruptIdleWorkers(false);&#125; 接着看shutdownNow()方法： 1234567891011121314151617181920public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 权限校验，安全策略相关判断 checkShutdownAccess(); // 设置STOP状态 advanceRunState(STOP); // 中断所有的空闲的工作线程 interruptWorkers(); // 清空工作队列并且取出所有的未执行的任务 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; // 调用上面分析果敢的尝试terminate方法，使状态更变为TIDYING，执行钩子方法terminated()后，最终状态更新为TERMINATED tryTerminate(); return tasks;&#125; shutdownNow()方法会把线程池状态先更变为STOP，然后遍历任务队列，取出（移除）所有任务存放在一个列表中返回。 最后看awaitTermination()方法： 123456789101112131415161718public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException &#123; // 转换timeout的单位为纳秒 long nanos = unit.toNanos(timeout); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 循环等待直到线程池状态更变为TERMINATED，每轮循环等待nanos纳秒 while (runStateLessThan(ctl.get(), TERMINATED)) &#123; if (nanos &lt;= 0L) return false; nanos = termination.awaitNanos(nanos); &#125; return true; &#125; finally &#123; mainLock.unlock(); &#125;&#125; awaitTermination()虽然不是shutdown()方法体系，但是它的处理逻辑就是确保调用此方法的线程会阻塞到tryTerminate()方法成功把线程池状态更新为TERMINATED后再返回，可以使用在某些需要感知线程池终结时刻的场景。 有一点值得关注的是：shutdown()或者shutdownNow()方法只会中断空闲的工作线程，如果工作线程正在执行任务对象Runnable#run()，这种情况下的工作线程不会中断，而是等待下一轮执行getTask()方法的时候通过线程池状态判断正常终结该工作线程。 reject方法源码分析 reject(Runnable command)方法很简单： 123final void reject(Runnable command) &#123; handler.rejectedExecution(command, this);&#125; 调用线程池持有的成员RejectedExecutionHandler实例回调任务实例和当前线程池实例。 钩子方法分析 到JDK11为止，ThreadPoolExecutor提供的钩子方法没有增加，有以下几个： beforeExecute(Thread t, Runnable r)：任务对象Runnable#run()执行之前触发回调。 afterExecute(Runnable r, Throwable t)：任务对象Runnable#run()执行之后（包括异常完成情况和正常完成情况）触发回调。 terminated()：线程池关闭的时候，状态更变为TIDYING成功之后会回调此方法，执行此方法完毕后，线程池状态会更新为TERMINATED。 onShutdown()：shutdown()方法执行时候会回调此方法，API注释中提到此方法主要提供给ScheduledThreadPoolExecutor使用。 其中onShutdown()的方法修饰符为default，其他三个方法的修饰符为protected，必要时候可以自行扩展这些方法，可以实现监控、基于特定时机触发具体操作等等。 其他方法 线程池本身提供了大量数据统计相关的方法、扩容方法、预创建方法等等，这些方法的源码并不复杂，这里不做展开分析。 核心线程相关： getCorePoolSize()：获取核心线程数。 setCorePoolSize()：重新设置线程池的核心线程数。 prestartCoreThread()：预启动一个核心线程，当且仅当工作线程数量小于核心线程数量。 prestartAllCoreThreads()：预启动所有核心线程。 线程池容量相关： getMaximumPoolSize()：获取线程池容量。 setMaximumPoolSize()：重新设置线程池的最大容量。 线程存活周期相关： setKeepAliveTime()：设置空闲工作线程的存活周期。 getKeepAliveTime()：获取空闲工作线程的存活周期。 其他监控统计相关方法： getTaskCount()：获取所有已经被执行的任务总数的近似值。 getCompletedTaskCount()：获取所有已经执行完成的任务总数的近似值。 getLargestPoolSize()：获取线程池的峰值线程数（最大池容量）。 getActiveCount()：获取所有活跃线程总数（正在执行任务的工作线程）的近似值。 getPoolSize()：获取工作线程集合的容量（当前线程池中的总工作线程数）。 任务队列操作相关方法： purge()：移除任务队列中所有是Future类型并且已经处于Cancelled状态的任务。 remove()：从任务队列中移除指定的任务。 BlockingQueue&lt;Runnable&gt; getQueue()：获取任务队列的引用。 小结 本文花大量功夫基于每一行代码分析JUC线程池ThreadPoolExecutor的核心方法execute()的实现，这个方法是整个线程池相关体系的基石，有了它才能扩展出带回调的异步执行和基于时间进行任务调度的功能，后面将会编写两篇文章分别详细分析线程池扩展服务ExecutorService的功能源码实现以及调度线程池ScheduledThreadPoolExecutor的源码实现，预计要耗时2-3周。 （本文完 e-a-20190715 c-7-d 最近项目比较紧，没办法及时更新）","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Concurrency","slug":"Java/Concurrency","permalink":"http://throwable.club/blog/categories/Java/Concurrency/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"ThreadPoolExecutor","slug":"ThreadPoolExecutor","permalink":"http://throwable.club/blog/tags/ThreadPoolExecutor/"}]},{"title":"JUC线程池扩展可回调的Future","slug":"java-concurrency-listenable-future","date":"2019-07-02T00:35:01.000Z","updated":"2019-07-07T07:00:41.203Z","comments":true,"path":"2019/07/02/java-concurrency-listenable-future/","link":"","permalink":"http://throwable.club/2019/07/02/java-concurrency-listenable-future/","excerpt":"前提 最近在看JUC线程池java.util.concurrent.ThreadPoolExecutor的源码实现，其中了解到java.util.concurrent.Future的实现原理。从目前java.util.concurrent.Future的实现来看，虽然实现了异步提交任务，但是任务结果的获取过程需要主动调用Future#get()或者Future#get(long timeout, TimeUnit unit)，而前者是阻塞的，后者在异步任务执行时间不确定的情况下有可能需要进行轮询，这两种情况和异步调用的初衷有点相违背。于是笔者想结合目前了解到的Future实现原理的前提下扩展出支持（监听）回调的Future，思路上参考了Guava增强的ListenableFuture。本文编写的时候使用的JDK是JDK11，代码可以在JDK[8,12]版本上运行，其他版本可能不适合。","text":"前提 最近在看JUC线程池java.util.concurrent.ThreadPoolExecutor的源码实现，其中了解到java.util.concurrent.Future的实现原理。从目前java.util.concurrent.Future的实现来看，虽然实现了异步提交任务，但是任务结果的获取过程需要主动调用Future#get()或者Future#get(long timeout, TimeUnit unit)，而前者是阻塞的，后者在异步任务执行时间不确定的情况下有可能需要进行轮询，这两种情况和异步调用的初衷有点相违背。于是笔者想结合目前了解到的Future实现原理的前提下扩展出支持（监听）回调的Future，思路上参考了Guava增强的ListenableFuture。本文编写的时候使用的JDK是JDK11，代码可以在JDK[8,12]版本上运行，其他版本可能不适合。 简单分析Future的实现原理 虚拟例子推演 并发大师Doug Lea在设计JUC线程池的时候，提供了一个顶层执行器接口Executor： 1234public interface Executor &#123; void execute(Runnable command);&#125; 实际上，这里定义的方法Executor#execute()是整套线程池体系最核心的接口，也就是ThreadPoolExecutor定义的核心线程、额外创建的线程（线程池最大线程容量 - 核心线程数）都是在这个接口提交任务的时候懒创建的，也就是说ExecutorService接口扩展的功能都是基于Executor#execute()的基础进行扩展。Executor#execute()方法只是单纯地把任务实例Runnable对象投放到线程池中分配合适的线程执行，但是由于方法返回值是void类型，我们是无法感知任务什么时候执行完毕。这个时候就需要对Runnable任务实例进行包装（下面是伪代码 + 伪逻辑）： 1234567891011121314151617// 下面这个Wrapper和Status类是笔者虚构出来@RequiredArgsConstructorclass Wrapper implements Runnable&#123; private final Runnable target; private Status status = Status.of(\"初始化\"); @Override public void run()&#123; try&#123; target.run(); status = Status.of(\"执行成功\"); &#125;catch(Throwable t)&#123; status = Status.of(\"执行异常\"); &#125; &#125;&#125; 我们只需要把new Wrapper(原始Runnable实例)投放到线程池执行，那么通过定义好的Status状态记录变量就能得知异步任务执行的状态，以及什么时候执行完毕（包括正常的执行完毕和异常的执行完毕）。这里仅仅解决了任务执行的状态获取，但是Executor#execute()方法法返回值是void类型的特点使得我们无法回调Runnable对象执行的结果。这个时候需要定义一个可以回调执行结果的接口，其实已经有现成的接口Callable： 12345@FunctionalInterfacepublic interface Callable&lt;V&gt; &#123; V call() throws Exception;&#125; 这里遇到了一个问题：由于Executor#execute()只接收Runnable参数，我们需要把Callable接口适配到Runnable接口，这个时候，做一次简单的委托即可： 12345678910111213141516171819@RequiredArgsConstructorclass Wrapper implements Runnable&#123; private final Callable callable; private Status status = Status.of(\"初始化\"); @Getter private Object outcome; @Override public void run()&#123; try&#123; outcome = callable.call(); status = Status.of(\"执行成功\"); &#125;catch(Throwable t)&#123; status = Status.of(\"执行异常\"); outcome = t; &#125; &#125;&#125; 这里把Callable实例直接委托给Wrapper，而Wrapper实现了Runnable接口，执行结果直接存放在定义好的Object类型的对象outcome中即可。当我们感知到执行状态已经结束，就可以从outcome中提取到执行结果。 Future的实现 上面一个小结仅仅对Future实现做一个相对合理的虚拟推演，实际上，RunnableFuture才是JUC中常用的复合接口，它同时实现了Runnable和Future： 1234public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125; 上一节提到的虚构出来的Wrapper类，在JUC中类似的实现是java.util.concurrent.FutureTask，它就是Callable和Runnable的适配器，FutureTask实现了RunnableFuture接口： 12345678910111213141516171819202122public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; &#123; private volatile int state; private static final int NEW = 0; private static final int COMPLETING = 1; private static final int NORMAL = 2; private static final int EXCEPTIONAL = 3; private static final int CANCELLED = 4; private static final int INTERRUPTING = 5; private static final int INTERRUPTED = 6; /** The underlying callable; nulled out after running */ private Callable&lt;V&gt; callable; /** The result to return or exception to throw from get() */ private Object outcome; // non-volatile, protected by state reads/writes /** The thread running the callable; CASed during run() */ private volatile Thread runner; /** Treiber stack of waiting threads */ private volatile WaitNode waiters; // 省略其他代码&#125; 注意到核心属性state表示执行状态，outcome承载执行结果。接着看提交Callable类型任务的方法ExecutorService#submit()： 123456public interface ExecutorService extends Executor &#123; // 省略其他接口方法 &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);&#125; 当我们通过上述ExecutorService#submit()方法提交Callable类型任务的时候，实际上做了如下的步骤： 检查入参task的存在性，如果为null抛出NullPointerException。 把Callable类型的task包装为FutureTask实例。 把新建的FutureTask实例放到线程池中执行，也就是调用Executor#execute(FutureTask实例)。 返回FutureTask实例的接口实例RunnableFuture（实际上是返回子接口Future实例）。 如果我们需要获取结果，可以Future#get()或者Future#get(long timeout, TimeUnit unit)获取，调用这两个方法的时候参看FutureTask里面的方法实现，得知步骤如下： 如果状态state小于等于COMPLETING(1)，说明任务还在执行中，获取结果的请求线程会放入WaitNode类型的队列中进行阻塞。 如果任务执行完毕，不管异常完毕还是正常完毕，除了会更新状态state和把结果赋值到outcome之外，还会唤醒所有阻塞获取结果的线程，然后调用钩子方法FutureTask#done()（具体见源码FutureTask#finishCompletion()）。 其实分析了这么多，笔者想指出的结论就是：Callable类型任务提交到线程池中执行完毕（包括正常执行完毕和异常执行完毕）之后，都会回调钩子方法FutureTask#done()。这个就是我们扩展可监听Future的理论依据。 扩展可回调的Future 先做一次编码实现，再简单测试其功能。 编码实现 先定义一个Future接口的子接口ListenableFuture，用于添加可监听的回调： 1234public interface ListenableFuture&lt;V&gt; extends Future&lt;V&gt; &#123; void addCallback(ListenableFutureCallback&lt;V&gt; callback, Executor executor);&#125; ListenableFutureCallback是一个函数式回调接口： 12345@FunctionalInterfacepublic interface ListenableFutureCallback&lt;V&gt; &#123; void callback(V value, Throwable throwable);&#125; 对于ListenableFutureCallback而言，回调的结果value和throwable是互斥的。正常执行完毕的情况下value将会是执行结果值，throwable为null；异常执行完毕的情况下，value将会是null，throwable将会是抛出的异常实例。如果更习惯于分开处理正常执行完毕的结果和异常执行完毕的结果，ListenableFutureCallback可以这样定义： 123456public interface ListenableFutureCallback&lt;V&gt; &#123; void onSuccess(V value); void onError(Throwable throwable);&#125; 接着定义ListenableExecutorService接口继承ExecutorService接口： 1234567891011121314public interface ListenableExecutorService extends ExecutorService &#123; &lt;T&gt; ListenableFuture&lt;T&gt; listenableSubmit(Callable&lt;T&gt; callable); /** * 定义这个方法是因为有些时候由于任务执行时间非常短，有可能通过返回的ListenableFuture实例添加回调之前已经执行完毕，因此可以支持显式传入回调 * * @param callable callable * @param callbacks callbacks * @param executor executor * @return ListenableFuture */ &lt;T&gt; ListenableFuture&lt;T&gt; listenableSubmit(Callable&lt;T&gt; callable, List&lt;ListenableFutureCallback&lt;T&gt;&gt; callbacks, Executor executor);&#125; 然后添加一个执行单元适配器ListenableFutureCallbackRunnable，承载每次回调触发的调用（实现Runnable接口，从而支持异步执行）： 123456789101112@RequiredArgsConstructorpublic class ListenableFutureCallbackRunnable&lt;V&gt; implements Runnable &#123; private final ListenableFutureCallback&lt;V&gt; callback; private final V value; private final Throwable throwable; @Override public void run() &#123; callback.callback(value, throwable); &#125;&#125; 接着需要定义一个FutureTask的子类ListenableFutureTask，核心逻辑是覆盖FutureTask#done()方法触发回调： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// ListenableFutureTaskpublic class ListenableFutureTask&lt;V&gt; extends FutureTask&lt;V&gt; implements ListenableFuture&lt;V&gt; &#123; private final List&lt;Execution&lt;V&gt;&gt; executions = new ArrayList&lt;&gt;(); public ListenableFutureTask(Callable&lt;V&gt; callable) &#123; super(callable); &#125; public ListenableFutureTask(Runnable runnable, V result) &#123; super(runnable, result); &#125; public static &lt;V&gt; ListenableFutureTask&lt;V&gt; newTaskFor(Callable&lt;V&gt; callable) &#123; return new ListenableFutureTask&lt;&gt;(callable); &#125; @Override protected void done() &#123; Iterator&lt;Execution&lt;V&gt;&gt; iterator = executions.iterator(); Throwable throwable = null; V value = null; try &#123; value = get(); &#125; catch (Throwable t) &#123; throwable = t; &#125; while (iterator.hasNext()) &#123; Execution&lt;V&gt; execution = iterator.next(); ListenableFutureCallbackRunnable&lt;V&gt; callbackRunnable = new ListenableFutureCallbackRunnable&lt;&gt;(execution.getCallback(), value, throwable); // 异步回调 if (null != execution.getExecutor()) &#123; execution.getExecutor().execute(callbackRunnable); &#125; else &#123; // 同步回调 callbackRunnable.run(); &#125; &#125; &#125; @Override public void addCallback(ListenableFutureCallback&lt;V&gt; callback, Executor executor) &#123; Execution&lt;V&gt; execution = new Execution&lt;&gt;(); execution.setCallback(callback); execution.setExecutor(executor); executions.add(execution); &#125;&#125;// Execution - 承载每个回调实例和对应的Executor，Executor实例为null则进行同步回调@Datapublic class Execution &lt;V&gt;&#123; private Executor executor; private ListenableFutureCallback&lt;V&gt; callback;&#125; 最后一步就是编写线程池ListenableThreadPoolExecutor，继承自ThreadPoolExecutor并且实现ListenableExecutorService接口： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ListenableThreadPoolExecutor extends ThreadPoolExecutor implements ListenableExecutorService &#123; public ListenableThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); &#125; public ListenableThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory); &#125; public ListenableThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, handler); &#125; public ListenableThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler); &#125; @Override public &lt;T&gt; ListenableFuture&lt;T&gt; listenableSubmit(Callable&lt;T&gt; callable) &#123; if (null == callable) &#123; throw new IllegalArgumentException(\"callable\"); &#125; ListenableFutureTask&lt;T&gt; listenableFutureTask = ListenableFutureTask.newTaskFor(callable); execute(listenableFutureTask); return listenableFutureTask; &#125; @Override public &lt;T&gt; ListenableFuture&lt;T&gt; listenableSubmit(Callable&lt;T&gt; callable, List&lt;ListenableFutureCallback&lt;T&gt;&gt; callbacks, Executor executor) &#123; if (null == callable) &#123; throw new IllegalArgumentException(\"callable\"); &#125; if (null == callbacks) &#123; throw new IllegalArgumentException(\"callbacks\"); &#125; ListenableFutureTask&lt;T&gt; listenableFutureTask = ListenableFutureTask.newTaskFor(callable); for (ListenableFutureCallback&lt;T&gt; callback : callbacks) &#123; listenableFutureTask.addCallback(callback, executor); &#125; execute(listenableFutureTask); return listenableFutureTask; &#125;&#125; 测试 引入junit，编写测试类如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class ListenableFutureTest &#123; private static ListenableExecutorService EXECUTOR; private static Executor E; @BeforeClass public static void before() &#123; EXECUTOR = new ListenableThreadPoolExecutor(1, 3, 0, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10), new ThreadFactory() &#123; private final AtomicInteger counter = new AtomicInteger(); @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r); thread.setDaemon(true); thread.setName(String.format(\"ListenableWorker-%d\", counter.getAndIncrement())); return thread; &#125; &#125;); E = Executors.newFixedThreadPool(3); &#125; @Test public void testListenableFuture1() throws Exception &#123; ListenableFuture&lt;String&gt; future = EXECUTOR.listenableSubmit(() -&gt; &#123; Thread.sleep(1000); return \"message\"; &#125;); future.addCallback((v, t) -&gt; &#123; System.out.println(String.format(\"Value = %s,Throwable = %s\", v, t)); &#125;, null); Thread.sleep(2000); &#125; @Test public void testListenableFuture2() throws Exception &#123; ListenableFuture&lt;String&gt; future = EXECUTOR.listenableSubmit(() -&gt; &#123; Thread.sleep(1000); throw new RuntimeException(\"exception\"); &#125;); future.addCallback((v, t) -&gt; &#123; System.out.println(String.format(\"Value = %s,Throwable = %s\", v, t)); &#125;, null); Thread.sleep(2000); &#125; @Test public void testListenableFuture3() throws Exception &#123; ListenableFuture&lt;String&gt; future = EXECUTOR.listenableSubmit(() -&gt; &#123; Thread.sleep(1000); return \"message\"; &#125;); future.addCallback((v, t) -&gt; &#123; System.out.println(String.format(\"Value = %s,Throwable = %s\", v, t)); &#125;, E); System.out.println(\"testListenableFuture3 end...\"); Thread.sleep(2000); &#125; @Test public void testListenableFuture4() throws Exception &#123; ListenableFuture&lt;String&gt; future = EXECUTOR.listenableSubmit(() -&gt; &#123; Thread.sleep(1000); throw new RuntimeException(\"exception\"); &#125;); future.addCallback((v, t) -&gt; &#123; System.out.println(String.format(\"Value = %s,Throwable = %s\", v, t)); &#125;, E); System.out.println(\"testListenableFuture4 end...\"); Thread.sleep(2000); &#125;&#125; 执行结果: 12345678910111213// testListenableFuture1Value = message,Throwable = null// testListenableFuture2Value = null,Throwable = java.util.concurrent.ExecutionException: java.lang.RuntimeException: exception// testListenableFuture3testListenableFuture3 end...Value = message,Throwable = null// testListenableFuture4testListenableFuture4 end...Value = null,Throwable = java.util.concurrent.ExecutionException: java.lang.RuntimeException: exception 和预期的结果一致，注意一下如果Callable执行抛出异常，异常被包装为ExecutionException，要调用Throwable#getCause()才能得到原始的异常实例。 小结 本文通过了解ThreadPoolExecutor和Future的实现原理做简单的扩展，使得异步提交任务变得更加优雅和简便。强化了动手能力的同时，也能加深对并发编程的一些认知。当然，本文只是提供一个十分简陋的实现，笔者其实还想到了如对回调处理的耗时做监控、回调打上分组标签执行等等更完善的功能，等到有需要的场景再进行实现。 这里记录一下过程中的一些领悟： Executor#execute()是线程池的核心接口，所有其他功能都是基于此接口做扩展，它的设计本身是无状态的。 灵活使用适配器模式，可以在不改变已发布的接口的功能同时实现新的接口的功能适配。 要善于发掘和使用JDK类库设计者留给开发者的扩展接口。 （本文完 c-1-d e-a-20190702）","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Concurrency","slug":"Java/Concurrency","permalink":"http://throwable.club/blog/categories/Java/Concurrency/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"ListenableFuture","slug":"ListenableFuture","permalink":"http://throwable.club/blog/tags/ListenableFuture/"}]},{"title":"深入理解Instrument(一)","slug":"java-understand-instrument-first","date":"2019-06-29T10:22:39.000Z","updated":"2019-06-30T02:29:22.568Z","comments":true,"path":"2019/06/29/java-understand-instrument-first/","link":"","permalink":"http://throwable.club/2019/06/29/java-understand-instrument-first/","excerpt":"前提 很早之前就了解到目前主流的APM开源框架如Pinpoint、SkyWalking等等都是通过java.lang.instrument包提供的字节码增强功能来实现的。趁着对这块的热情还没消退，抽时间分析一下java.lang.instrument包的使用方式，记录下来写成一个系列的文章。本系列博文针对的是JDK11，其他版本的JDK可能不适合。","text":"前提 很早之前就了解到目前主流的APM开源框架如Pinpoint、SkyWalking等等都是通过java.lang.instrument包提供的字节码增强功能来实现的。趁着对这块的热情还没消退，抽时间分析一下java.lang.instrument包的使用方式，记录下来写成一个系列的文章。本系列博文针对的是JDK11，其他版本的JDK可能不适合。 instrument简介 java.lang.instrument包的结构如下： 1234567java.lang.instrument - ClassDefinition - ClassFileTransformer - IllegalClassFormatException - Instrumentation - UnmodifiableClassException - UnmodifiableModuleException 其中，核心功能由接口java.lang.instrument.Instrumentation提供，这里可以通过Instrumentation类的API注释来理解一下什么是instrument： Instrumentation类提供控制Java语言程序代码的服务。Instrumentation可以实现在方法插入额外的字节码从而达到收集使用中的数据到指定工具的目的。由于插入的字节码是附加的，这些更变不会修改原来程序的状态或者行为。通过这种方式实现的良性工具包括监控代理、分析器、覆盖分析程序和事件日志记录程序等等。 也就是说，java.lang.instrument包的最大功能就是可以在已有的类上附加（修改）字节码来实现增强的逻辑，如果良性使用当然不会影响程序的正常行为，如果恶性使用就可能产生一些负面的影响（其实很多商用Java程序如IntelliJ IDEA的License的破解都可以基于Instrumentation的功能实现，前提是找到程序认证License的入口）。 instrument原理 instrument的底层实现依赖于JVMTI，也就是JVM Tool Interface，它是JVM暴露出来的一些供用户扩展的接口集合，JVMTI是基于事件驱动的，JVM每执行到一定的逻辑就会调用一些事件的回调接口（如果有的话），这些接口可以供开发者去扩展自己的逻辑。JVMTIAgent是一个利用JVMTI暴露出来的接口提供了代理启动时加载(agent on load)、代理通过attach形式加载(agent on attach)和代理卸载(agent on unload)功能的动态库。而instrument agent可以理解为一类JVMTIAgent动态库，别名是JPLISAgent(Java Programming Language Instrumentation Services Agent)，也就是专门为java语言编写的插桩服务提供支持的代理。因为涉及到源码分析，笔者暂时没能力展开，可以详细阅读参考资料中你假笨大神的那篇专门分析JVM相关源码实现的文章。 其中，VM启动时加载Agent可以使用命令行参数-javaagent:yourAgent.jar的形式实现。 Instrumentation接口详解 void addTransformer(ClassFileTransformer transformer, boolean canRetransform) 注册ClassFileTransformer实例，注册多个会按照注册顺序进行调用。所有的类被加载完毕之后会调用ClassFileTransformer实例，相当于它们通过了redefineClasses方法进行重定义。布尔值参数canRetransform决定这里被重定义的类是否能够通过retransformClasses方法进行回滚。 void addTransformer(ClassFileTransformer transformer) 相当于addTransformer(transformer, false)，也就是通过ClassFileTransformer实例重定义的类不能进行回滚。 boolean removeTransformer(ClassFileTransformer transformer) 移除(反注册)ClassFileTransformer实例。 boolean isRetransformClassesSupported() 返回当前JVM配置是否支持类重新转换的特性。 void retransformClasses(Class&lt;?&gt;... classes) throws UnmodifiableClassException 已加载类进行重新转换的方法，重新转换的类会被回调到ClassFileTransformer的列表中进行处理，想深入理解建议阅读API注释。 boolean isRedefineClassesSupported() 返回当前JVM配置是否支持重定义类（修改类的字节码）的特性。 void redefineClasses(ClassDefinition... definitions) throws ClassNotFoundException, UnmodifiableClassException 重定义类，也就是对已经加载的类进行重定义，ClassDefinition类型的入参包括了对应的类型Class&lt;?&gt;对象和字节码文件对应的字节数组。 其他功能： boolean isModifiableClass(Class&lt;?&gt; theClass)：判断对应类是否被修改过。 Class[] getAllLoadedClasses()：获取所有已经被加载的类。 Class[] getInitiatedClasses(ClassLoader loader)：获取所有已经被初始化过了的类。 long getObjectSize(Object objectToSize)：获取某个对象的(字节)大小，注意嵌套对象或者对象中的属性引用需要另外单独计算。 void appendToBootstrapClassLoaderSearch(JarFile jarfile)：将某个jar加入到Bootstrap Classpath里优先其他jar被加载。 void appendToSystemClassLoaderSearch(JarFile jarfile)：将某个jar加入到Classpath里供AppClassloard去加载。 void setNativeMethodPrefix(ClassFileTransformer transformer, String prefix)：设置某些native方法的前缀，主要在找native方法的时候做规则匹配。 boolean isNativeMethodPrefixSupported()：是否支持设置native方法的前缀。 void redefineModule(...)：重定义Module。 boolean isModifiableModule(Module module)：判断指定Module是否重定义过。 如何使用Instrumentation Instrumentation类在API注释中有十分简洁的使用方式描述： 有两种方式可以获取Instrumentation接口的实例： JVM在指定代理的方式下启动，此时Instrumentation实例会传递到代理类的premain方法。 JVM提供一种在启动之后的某个时刻启动代理的机制，此时Instrumentation实例会传递到代理类代码的agentmain方法。 首先我们知道Instrumentation的实现类是sun.instrument.InstrumentationImpl，在JDK9之后，由于模块权限控制，不可能通过反射构造其实例，一般情况下反射做不到的东西只能通过JVM实现。而且根据上面简洁的API注释我们是无法得知如何使用Instrumentation。其实，premain对应的就是VM启动时的Instrument Agent加载，也就是上文提到的agent on load，而agentmain对应的是VM运行时的Instrument Agent加载，也就是上文提到的agent on attach。两种加载形式所加载的Instrument Agent都关注同一个JVMTI事件 – ClassFileLoadHook事件，而这个事件是在读取字节码文件之后回调时用。换言之，premain和agentmain方式的回调时机都是类文件字节码读取之后（或者说是类加载之后）。 实际上，premain和agentmain两种方式最终的目的都是为了回调Instrumentation实例并且激活sun.instrument.InstrumentationImpl#transform()从而回调注册到Instrumentation中的ClassFileTransformer实现字节码修改，本质功能上没有很大区别。两者的非本质功能的区别如下： premain需要通过命令行使用外部代理jar包；而agentmain则可以通过attach机制直接附着到目标VM中加载代理，也就是使用agentmain方式下，操作attach的程序和被代理的程序可以是完全不同的两个程序。 premain方式回调到ClassFileTransformer中的类是虚拟机加载的所有类，这个是由于代理加载的顺序比较靠前决定的，在开发者逻辑看来就是：所有类首次加载并且进入程序main()方法之前，premain方法会被激活，然后所有被加载的类都会执行ClassFileTransformer列表中的回调。 agentmain方式由于是采用attach机制，被代理的目标程序VM有可能很早之前已经启动，当然其所有类已经被加载完成，这个时候需要借助Instrumentation#retransformClasses(Class&lt;?&gt;... classes)让对应的类可以重新转换，从而激活重新转换的类执行ClassFileTransformer列表中的回调。 premain方式是JDK1.5引入的，而agentmain方式是JDK1.6引入的，也就是JDK1.6之后可以自行选择使用premain或者agentmain。 premain使用方式 premain方式依赖独立的javaagent，也就是单独建立一个项目编写好代码之后打成jar包供另一个使用程序通过代理形式引入。简单的步骤如下： 编写premain函数，也就是编写一个普通的Java类，包含下面两个方法的其中之一。 12public static void premain(String agentArgs, Instrumentation inst); [1]public static void premain(String agentArgs); [2] [1]的回调优先级会比[2]高，也就是[1]和[2]同时存在的情况下，只有[1]会被回调。而agentArgs是premain函数得到的程序参数，通过– javaagent命令行参数传入。 代理服务打包为Jar。 Agent一般是一个普通的Java服务，只是需要编写premain函数，并且该Jar包的manifest(也就是MANIFEST.MF文件)属性中需要加入Premain-Class来指定步骤1中编写好premain函数的那个Java类。 通过指定Agent运行。 1java -javaagent:代理Jar包的路径 [=传入premain的参数] yourTarget.jar 简单例子如下： 新建一个premain-agent的项目，新建一个类club.throwable.permain.PermainAgent如下： 1234567891011121314151617181920212223public class PermainAgent &#123; private static Instrumentation INST; public static void premain(String agentArgs, Instrumentation inst) &#123; INST = inst; process(); &#125; private static void process() &#123; INST.addTransformer(new ClassFileTransformer() &#123; @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; clazz, ProtectionDomain protectionDomain, byte[] byteCode) throws IllegalClassFormatException &#123; System.out.println(String.format(\"Process by ClassFileTransformer,target class = %s\", className)); return byteCode; &#125; &#125;); &#125;&#125; 引入Maven插件maven-jar-plugin： 12345678910111213141516&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.2&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifestEntries&gt; &lt;Premain-Class&gt;club.throwable.permain.PermainAgent&lt;/Premain-Class&gt; &lt;Can-Redefine-Classes&gt;true&lt;/Can-Redefine-Classes&gt; &lt;Can-Retransform-Classes&gt;true&lt;/Can-Retransform-Classes&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/plugins&gt; 通过mvn package命令打包即可得到premain-agent.jar（笔者发现该插件未支持JDK11，所以降级到JDK8）。接着可以使用该代理Jar： 123456789101112131415161718192021222324252627// 这个是样品类public class HelloSample &#123; public void sayHello(String name) &#123; System.out.println(String.format(\"%s say hello!\", name)); &#125;&#125;// main函数，vm参数：-javaagent:I:\\J-Projects\\instrument-sample\\premain-agent\\target\\premain-agent.jarpublic class PermainMain &#123; public static void main(String[] args) throws Exception&#123; &#125;&#125;// 输出结果Process by ClassFileTransformer,target class = sun/nio/cs/ThreadLocalCodersProcess by ClassFileTransformer,target class = sun/nio/cs/ThreadLocalCoders$1Process by ClassFileTransformer,target class = sun/nio/cs/ThreadLocalCoders$CacheProcess by ClassFileTransformer,target class = sun/nio/cs/ThreadLocalCoders$2Process by ClassFileTransformer,target class = com/intellij/rt/execution/application/AppMainV2$AgentProcess by ClassFileTransformer,target class = com/intellij/rt/execution/application/AppMainV2Process by ClassFileTransformer,target class = com/intellij/rt/execution/application/AppMainV2$1Process by ClassFileTransformer,target class = java/lang/reflect/InvocationTargetExceptionProcess by ClassFileTransformer,target class = java/net/InetAddress$1Process by ClassFileTransformer,target class = java/lang/ClassValue// ... 省略大量其他输出 实际上，如果我们要定制功能需要排除掉一些java.lang包和sun包的类，当然这里仅仅作为演示所以无伤大雅。 agentmain使用方式 agentmain的使用方式和permain十分相似，包括编写MANIFEST.MF和生成代理Jar包。但是，它并不需要通过-javaagent命令行形式引入代理Jar，而是在运行时通过attach工具激活指定代理即可。简单的步骤如下： 编写premain函数，也就是编写一个普通的Java类，包含下面两个方法的其中之一。 12public static void agentmain(String agentArgs, Instrumentation inst); [1]public static void agentmain(String agentArgs); [2] [1]的回调优先级会比[2]高，也就是[1]和[2]同时存在的情况下，只有[1]会被回调。而agentArgs是agentmain函数得到的程序参数，通过com.sun.tools.attach.VirtualMachine#loadAgent(var1,var2)中的var2传入，var1就是代理Jar的绝对路径。 代理服务打包为Jar。 Agent一般是一个普通的Java服务，只是需要编写agentmain函数，并且该Jar包的manifest(也就是MANIFEST.MF文件)属性中需要加入Agent-Class来指定步骤1中编写好agentmain函数的那个Java类。 通过attach工具直接加载Agent，执行attach的程序和需要被代理的程序可以是两个完全不同的程序。 123456// 列出所有VM实例List&lt;VirtualMachineDescriptor&gt; list = VirtualMachine.list();// attach目标VMVirtualMachine.attach(descriptor.id());// 目标VM加载AgentVirtualMachine#loadAgent(\"代理Jar路径\",\"命令参数\"); 举个简单的例子：编写agentmain函数的类如下： 12345678910111213141516171819202122232425262728public class AgentmainAgent &#123; private static Instrumentation INST; public static void agentmain(String agentArgs, Instrumentation inst) &#123; INST = inst; process(); &#125; private static void process() &#123; INST.addTransformer(new ClassFileTransformer() &#123; @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; clazz, ProtectionDomain protectionDomain, byte[] byteCode) throws IllegalClassFormatException &#123; System.out.println(String.format(\"Agentmain process by ClassFileTransformer,target class = %s\", className)); return byteCode; &#125; &#125;, true); try &#123; INST.retransformClasses(Class.forName(\"club.throwable.instrument.AgentTargetSample\")); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 更改Maven插件maven-jar-plugin的配置，然后通过mvn pacakge打包： 1234567891011121314151617&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.2&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifestEntries&gt; &lt;!-- 主要改这个配置项 --&gt; &lt;Agent-Class&gt;club.throwable.agentmain.AgentmainAgent&lt;/Premain-Class&gt; &lt;Can-Redefine-Classes&gt;true&lt;/Can-Redefine-Classes&gt; &lt;Can-Retransform-Classes&gt;true&lt;/Can-Retransform-Classes&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/plugins&gt; 负责attach工作的程序AgentmainAttachMain： 12345678910111213public class AgentmainAttachMain &#123; public static void main(String[] args) throws Exception &#123; List&lt;VirtualMachineDescriptor&gt; list = VirtualMachine.list(); for (VirtualMachineDescriptor descriptor : list) &#123; if (descriptor.displayName().endsWith(\"AgentTargetSample\")) &#123; VirtualMachine virtualMachine = VirtualMachine.attach(descriptor.id()); virtualMachine.loadAgent(\"I:\\\\J-Projects\\\\instrument-sample\\\\premain-agent\\\\target\\\\premain-agent.jar\", \"arg1\"); virtualMachine.detach(); &#125; &#125; &#125;&#125; 被代理的目标程序AgentTargetSample： 1234567891011121314public class AgentTargetSample &#123; public void sayHello(String name) &#123; System.out.println(String.format(\"%s say hello!\", name)); &#125; public static void main(String[] args) throws Exception &#123; AgentTargetSample sample = new AgentTargetSample(); for (; ; ) &#123; Thread.sleep(1000); sample.sayHello(Thread.currentThread().getName()); &#125; &#125;&#125; 接着先启动AgentTargetSample，然后再启动AgentmainAttachMain: 1234567891011main say hello!main say hello!main say hello!main say hello!main say hello!main say hello!main say hello!Agentmain process by ClassFileTransformer,target class = club/throwable/instrument/AgentTargetSamplemain say hello!main say hello!main say hello! PS：如果没有找到VirtualMachineDescriptor或者VirtualMachine，只需要把${JAVA_HONE}/lib/tools.jar拷贝到${JAVA_HONE}/jre/lib目录下即可。 Instrumentation的局限性 大多数情况下，我们使用Instrumentation都是使用其字节码插桩的功能，或者笼统说就是类重定义(Class Redefine)的功能，但是有以下的局限性： premain和agentmain两种方式修改字节码的时机都是类文件加载之后，也就是说必须要带有Class类型的参数，不能通过字节码文件和自定义的类名重新定义一个本来不存在的类。 类的字节码修改称为类转换(Class Transform)，类转换其实最终都回归到类重定义Instrumentation#redefineClasses()方法，此方法有以下限制： 新类和老类的父类必须相同。 新类和老类实现的接口数也要相同，并且是相同的接口。 新类和老类访问符必须一致。 新类和老类字段数和字段名要一致。 新类和老类新增或删除的方法必须是private static/final修饰的。 可以修改方法体。 除了上面的方式，如果想要重新定义一个类，可以考虑基于类加载器隔离的方式：创建一个新的自定义类加载器去通过新的字节码去定义一个全新的类，不过也存在只能通过反射调用该全新类的局限性。 小结 本文仅仅简单分析instrument的原理和基本使用，可以体会到instrument让Java具有了更强的动态控制、解释能力，从而让Java语言变得更加灵活多变。在JDK1.6之后，使用Instrumentation，开发者可以构建一个独立于应用程序的代理程序，用来监测和协助运行在JVM上的程序，可以远程重新转换指定JVM实例里面的已经加载的类，这一点实现从开发者角度来看就像是从JVM级别支持了AOP编程。下一篇文章将会结合实际的场景和字节码改造进行更深入的探究。 参考资料： JVM源码分析之javaagent原理完全解读 - By你假笨 JDK11相关源码 动手写一个javaagent （本文完 c-3-d e-a-20190629 6月份过完了，这个月没有什么产出，o(╯□╰)o）","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Instrument","slug":"Java/Instrument","permalink":"http://throwable.club/blog/categories/Java/Instrument/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Instrument","slug":"Instrument","permalink":"http://throwable.club/blog/tags/Instrument/"}]},{"title":"Java线程生命周期与状态切换","slug":"java-concurrency-thread-state","date":"2019-06-23T15:20:16.000Z","updated":"2019-10-04T02:33:57.859Z","comments":true,"path":"2019/06/23/java-concurrency-thread-state/","link":"","permalink":"http://throwable.club/2019/06/23/java-concurrency-thread-state/","excerpt":"Java线程生命周期与状态切换 前提 最近有点懒散，没什么比较有深度的产出。刚好想重新研读一下JUC线程池的源码实现，在此之前先深入了解一下Java中的线程实现，包括线程的生命周期、状态切换以及线程的上下文切换等等。编写本文的时候，使用的JDK版本是11。","text":"Java线程生命周期与状态切换 前提 最近有点懒散，没什么比较有深度的产出。刚好想重新研读一下JUC线程池的源码实现，在此之前先深入了解一下Java中的线程实现，包括线程的生命周期、状态切换以及线程的上下文切换等等。编写本文的时候，使用的JDK版本是11。 Java线程的实现 在JDK1.2之后，Java线程模型已经确定了基于操作系统原生线程模型实现。因此，目前或者今后的JDK版本中，操作系统支持怎么样的线程模型，在很大程度上决定了Java虚拟机的线程如何映射，这一点在不同的平台上没有办法达成一致，虚拟机规范中也未限定Java线程需要使用哪种线程模型来实现。线程模型只对线程的并发规模和操作成本产生影响，对于Java程序来说，这些差异是透明的。 对应Oracle Sun JDK或者说Oracle Sun JVM而言，它的Windows版本和Linux版本都是使用一对一的线程模型实现的（如下图所示）。 也就是一条Java线程就映射到一条轻量级进程(Light Weight Process)中，而一条轻量级线程又映射到一条内核线程(Kernel-Level Thread)。我们平时所说的线程，往往就是指轻量级进程（或者说我们平时新建的java.lang.Thread就是轻量级进程实例）。前面推算这个线程映射关系，可以知道，我们在应用程序中创建或者操作的java.lang.Thread实例最终会映射到系统的内核线程，如果我们恶意或者实验性无限创建java.lang.Thread实例，最终会影响系统的正常运行甚至导致系统崩溃（可以在Windows开发环境中做实验，确保内存足够的情况下使用死循环创建和运行java.lang.Thread实例）。 线程调度方式包括两种，协同式线程调度和抢占式线程调度。 线程调度方式 描述 劣势 优势 协同式线程调度 线程的执行时间由线程本身控制，执行完毕后主动通知操作系统切换到另一个线程上 某个线程如果不让出CPU执行时间可能会导致整个系统崩溃 实现简单，没有线程同步的问题 抢占式线程调度 每个线程由操作系统来分配执行时间，线程的切换不由线程自身决定 实现相对复杂，操作系统需要控制线程同步和切换 不会出现一个线程阻塞导致系统崩溃的问题 Java线程最终会映射为系统内核原生线程，所以Java线程调度最终取决于系操作系统，而目前主流的操作系统内核线程调度基本都是使用抢占式线程调度。也就是可以死记硬背一下：Java线程是使用抢占式线程调度方式进行线程调度的。 很多操作系统都提供线程优先级的概念，但是由于平台特性的问题，Java中的线程优先级和不同平台中系统线程优先级并不匹配，所以Java线程优先级可以仅仅理解为“建议优先级”，通俗来说就是java.lang.Thread#setPriority(int newPriority)并不一定生效，有可能Java线程的优先级会被系统自行改变。 Java线程的状态切换 Java线程的状态可以从java.lang.Thread的内部枚举类java.lang.Thread$State得知： 1234567891011121314public enum State &#123; NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED;&#125; 这些状态的描述总结成图如下： 线程状态之间关系切换图如下： 下面通过API注释和一些简单的代码例子分析一下Java线程的状态含义和状态切换。 NEW状态 API注释： 12345/** * Thread state for a thread which has not yet started. * */NEW, 线程实例尚未启动时候的线程状态。 一个刚创建而尚未启动（尚未调用Thread#start()方法）的Java线程实例的就是出于NEW状态。 12345678910public class ThreadState &#123; public static void main(String[] args) throws Exception &#123; Thread thread = new Thread(); System.out.println(thread.getState()); &#125;&#125;// 输出结果NEW RUNNABLE状态 API注释： 1234567/** * Thread state for a runnable thread. A thread in the runnable * state is executing in the Java virtual machine but it may * be waiting for other resources from the operating system * such as processor. */RUNNABLE, 可运行状态下线程的线程状态。可运行状态下的线程在Java虚拟机中执行，但它可能执行等待操作系统的其他资源，例如处理器。 当Java线程实例调用了Thread#start()之后，就会进入RUNNABLE状态。RUNNABLE状态可以认为包含两个子状态：READY和RUNNING。 READY：该状态的线程可以被线程调度器进行调度使之更变为RUNNING状态。 RUNNING：该状态表示线程正在运行，线程对象的run()方法中的代码所对应的的指令正在被CPU执行。 当Java线程实例Thread#yield()方法被调用时或者由于线程调度器的调度，线程实例的状态有可能由RUNNING转变为READY，但是从线程状态Thread#getState()获取到的状态依然是RUNNABLE。例如： 123456789101112131415public class ThreadState1 &#123; public static void main(String[] args) throws Exception &#123; Thread thread = new Thread(()-&gt; &#123; while (true)&#123; Thread.yield(); &#125; &#125;); thread.start(); Thread.sleep(2000); System.out.println(thread.getState()); &#125;&#125;// 输出结果RUNNABLE WAITING状态 API注释： 1234567891011121314151617181920/** * Thread state for a waiting thread. * A thread is in the waiting state due to calling one of the * following methods: * &lt;ul&gt; * &lt;li&gt;&#123;@link Object#wait() Object.wait&#125; with no timeout&lt;/li&gt; * &lt;li&gt;&#123;@link #join() Thread.join&#125; with no timeout&lt;/li&gt; * &lt;li&gt;&#123;@link LockSupport#park() LockSupport.park&#125;&lt;/li&gt; * &lt;/ul&gt; * * &lt;p&gt;A thread in the waiting state is waiting for another thread to * perform a particular action. * * For example, a thread that has called &#123;@code Object.wait()&#125; * on an object is waiting for another thread to call * &#123;@code Object.notify()&#125; or &#123;@code Object.notifyAll()&#125; on * that object. A thread that has called &#123;@code Thread.join()&#125; * is waiting for a specified thread to terminate. */ WAITING, 等待中线程的状态。一个线程进入等待状态是由于调用了下面方法之一： 不带超时的Object#wait() 不带超时的Thread#join() LockSupport.park() 一个处于等待状态的线程总是在等待另一个线程进行一些特殊的处理。 例如：一个线程调用了Object#wait()，那么它在等待另一个线程调用对象上的Object#notify()或者Object#notifyAll()；一个线程调用了Thread#join()，那么它在等待另一个线程终结。 WAITING是无限期的等待状态，这种状态下的线程不会被分配CPU执行时间。当一个线程执行了某些方法之后就会进入无限期等待状态，直到被显式唤醒，被唤醒后，线程状态由WAITING更变为RUNNABLE然后继续执行。 RUNNABLE转换为WAITING的方法（无限期等待） WAITING转换为RUNNABLE的方法（唤醒） Object#wait() Object#notify()或者Object#notifyAll() Thread#join() - LockSupport.park() LockSupport.unpark(thread) 其中Thread#join()方法相对比较特殊，它会阻塞线程实例直到线程实例执行完毕，可以观察它的源码如下： 123456789101112131415161718192021222324252627public final void join() throws InterruptedException &#123; join(0);&#125;public final synchronized void join(long millis)throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException(\"timeout value is negative\"); &#125; if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125; 可见Thread#join()是在线程实例存活的时候总是调用Object#wait()方法，也就是必须在线程执行完毕isAlive()为false（意味着线程生命周期已经终结）的时候才会解除阻塞。 基于WAITING状态举个例子： 1234567891011121314151617181920public class ThreadState3 &#123; public static void main(String[] args) throws Exception &#123; Thread thread = new Thread(()-&gt; &#123; LockSupport.park(); while (true)&#123; Thread.yield(); &#125; &#125;); thread.start(); Thread.sleep(50); System.out.println(thread.getState()); LockSupport.unpark(thread); Thread.sleep(50); System.out.println(thread.getState()); &#125;&#125;// 输出结果WAITINGRUNNABLE TIMED WAITING状态 API注释： 12345678910111213/*** Thread state for a waiting thread with a specified waiting time.* A thread is in the timed waiting state due to calling one of* the following methods with a specified positive waiting time:* &lt;ul&gt;* &lt;li&gt;&#123;@link #sleep Thread.sleep&#125;&lt;/li&gt;* &lt;li&gt;&#123;@link Object#wait(long) Object.wait&#125; with timeout&lt;/li&gt;* &lt;li&gt;&#123;@link #join(long) Thread.join&#125; with timeout&lt;/li&gt;* &lt;li&gt;&#123;@link LockSupport#parkNanos LockSupport.parkNanos&#125;&lt;/li&gt;* &lt;li&gt;&#123;@link LockSupport#parkUntil LockSupport.parkUntil&#125;&lt;/li&gt;* &lt;/ul&gt;*/TIMED_WAITING, 定义了具体等待时间的等待中线程的状态。一个线程进入该状态是由于指定了具体的超时期限调用了下面方法之一： Thread.sleep() 带超时的Object#wait() 带超时的Thread#join() LockSupport.parkNanos() LockSupport.parkUntil() TIMED WAITING就是有限期等待状态，它和WAITING有点相似，这种状态下的线程不会被分配CPU执行时间，不过这种状态下的线程不需要被显式唤醒，只需要等待超时限期到达就会被VM唤醒，有点类似于现实生活中的闹钟。 RUNNABLE转换为TIMED WAITING的方法（有限期等待） TIMED WAITING转换为RUNNABLE的方法（超时解除等待） Object#wait(timeout) - Thread#sleep(timeout) - Thread#join(timeout) - LockSupport.parkNanos(timeout) - LockSupport.parkUntil(timeout) - 举个例子： 1234567891011121314151617181920public class ThreadState4 &#123; public static void main(String[] args) throws Exception &#123; Thread thread = new Thread(()-&gt; &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; //ignore &#125; &#125;); thread.start(); Thread.sleep(50); System.out.println(thread.getState()); Thread.sleep(1000); System.out.println(thread.getState()); &#125;&#125;// 输出结果TIMED_WAITINGTERMINATED BLOCKED状态 API注释： 12345678/*** Thread state for a thread blocked waiting for a monitor lock.* A thread in the blocked state is waiting for a monitor lock* to enter a synchronized block/method or* reenter a synchronized block/method after calling* &#123;@link Object#wait() Object.wait&#125;.*/BLOCKED, 此状态表示一个线程正在阻塞等待获取一个监视器锁。如果线程处于阻塞状态，说明线程等待进入同步代码块或者同步方法的监视器锁或者在调用了Object#wait()之后重入同步代码块或者同步方法。 BLOCKED状态也就是阻塞状态，该状态下的线程不会被分配CPU执行时间。线程的状态为BLOCKED的时候有两种可能的情况： A thread in the blocked state is waiting for a monitor lock to enter a synchronized block/method 线程正在等待一个监视器锁，只有获取监视器锁之后才能进入synchronized代码块或者synchronized方法，在此等待获取锁的过程线程都处于阻塞状态。 reenter a synchronized block/method after calling Object#wait() 线程X步入synchronized代码块或者synchronized方法后（此时已经释放监视器锁）调用Object#wait()方法之后进行阻塞，当接收其他线程T调用该锁对象Object#notify()/notifyAll()，但是线程T尚未退出它所在的synchronized代码块或者synchronized方法，那么线程X依然处于阻塞状态（注意API注释中的reenter，理解它场景2就豁然开朗）。 更加详细的描述可以参考笔者之前写过的一篇文章：深入理解Object提供的阻塞和唤醒API。 针对上面的场景1举个简单的例子： 12345678910111213141516171819202122232425262728public class ThreadState6 &#123; private static final Object MONITOR = new Object(); public static void main(String[] args) throws Exception &#123; Thread thread1 = new Thread(()-&gt; &#123; synchronized (MONITOR)&#123; try &#123; Thread.sleep(Integer.MAX_VALUE); &#125; catch (InterruptedException e) &#123; //ignore &#125; &#125; &#125;); Thread thread2 = new Thread(()-&gt; &#123; synchronized (MONITOR)&#123; System.out.println(\"thread2 got monitor lock...\"); &#125; &#125;); thread1.start(); Thread.sleep(50); thread2.start(); Thread.sleep(50); System.out.println(thread2.getState()); &#125;&#125;// 输出结果BLOCKED 针对上面的场景2举个简单的例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ThreadState7 &#123; private static final Object MONITOR = new Object(); private static final DateTimeFormatter F = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"); public static void main(String[] args) throws Exception &#123; System.out.println(String.format(\"[%s]-begin...\", F.format(LocalDateTime.now()))); Thread thread1 = new Thread(() -&gt; &#123; synchronized (MONITOR) &#123; System.out.println(String.format(\"[%s]-thread1 got monitor lock...\", F.format(LocalDateTime.now()))); try &#123; Thread.sleep(1000); MONITOR.wait(); &#125; catch (InterruptedException e) &#123; //ignore &#125; System.out.println(String.format(\"[%s]-thread1 exit waiting...\", F.format(LocalDateTime.now()))); &#125; &#125;); Thread thread2 = new Thread(() -&gt; &#123; synchronized (MONITOR) &#123; System.out.println(String.format(\"[%s]-thread2 got monitor lock...\", F.format(LocalDateTime.now()))); try &#123; MONITOR.notify(); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; //ignore &#125; System.out.println(String.format(\"[%s]-thread2 releases monitor lock...\", F.format(LocalDateTime.now()))); &#125; &#125;); thread1.start(); thread2.start(); // 这里故意让主线程sleep 1500毫秒从而让thread2调用了Object#notify()并且尚未退出同步代码块，确保thread1调用了Object#wait() Thread.sleep(1500); System.out.println(thread1.getState()); System.out.println(String.format(\"[%s]-end...\", F.format(LocalDateTime.now()))); &#125;&#125;// 某个时刻的输出如下：[2019-06-20 00:30:22]-begin...[2019-06-20 00:30:22]-thread1 got monitor lock...[2019-06-20 00:30:23]-thread2 got monitor lock...BLOCKED[2019-06-20 00:30:23]-end...[2019-06-20 00:30:25]-thread2 releases monitor lock...[2019-06-20 00:30:25]-thread1 exit waiting... 场景2中： 线程2调用Object#notify()后睡眠2000毫秒再退出同步代码块，释放监视器锁。 线程1只睡眠了1000毫秒就调用了Object#wait()，此时它已经释放了监视器锁，所以线程2成功进入同步块，线程1处于API注释中所述的reenter a synchronized block/method的状态。 主线程睡眠1500毫秒刚好可以命中线程1处于reenter状态并且打印其线程状态，刚好就是BLOCKED状态。 这三点看起来有点绕，多看几次多思考一下应该就能理解。 TERMINATED状态 API注释： 12345/** * Thread state for a terminated thread. * The thread has completed execution. */ TERMINATED; 终结的线程对应的线程状态，此时线程已经执行完毕。 TERMINATED状态表示线程已经终结。一个线程实例只能被启动一次，准确来说，只会调用一次Thread#run()方法，Thread#run()方法执行结束之后，线程状态就会更变为TERMINATED，意味着线程的生命周期已经结束。 举个简单的例子： 12345678910111213public class ThreadState8 &#123; public static void main(String[] args) throws Exception &#123; Thread thread = new Thread(() -&gt; &#123; &#125;); thread.start(); Thread.sleep(50); System.out.println(thread.getState()); &#125;&#125;// 输出结果TERMINATED 上下文切换 多线程环境中，当一个线程的状态由RUNNABLE转换为非RUNNABLE（BLOCKED、WAITING或者TIMED_WAITING）时，相应线程的上下文信息（也就是常说的Context，包括CPU的寄存器和程序计数器在某一时间点的内容等等）需要被保存，以便线程稍后恢复为RUNNABLE状态时能够在之前的执行进度的基础上继续执行。而一个线程的状态由非RUNNABLE状态进入RUNNABLE状态时可能涉及恢复之前保存的线程上下文信息并且在此基础上继续执行。这里的对线程的上下文信息进行保存和恢复的过程就称为上下文切换（Context Switch）。 线程的上下文切换会带来额外的性能开销，这包括保存和恢复线程上下文信息的开销、对线程进行调度的CPU时间开销以及CPU缓存内容失效的开销（线程所执行的代码从CPU缓存中访问其所需要的变量值要比从主内存(RAM)中访问响应的变量值要快得多，但是线程上下文切换会导致相关线程所访问的CPU缓存内容失效，一般是CPU的L1 Cache和L2 Cache，使得相关线程稍后被重新调度到运行时其不得不再次访问主内存中的变量以重新创建CPU缓存内容）。 在Linux系统中，可以通过vmstat命令来查看全局的上下文切换的次数，例如： 1$ vmstat 1 对于Java程序的运行，在Linux系统中也可以通过perf命令进行监视，例如： 1$ perf stat -e cpu-clock,task-clock,cs,cache-reference,cache-misses java YourJavaClass 参考资料中提到Windows系统下可以通过自带的工具perfmon（其实也就是任务管理器）来监视线程的上下文切换，实际上笔者并没有从任务管理器发现有任何办法查看上下文切换，通过搜索之后发现了一个工具：Process Explorer。运行Process Explorer同时运行一个Java程序并且查看其状态： 因为打了断点，可以看到运行中的程序的上下文切换一共7000多次，当前一秒的上下文切换增量为26（因为笔者设置了Process Explorer每秒刷新一次数据）。 监控线程状态 如果项目在生产环境中运行，不可能频繁调用Thread#getState()方法去监测线程的状态变化。JDK本身提供了一些监控线程状态的工具，还有一些开源的轻量级工具如阿里的Arthas，这里简单介绍一下。 使用jvisualvm jvisualvm是JDK自带的堆、线程等待JVM指标监控工具，适合使用于开发和测试环境。它位于JAVA_HOME/bin目录之下。 其中线程Dump的按钮类似于下面要提到的jstack命令，用于导出所有线程的栈信息。 使用jstack jstack是JDK自带的命令行工具，功能是用于获取指定PID的Java进程的线程栈信息。例如本地运行的一个IDEA实例的PID是11376，那么只需要输入： 1jstack 11376 另外，如果想要定位具体Java进程的PID，可以使用jps命令。 使用JMC JMC也就是Java Mission Control，它也是JDK自带的工具，提供的功能要比jvisualvm强大，包括MBean的处理、线程栈以及线程状态查看、飞行记录器等等。 小结 理解Java线程状态的切换和一些监控手段，更有利于日常开发多线程程序，对于生产环境出现问题，通过监控线程的栈信息能够快速定位到问题的根本原因（通常来说，目前比较主流的MVC应用都是通过一个线程处理一个单独的请求，当请求出现阻塞的时候，导出对应处理请求的线程基本可以定位到阻塞的精准位置，如果使用消息队列例如RabbitMQ，消费者线程出现阻塞也可以利用相似的思路解决）。 参考资料： Jdk11相关源码 《Java多线程编程实战指南》 《深入理解Java虚拟机-2nd》 (本文完 c-7-d e-a-20190623 最近业务迭代有点忙)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Concurrency","slug":"Java/Concurrency","permalink":"http://throwable.club/blog/categories/Java/Concurrency/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Thread","slug":"Thread","permalink":"http://throwable.club/blog/tags/Thread/"}]},{"title":"深入理解Java中的Garbage Collection","slug":"java-jvm-garbage-collection-summary","date":"2019-06-09T03:45:51.000Z","updated":"2019-06-09T03:56:26.814Z","comments":true,"path":"2019/06/09/java-jvm-garbage-collection-summary/","link":"","permalink":"http://throwable.club/2019/06/09/java-jvm-garbage-collection-summary/","excerpt":"前提 最近由于系统业务量比较大，从生产的GC日志(结合Pinpoint)来看，需要对部分系统进行GC调优。但是鉴于以往不是专门做这一块，但是一直都有零散的积累，这里做一个相对全面的总结。本文只针对HotSpot VM也就是Oracle Hotspot VM或者OpenJDK Hotspot VM，版本为Java8，其他VM不一定适用。 什么是GC(Garbage Collection) Garbage Collection可以翻译为“垃圾收集” – 一般主观上会认为做法是：找到垃圾，然后把垃圾扔掉。在VM中，GC的实现过程恰恰相反，GC的目的是为了追踪所有正在使用的对象，并且将剩余的对象标记为垃圾，随后标记为垃圾的对象会被清除，回收这些垃圾对象占据的内存，从而实现内存的自动管理。","text":"前提 最近由于系统业务量比较大，从生产的GC日志(结合Pinpoint)来看，需要对部分系统进行GC调优。但是鉴于以往不是专门做这一块，但是一直都有零散的积累，这里做一个相对全面的总结。本文只针对HotSpot VM也就是Oracle Hotspot VM或者OpenJDK Hotspot VM，版本为Java8，其他VM不一定适用。 什么是GC(Garbage Collection) Garbage Collection可以翻译为“垃圾收集” – 一般主观上会认为做法是：找到垃圾，然后把垃圾扔掉。在VM中，GC的实现过程恰恰相反，GC的目的是为了追踪所有正在使用的对象，并且将剩余的对象标记为垃圾，随后标记为垃圾的对象会被清除，回收这些垃圾对象占据的内存，从而实现内存的自动管理。 分代假说(Generational Hypothesis) 名称 具体内容 弱分代假说（Weak Generational Hypothesis） 大多数对象在年轻时死亡 强分代假说（Strong Generational Hypothesis） 越老的对象越不容易死亡 弱分代假说已经在各种不同类型的编程范式或者编程语言中得到证实，而强分代假说目前提供的证据并不充足，观点还存在争论。 分代垃圾回收器的主要设计目的是减少回收过程的停顿时间，同时提升空间吞吐量。如果采用复制算法对年轻代对象进行回收，那么期望的停顿时间很大程度取决于次级回收(Minor Collection)之后存活的对象总量，而这一数值又取决于年轻代的整体空间。 如果年轻代的整体空间太小，虽然一次回收的过程比较快，但是由于两次回收之间的间隔太短，年轻代对象有可能没有足够的时间“到达死亡”，因而导致回收的内存不多，有可能引发下面的情况： 年轻代的对象回收过于频繁并且存活下来需要复制的对象数量变多，增大垃圾回收器停顿线程和扫描其栈上数据的开销。 将较大比例的年轻代对象提升到老年代会导致老年代被快速填充，会影响整个堆的垃圾回收速率。 许多证据表明，对新生代对象的修改会比老年代对象的修改更加频繁，如果过早将年轻代对象晋升到老年代，那么大量的更新操作(mutation)会给赋值器的写屏障带来比较大的压力。 对象的晋升会使得程序的工作集合变得稀疏。 分代垃圾回收器的设计师对上面几个方面进行平衡的一门艺术： 要尽量加快次级回收的速度。 要尽量减少次级回收的成本。 要减少回收成本更高的主回收(Major Collection)。 要适当减少赋值器的内存管理开销。 基于弱分代假说，JVM中把堆内存分为年轻代(Young Generation)和老年代(Old Generation)，而老年代有些时候也称为Tenured。 JVM对不同分代提供了不同的垃圾回收算法。实际上，不同分代之间的对象有可能相互引用，这些被引用的对象在分代垃圾回收的时候也会被视为GC Roots(见下一节分析)。弱分代假说有可能在特定场景中对某些应用是不适用的；而GC算法针对年轻代或者老年代的对象进行了优化，对于具备“中等”预期寿命的对象，JVM的垃圾回收表现是相对劣势的。 对象判活算法 JVM中是通过可达性算法(Reachability Analysis)来判定对象是否存活的。这个算法的基本思路就是：通过一些列的称为GC Roots(GC根集合)的活跃引用为起始点，从这些集合节点开始向下搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链相连时，说明该对象是不可达的。 GC Roots具体是指什么？这一点可以从HotSpot VM的Parallel Scavenge源码实现总结出来，参考jdk9分支的psTasks.hpp和psTasks.cpp： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192// psTasks.hppclass ScavengeRootsTask : public GCTask &#123; public: enum RootType &#123; universe = 1, jni_handles = 2, threads = 3, object_synchronizer = 4, flat_profiler = 5, system_dictionary = 6, class_loader_data = 7, management = 8, jvmti = 9, code_cache = 10 &#125;; private: RootType _root_type; public: ScavengeRootsTask(RootType value) : _root_type(value) &#123;&#125; char* name() &#123; return (char *)\"scavenge-roots-task\"; &#125; virtual void do_it(GCTaskManager* manager, uint which);&#125;;// psTasks.cppvoid ScavengeRootsTask::do_it(GCTaskManager* manager, uint which) &#123; assert(ParallelScavengeHeap::heap()-&gt;is_gc_active(), \"called outside gc\"); PSPromotionManager* pm = PSPromotionManager::gc_thread_promotion_manager(which); PSScavengeRootsClosure roots_closure(pm); PSPromoteRootsClosure roots_to_old_closure(pm); switch (_root_type) &#123; case universe: Universe::oops_do(&amp;roots_closure); break; case jni_handles: JNIHandles::oops_do(&amp;roots_closure); break; case threads: &#123; ResourceMark rm; Threads::oops_do(&amp;roots_closure, NULL); &#125; break; case object_synchronizer: ObjectSynchronizer::oops_do(&amp;roots_closure); break; case flat_profiler: FlatProfiler::oops_do(&amp;roots_closure); break; case system_dictionary: SystemDictionary::oops_do(&amp;roots_closure); break; case class_loader_data: &#123; PSScavengeKlassClosure klass_closure(pm); ClassLoaderDataGraph::oops_do(&amp;roots_closure, &amp;klass_closure, false); &#125; break; case management: Management::oops_do(&amp;roots_closure); break; case jvmti: JvmtiExport::oops_do(&amp;roots_closure); break; case code_cache: &#123; MarkingCodeBlobClosure each_scavengable_code_blob(&amp;roots_to_old_closure, CodeBlobToOopClosure::FixRelocations); CodeCache::scavenge_root_nmethods_do(&amp;each_scavengable_code_blob); AOTLoader::oops_do(&amp;roots_closure); &#125; break; default: fatal(\"Unknown root type\"); &#125; // Do the real work pm-&gt;drain_stacks(false);&#125; 由于HotSpot VM的源码里面注释比较少，所以只能参考一些资料和源码方法的具体实现猜测GC Roots的具体组成： Universe::oops_do：VM的一些静态数据结构里指向GC堆里的对象的活跃引用等等。 JNIHandles::oops_do：所有的JNI handle，包括所有的global handle和local handle。 Threads::oops_do：所有线程的虚拟机栈，具体应该是所有Java线程当前活跃的栈帧里指向GC堆里的对象的引用，或者换句话说，当前所有正在被调用的方法的引用类型的参数/局部变量/临时值。 ObjectSynchronizer::oops_do：所有被对象同步器关联的对象，看源码应该是ObjectMonitor中处于Block状态的对象，从Java代码层面应该是通过synchronized关键字加锁或者等待加锁的对象。 FlatProfiler::oops_do：所有线程的中的ThreadProfiler。 SystemDictionary::oops_do：System Dictionary，也就是系统字典，是记录了指向Klass，KEY是一个Entry，由KalssName和Classloader组成，实际上，YGC不会处理System Dictionary，但是会扫描System Dictionary，某些GC可能触发类卸载功能，可以这样理解：System Dictionary包含了所有的类加载器。 ClassLoaderDataGraph::oops_do：所有已加载的类或者已加载的系统类。 Management::oops_do：MBean所持有的对象。 JvmtiExport::oops_do：JVMTI导出的对象，断点或者对象分配事件收集器相关的对象。 CodeCache::scavenge_root_nmethods_do：代码缓存(Code Cache)。 AOTLoader::oops_do：AOT加载器相关，包括了AOT相关代码缓存。 还有其他有可能的引用： StringTable::oops_do：所有驻留的字符串(StringTable中的)。 JVM中的内存池 JVM把内存池划分为多个区域，下面分别介绍每个区域的组成和基本功能，方便下面介绍GC算法的时候去理解垃圾收集如何在不同的内存池空间中发挥其职责。 年轻代(Young Generation)：包括Eden和Survivor Spaces，而Survivor Spaces又等分为Survivor 0和Survivor 1，有时候也称为from和to两个区。 老年代(Old Generation)：一般称为Tenured。 元空间：称为Metaspace，在Java8中VM已经移除了永久代Permanent Generation。 Eden 伊甸园是地上的乐园，根据《圣经·旧约·创世纪》记载，神·耶和华照自己的形像造了人类的祖先男人亚当，再用亚当的一个肋骨创造了女人夏娃，并安置第一对男女住在伊甸园中。 Eden，也就是伊甸园，是一块普通的在创建对象的时候进行对象分配的内存区域。而Eden进一步划分为驻留在Eden空间中的一个或者多个Thread Local Allocation Buffer(线程本地分配缓冲区，简称TLAB)，TLAB是线程独占的。JVM允许线程在创建大多数对象的时候直接在相应的TLAB中进行分配，这样可以避免多线程之间进行同步带来的性能开销。 当无法在TLAB中进行对象分配的时候(一般是缓冲区没有足够的空间)，那么对象分配操作将会在Eden中共享的空间(Common Area)中进行。如果整个Eden都没有足够的空间，则会触发YGC(Young Generation Garbage Collection)，以释放更多的Eden中的空间。触发YGC后依然没有足够的内存，那么对象就会在老年代中分配（一般这种情况称为分配担保(Handle Promotion)，是有前置条件的）。 当垃圾回收器收集Eden的时候，会遍历所有相对于GC Roots可达的对象，并且标记它们是活对象，这一阶段称为标记阶段。 这里还有一点需要注意的是：堆中的对象有可能跨代链接，也就是有可能年轻代中的对象被老年代中的对象持有(注：老年代中的对象被年轻代中的对象持有这种情况在YGC中不需要考虑)，这个时候如果不遍历老年代的对象，那么就无法通过可达性算法分析这种被被老年代中的对象持有的年轻代对象是否可达。JVM中采用了Card Marking（卡片标记）的方式解决了这个问题，这里不对卡片标记的细节实现进行展开。 标记阶段完成后，Eden中所有存活的对象会被复制到幸存者空间(Survivor Spaces) 的其中一块空间。复制阶段完成后，整个Eden被认为是空的，可以重新用于分配更多其他的对象。这里采用的GC算法称为标记-复制(Mark and Copy) 算法：标记存活的对象，然后复制它们到幸存者空间(Survivor Spaces) 的其中一块空间，注意这里是复制，不是移动。 关于Eden就介绍这么多，其中TLAB和Card Marking是JVM中的相对底层实现，大概知道即可。 Survivor Spaces Survivor Spaces也就是幸存者空间，幸存者空间最常用的名称是from和to。最重要的一点是：幸存者空间中的两个区域总有一个区域是空的。 下一次YGC触发之后，空闲的那一块幸存者空间才会入驻对象。年轻代的所有存活的对象(包括Eden和非空的from幸存者区域中的存活对象)，都会被复制到to幸存者区域，这个过程完成之后，to幸存者区域会存放着活跃的对象，而from幸存者区域会被清空。接下来，from幸存者区域和to幸存者区域的角色会交换，也就是下一轮YGC触发之后存活的对象会复制到from幸存者区域，而to幸存者区域会被清空，如此循环往复。 上面提到的存活对象的复制过程在两个幸存者空间之间多次往复之后，某些存活的对象“年龄足够大”(经过多次复制还存活下来)，则这些“年纪大的”对象就会晋升到老年代中，这些对象会从幸存者空间移动到老年代空间中，然后它们就驻留在老年代中，直到自身变为不可达。 如果对象在Eden中出生并且经过了第一次YGC之后依然存活，并且能够被Survivor Spaces容纳的话，对象将会被复制到Survivor Spaces并且对象年龄被设定为1。对象在Survivor Spaces中每经历一次YGC之后还能存活下来，则对象年龄就会增加1，当它的年龄增加到晋升老年代的年龄阈值，那么它就会晋升到老年代也就是被移动到老年代中。晋升老年代的年龄阈值的JVM参数是-XX:MaxTenuringThreshold=n： VM参数 功能 可选值 默认值 -XX:MaxTenuringThreshold=n Survivor Spaces存活对象晋升老年代的年龄阈值 1&lt;= n &lt;= 15 15 值得注意的是：JVM中设置-XX:MaxTenuringThreshold的默认值为最大可选值，也就是15。 JVM还具备动态对象年龄判断的功能，JVM并不是永远地要求存活对象的年龄必须达到MaxTenuringThreshold才能晋升到老年代，如果在Survivor Spaces中相同年龄的所有对象的大小总和大于Survivor Spaces的一半，那么年龄大于或者等于该年龄的对象可以直接晋升到老年代，不需要等待对象年龄到达MaxTenuringThreshold，例如： 类型 占比 年龄 动作(MaxTenuringThreshold=15) ObjectType-1 60% 5 下一次YGC如果存活直接晋升到老年代 ObjectType-2 1% 6 下一次YGC如果存活直接晋升到老年代 ObjectType-3 10% 4 下一次YGC如果存活对象年龄增加1 可以简单总结一下对象进入老年代的几种情况： 多次YGC对象存活下来并且年龄到达设定的-XX:MaxTenuringThreshold=n导致对象晋升。 因为动态对象年龄判断导致对象晋升。 大对象直接进入老年代，这里大对象通常指需要大量连续内存的Java对象，最常见的就是大型的数组对象或者长度很大的字符串，因为年轻代完全有可能装不下这类大对象。 年轻代空间不足的时候，老年代会进行空间分配担保，这种情况下对象也是直接在老年代分配。 Tenured 老年代(Old Generation)更多时候被称为Tenured，它的内存空间的实现一般会更加复杂。老年代空间一般要比年轻大大得多，它里面承载的对象一般不会是“内存垃圾”，侧面也说明老年代中的对象的回收率一般比较低。 老年代发生GC的频率一般情况下会比年轻代低，并且老年代中的大多数对象都被期望为存活的对象(也就是对象经历GC之后存活率比较高)，因此标记和复制算法并不适用于老年代。老年代的GC算法一般是移动对象以最小化内存碎片。老年代的GC算法一般规则如下： 通过GC Roots遍历和标记所有可达的对象。 删除所有相对于GC Roots不可达的对象。 通过把存活的对象连续地复制到老年代内存空间的开头(也就是起始地址的一端)以压缩老年代内存空间的内容，这个过程主要包括显式的内存压缩从而避免过多的内存碎片。 Metaspace 在Java8之前JVM内存池中还定义了一块空间叫永久代(Permanent Generation)，这块内存空间主要用于存放元数据例如Class信息等等，它还存放其他数据内容，例如驻留的字符串(字符串常量池)。实际上永久代曾经给Java开发者带来了很多麻烦，因为大多数情况下很难预测永久代需要设定多大的空间，因为开发者也很难预测元数据或者字符串常量池的具体大小，一旦分配的元数据等内容出现了失败就会遇到java.lang.OutOfMemoryError: Permgen space异常。排除内存溢出导致的java.lang.OutOfMemoryError异常，如果是正常情况下导致的异常，唯一的解决手段就是通过VM参数-XX:MaxPermSize=XXXXm增大永久代的内存，不过这样也是治标不治本。 因为元数据等内容是难以预测的，Java8中已经移除了永久代，新增了一块内存区域Metaspace(元空间)，很多其他杂项(例如字符串常量池)都移动了Java堆中。Class定义信息等元数据目前是直接加载到元空间中。元空间是一片分配在机器本地内存(native memory)的内存区，它和承载Java对象的堆内存是隔离的。默认情况下，元空间的大小仅仅受限于机器本地内存可以分配给Java程序的极限值，这样基本可以避免因为添加新的类导致java.lang.OutOfMemoryError: Permgen space异常发生的场景。 VM参数 功能 可选值 默认值 XX:MetaspaceSize=Xm Metaspace扩容时触发FullGC的初始化阈值 - - XX:MaxMetaspaceSize=Ym Metaspace的内存上限 - 接近于无穷大 常用内存池相关的VM参数 -Xmx 和 -Xms VM参数 功能 可选值 默认值 -Xmx 设置最大堆内存大小 有下限控制，视VM版本 - -Xms 设置最小堆内存大小 有下限控制，视VM版本 - -Xmn、-XX:NewRatio 和 -XX:SurvivorRatio VM参数 功能 可选值 默认值 -Xmn 设置年轻代内存大小 - - -XX:NewRatio= 设置老年代和年轻代的内存大小比值，设置为4表示年轻代占堆内存的1/5 - 4 -XX:SurvivorRatio= 设置Eden和幸存者区域的内存大小比值，设置为8表示from:to:Eden=1:1:8 - 8 GC类型 参考R大(RednaxelaFX)的知乎回答，其实在HotSpot VM的GC分类只有两大种： Partial GC：也就是部分GC，不收集整个GC堆。 Young GC：只收集young gen的GC。 Old GC：只收集old gen的GC，目前只有CMS的concurrent collection是这个模式。 Mixed GC：收集整个young gen以及部分old gen的GC，目前只有G1有这个模式。 Full GC：收集整个堆，包括young gen、old gen、perm gen（如果存在的话）等所有部分的模式。 因为HotSpot VM发展多年，外界对GC的名词解读已经混乱，所以才出现了Minor GC、Major GC和Full GC。 Minor GC Minor GC，也就是Minor Garbage Collection，直译为次级垃圾回收，它的定义相对清晰：发生在年轻代的垃圾回收就叫做Minor GC。Minor Garbage Collection处理过程中会发生： 当JVM无法为新的对象分配内存空间的时候，始终会触发Minor GC，常见的情况如Eden的内存已经满了，并且对象分配的发生率越高，Minor GC发生的频率越高。 Minor GC期间，老年代中的对象会被忽略。老年代中的对象引用的年轻代的对象会被认为是GC Roots的一部分，在标记阶段会简单忽略年轻代对象中引用的老年代对象。 Minor GC会导致Stop The World，表现为暂停应用线程。大多数情况下，Eden中的大多数对象都可以视为垃圾并且这些垃圾不会被复制到幸存者空间，这个时候Minor GC的停顿时间会十分短暂，甚至可以忽略不计。相反，如果Eden中有大量存活对象需要复制到幸存者空间，那么Minor GC的停顿时间会显著增加。 Major GC和Full GC Major GC(Major Garbage Collection，可以直译为主垃圾收集)和Full GC目前是两个没有正式定义的术语，具体来说就是：JVM规范中或者垃圾收集研究论文中都没有明确定义Major GC或者Full GC。不过按照民间或者约定俗成，两者区别如下： Major GC：对老年代进行垃圾收集。 Full GC：对整个堆进行垃圾收集 – 包括年轻代和老年代。 实际上，GC过程是十分复杂的，而且很多Major GC都是由Minor GC触发的，所以要严格分割Major GC或者Minor GC几乎是不可能的。另一方面，现在垃圾收集算法像G1收集算法提供部分垃圾回收功能，侧面说明并不能单纯按照收集什么区域来划分GC的类型。 上面的一些理论或者资料指明：与其讨论或者担心GC到底是Major GC或者是Minor GC，不如花更多精力去关注GC过程是否会导致应用的线程停顿或者GC过程是否能够和应用线程并发执行。 常用的GC算法 下面分析一下目前Hotspot VM中比较常见的GC算法，因为G1算法相对复杂，这里暂时没有能力分析。 GC算法的目的 GC算法的目的主要有两个： 找出所有存活的对象，对它们进行标记。 移除所有无用的对象。 寻找存活的对象主要是基于GC Roots的可达性算法，关于标记阶段有几点注意事项： 标记阶段所有应用线程将会停顿(也就是Stop The World)，应用线程暂时停顿保存其信息在还原点中(Safepoint)。 标记阶段的持续时间并不取决于堆中的对象总数或者是堆的大小，而是取决于存活对象的总数，因此增加堆的大小并不会显著影响标记阶段的持续时间。 标记阶段完成后的下一个阶段就是移除所有无用的对象，按照处理方式分为三种常见的算法： Sweep – 清理，也就是Mark and Sweep，标记-清理。 Compact – 压缩，也就是Mark-Sweep-Compact，标记-清理-压缩。 Copy – 复制，也就是Mark and Copy，标记-复制。 Mark-Sweep算法 Mark-Sweep算法，也就是标记-清理算法，是一种间接回收算法(Indirect Collection)，它并非直接检测垃圾对象本身，而是先确定所有存活的对象，然后反过来判断其他对象是垃圾对象。主要包括标记和清理两个阶段，它是最简单和最基础的收集算法，主要包括两个阶段： 第一阶段为追踪(trace)阶段：收集器从GC Roots开始遍历所有可达对象，并且对这些存活的对象进行标记(mark)。 第二阶段为清理(sweep)阶段：收集器把所有未标记的对象进行清理和回收。 Mark-Sweep-Compact算法 内存碎片化是非移动式收集算法无法解决的一个问题之一：尽管堆中有可用空间，但是内存管理器却无法找到一块连续内存块来满足较大对象的分配需求，或者花费较长时间才能找到合适的空闲内存空间。 Mark-Sweep-Compact算法，也就是标记-清理-压缩算法，也是一种间接回收算法(Indirect Collection)，它主要包括三个阶段： 标记阶段：收集器从GC Roots开始遍历所有可达对象，并且对这些存活的对象进行标记。 清理阶段：收集器把所有未标记的对象进行清理和回收。 压缩阶段：收集器把所有存活的对象移动到堆内存的起始端，然后清理掉端边界之外的内存空间。 对堆内存进行压缩整理可以有效地降低内存外部碎片化(External Fragmentation)问题，这个是标记-清理-压缩算法的一个优势。 Mark-Copy算法 Mark-Copy算法，也就是标记-复制算法，和标记-清理-压缩算法十分相似，重要的区别在于：标记-复制算法在标记和清理完成之后，所有存活的对象会被复制到一个不同的内存区域 – 幸存者空间。主要包括三个阶段： 标记阶段：收集器从GC Roots开始遍历所有可达对象，并且对这些存活的对象进行标记。 清理阶段：收集器把所有未标记的对象进行清理和回收 — 实际上这一步可能是不存在的，因为存活对象指针被复制之后，原来指针所在的位置已经可以重新分配新的对象，可以不进行清理。 复制阶段：把所有存活的对象复制到Survivor Spaces中的某一块空间中。 标记-复制算法可以避免内存碎片化的问题，但是它的代价比较大，因为用的是半区复制回收，区域可用内存为原来的一半。 小结 JVM和GC是Java开发者必须掌握的内容，包含的知识其实还是挺多的，本文也只是简单介绍了一些基本概念： 分代假说。 Minor GC、Major GC和Full GC。 内存池组成。 常用的GC算法。 后面会分析一下GC收集器搭配和GC日志查看、JVM提供的工具等等。 参考资料： 《深入理解Java虚拟机-2nd》 《The Garbage Collection Handbook》 知乎-RednaxelaFX部分回答 Java Garbage Collection handbook OpenJDK HotSpot VM部分源码","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"http://throwable.club/blog/categories/Java/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://throwable.club/blog/tags/JVM/"}]},{"title":"Hystrix完整配置列表","slug":"framework-hystrix-full-configuration","date":"2019-05-29T03:27:56.000Z","updated":"2019-06-01T17:24:02.008Z","comments":true,"path":"2019/05/29/framework-hystrix-full-configuration/","link":"","permalink":"http://throwable.club/2019/05/29/framework-hystrix-full-configuration/","excerpt":"前提 Hystrix在2018年11月20日之后已经停止维护，最后一个提交记录是：Latest commit 3cb2158 on 20 Nov 2018，最后一个正式版本为1.5.18。鉴于目前所在公司的技术栈是Spring Cloud，熔断和降级组件主要用的还是Hystrix，这里就Hystrix的完整列表做一个分析记录，方便以后可以随时查询。本文主要参考：Hystrix Configuration。其中，命令配置是针对HystrixCommand，主要包括命令执行(execution)配置、命令降级(fallback)配置、熔断器(circuit breaker)配置、度量统计(metrics)配置和请求上下文配置。","text":"前提 Hystrix在2018年11月20日之后已经停止维护，最后一个提交记录是：Latest commit 3cb2158 on 20 Nov 2018，最后一个正式版本为1.5.18。鉴于目前所在公司的技术栈是Spring Cloud，熔断和降级组件主要用的还是Hystrix，这里就Hystrix的完整列表做一个分析记录，方便以后可以随时查询。本文主要参考：Hystrix Configuration。其中，命令配置是针对HystrixCommand，主要包括命令执行(execution)配置、命令降级(fallback)配置、熔断器(circuit breaker)配置、度量统计(metrics)配置和请求上下文配置。 HystrixCommandKey、HystrixCommandGroupKey和HystrixThreadPoolKey HystrixCommandKey、HystrixCommandGroupKey和HystrixThreadPoolKey三个KEY是HystrixCommand的重要标识。下面分别分析一下它们的含义。 HystrixCommandKey HystrixCommandKey是Hystrix命令的唯一标识，准确来说是HystrixCommand实例或者HystrixObservableCommand实例的唯一标识。它是必须的，如果不自定义配置，它会通过下面方式确定默认值： 1[HystrixCommand或者HystrixObservableCommand的具体子类].getClass().getSimpleName(); 编程式配置如下： 1234567HystrixCommandKey.Factory.asKey(\"Your Key\");public Command() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"Group Key\")) .andCommandKey(HystrixCommandKey.Factory.asKey(\"Command Key\")));&#125; 注意一点：大部分Hystrix的配置都是和HystrixCommandKey绑定，所以HystrixCommandKey是比较重要的。 HystrixCommandGroupKey HystrixCommandGroupKey是用于对Hystrix命令进行分组，分组之后便于统计展示于仪表盘、上传报告和预警等等，也就是说，HystrixCommandGroupKey是Hystrix内部进行度量统计时候的分组标识，数据上报和统计的最小维度就是分组的KEY。HystrixCommandGroupKey是必须配置的，配置方式如下： 12345HystrixCommandGroupKey.Factory.asKey(\"Group Key\")public Command() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"Group Key\")));&#125; HystrixThreadPoolKey HystrixThreadPoolKey主要标识用于监控、度量和缓存等等作用的HystrixThreadPool实例。一个HystrixCommand会和一个独立的HystrixThreadPool实例关联，也就是说一类HystrixCommand总是在同一个HystrixThreadPool实例中执行。如果不显式配置HystrixThreadPoolKey，那么会使用HystrixCommandGroupKey的值去配置HystrixThreadPoolKey。HystrixThreadPoolKey的配置方式如下： 1234567HystrixThreadPoolKey.Factory.asKey(\"ThreadPoolKey\")public Command() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"xxx\")) .andCommandKey(HystrixCommandKey.Factory.asKey(\"YYY\")) .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(\"ThreadPoolKey\")));&#125; 命令执行(execution)配置 隔离策略 execution.isolation.strategy 隔离策略决定Hystrix命令执行的时候采用什么类型的策略进行依赖隔离。 项 值 默认值 THREAD (见ExecutionIsolationStrategy.THREAD) 可选值 THREAD,SEMAPHORE 默认全局配置 hystrix.command.default.execution.isolation.strategy 实例配置 hystrix.command.[HystrixCommandKey].execution.isolation.strategy 执行隔离策略到底选择线程池(THREAD)还是信号量(SEMAPHORE)？文档中给出的建议是： 使用HystrixCommand的时候建议用THREAD策略，使用HystrixObservableCommand的时候建议使用SEMAPHORE策略。 使用THREAD策略让HystrixCommand在线程中执行可以提供额外的保护层，以防止因为网络超时导致的延时失败。 一般情况下，只有这种特殊例子下HystrixCommand会搭配SEMAPHORE策略使用：调用的频次太高(例如每个实例每秒数百次调用)，这种情况如果选用THREAD策略有可能导致超过线程隔离的上限(有可能需要太多的线程或者命令太多线程不足够用于隔离请求)，这种情况一般是非网络请求调用。 笔者想说的是：建议选用默认值，因为目前很少遇到使用信号量隔离的场景。 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withExecutionIsolationStrategy(HystrixCommandProperties.ExecutionIsolationStrategy.THREAD))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.execution.isolation.strategy=THREAD# 实例配置hystrix.command.CustomCommand.execution.isolation.strategy=THREAD 是否允许超时 execution.timeout.enabled 决定HystrixCommand#run()执行时是否允许超时，只有设置为true的时候，下面提到的“超时时间上限”才会有效。 项 值 默认值 true 可选值 true,false 默认全局配置 hystrix.command.default.execution.timeout.enabled 实例配置 hystrix.command.[HystrixCommandKey].execution.timeout.enabled 建议(笔者备注) 保持选用默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withExecutionTimeoutEnabled(true))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.execution.timeout.enabled=true# 实例配置hystrix.command.CustomCommand.execution.timeout.enabled=true 超时时间上限 execution.isolation.thread.timeoutInMilliseconds HystrixCommand执行时候超时的最大上限，单位是毫秒，如果命令执行耗时超过此时间值那么会进入降级逻辑。这个配置生效的前提是hystrix.command.default.execution.timeout.enabled或者hystrix.command.[HystrixCommandKey].execution.timeout.enabled为true。 项 值 默认值 1000 可选值 - 默认全局配置 hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds 实例配置 hystrix.command.[HystrixCommandKey].execution.isolation.thread.timeoutInMilliseconds 建议(笔者备注) 保持选用默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withExecutionTimeoutInMilliseconds(1000))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=1000# 实例配置hystrix.command.CustomCommand.execution.isolation.thread.timeoutInMilliseconds=1000 超时是否中断 此配置项决定HystrixCommand#run()执行的时候调用超时的情况下是否中断。 项 值 默认值 true 可选值 true、false 默认全局配置 hystrix.command.default.execution.isolation.thread.interruptOnTimeout 实例配置 hystrix.command.[HystrixCommandKey].execution.isolation.thread.interruptOnTimeout 建议(笔者备注) 保持选用默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withExecutionIsolationThreadInterruptOnTimeout(true))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.execution.isolation.thread.interruptOnTimeout=true# 实例配置hystrix.command.CustomCommand.execution.isolation.thread.interruptOnTimeout=true 取消是否中断 execution.isolation.thread.interruptOnCancel 此配置项决定HystrixCommand#run()执行的时候取消调用的情况下是否中断。 项 值 默认值 false 可选值 true、false 默认全局配置 hystrix.command.default.execution.isolation.thread.interruptOnCancel 实例配置 hystrix.command.[HystrixCommandKey].execution.isolation.thread.interruptOnCancel 建议(笔者备注) 保持选用默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withExecutionIsolationThreadInterruptOnFutureCancel(false))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.execution.isolation.thread.interruptOnCancel=false# 实例配置hystrix.command.CustomCommand.execution.isolation.thread.interruptOnCancel=false 最大并发请求上限(SEMAPHORE) execution.isolation.semaphore.maxConcurrentRequests 此配置项决定使用HystrixCommand#run()方法和ExecutionIsolationStrategy.SEMAPHORE隔离策略下并发请求数量的最高上限。 项 值 默认值 10 可选值 - 默认全局配置 hystrix.command.default.execution.isolation.semaphore.maxConcurrentRequests 实例配置 hystrix.command.[HystrixCommandKey].execution.isolation.semaphore.maxConcurrentRequests 建议(笔者备注) 必须根据实际情况设定此值 编程式配置： 1234567891011121314public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withExecutionIsolationStrategy(HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE) .withExecutionIsolationSemaphoreMaxConcurrentRequests(100))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.execution.isolation.semaphore.maxConcurrentRequests=100# 实例配置hystrix.command.CustomCommand.execution.isolation.semaphore.maxConcurrentRequests=100 命令降级(fallback)配置 命令降级配置控制HystrixCommand#getFallback()的执行逻辑，所有命令降级配置对策略ExecutionIsolationStrategy.THREAD或者ExecutionIsolationStrategy.SEMAPHORE都生效。 最大并发降级请求处理上限 fallback.isolation.semaphore.maxConcurrentRequests 这个属性用于控制一个HystrixCommand#getFallback()实例方法在执行线程中调用的最大上限，如果超过此上限，降级逻辑不会执行并且会抛出一个异常。 项 值 默认值 10 可选值 - 默认全局配置 hystrix.command.default.fallback.isolation.semaphore.maxConcurrentRequests 实例配置 hystrix.command.[HystrixCommandKey].fallback.isolation.semaphore.maxConcurrentRequests 建议(笔者备注) 必须根据实际情况设定此值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withFallbackIsolationSemaphoreMaxConcurrentRequests(20))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.fallback.isolation.semaphore.maxConcurrentRequests=20# 实例配置hystrix.command.CustomCommand.fallback.isolation.semaphore.maxConcurrentRequests=20 是否开启降级 fallback.enabled 此属性控制当HystrixCommand执行失败之后是否调用HystrixCommand#getFallback()。 项 值 默认值 true 可选值 false、true 默认全局配置 hystrix.command.default.fallback.enabled 实例配置 hystrix.command.[HystrixCommandKey].fallback.enabled 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withFallbackEnabled(true))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.fallback.enabled=true# 实例配置hystrix.command.CustomCommand.fallback.enabled=true 断路器(circuit breaker)配置 断路器配置用于控制HystrixCircuitBreaker实例的行为。 是否启用断路器 circuitBreaker.enabled 此属性确定断路器是否用于跟踪健康状况，以及当断路器打开的时候是否用于短路请求(使请求快速失败进入降级逻辑)。 项 值 默认值 true 可选值 false、true 默认全局配置 hystrix.command.default.circuitBreaker.enabled 实例配置 hystrix.command.[HystrixCommandKey].circuitBreaker.enabled 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withCircuitBreakerEnabled(true))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.circuitBreaker.enabled=true# 实例配置hystrix.command.CustomCommand.circuitBreaker.enabled=true 断路器请求量阈值 circuitBreaker.requestVolumeThreshold 此属性设置将使断路器打开的滑动窗口中的最小请求数量。 例如，如果值是20，那么如果在滑动窗口中只接收到19个请求(比如一个10秒的窗口)，即使所有19个请求都失败了，断路器也不会打开。 项 值 默认值 20 可选值 - 默认全局配置 hystrix.command.default.circuitBreaker.requestVolumeThreshold 实例配置 hystrix.command.[HystrixCommandKey].circuitBreaker.requestVolumeThreshold 建议(笔者备注) 建议保持默认值，如果部分接口不能容忍默认阈值可以单独配置 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withCircuitBreakerRequestVolumeThreshold(10))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.circuitBreaker.requestVolumeThreshold=10# 实例配置hystrix.command.CustomCommand.circuitBreaker.requestVolumeThreshold=10 断路器等待窗口时间 circuitBreaker.sleepWindowInMilliseconds 此属性设置断路器打开后拒绝请求的时间量，每隔一段时间(sleepWindowInMilliseconds，单位是毫秒)允许再次尝试(也就是放行一个请求)确定是否应该关闭断路器。 项 值 默认值 5000 可选值 - 默认全局配置 hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds 实例配置 hystrix.command.[HystrixCommandKey].circuitBreaker.sleepWindowInMilliseconds 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withCircuitBreakerSleepWindowInMilliseconds(5000))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds=5000# 实例配置hystrix.command.CustomCommand.circuitBreaker.sleepWindowInMilliseconds=5000 断路器错误百分比阈值 circuitBreaker.errorThresholdPercentage 此属性设置一个错误百分比，当请求错误率超过设定值，断路器就会打开。 项 值 默认值 50 可选值 - 默认全局配置 hystrix.command.default.circuitBreaker.errorThresholdPercentage 实例配置 hystrix.command.[HystrixCommandKey].circuitBreaker.errorThresholdPercentage 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withCircuitBreakerErrorThresholdPercentage(50))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.circuitBreaker.errorThresholdPercentage=50# 实例配置hystrix.command.CustomCommand.circuitBreaker.errorThresholdPercentage=50 注意： 配置项circuitBreaker.requestVolumeThreshold针对错误请求数量。 配置项circuitBreaker.errorThresholdPercentage针对错误请求百分比。 是否强制打开断路器 circuitBreaker.forceOpen 此属性控制断路器是否强制打开，强制打开断路器会使所有请求直接进入降级逻辑，也就是包裹在HystrixCommand#run()的逻辑不会执行。circuitBreaker.forceOpen属性和circuitBreaker.forceClosed属性互斥。 项 值 默认值 false 可选值 false、true 默认全局配置 hystrix.command.default.circuitBreaker.forceOpen 实例配置 hystrix.command.[HystrixCommandKey].circuitBreaker.forceOpen 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withCircuitBreakerForceOpen(true))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.circuitBreaker.forceOpen=true# 实例配置hystrix.command.CustomCommand.circuitBreaker.forceOpen=true 是否强制关闭断路器 circuitBreaker.forceClosed 此属性控制断路器是否强制关闭，强制关闭断路器会导致所有和断路器相关的配置和功能都失效，HystrixCommand#run()抛出异常会正常进入降级逻辑。circuitBreaker.forceClosed属性和circuitBreaker.forceOpen属性互斥。 项 值 默认值 false 可选值 false、true 默认全局配置 hystrix.command.default.circuitBreaker.forceClosed 实例配置 hystrix.command.[HystrixCommandKey].circuitBreaker.forceClosed 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withCircuitBreakerForceClosed(true))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.circuitBreaker.forceClosed=true# 实例配置hystrix.command.CustomCommand.circuitBreaker.forceClosed=true 度量统计(metrics)配置 度量统计配置会对HystrixCommand或者HystrixObservableCommand执行时候的统计数据收集动作生效。 滑动窗口持续时间 metrics.rollingStats.timeInMilliseconds 项 值 默认值 10000 可选值 - 默认全局配置 hystrix.command.default.metrics.rollingStats.timeInMilliseconds 实例配置 hystrix.command.[HystrixCommandKey].metrics.rollingStats.timeInMilliseconds 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withMetricsRollingStatisticalWindowInMilliseconds(10000))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.metrics.rollingStats.timeInMilliseconds=10000# 实例配置hystrix.command.CustomCommand.metrics.rollingStats.timeInMilliseconds=10000 滑动窗口Bucket总数 metrics.rollingStats.numBuckets 项 值 默认值 10 可选值 需要满足metrics.rollingStats.timeInMilliseconds % metrics.rollingStats.numBuckets == 0，要尽量小，否则有可能影响性能 默认全局配置 hystrix.command.default.metrics.rollingStats.numBuckets 实例配置 hystrix.command.[HystrixCommandKey].metrics.rollingStats.numBuckets 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withMetricsRollingStatisticalWindowBuckets(100))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.metrics.rollingStats.numBuckets=10# 实例配置hystrix.command.CustomCommand.metrics.rollingStats.numBuckets=10 是否启用百分数计算 metrics.rollingPercentile.enabled 项 值 默认值 true 可选值 true、false 默认全局配置 hystrix.command.default.metrics.rollingPercentile.enabled 实例配置 hystrix.command.[HystrixCommandKey].metrics.rollingPercentile.enabled 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withMetricsRollingPercentileEnabled(true))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.metrics.rollingPercentile.enabled=true# 实例配置hystrix.command.CustomCommand.metrics.rollingPercentile.enabled=true 百分数计算使用的滑动窗口持续时间 metrics.rollingPercentile.timeInMilliseconds 项 值 默认值 60000 可选值 - 默认全局配置 hystrix.command.default.metrics.rollingPercentile.timeInMilliseconds 实例配置 hystrix.command.[HystrixCommandKey].metrics.rollingPercentile.timeInMilliseconds 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withMetricsRollingPercentileWindowInMilliseconds(60000))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.metrics.rollingPercentile.timeInMilliseconds=60000# 实例配置hystrix.command.CustomCommand.metrics.rollingPercentile.timeInMilliseconds=60000 百分数计算使用的Bucket总数 metrics.rollingPercentile.numBuckets 项 值 默认值 6 可选值 满足metrics.rollingPercentile.timeInMilliseconds % metrics.rollingPercentile.numBuckets == 0，要尽量小，否则有可能影响性能 默认全局配置 hystrix.command.default.metrics.rollingPercentile.numBuckets 实例配置 hystrix.command.[HystrixCommandKey].metrics.rollingPercentile.numBuckets 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withMetricsRollingPercentileWindowBuckets(6))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.metrics.rollingPercentile.numBuckets=6# 实例配置hystrix.command.CustomCommand.metrics.rollingPercentile.numBuckets=6 百分数计算使用的Bucket容量 metrics.rollingPercentile.bucketSize 项 值 默认值 100 可选值 - 默认全局配置 hystrix.command.default.metrics.rollingPercentile.bucketSize 实例配置 hystrix.command.[HystrixCommandKey].metrics.rollingPercentile.bucketSize 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withMetricsRollingPercentileBucketSize(100))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.metrics.rollingPercentile.bucketSize=100# 实例配置hystrix.command.CustomCommand.metrics.rollingPercentile.bucketSize=100 健康状态快照收集的周期 metrics.healthSnapshot.intervalInMilliseconds 项 值 默认值 500 可选值 - 默认全局配置 hystrix.command.default.metrics.healthSnapshot.intervalInMilliseconds 实例配置 hystrix.command.[HystrixCommandKey].metrics.healthSnapshot.intervalInMilliseconds 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withMetricsHealthSnapshotIntervalInMilliseconds(500))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.metrics.healthSnapshot.intervalInMilliseconds=500# 实例配置hystrix.command.CustomCommand.metrics.healthSnapshot.intervalInMilliseconds=500 请求上下文配置 请求上下文属性主要涉及到HystrixRequestContext和HystrixCommand的使用。 是否启用请求缓存 requestCache.enabled 项 值 默认值 true 可选值 true、false 默认全局配置 hystrix.command.default.requestCache.enabled 实例配置 hystrix.command.[HystrixCommandKey].requestCache.enabled 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withRequestCacheEnabled(true))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.requestCache.enabled=true# 实例配置hystrix.command.CustomCommand.requestCache.enabled=true 是否启用请求日志 requestLog.enabled 项 值 默认值 true 可选值 true、false 默认全局配置 hystrix.command.default.requestLog.enabled 实例配置 hystrix.command.[HystrixCommandKey].requestLog.enabled 建议(笔者备注) 建议保持默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() .withRequestLogEnabled(true))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.command.default.requestLog.enabled=true# 实例配置hystrix.command.CustomCommand.requestLog.enabled=true 请求合成器配置 请求合成器配置主要控制HystrixCollapser的行为。 请求合成的最大批次量 maxRequestsInBatch 项 值 默认值 Integer.MAX_VALUE 可选值 - 默认全局配置 hystrix.collapser.default.maxRequestsInBatch 实例配置 hystrix.collapser.[HystrixCollapserKey].maxRequestsInBatch 建议(笔者备注) 建议保持默认值 编程式配置： 1234567891011121314151617181920212223public class CustomHystrixCollapser extends HystrixCollapser&lt;List&lt;String&gt;, String, String&gt; &#123; public CustomHystrixCollapser(Setter setter) &#123; super(Setter.withCollapserKey(HystrixCollapserKey.Factory.asKey(\"CustomHystrixCollapser\")) .andCollapserPropertiesDefaults(HystrixCollapserProperties.Setter() .withMaxRequestsInBatch(10))); &#125; @Override public String getRequestArgument() &#123; return null; &#125; @Override protected HystrixCommand&lt;List&lt;String&gt;&gt; createCommand(Collection&lt;CollapsedRequest&lt;String, String&gt;&gt; collapsedRequests) &#123; return null; &#125; @Override protected void mapResponseToRequests(List&lt;String&gt; batchResponse, Collection&lt;CollapsedRequest&lt;String, String&gt;&gt; collapsedRequests) &#123; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.collapser.default.maxRequestsInBatch=10# 实例配置hystrix.collapser.CustomHystrixCollapser.maxRequestsInBatch=10 延迟执行时间 timerDelayInMilliseconds 项 值 默认值 10 可选值 - 默认全局配置 hystrix.collapser.default.timerDelayInMilliseconds 实例配置 hystrix.collapser.[HystrixCollapserKey].timerDelayInMilliseconds 建议(笔者备注) 建议保持默认值 编程式配置： 1234567891011121314151617181920212223public class CustomHystrixCollapser extends HystrixCollapser&lt;List&lt;String&gt;, String, String&gt; &#123; public CustomHystrixCollapser(Setter setter) &#123; super(Setter.withCollapserKey(HystrixCollapserKey.Factory.asKey(\"CustomHystrixCollapser\")) .andCollapserPropertiesDefaults(HystrixCollapserProperties.Setter() .withTimerDelayInMilliseconds(10))); &#125; @Override public String getRequestArgument() &#123; return null; &#125; @Override protected HystrixCommand&lt;List&lt;String&gt;&gt; createCommand(Collection&lt;CollapsedRequest&lt;String, String&gt;&gt; collapsedRequests) &#123; return null; &#125; @Override protected void mapResponseToRequests(List&lt;String&gt; batchResponse, Collection&lt;CollapsedRequest&lt;String, String&gt;&gt; collapsedRequests) &#123; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.collapser.default.timerDelayInMilliseconds=10# 实例配置hystrix.collapser.CustomHystrixCollapser.timerDelayInMilliseconds=10 是否启用请求合成缓存 requestCache.enabled 项 值 默认值 true 可选值 true、false 默认全局配置 hystrix.collapser.default.requestCache.enabled 实例配置 hystrix.collapser.[HystrixCollapserKey].requestCache.enabled 建议(笔者备注) 建议保持默认值 编程式配置： 1234567891011121314151617181920212223public class CustomHystrixCollapser extends HystrixCollapser&lt;List&lt;String&gt;, String, String&gt; &#123; public CustomHystrixCollapser(Setter setter) &#123; super(Setter.withCollapserKey(HystrixCollapserKey.Factory.asKey(\"CustomHystrixCollapser\")) .andCollapserPropertiesDefaults(HystrixCollapserProperties.Setter() .withTimerDelayInMilliseconds(10))); &#125; @Override public String getRequestArgument() &#123; return null; &#125; @Override protected HystrixCommand&lt;List&lt;String&gt;&gt; createCommand(Collection&lt;CollapsedRequest&lt;String, String&gt;&gt; collapsedRequests) &#123; return null; &#125; @Override protected void mapResponseToRequests(List&lt;String&gt; batchResponse, Collection&lt;CollapsedRequest&lt;String, String&gt;&gt; collapsedRequests) &#123; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.collapser.default.requestCache.enabled=true# 实例配置hystrix.collapser.CustomHystrixCollapser.requestCache.enabled=true 线程池配置 Hystrix使用的是JUC线程池ThreadPoolExecutor，线程池相关配置直接影响ThreadPoolExecutor实例。Hystrix的命令执行选用了线程池策略，那么就是通过线程池隔离执行的，最好为每一个分组设立独立的线程池。笔者在生产实践的时候，一般把HystrixCommandGroupKey和HystrixThreadPoolKey设置为一致。 核心线程数 coreSize 项 值 默认值 10 可选值 - 默认全局配置 hystrix.threadpool.default.coreSize 实例配置 hystrix.threadpool.[HystrixThreadPoolKey].coreSize 建议(笔者备注) 根据真实情况自行配置和调整 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() .withCoreSize(10))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.threadpool.default.coreSize=10# 实例配置hystrix.threadpool.CustomCommand.coreSize=10 最大线程数 maximumSize 此属性只有在allowMaximumSizeToDivergeFromCoreSize为true的时候才生效。 项 值 默认值 10 可选值 - 默认全局配置 hystrix.threadpool.default.maximumSize 实例配置 hystrix.threadpool.[HystrixThreadPoolKey].maximumSize 建议(笔者备注) 根据真实情况自行配置和调整 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() .withMaximumSize(10))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.threadpool.default.maximumSize=10# 实例配置hystrix.threadpool.CustomCommand.maximumSize=10 最大任务队列容量 maxQueueSize 此属性配置为-1时使用的是SynchronousQueue，配置为大于1的整数时使用的是LinkedBlockingQueue。 项 值 默认值 -1 可选值 -1或者大于0的整数 默认全局配置 hystrix.threadpool.default.maxQueueSize 实例配置 hystrix.threadpool.[HystrixThreadPoolKey].maxQueueSize 建议(笔者备注) 根据真实情况自行配置和调整 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() .withMaxQueueSize(-1))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.threadpool.default.maxQueueSize=-1# 实例配置hystrix.threadpool.CustomCommand.maxQueueSize=-1 任务拒绝的任务队列阈值 queueSizeRejectionThreshold 当maxQueueSize配置为-1的时候，此配置项不生效。 项 值 默认值 5 可选值 大于0的整数 默认全局配置 hystrix.threadpool.default.queueSizeRejectionThreshold 实例配置 hystrix.threadpool.[HystrixThreadPoolKey].queueSizeRejectionThreshold 建议(笔者备注) 根据真实情况自行配置和调整 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() .withQueueSizeRejectionThreshold(5))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.threadpool.default.queueSizeRejectionThreshold=5# 实例配置hystrix.threadpool.CustomCommand.queueSizeRejectionThreshold=5 非核心线程存活时间 keepAliveTimeMinutes 当allowMaximumSizeToDivergeFromCoreSize为true并且maximumSize大于coreSize时此配置才生效。 项 值 默认值 1 可选值 大于0的整数 默认全局配置 hystrix.threadpool.default.keepAliveTimeMinutes 实例配置 hystrix.threadpool.[HystrixThreadPoolKey].keepAliveTimeMinutes 建议(笔者备注) 根据真实情况自行配置和调整 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() .withKeepAliveTimeMinutes(1))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.threadpool.default.keepAliveTimeMinutes=1# 实例配置hystrix.threadpool.CustomCommand.keepAliveTimeMinutes=1 是否允许最大线程数生效 allowMaximumSizeToDivergeFromCoreSize 项 值 默认值 false 可选值 true、false 默认全局配置 hystrix.threadpool.default.allowMaximumSizeToDivergeFromCoreSize 实例配置 hystrix.threadpool.[HystrixThreadPoolKey].allowMaximumSizeToDivergeFromCoreSize 建议(笔者备注) 根据真实情况自行配置和调整 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() .withAllowMaximumSizeToDivergeFromCoreSize(true))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.threadpool.default.allowMaximumSizeToDivergeFromCoreSize=true# 实例配置hystrix.threadpool.CustomCommand.allowMaximumSizeToDivergeFromCoreSize=true 线程池滑动窗口持续时间 metrics.rollingStats.timeInMilliseconds 项 值 默认值 10000 可选值 - 默认全局配置 hystrix.threadpool.default.metrics.rollingStats.timeInMilliseconds 实例配置 hystrix.threadpool.[HystrixThreadPoolKey].metrics.rollingStats.timeInMilliseconds 建议(笔者备注) 建议使用默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() .withMetricsRollingStatisticalWindowInMilliseconds(10000))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.threadpool.default.metrics.rollingStats.timeInMilliseconds=10000# 实例配置hystrix.threadpool.CustomCommand.metrics.rollingStats.timeInMilliseconds=10000 线程池滑动窗口Bucket总数 metrics.rollingStats.numBuckets 项 值 默认值 10 可选值 满足metrics.rollingStats.timeInMilliseconds % metrics.rollingStats.numBuckets == 0，值要尽量少，否则会影响性能 默认全局配置 hystrix.threadpool.default.metrics.rollingStats.numBuckets 实例配置 hystrix.threadpool.[HystrixThreadPoolKey].metrics.rollingStats.numBuckets 建议(笔者备注) 建议使用默认值 编程式配置： 12345678910111213public class CustomCommand extends HystrixCommand&lt;String&gt; &#123; public CustomCommand() &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"CustomCommand\")) .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() .withMetricsRollingStatisticalWindowBuckets(10))); &#125; @Override protected String run() throws Exception &#123; return null; &#125;&#125; 配置文件中(Properties)配置： 1234567# 下面配置二选一# 默认全局配置hystrix.threadpool.default.metrics.rollingStats.numBuckets=10# 实例配置hystrix.threadpool.CustomCommand.metrics.rollingStats.numBuckets=10 (本文完 e-a-201890602 1:00 AM c-3-d)","categories":[{"name":"Framework","slug":"Framework","permalink":"http://throwable.club/blog/categories/Framework/"},{"name":"Hystrix","slug":"Framework/Hystrix","permalink":"http://throwable.club/blog/categories/Framework/Hystrix/"}],"tags":[{"name":"Framework","slug":"Framework","permalink":"http://throwable.club/blog/tags/Framework/"},{"name":"Hystrix","slug":"Hystrix","permalink":"http://throwable.club/blog/tags/Hystrix/"}]},{"title":"内部分享-Spring Cloud Gateway初体验","slug":"in-action-share-spring-cloud-gateway-guide","date":"2019-05-27T13:46:31.000Z","updated":"2019-05-27T14:01:29.988Z","comments":true,"path":"2019/05/27/in-action-share-spring-cloud-gateway-guide/","link":"","permalink":"http://throwable.club/2019/05/27/in-action-share-spring-cloud-gateway-guide/","excerpt":"","text":"目录 === 简介 === === === 工作原理 === === === === === === === === === === ===","categories":[],"tags":[{"name":"In Action","slug":"In-Action","permalink":"http://throwable.club/blog/tags/In-Action/"},{"name":"Spring Cloud Gateway","slug":"Spring-Cloud-Gateway","permalink":"http://throwable.club/blog/tags/Spring-Cloud-Gateway/"}]},{"title":"内部分享-聊聊常用的线程模型","slug":"in-action-share-talk-about-java-thread-model","date":"2019-05-26T12:02:01.000Z","updated":"2019-05-27T14:26:22.630Z","comments":true,"path":"2019/05/26/in-action-share-talk-about-java-thread-model/","link":"","permalink":"http://throwable.club/2019/05/26/in-action-share-talk-about-java-thread-model/","excerpt":"","text":"基本概念 === === 单线程模型 === === 多线程模型 === === === Reactor线程模型 === ===","categories":[],"tags":[{"name":"In Action","slug":"In-Action","permalink":"http://throwable.club/blog/tags/In-Action/"},{"name":"Concurrency","slug":"Concurrency","permalink":"http://throwable.club/blog/tags/Concurrency/"}]},{"title":"Spring Cloud Gateway-使用自定义过滤器通过Hystrix实现降级处理","slug":"spring-cloud-gateway-hystrix","date":"2019-05-25T12:33:44.000Z","updated":"2019-06-02T01:53:47.141Z","comments":true,"path":"2019/05/25/spring-cloud-gateway-hystrix/","link":"","permalink":"http://throwable.club/2019/05/25/spring-cloud-gateway-hystrix/","excerpt":"前提 在微服务架构中，下游依赖出现问题如果上游调用方不做请求降级处理，下游的异常依赖没有被隔离，很有可能出现因为一两个服务或者小到一两个接口异常导致上游所有服务不可用，甚至影响整个业务线。请求降级处理目前比较主流的依然是Netfilx出品的Hystrix。Hystrix的工作原理是： 把请求基于线程池或者信号量隔离，一旦下游服务在指定配置的超时时间内无法响应会进入预设或者默认的降级实现。 每个请求的状态都会记录下来，在一个滑动窗口内处理失败的比率超过设定的阈值就会触发熔断器(Circle Breaker)开启，熔断器开启之后所有请求都会直接进入预设或者默认的降级逻辑。 熔断器打开后，且距离熔断器打开的时间或上一次试探请求放行的时间超过设定值，熔断器器进入半开状态，允许放行一个试探请求。 请求成功率提高后，基于统计数据确定对熔断器进行关闭，所有请求正常放行。 这里不对Hystrix的细节做更深入分析，而是接着谈谈Spring Cloud Gateway中如何使用Hystrix，主要包括内置的Hystrix过滤器和定制过滤器结合Hystrix实现我们想要的功能。除了要引入spring-cloud-starter-gateway依赖之外，还需要引入spring-cloud-starter-netflix-hystrix。 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;","text":"前提 在微服务架构中，下游依赖出现问题如果上游调用方不做请求降级处理，下游的异常依赖没有被隔离，很有可能出现因为一两个服务或者小到一两个接口异常导致上游所有服务不可用，甚至影响整个业务线。请求降级处理目前比较主流的依然是Netfilx出品的Hystrix。Hystrix的工作原理是： 把请求基于线程池或者信号量隔离，一旦下游服务在指定配置的超时时间内无法响应会进入预设或者默认的降级实现。 每个请求的状态都会记录下来，在一个滑动窗口内处理失败的比率超过设定的阈值就会触发熔断器(Circle Breaker)开启，熔断器开启之后所有请求都会直接进入预设或者默认的降级逻辑。 熔断器打开后，且距离熔断器打开的时间或上一次试探请求放行的时间超过设定值，熔断器器进入半开状态，允许放行一个试探请求。 请求成功率提高后，基于统计数据确定对熔断器进行关闭，所有请求正常放行。 这里不对Hystrix的细节做更深入分析，而是接着谈谈Spring Cloud Gateway中如何使用Hystrix，主要包括内置的Hystrix过滤器和定制过滤器结合Hystrix实现我们想要的功能。除了要引入spring-cloud-starter-gateway依赖之外，还需要引入spring-cloud-starter-netflix-hystrix。 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 使用内置的Hystrix过滤器 内置的Hystrix过滤器是HystrixGatewayFilterFactory，它支持的配置是： 1234567891011121314151617181920212223242526272829303132333435363738394041public static class Config &#123; // 如果下面的Setter配置为null的时候，name会作为Hystrix的HystrixCommandKey private String name; // Hystrix的Setter属性，主要用来配置命令的KEY和其他属性 private Setter setter; // 降级的目标URI，必须以forward开头，URI会匹配到网关应用的控制器方法 private URI fallbackUri; public String getName() &#123; return name; &#125; public Config setName(String name) &#123; this.name = name; return this; &#125; public Config setFallbackUri(String fallbackUri) &#123; if (fallbackUri != null) &#123; setFallbackUri(URI.create(fallbackUri)); &#125; return this; &#125; public URI getFallbackUri() &#123; return fallbackUri; &#125; // 注意这个方法，配置的fallbackUri要以forward开始作为schema，否则会抛异常 public void setFallbackUri(URI fallbackUri) &#123; if (fallbackUri != null &amp;&amp; !\"forward\".equals(fallbackUri.getScheme())) &#123; throw new IllegalArgumentException(\"Hystrix Filter currently only supports 'forward' URIs, found \" + fallbackUri); &#125; this.fallbackUri = fallbackUri; &#125; public Config setSetter(Setter setter) &#123; this.setter = setter; return this; &#125;&#125; 另外，（1）全局的Hystrix配置也会对HystrixGatewayFilterFactory生效；（2）HystrixGatewayFilterFactory可以作为默认过滤器(default-filters)对所有的路由配置作为兜底过滤器并发挥作用。 对于第（1）点，我们如果在application.yaml中配置如下： 12345678910111213141516// 执行超时时间为1秒，会对下面路由order_route绑定的HystrixGatewayFilterFactory生效hystrix.command.fallbackcmd.execution.isolation.thread.timeoutInMilliseconds: 1000spring: cloud: gateway: routes: - id: order_route uri: http://localhost:9091 predicates: - Path=/order/** filters: - name: Hystrix args: name: HystrixCommand fallbackUri: forward:/fallback 配置的hystrix.command.fallbackcmd.execution.isolation.thread.timeoutInMilliseconds会对绑定在路由order_route中的HystrixGatewayFilterFactory生效。 对于第（2）点，我们可以把HystrixGatewayFilterFactory配置为默认过滤器，这样子所有的路由都会关联此过滤器，但是非必要时建议不要这样做： 12345678910111213spring: cloud: gateway: routes: - id: order_route uri: http://localhost:9091 predicates: - Path=/order/** default-filters: - name: Hystrix args: name: HystrixCommand fallbackUri: forward:/fallback 笔者在测试的时候，发现上面提到的Setter无法配置，估计是由于Hystrix的Setter对象是经过多重包装，暂时没有办法设置该属性。接着我们要在网关服务加一个控制器方法用于处理重定向的/fallback请求： 123456789101112131415161718@RestControllerpublic class FallbackController &#123; @RequestMapping(value = \"/fallback\") @ResponseStatus public Mono&lt;Map&lt;String, Object&gt;&gt; fallback(ServerWebExchange exchange, Throwable throwable) &#123; Map&lt;String, Object&gt; result = new HashMap&lt;&gt;(8); ServerHttpRequest request = exchange.getRequest(); result.put(\"path\", request.getPath().pathWithinApplication().value()); result.put(\"method\", request.getMethodValue()); if (null != throwable.getCause()) &#123; result.put(\"message\", throwable.getCause().getMessage()); &#125; else &#123; result.put(\"message\", throwable.getMessage()); &#125; return Mono.just(result); &#125;&#125; 控制器方法入参会被Spring Cloud Gateway的内部组件处理，可以回调一些有用的类型例如ServerWebExchange实例、具体的异常实例等等。 使用Hystrix定制过滤器 HystrixGatewayFilterFactory在大多数情况下应该可以满足业务需要，但是这里也做一次定制一个整合Hystrix的过滤器，实现的功能如下： 基于每个请求URL创建一个新的Hystrix命令实例进行调用。 每个URL可以指定特有的线程池配置，如果不指定则使用默认的。 每个URL可以配置单独的Hystrix超时时间。 也就是通过Hystrix使用线程池对每种不同的外部请求URL进行隔离。当然，这样的过滤器仅仅在外部请求的不同URL的数量有限的情况下才比较合理，否则有可能创建过多的线程池造成系统性能的下降，适得其反。改造如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174@Componentpublic class CustomHystrixFilter extends AbstractGatewayFilterFactory&lt;CustomHystrixFilter.Config&gt; &#123; private static final String FORWARD_KEY = \"forward\"; private static final String NAME = \"CustomHystrix\"; private static final int TIMEOUT_MS = 1000; private final ObjectProvider&lt;DispatcherHandler&gt; dispatcherHandlerProvider; private volatile DispatcherHandler dispatcherHandler; private boolean processConfig = false; public CustomHystrixFilter(ObjectProvider&lt;DispatcherHandler&gt; dispatcherHandlerProvider) &#123; super(Config.class); this.dispatcherHandlerProvider = dispatcherHandlerProvider; &#125; private DispatcherHandler getDispatcherHandler() &#123; if (dispatcherHandler == null) &#123; dispatcherHandler = dispatcherHandlerProvider.getIfAvailable(); &#125; return dispatcherHandler; &#125; @Override public List&lt;String&gt; shortcutFieldOrder() &#123; return Collections.singletonList(NAME_KEY); &#125; @Override public GatewayFilter apply(Config config) &#123; processConfig(config); return (exchange, chain) -&gt; &#123; ServerHttpRequest request = exchange.getRequest(); String path = request.getPath().pathWithinApplication().value(); int timeout = config.getTimeout().getOrDefault(path, TIMEOUT_MS); CustomHystrixCommand command = new CustomHystrixCommand(config.getFallbackUri(), exchange, chain, timeout, path); return Mono.create(s -&gt; &#123; Subscription sub = command.toObservable().subscribe(s::success, s::error, s::success); s.onCancel(sub::unsubscribe); &#125;).onErrorResume((Function&lt;Throwable, Mono&lt;Void&gt;&gt;) throwable -&gt; &#123; if (throwable instanceof HystrixRuntimeException) &#123; HystrixRuntimeException e = (HystrixRuntimeException) throwable; HystrixRuntimeException.FailureType failureType = e.getFailureType(); switch (failureType) &#123; case TIMEOUT: return Mono.error(new TimeoutException()); case COMMAND_EXCEPTION: &#123; Throwable cause = e.getCause(); if (cause instanceof ResponseStatusException || AnnotatedElementUtils .findMergedAnnotation(cause.getClass(), ResponseStatus.class) != null) &#123; return Mono.error(cause); &#125; &#125; default: break; &#125; &#125; return Mono.error(throwable); &#125;).then(); &#125;; &#125; /** * YAML解析的时候MAP的KEY不支持'/'，这里只能用'-'替代 * * @param config config */ private void processConfig(Config config) &#123; if (!processConfig) &#123; processConfig = true; if (null != config.getTimeout()) &#123; Map&lt;String, Integer&gt; timeout = new HashMap&lt;&gt;(8); config.getTimeout().forEach((k, v) -&gt; &#123; String key = k.replace(\"-\", \"/\"); if (!key.startsWith(\"/\")) &#123; key = \"/\" + key; &#125; timeout.put(key, v); &#125;); config.setTimeout(timeout); &#125; &#125; &#125; @Override public String name() &#123; return NAME; &#125; private class CustomHystrixCommand extends HystrixObservableCommand&lt;Void&gt; &#123; private final URI fallbackUri; private final ServerWebExchange exchange; private final GatewayFilterChain chain; public CustomHystrixCommand(URI fallbackUri, ServerWebExchange exchange, GatewayFilterChain chain, int timeout, String key) &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(key)) .andCommandKey(HystrixCommandKey.Factory.asKey(key)) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter().withExecutionTimeoutInMilliseconds(timeout))); this.fallbackUri = fallbackUri; this.exchange = exchange; this.chain = chain; &#125; @Override protected Observable&lt;Void&gt; construct() &#123; return RxReactiveStreams.toObservable(this.chain.filter(exchange)); &#125; @Override protected Observable&lt;Void&gt; resumeWithFallback() &#123; if (null == fallbackUri) &#123; return super.resumeWithFallback(); &#125; URI uri = exchange.getRequest().getURI(); boolean encoded = containsEncodedParts(uri); URI requestUrl = UriComponentsBuilder.fromUri(uri) .host(null) .port(null) .uri(this.fallbackUri) .build(encoded) .toUri(); exchange.getAttributes().put(GATEWAY_REQUEST_URL_ATTR, requestUrl); ServerHttpRequest request = this.exchange.getRequest().mutate().uri(requestUrl).build(); ServerWebExchange mutated = exchange.mutate().request(request).build(); return RxReactiveStreams.toObservable(getDispatcherHandler().handle(mutated)); &#125; &#125; public static class Config &#123; private String id; private URI fallbackUri; /** * url -&gt; timeout ms */ private Map&lt;String, Integer&gt; timeout; public String getId() &#123; return id; &#125; public Config setId(String id) &#123; this.id = id; return this; &#125; public URI getFallbackUri() &#123; return fallbackUri; &#125; public Config setFallbackUri(URI fallbackUri) &#123; if (fallbackUri != null &amp;&amp; !FORWARD_KEY.equals(fallbackUri.getScheme())) &#123; throw new IllegalArgumentException(\"Hystrix Filter currently only supports 'forward' URIs, found \" + fallbackUri); &#125; this.fallbackUri = fallbackUri; return this; &#125; public Map&lt;String, Integer&gt; getTimeout() &#123; return timeout; &#125; public Config setTimeout(Map&lt;String, Integer&gt; timeout) &#123; this.timeout = timeout; return this; &#125; &#125;&#125; 其实大部分代码和内置的Hystrix过滤器差不多，只是改了命令改造函数部分和配置加载处理的部分。配置文件如下： 1234567891011121314151617181920spring: cloud: gateway: routes: - id: hystrix_route uri: http://localhost:9091 predicates: - Host=localhost:9090 filters: - name: CustomHystrix args: id: CustomHystrix fallbackUri: forward:/fallback timeout: # 这里暂时用-分隔URL，因为/不支持 order-remote: 2000 application: name: route-serverserver: port: 9090 网关添加一个/fallback处理控制器如下： 123456789101112131415161718@RestControllerpublic class FallbackController &#123; @RequestMapping(value = \"/fallback\") @ResponseStatus public Mono&lt;Map&lt;String, Object&gt;&gt; fallback(ServerWebExchange exchange, Throwable throwable) &#123; Map&lt;String, Object&gt; result = new HashMap&lt;&gt;(8); ServerHttpRequest request = exchange.getRequest(); result.put(\"path\", request.getPath().pathWithinApplication().value()); result.put(\"method\", request.getMethodValue()); if (null != throwable.getCause()) &#123; result.put(\"message\", throwable.getCause().getMessage()); &#125; else &#123; result.put(\"message\", throwable.getMessage()); &#125; return Mono.just(result); &#125;&#125; 故意在下游服务打断点： 12345678curl http://localhost:9090/order/remote响应结果：&#123; \"path\": \"/fallback\", \"method\": \"GET\", \"message\": null # &lt;== 这里由于是超时异常，message就是null&#125; 刚好符合预期结果。 小结 这篇文章仅仅是对Hystrix和过滤器应用提供一个可用的例子和解决问题的思路，具体如何使用还是需要针对真实的场景。 (本文完 c-2-d e-a-20190522)","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://throwable.club/blog/categories/Spring-Cloud/"},{"name":"Spring Cloud Gateway","slug":"Spring-Cloud/Spring-Cloud-Gateway","permalink":"http://throwable.club/blog/categories/Spring-Cloud/Spring-Cloud-Gateway/"}],"tags":[{"name":"Spring Cloud Gateway","slug":"Spring-Cloud-Gateway","permalink":"http://throwable.club/blog/tags/Spring-Cloud-Gateway/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://throwable.club/blog/tags/Spring-Cloud/"}]},{"title":"经典面试题-两个线程交替打印奇数和偶数","slug":"interview-problem-double-thread-print-odd-even-alternately","date":"2019-05-20T14:43:49.000Z","updated":"2019-06-09T03:48:05.767Z","comments":true,"path":"2019/05/20/interview-problem-double-thread-print-odd-even-alternately/","link":"","permalink":"http://throwable.club/2019/05/20/interview-problem-double-thread-print-odd-even-alternately/","excerpt":"前提 今天下班时候和同事聊天偶然听到面试题“两个线程交替打印奇数和偶数”的实现，这里做一个复盘。","text":"前提 今天下班时候和同事聊天偶然听到面试题“两个线程交替打印奇数和偶数”的实现，这里做一个复盘。 复盘 场景一：线程A打印奇数，线程B打印偶数，线程A和线程B交替打印，使用对象监视器实现。 场景二：线程A打印奇数，线程B打印偶数，线程A和线程B交替打印，使用JDK提供的并发类库实现。 这两个场景中，场景一是一种比较古老的同步方式，本质由JVM实现；场景二是JDK1.5引入JUC包之后简化了并发编程的前提下的更简便的实现。下面针对两个场景做对应的实现。 场景一 场景一中，线程A和线程B交替打印奇数和偶数，使用对象监视器实现，通俗来说：线程A或线程B只要有一者竞争锁成功，就打印++i，通知其他线程从等待集合中释放，然后自身线程加入等待集合并且释放锁即可。 12345678910111213141516171819202122232425262728293031323334public class OddEvenPrinter &#123; private final Object monitor = new Object(); private final int limit; private volatile int count; public OddEvenPrinter(int limit, int initCount) &#123; this.limit = limit; this.count = initCount; &#125; public void print() &#123; synchronized (monitor) &#123; while (count &lt; limit) &#123; try &#123; System.out.println(String.format(\"线程[%s]打印数字:%d\", Thread.currentThread().getName(), ++count)); monitor.notifyAll(); monitor.wait(); &#125; catch (InterruptedException e) &#123; //ignore &#125; &#125; &#125; &#125; public static void main(String[] args) throws Exception &#123; OddEvenPrinter printer = new OddEvenPrinter(10, 0); Thread thread1 = new Thread(printer::print, \"thread-1\"); Thread thread2 = new Thread(printer::print, \"thread-2\"); thread1.start(); thread2.start(); Thread.sleep(Integer.MAX_VALUE); &#125;&#125; 执行后的输出结果： 12345678910线程[thread-1]打印数字:1线程[thread-2]打印数字:2线程[thread-1]打印数字:3线程[thread-2]打印数字:4线程[thread-1]打印数字:5线程[thread-2]打印数字:6线程[thread-1]打印数字:7线程[thread-2]打印数字:8线程[thread-1]打印数字:9线程[thread-2]打印数字:10 场景二 场景二中，如果需要使用JUC中提供的并发类库，可以考虑和对象监视器功能接近的可重入锁ReentrantLock。具体代码如下： 123456789101112131415161718192021222324252627282930313233343536373839public class OddEvenPrinterEx &#123; private final ReentrantLock lock = new ReentrantLock(); private final Condition condition = lock.newCondition(); private final int limit; private volatile int count; public OddEvenPrinterEx(int limit, int initCount) &#123; this.limit = limit; this.count = initCount; &#125; public void print() &#123; lock.lock(); try &#123; while (count &lt; limit)&#123; System.out.println(String.format(\"线程[%s]打印数字:%d\", Thread.currentThread().getName(), ++count)); condition.signalAll(); try &#123; condition.await(); &#125; catch (InterruptedException e) &#123; //ignore &#125; &#125; &#125; finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args) throws Exception &#123; OddEvenPrinterEx printer = new OddEvenPrinterEx(10, 0); Thread thread1 = new Thread(printer::print, \"thread-1\"); Thread thread2 = new Thread(printer::print, \"thread-2\"); thread1.start(); thread2.start(); Thread.sleep(Integer.MAX_VALUE); &#125;&#125; 执行后的输出结果： 12345678910线程[thread-2]打印数字:1线程[thread-1]打印数字:2线程[thread-2]打印数字:3线程[thread-1]打印数字:4线程[thread-2]打印数字:5线程[thread-1]打印数字:6线程[thread-2]打印数字:7线程[thread-1]打印数字:8线程[thread-2]打印数字:9线程[thread-1]打印数字:10 眼尖的可能看到这里是先由thread-2打印奇数，然后thread-1打印偶数，这个和同步器框架的等待队列以及同步队列的竞争有关。 小结 这个问题有很多种解决思路，但是目前笔者没想到无锁实现方案。很多现成的(参考多个博客)方案里面都是使用各种多重同步或者加锁，其实意义是不大，实际上要理解对象监视器和同步器框架AQS的一些原理，那么实现起来自然比较简单。参看笔者之前写的两篇文章： 深入理解Object提供的阻塞和唤醒API JUC同步器框架AbstractQueuedSynchronizer源码图文分析 (本文完 c-1-d e-a-20190520)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Concurrency","slug":"Java/Concurrency","permalink":"http://throwable.club/blog/categories/Java/Concurrency/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Concurrency","slug":"Concurrency","permalink":"http://throwable.club/blog/tags/Concurrency/"}]},{"title":"Spring Cloud Gateway-ServerWebExchange核心方法与请求或者响应内容的修改","slug":"spring-cloud-gateway-modify-request-response","date":"2019-05-18T07:47:45.000Z","updated":"2019-06-02T02:08:24.089Z","comments":true,"path":"2019/05/18/spring-cloud-gateway-modify-request-response/","link":"","permalink":"http://throwable.club/2019/05/18/spring-cloud-gateway-modify-request-response/","excerpt":"前提 本文编写的时候使用的Spring Cloud Gateway版本为当时最新的版本Greenwich.SR1。 我们在使用Spring Cloud Gateway的时候，注意到过滤器（包括GatewayFilter、GlobalFilter和过滤器链GatewayFilterChain），都依赖到ServerWebExchange： 1234567891011121314public interface GlobalFilter &#123; Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain);&#125;public interface GatewayFilter extends ShortcutConfigurable &#123; Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain);&#125;public interface GatewayFilterChain &#123; Mono&lt;Void&gt; filter(ServerWebExchange exchange);&#125; 这里的设计和Servlet中的Filter是相似的，当前过滤器可以决定是否执行下一个过滤器的逻辑，由GatewayFilterChain#filter()是否被调用来决定。而ServerWebExchange就相当于当前请求和响应的上下文。ServerWebExchange实例不单存储了Request和Response对象，还提供了一些扩展方法，如果想实现改造请求参数或者响应参数，就必须深入了解ServerWebExchange。","text":"前提 本文编写的时候使用的Spring Cloud Gateway版本为当时最新的版本Greenwich.SR1。 我们在使用Spring Cloud Gateway的时候，注意到过滤器（包括GatewayFilter、GlobalFilter和过滤器链GatewayFilterChain），都依赖到ServerWebExchange： 1234567891011121314public interface GlobalFilter &#123; Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain);&#125;public interface GatewayFilter extends ShortcutConfigurable &#123; Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain);&#125;public interface GatewayFilterChain &#123; Mono&lt;Void&gt; filter(ServerWebExchange exchange);&#125; 这里的设计和Servlet中的Filter是相似的，当前过滤器可以决定是否执行下一个过滤器的逻辑，由GatewayFilterChain#filter()是否被调用来决定。而ServerWebExchange就相当于当前请求和响应的上下文。ServerWebExchange实例不单存储了Request和Response对象，还提供了一些扩展方法，如果想实现改造请求参数或者响应参数，就必须深入了解ServerWebExchange。 理解ServerWebExchange 先看ServerWebExchange的注释： Contract for an HTTP request-response interaction. Provides access to the HTTP request and response and also exposes additional server-side processing related properties and features such as request attributes. 翻译一下大概是： ServerWebExchange是一个HTTP请求-响应交互的契约。提供对HTTP请求和响应的访问，并公开额外的服务器端处理相关属性和特性，如请求属性。 其实，ServerWebExchange命名为服务网络交换器，存放着重要的请求-响应属性、请求实例和响应实例等等，有点像Context的角色。 ServerWebExchange接口 ServerWebExchange接口的所有方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public interface ServerWebExchange &#123; // 日志前缀属性的KEY，值为org.springframework.web.server.ServerWebExchange.LOG_ID // 可以理解为 attributes.set(\"org.springframework.web.server.ServerWebExchange.LOG_ID\",\"日志前缀的具体值\"); // 作用是打印日志的时候会拼接这个KEY对饮的前缀值，默认值为\"\" String LOG_ID_ATTRIBUTE = ServerWebExchange.class.getName() + \".LOG_ID\"; String getLogPrefix(); // 获取ServerHttpRequest对象 ServerHttpRequest getRequest(); // 获取ServerHttpResponse对象 ServerHttpResponse getResponse(); // 返回当前exchange的请求属性，返回结果是一个可变的Map Map&lt;String, Object&gt; getAttributes(); // 根据KEY获取请求属性 @Nullable default &lt;T&gt; T getAttribute(String name) &#123; return (T) getAttributes().get(name); &#125; // 根据KEY获取请求属性，做了非空判断 @SuppressWarnings(\"unchecked\") default &lt;T&gt; T getRequiredAttribute(String name) &#123; T value = getAttribute(name); Assert.notNull(value, () -&gt; \"Required attribute '\" + name + \"' is missing\"); return value; &#125; // 根据KEY获取请求属性，需要提供默认值 @SuppressWarnings(\"unchecked\") default &lt;T&gt; T getAttributeOrDefault(String name, T defaultValue) &#123; return (T) getAttributes().getOrDefault(name, defaultValue); &#125; // 返回当前请求的网络会话 Mono&lt;WebSession&gt; getSession(); // 返回当前请求的认证用户，如果存在的话 &lt;T extends Principal&gt; Mono&lt;T&gt; getPrincipal(); // 返回请求的表单数据或者一个空的Map，只有Content-Type为application/x-www-form-urlencoded的时候这个方法才会返回一个非空的Map -- 这个一般是表单数据提交用到 Mono&lt;MultiValueMap&lt;String, String&gt;&gt; getFormData(); // 返回multipart请求的part数据或者一个空的Map，只有Content-Type为multipart/form-data的时候这个方法才会返回一个非空的Map -- 这个一般是文件上传用到 Mono&lt;MultiValueMap&lt;String, Part&gt;&gt; getMultipartData(); // 返回Spring的上下文 @Nullable ApplicationContext getApplicationContext(); // 这几个方法和lastModified属性相关 boolean isNotModified(); boolean checkNotModified(Instant lastModified); boolean checkNotModified(String etag); boolean checkNotModified(@Nullable String etag, Instant lastModified); // URL转换 String transformUrl(String url); // URL转换映射 void addUrlTransformer(Function&lt;String, String&gt; transformer); // 注意这个方法，方法名是：改变，这个是修改ServerWebExchange属性的方法，返回的是一个Builder实例，Builder是ServerWebExchange的内部类 default Builder mutate() &#123; return new DefaultServerWebExchangeBuilder(this); &#125; interface Builder &#123; // 覆盖ServerHttpRequest Builder request(Consumer&lt;ServerHttpRequest.Builder&gt; requestBuilderConsumer); Builder request(ServerHttpRequest request); // 覆盖ServerHttpResponse Builder response(ServerHttpResponse response); // 覆盖当前请求的认证用户 Builder principal(Mono&lt;Principal&gt; principalMono); // 构建新的ServerWebExchange实例 ServerWebExchange build(); &#125;&#125; 注意到ServerWebExchange#mutate()方法，ServerWebExchange实例可以理解为不可变实例，如果我们想要修改它，需要通过mutate()方法生成一个新的实例，例如这样： 123456789101112131415public class CustomGlobalFilter implements GlobalFilter &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; ServerHttpRequest request = exchange.getRequest(); // 这里可以修改ServerHttpRequest实例 ServerHttpRequest newRequest = ... ServerHttpResponse response = exchange.getResponse(); // 这里可以修改ServerHttpResponse实例 ServerHttpResponse newResponse = ... // 构建新的ServerWebExchange实例 ServerWebExchange newExchange = exchange.mutate().request(newRequest).response(newResponse).build(); return chain.filter(newExchange); &#125;&#125; ServerHttpRequest接口 ServerHttpRequest实例是用于承载请求相关的属性和请求体，Spring Cloud Gateway中底层使用Netty处理网络请求，通过追溯源码，可以从ReactorHttpHandlerAdapter中得知ServerWebExchange实例中持有的ServerHttpRequest实例的具体实现是ReactorServerHttpRequest。之所以列出这些实例之间的关系，是因为这样比较容易理清一些隐含的问题，例如： ReactorServerHttpRequest的父类AbstractServerHttpRequest中初始化内部属性headers的时候把请求的HTTP头部封装为只读的实例： 12345678910111213141516public AbstractServerHttpRequest(URI uri, @Nullable String contextPath, HttpHeaders headers) &#123; this.uri = uri; this.path = RequestPath.parse(uri, contextPath); this.headers = HttpHeaders.readOnlyHttpHeaders(headers);&#125;// HttpHeaders类中的readOnlyHttpHeaders方法，其中ReadOnlyHttpHeaders屏蔽了所有修改请求头的方法，直接抛出UnsupportedOperationExceptionpublic static HttpHeaders readOnlyHttpHeaders(HttpHeaders headers) &#123; Assert.notNull(headers, \"HttpHeaders must not be null\"); if (headers instanceof ReadOnlyHttpHeaders) &#123; return headers; &#125; else &#123; return new ReadOnlyHttpHeaders(headers); &#125;&#125; 所以不能直接从ServerHttpRequest实例中直接获取请求头HttpHeaders实例并且进行修改。 ServerHttpRequest接口如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public interface HttpMessage &#123; // 获取请求头，目前的实现中返回的是ReadOnlyHttpHeaders实例，只读 HttpHeaders getHeaders();&#125; public interface ReactiveHttpInputMessage extends HttpMessage &#123; // 返回请求体的Flux封装 Flux&lt;DataBuffer&gt; getBody();&#125;public interface HttpRequest extends HttpMessage &#123; // 返回HTTP请求方法，解析为HttpMethod实例 @Nullable default HttpMethod getMethod() &#123; return HttpMethod.resolve(getMethodValue()); &#125; // 返回HTTP请求方法，字符串 String getMethodValue(); // 请求的URI URI getURI();&#125; public interface ServerHttpRequest extends HttpRequest, ReactiveHttpInputMessage &#123; // 连接的唯一标识或者用于日志处理标识 String getId(); // 获取请求路径，封装为RequestPath对象 RequestPath getPath(); // 返回查询参数，是只读的MultiValueMap实例 MultiValueMap&lt;String, String&gt; getQueryParams(); // 返回Cookie集合，是只读的MultiValueMap实例 MultiValueMap&lt;String, HttpCookie&gt; getCookies(); // 远程服务器地址信息 @Nullable default InetSocketAddress getRemoteAddress() &#123; return null; &#125; // SSL会话实现的相关信息 @Nullable default SslInfo getSslInfo() &#123; return null; &#125; // 修改请求的方法，返回一个建造器实例Builder，Builder是内部类 default ServerHttpRequest.Builder mutate() &#123; return new DefaultServerHttpRequestBuilder(this); &#125; interface Builder &#123; // 覆盖请求方法 Builder method(HttpMethod httpMethod); // 覆盖请求的URI、请求路径或者上下文，这三者相互有制约关系，具体可以参考API注释 Builder uri(URI uri); Builder path(String path); Builder contextPath(String contextPath); // 覆盖请求头 Builder header(String key, String value); Builder headers(Consumer&lt;HttpHeaders&gt; headersConsumer); // 覆盖SslInfo Builder sslInfo(SslInfo sslInfo); // 构建一个新的ServerHttpRequest实例 ServerHttpRequest build(); &#125; &#125; 如果要修改ServerHttpRequest实例，那么需要这样做： 12ServerHttpRequest request = exchange.getRequest();ServerHttpRequest newRequest = request.mutate().headers(\"key\",\"value\").path(\"/myPath\").build(); 这里最值得注意的是：ServerHttpRequest或者说HttpMessage接口提供的获取请求头方法HttpHeaders getHeaders();返回结果是一个只读的实例，具体是ReadOnlyHttpHeaders类型，这里提多一次，笔者写这篇博文时候使用的Spring Cloud Gateway版本为Greenwich.SR1。 ServerHttpResponse接口 ServerHttpResponse实例是用于承载响应相关的属性和响应体，Spring Cloud Gateway中底层使用Netty处理网络请求，通过追溯源码，可以从ReactorHttpHandlerAdapter中得知ServerWebExchange实例中持有的ServerHttpResponse实例的具体实现是ReactorServerHttpResponse。之所以列出这些实例之间的关系，是因为这样比较容易理清一些隐含的问题，例如： 1234567891011121314// ReactorServerHttpResponse的父类public AbstractServerHttpResponse(DataBufferFactory dataBufferFactory, HttpHeaders headers) &#123; Assert.notNull(dataBufferFactory, \"DataBufferFactory must not be null\"); Assert.notNull(headers, \"HttpHeaders must not be null\"); this.dataBufferFactory = dataBufferFactory; this.headers = headers; this.cookies = new LinkedMultiValueMap&lt;&gt;();&#125;public ReactorServerHttpResponse(HttpServerResponse response, DataBufferFactory bufferFactory) &#123; super(bufferFactory, new HttpHeaders(new NettyHeadersAdapter(response.responseHeaders()))); Assert.notNull(response, \"HttpServerResponse must not be null\"); this.response = response;&#125; 可知ReactorServerHttpResponse构造函数初始化实例的时候，存放响应Header的是HttpHeaders实例，也就是响应Header是可以直接修改的。 ServerHttpResponse接口如下： 123456789101112131415161718192021222324252627282930313233343536373839404142public interface HttpMessage &#123; // 获取响应Header，目前的实现中返回的是HttpHeaders实例，可以直接修改 HttpHeaders getHeaders();&#125; public interface ReactiveHttpOutputMessage extends HttpMessage &#123; // 获取DataBufferFactory实例，用于包装或者生成数据缓冲区DataBuffer实例(创建响应体) DataBufferFactory bufferFactory(); // 注册一个动作，在HttpOutputMessage提交之前此动作会进行回调 void beforeCommit(Supplier&lt;? extends Mono&lt;Void&gt;&gt; action); // 判断HttpOutputMessage是否已经提交 boolean isCommitted(); // 写入消息体到HTTP协议层 Mono&lt;Void&gt; writeWith(Publisher&lt;? extends DataBuffer&gt; body); // 写入消息体到HTTP协议层并且刷新缓冲区 Mono&lt;Void&gt; writeAndFlushWith(Publisher&lt;? extends Publisher&lt;? extends DataBuffer&gt;&gt; body); // 指明消息处理已经结束，一般在消息处理结束自动调用此方法，多次调用不会产生副作用 Mono&lt;Void&gt; setComplete();&#125;public interface ServerHttpResponse extends ReactiveHttpOutputMessage &#123; // 设置响应状态码 boolean setStatusCode(@Nullable HttpStatus status); // 获取响应状态码 @Nullable HttpStatus getStatusCode(); // 获取响应Cookie，封装为MultiValueMap实例，可以修改 MultiValueMap&lt;String, ResponseCookie&gt; getCookies(); // 添加响应Cookie void addCookie(ResponseCookie cookie); &#125; 这里可以看到除了响应体比较难修改之外，其他的属性都是可变的。 ServerWebExchangeUtils和上下文属性 ServerWebExchangeUtils里面存放了很多静态公有的字符串KEY值(这些字符串KEY的实际值是org.springframework.cloud.gateway.support.ServerWebExchangeUtils. + 下面任意的静态公有KEY)，这些字符串KEY值一般是用于ServerWebExchange的属性(Attribute，见上文的ServerWebExchange#getAttributes()方法)的KEY，这些属性值都是有特殊的含义，在使用过滤器的时候如果时机适当可以直接取出来使用，下面逐个分析。 PRESERVE_HOST_HEADER_ATTRIBUTE：是否保存Host属性，值是布尔值类型，写入位置是PreserveHostHeaderGatewayFilterFactory，使用的位置是NettyRoutingFilter，作用是如果设置为true，HTTP请求头中的Host属性会写到底层Reactor-Netty的请求Header属性中。 CLIENT_RESPONSE_ATTR：保存底层Reactor-Netty的响应对象，类型是reactor.netty.http.client.HttpClientResponse。 CLIENT_RESPONSE_CONN_ATTR：保存底层Reactor-Netty的连接对象，类型是reactor.netty.Connection。 URI_TEMPLATE_VARIABLES_ATTRIBUTE：PathRoutePredicateFactory解析路径参数完成之后，把解析完成后的占位符KEY-路径Path映射存放在ServerWebExchange的属性中，KEY就是URI_TEMPLATE_VARIABLES_ATTRIBUTE。 CLIENT_RESPONSE_HEADER_NAMES：保存底层Reactor-Netty的响应Header的名称集合。 GATEWAY_ROUTE_ATTR：用于存放RoutePredicateHandlerMapping中匹配出来的具体的路由(org.springframework.cloud.gateway.route.Route)实例，通过这个路由实例可以得知当前请求会路由到下游哪个服务。 GATEWAY_REQUEST_URL_ATTR：java.net.URI类型的实例，这个实例代表直接请求或者负载均衡处理之后需要请求到下游服务的真实URI。 GATEWAY_ORIGINAL_REQUEST_URL_ATTR：java.net.URI类型的实例，需要重写请求URI的时候，保存原始的请求URI。 GATEWAY_HANDLER_MAPPER_ATTR：保存当前使用的HandlerMapping具体实例的类型简称(一般是字符串&quot;RoutePredicateHandlerMapping&quot;)。 GATEWAY_SCHEME_PREFIX_ATTR：确定目标路由URI中如果存在schemeSpecificPart属性，则保存该URI的scheme在此属性中，路由URI会被重新构造，见RouteToRequestUrlFilter。 GATEWAY_PREDICATE_ROUTE_ATTR：用于存放RoutePredicateHandlerMapping中匹配出来的具体的路由(org.springframework.cloud.gateway.route.Route)实例的ID。 WEIGHT_ATTR：实验性功能(此版本还不建议在正式版本使用)存放分组权重相关属性，见WeightCalculatorWebFilter。 ORIGINAL_RESPONSE_CONTENT_TYPE_ATTR：存放响应Header中的ContentType的值。 HYSTRIX_EXECUTION_EXCEPTION_ATTR：Throwable的实例，存放的是Hystrix执行异常时候的异常实例，见HystrixGatewayFilterFactory。 GATEWAY_ALREADY_ROUTED_ATTR：布尔值，用于判断是否已经进行了路由，见NettyRoutingFilter。 GATEWAY_ALREADY_PREFIXED_ATTR：布尔值，用于判断请求路径是否被添加了前置部分，见PrefixPathGatewayFilterFactory。 ServerWebExchangeUtils提供的上下文属性用于Spring Cloud Gateway的ServerWebExchange组件处理请求和响应的时候，内部一些重要实例或者标识属性的安全传输和使用，使用它们可能存在一定的风险，因为没有人可以确定在版本升级之后，原有的属性KEY或者VALUE是否会发生改变，如果评估过风险或者规避了风险之后，可以安心使用。例如我们在做请求和响应日志(类似Nginx的Access Log)的时候，可以依赖到GATEWAY_ROUTE_ATTR，因为我们要打印路由的目标信息。举个简单例子： 1234567891011121314151617181920@Slf4j@Componentpublic class AccessLogFilter implements GlobalFilter &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; ServerHttpRequest request = exchange.getRequest(); String path = request.getPath().pathWithinApplication().value(); HttpMethod method = request.getMethod(); // 获取路由的目标URI URI targetUri = exchange.getAttribute(ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR); InetSocketAddress remoteAddress = request.getRemoteAddress(); return chain.filter(exchange.mutate().build()).then(Mono.fromRunnable(() -&gt; &#123; ServerHttpResponse response = exchange.getResponse(); HttpStatus statusCode = response.getStatusCode(); log.info(\"请求路径:&#123;&#125;,客户端远程IP地址:&#123;&#125;,请求方法:&#123;&#125;,目标URI:&#123;&#125;,响应码:&#123;&#125;\", path, remoteAddress, method, targetUri, statusCode); &#125;)); &#125;&#125; 修改请求体 修改请求体是一个比较常见的需求。例如我们使用Spring Cloud Gateway实现网关的时候，要实现一个功能：把存放在请求头中的JWT解析后，提取里面的用户ID，然后写入到请求体中。我们简化这个场景，假设我们把userId明文存放在请求头中的accessToken中，请求体是一个JSON结构： 123456&#123; \"serialNumber\": \"请求流水号\", \"payload\" : &#123; // ... 这里是有效载荷，存放具体的数据 &#125;&#125; 我们需要提取accessToken，也就是userId插入到请求体JSON中如下： 1234567&#123; \"userId\": \"用户ID\", \"serialNumber\": \"请求流水号\", \"payload\" : &#123; // ... 这里是有效载荷，存放具体的数据 &#125;&#125; 这里为了简化设计，用全局过滤器GlobalFilter实现，实际需要结合具体场景考虑： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Slf4j@Componentpublic class ModifyRequestBodyGlobalFilter implements GlobalFilter &#123; private final DataBufferFactory dataBufferFactory = new NettyDataBufferFactory(ByteBufAllocator.DEFAULT); @Autowired private ObjectMapper objectMapper; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; ServerHttpRequest request = exchange.getRequest(); String accessToken = request.getHeaders().getFirst(\"accessToken\"); if (!StringUtils.hasLength(accessToken)) &#123; throw new IllegalArgumentException(\"accessToken\"); &#125; // 新建一个ServerHttpRequest装饰器,覆盖需要装饰的方法 ServerHttpRequestDecorator decorator = new ServerHttpRequestDecorator(request) &#123; @Override public Flux&lt;DataBuffer&gt; getBody() &#123; Flux&lt;DataBuffer&gt; body = super.getBody(); InputStreamHolder holder = new InputStreamHolder(); body.subscribe(buffer -&gt; holder.inputStream = buffer.asInputStream()); if (null != holder.inputStream) &#123; try &#123; // 解析JSON的节点 JsonNode jsonNode = objectMapper.readTree(holder.inputStream); Assert.isTrue(jsonNode instanceof ObjectNode, \"JSON格式异常\"); ObjectNode objectNode = (ObjectNode) jsonNode; // JSON节点最外层写入新的属性 objectNode.put(\"userId\", accessToken); DataBuffer dataBuffer = dataBufferFactory.allocateBuffer(); String json = objectNode.toString(); log.info(\"最终的JSON数据为:&#123;&#125;\", json); dataBuffer.write(json.getBytes(StandardCharsets.UTF_8)); return Flux.just(dataBuffer); &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; else &#123; return super.getBody(); &#125; &#125; &#125;; // 使用修改后的ServerHttpRequestDecorator重新生成一个新的ServerWebExchange return chain.filter(exchange.mutate().request(decorator).build()); &#125; private class InputStreamHolder &#123; InputStream inputStream; &#125;&#125; 测试一下： 12345678910111213141516171819202122// HTTPPOST /order/json HTTP/1.1Host: localhost:9090Content-Type: application/jsonaccessToken: 10086Accept: */*Cache-Control: no-cacheHost: localhost:9090accept-encoding: gzip, deflatecontent-length: 94Connection: keep-alivecache-control: no-cache&#123; \"serialNumber\": \"请求流水号\", \"payload\": &#123; \"name\": \"doge\" &#125;&#125;// 日志输出最终的JSON数据为:&#123;\"serialNumber\":\"请求流水号\",\"payload\":&#123;\"name\":\"doge\"&#125;,\"userId\":\"10086\"&#125; 最重要的是用到了ServerHttpRequest装饰器ServerHttpRequestDecorator，主要覆盖对应获取请求体数据缓冲区的方法即可，至于怎么处理其他逻辑需要自行考虑，这里只是做一个简单的示范。一般的代码逻辑如下： 12345678910111213ServerHttpRequest request = exchange.getRequest();ServerHttpRequestDecorator requestDecorator = new ServerHttpRequestDecorator(request) &#123; @Override public Flux&lt;DataBuffer&gt; getBody() &#123; // 拿到承载原始请求体的Flux Flux&lt;DataBuffer&gt; body = super.getBody(); // 这里通过自定义方式生成新的承载请求体的Flux Flux&lt;DataBuffer&gt; newBody = ... return newBody; &#125; &#125;return chain.filter(exchange.mutate().request(requestDecorator).build()); 修改响应体 修改响应体的需求也是比较常见的，具体的做法和修改请求体差不多。例如我们想要实现下面的功能：第三方服务请求经过网关，原始报文是密文，我们需要在网关实现密文解密，然后把解密后的明文路由到下游服务，下游服务处理成功响应明文，需要在网关把明文加密成密文再返回到第三方服务。现在简化整个流程，用AES加密算法，统一密码为字符串&quot;throwable&quot;，假设请求报文和响应报文明文如下： 12345678910111213141516171819202122232425// 请求密文&#123; \"serialNumber\": \"请求流水号\", \"payload\" : \"加密后的请求消息载荷\"&#125;// 请求明文（仅仅作为提示）&#123; \"serialNumber\": \"请求流水号\", \"payload\" : \"&#123;\\\"name:\\\":\\\"doge\\\"&#125;\"&#125;// 响应密文&#123; \"code\": 200, \"message\":\"ok\", \"payload\" : \"加密后的响应消息载荷\"&#125;// 响应明文（仅仅作为提示）&#123; \"code\": 200, \"message\":\"ok\", \"payload\" : \"&#123;\\\"name:\\\":\\\"doge\\\",\\\"age\\\":26&#125;\"&#125; 为了方便一些加解密或者编码解码的实现，需要引入Apache的commons-codec类库： 12345&lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;version&gt;1.12&lt;/version&gt;&lt;/dependency&gt; 这里定义一个全局过滤器专门处理加解密，实际上最好结合真实的场景决定是否适合全局过滤器，这里只是一个示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169// AES加解密工具类public enum AesUtils &#123; // 单例 X; private static final String PASSWORD = \"throwable\"; private static final String KEY_ALGORITHM = \"AES\"; private static final String SECURE_RANDOM_ALGORITHM = \"SHA1PRNG\"; private static final String DEFAULT_CIPHER_ALGORITHM = \"AES/ECB/PKCS5Padding\"; public String encrypt(String content) &#123; try &#123; Cipher cipher = Cipher.getInstance(DEFAULT_CIPHER_ALGORITHM); cipher.init(Cipher.ENCRYPT_MODE, provideSecretKey()); return Hex.encodeHexString(cipher.doFinal(content.getBytes(StandardCharsets.UTF_8))); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(e); &#125; &#125; public byte[] decrypt(String content) &#123; try &#123; Cipher cipher = Cipher.getInstance(DEFAULT_CIPHER_ALGORITHM); cipher.init(Cipher.DECRYPT_MODE, provideSecretKey()); return cipher.doFinal(Hex.decodeHex(content)); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(e); &#125; &#125; private SecretKey provideSecretKey() &#123; try &#123; KeyGenerator keyGen = KeyGenerator.getInstance(KEY_ALGORITHM); SecureRandom secureRandom = SecureRandom.getInstance(SECURE_RANDOM_ALGORITHM); secureRandom.setSeed(PASSWORD.getBytes(StandardCharsets.UTF_8)); keyGen.init(128, secureRandom); return new SecretKeySpec(keyGen.generateKey().getEncoded(), KEY_ALGORITHM); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(e); &#125; &#125;&#125;// EncryptionGlobalFilter@Slf4j@Componentpublic class EncryptionGlobalFilter implements GlobalFilter, Ordered &#123; @Autowired private ObjectMapper objectMapper; @Override public int getOrder() &#123; return -2; &#125; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; ServerHttpRequest request = exchange.getRequest(); ServerHttpResponse response = exchange.getResponse(); DataBufferFactory bufferFactory = exchange.getResponse().bufferFactory(); ServerHttpRequestDecorator requestDecorator = processRequest(request, bufferFactory); ServerHttpResponseDecorator responseDecorator = processResponse(response, bufferFactory); return chain.filter(exchange.mutate().request(requestDecorator).response(responseDecorator).build()); &#125; private ServerHttpRequestDecorator processRequest(ServerHttpRequest request, DataBufferFactory bufferFactory) &#123; Flux&lt;DataBuffer&gt; body = request.getBody(); DataBufferHolder holder = new DataBufferHolder(); body.subscribe(dataBuffer -&gt; &#123; int len = dataBuffer.readableByteCount(); holder.length = len; byte[] bytes = new byte[len]; dataBuffer.read(bytes); DataBufferUtils.release(dataBuffer); String text = new String(bytes, StandardCharsets.UTF_8); JsonNode jsonNode = readNode(text); JsonNode payload = jsonNode.get(\"payload\"); String payloadText = payload.asText(); byte[] content = AesUtils.X.decrypt(payloadText); String requestBody = new String(content, StandardCharsets.UTF_8); log.info(\"修改请求体payload,修改前:&#123;&#125;,修改后:&#123;&#125;\", payloadText, requestBody); rewritePayloadNode(requestBody, jsonNode); DataBuffer data = bufferFactory.allocateBuffer(); data.write(jsonNode.toString().getBytes(StandardCharsets.UTF_8)); holder.dataBuffer = data; &#125;); HttpHeaders headers = new HttpHeaders(); headers.putAll(request.getHeaders()); headers.remove(HttpHeaders.CONTENT_LENGTH); return new ServerHttpRequestDecorator(request) &#123; @Override public HttpHeaders getHeaders() &#123; int contentLength = holder.length; if (contentLength &gt; 0) &#123; headers.setContentLength(contentLength); &#125; else &#123; headers.set(HttpHeaders.TRANSFER_ENCODING, \"chunked\"); &#125; return headers; &#125; @Override public Flux&lt;DataBuffer&gt; getBody() &#123; return Flux.just(holder.dataBuffer); &#125; &#125;; &#125; private ServerHttpResponseDecorator processResponse(ServerHttpResponse response, DataBufferFactory bufferFactory) &#123; return new ServerHttpResponseDecorator(response) &#123; @SuppressWarnings(\"unchecked\") @Override public Mono&lt;Void&gt; writeWith(Publisher&lt;? extends DataBuffer&gt; body) &#123; if (body instanceof Flux) &#123; Flux&lt;? extends DataBuffer&gt; flux = (Flux&lt;? extends DataBuffer&gt;) body; return super.writeWith(flux.map(buffer -&gt; &#123; CharBuffer charBuffer = StandardCharsets.UTF_8.decode(buffer.asByteBuffer()); DataBufferUtils.release(buffer); JsonNode jsonNode = readNode(charBuffer.toString()); JsonNode payload = jsonNode.get(\"payload\"); String text = payload.toString(); String content = AesUtils.X.encrypt(text); log.info(\"修改响应体payload,修改前:&#123;&#125;,修改后:&#123;&#125;\", text, content); setPayloadTextNode(content, jsonNode); return bufferFactory.wrap(jsonNode.toString().getBytes(StandardCharsets.UTF_8)); &#125;)); &#125; return super.writeWith(body); &#125; &#125;; &#125; private void rewritePayloadNode(String text, JsonNode root) &#123; try &#123; JsonNode node = objectMapper.readTree(text); ObjectNode objectNode = (ObjectNode) root; objectNode.set(\"payload\", node); &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; private void setPayloadTextNode(String text, JsonNode root) &#123; try &#123; ObjectNode objectNode = (ObjectNode) root; objectNode.set(\"payload\", new TextNode(text)); &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; private JsonNode readNode(String in) &#123; try &#123; return objectMapper.readTree(in); &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; private class DataBufferHolder &#123; DataBuffer dataBuffer; int length; &#125;&#125; 先准备一份密文： 12345678Map&lt;String, Object&gt; json = new HashMap&lt;&gt;(8);json.put(\"serialNumber\", \"请求流水号\");String content = \"&#123;\\\"name\\\": \\\"doge\\\"&#125;\";json.put(\"payload\", AesUtils.X.encrypt(content));System.out.println(new ObjectMapper().writeValueAsString(json));// 输出&#123;\"serialNumber\":\"请求流水号\",\"payload\":\"144e3dc734743f5709f1adf857bca473da683246fd612f86ac70edeb5f2d2729\"&#125; 模拟请求： 12345678910111213141516171819202122232425POST /order/json HTTP/1.1Host: localhost:9090accessToken: 10086Content-Type: application/jsonUser-Agent: PostmanRuntime/7.13.0Accept: */*Cache-Control: no-cachePostman-Token: bda07fc3-ea1a-478c-b4d7-754fe6f37200,634734d9-feed-4fc9-ba20-7618bd986e1cHost: localhost:9090cookie: customCookieName=customCookieValueaccept-encoding: gzip, deflatecontent-length: 104Connection: keep-alivecache-control: no-cache&#123; \"serialNumber\": \"请求流水号\", \"payload\": \"FE49xzR0P1cJ8a34V7ykc9poMkb9YS+GrHDt618tJyk=\"&#125;// 响应结果&#123; \"serialNumber\": \"请求流水号\", \"payload\": \"oo/K1igg2t/S8EExkBVGWOfI1gAh5pBpZ0wyjNPW6e8=\" # &lt;--- 解密后：&#123;\"name\":\"doge\",\"age\":26&#125;&#125; 遇到的问题： 必须实现Ordered接口，返回一个小于-1的order值，这是因为NettyWriteResponseFilter的order值为-1，我们需要覆盖返回响应体的逻辑，自定义的GlobalFilter必须比NettyWriteResponseFilter优先执行。 网关每次重启之后，第一个请求总是无法从原始的ServerHttpRequest读取到有效的Body，准确来说出现的现象是NettyRoutingFilter调用ServerHttpRequest#getBody()的时候获取到一个空的对象，导致空指针；奇怪的是从第二个请求开始就能正常调用。笔者把Spring Cloud Gateway的版本降低到Finchley.SR3，Spring Boot的版本降低到2.0.8.RELEASE，问题不再出现，初步确定是Spring Cloud Gateway版本升级导致的兼容性问题或者是BUG。 最重要的是用到了ServerHttpResponse装饰器ServerHttpResponseDecorator，主要覆盖写入响应体数据缓冲区的部分，至于怎么处理其他逻辑需要自行考虑，这里只是做一个简单的示范。一般的代码逻辑如下： 1234567891011121314151617ServerHttpResponse response = exchange.getResponse();ServerHttpResponseDecorator responseDecorator = new ServerHttpResponseDecorator(response) &#123; @Override public Mono&lt;Void&gt; writeWith(Publisher&lt;? extends DataBuffer&gt; body) &#123; if (body instanceof Flux) &#123; Flux&lt;? extends DataBuffer&gt; flux = (Flux&lt;? extends DataBuffer&gt;) body; return super.writeWith(flux.map(buffer -&gt; &#123; // buffer就是原始的响应数据的缓冲区 // 下面处理完毕之后返回新的响应数据的缓冲区即可 return bufferFactory.wrap(...); &#125;)); &#125; return super.writeWith(body); &#125; &#125;;return chain.filter(exchange.mutate().response(responseDecorator).build()); 请求体或者响应体报文过大的问题 有热心的同学告诉笔者，如果请求报文过大或者响应报文过大的时候，前面两节的修改请求和响应报文的方法会出现问题，这里尝试重现一下遇到的具体问题。先把请求报文尝试加长： 123456789101112131415Map&lt;String, Object&gt; json = new HashMap&lt;&gt;(8);json.put(\"serialNumber\", \"请求流水号\");StringBuilder builder = new StringBuilder();for (int i = 0; i &lt; 1000; i++) &#123; builder.append(\"doge\");&#125;String content = String.format(\"&#123;\\\"name\\\": \\\"%s\\\"&#125;\", builder.toString());json.put(\"payload\", AesUtils.X.encrypt(content));System.out.println(new ObjectMapper().writeValueAsString(json));// 请求的JSON报文如下：&#123; \"serialNumber\": \"请求流水号\", \"payload\": \"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\"&#125; 用上面的请求报文发起请求，确实存在问题： 主要问题是： 请求体包数据装成的Flux&lt;DataBuffer&gt;实例被订阅之后，读取到的字节数组的长度被截断了，提供的原始请求报文里面字符串长度要大于1000，转换成byte数组绝对要大于1000，但是上面的示例中只读取到长度为673的byte数组。 读取到的字节数组被截断后，则使用Jackson进行反序列化的时候提示没有读取到字符串的EOF标识，导致反序列化失败。 既然遇到了问题，就想办法解决。首先第一步定位一下是什么原因，直觉告诉笔者：要开启一下DEBUG日志进行观察，如果还没有头绪可能要跟踪一下源码。 开启DEBUG日志级别之后做一次请求，发现了一些可疑的日志信息： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273742019-05-19 11:16:15.660 [reactor-http-nio-2] DEBUG reactor.ipc.netty.http.server.HttpServer - [id: 0xa9b527e5, L:/0:0:0:0:0:0:0:1:9090 - R:/0:0:0:0:0:0:0:1:58012] READ COMPLETE2019-05-19 11:16:15.660 [reactor-http-nio-2] DEBUG reactor.ipc.netty.http.server.HttpServer - [id: 0xa9b527e5, L:/0:0:0:0:0:0:0:1:9090 ! R:/0:0:0:0:0:0:0:1:58012] INACTIVE2019-05-19 11:16:15.660 [reactor-http-nio-3] DEBUG reactor.ipc.netty.http.server.HttpServer - [id: 0x5554e091, L:/0:0:0:0:0:0:0:1:9090 - R:/0:0:0:0:0:0:0:1:58013] READ: 1024B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 50 4f 53 54 20 2f 6f 72 64 65 72 2f 6a 73 6f 6e |POST /order/json||00000010| 20 48 54 54 50 2f 31 2e 31 0d 0a 61 63 63 65 73 | HTTP/1.1..acces||00000020| 73 54 6f 6b 65 6e 3a 20 31 30 30 38 36 0d 0a 43 |sToken: 10086..C||00000030| 6f 6e 74 65 6e 74 2d 54 79 70 65 3a 20 61 70 70 |ontent-Type: app||00000040| 6c 69 63 61 74 69 6f 6e 2f 6a 73 6f 6e 0d 0a 55 |lication/json..U||00000050| 73 65 72 2d 41 67 65 6e 74 3a 20 50 6f 73 74 6d |ser-Agent: Postm||00000060| 61 6e 52 75 6e 74 69 6d 65 2f 37 2e 31 33 2e 30 |anRuntime/7.13.0||00000070| 0d 0a 41 63 63 65 70 74 3a 20 2a 2f 2a 0d 0a 43 |..Accept: */*..C||00000080| 61 63 68 65 2d 43 6f 6e 74 72 6f 6c 3a 20 6e 6f |ache-Control: no||00000090| 2d 63 61 63 68 65 0d 0a 50 6f 73 74 6d 61 6e 2d |-cache..Postman-||000000a0| 54 6f 6b 65 6e 3a 20 31 31 32 30 38 64 35 39 2d |Token: 11208d59-||000000b0| 65 61 34 61 2d 34 62 39 63 2d 61 30 33 39 2d 30 |ea4a-4b9c-a039-0||000000c0| 30 65 36 64 38 61 30 65 33 65 66 0d 0a 48 6f 73 |0e6d8a0e3ef..Hos||000000d0| 74 3a 20 6c 6f 63 61 6c 68 6f 73 74 3a 39 30 39 |t: localhost:909||000000e0| 30 0d 0a 63 6f 6f 6b 69 65 3a 20 63 75 73 74 6f |0..cookie: custo||000000f0| 6d 43 6f 6f 6b 69 65 4e 61 6d 65 3d 63 75 73 74 |mCookieName=cust||00000100| 6f 6d 43 6f 6f 6b 69 65 56 61 6c 75 65 0d 0a 61 |omCookieValue..a||00000110| 63 63 65 70 74 2d 65 6e 63 6f 64 69 6e 67 3a 20 |ccept-encoding: ||00000120| 67 7a 69 70 2c 20 64 65 66 6c 61 74 65 0d 0a 63 |gzip, deflate..c||00000130| 6f 6e 74 65 6e 74 2d 6c 65 6e 67 74 68 3a 20 35 |ontent-length: 5||00000140| 34 31 36 0d 0a 43 6f 6e 6e 65 63 74 69 6f 6e 3a |416..Connection:||00000150| 20 6b 65 65 70 2d 61 6c 69 76 65 0d 0a 0d 0a 7b | keep-alive....&#123;||00000160| 0a 20 20 20 20 22 73 65 72 69 61 6c 4e 75 6d 62 |. \"serialNumb||00000170| 65 72 22 3a 20 22 e8 af b7 e6 b1 82 e6 b5 81 e6 |er\": \"..........||00000180| b0 b4 e5 8f b7 22 2c 0a 20 20 20 20 22 70 61 79 |.....\",. \"pay||00000190| 6c 6f 61 64 22 3a 20 22 30 44 63 66 32 70 6c 46 |load\": \"0Dcf2plF||000001a0| 70 45 53 70 72 4b 6a 6b 64 71 4e 48 4d 38 6a 6a |pESprKjkdqNHM8jj||000001b0| 49 41 72 6b 64 37 58 57 35 4c 6c 32 2f 71 61 42 |IArkd7XW5Ll2/qaB||000001c0| 71 76 2f 49 34 79 41 4b 35 48 65 31 31 75 53 35 |qv/I4yAK5He11uS5||000001d0| 64 76 36 6d 67 61 72 2f 79 4f 4d 67 43 75 52 33 |dv6mgar/yOMgCuR3||000001e0| 74 64 62 6b 75 58 62 2b 70 6f 47 71 2f 38 6a 6a |tdbkuXb+poGq/8jj||000001f0| 49 41 72 6b 64 37 58 57 35 4c 6c 32 2f 71 61 42 |IArkd7XW5Ll2/qaB||00000200| 71 76 2f 49 34 79 41 4b 35 48 65 31 31 75 53 35 |qv/I4yAK5He11uS5||00000210| 64 76 36 6d 67 61 72 2f 79 4f 4d 67 43 75 52 33 |dv6mgar/yOMgCuR3||00000220| 74 64 62 6b 75 58 62 2b 70 6f 47 71 2f 38 6a 6a |tdbkuXb+poGq/8jj||00000230| 49 41 72 6b 64 37 58 57 35 4c 6c 32 2f 71 61 42 |IArkd7XW5Ll2/qaB||00000240| 71 76 2f 49 34 79 41 4b 35 48 65 31 31 75 53 35 |qv/I4yAK5He11uS5||00000250| 64 76 36 6d 67 61 72 2f 79 4f 4d 67 43 75 52 33 |dv6mgar/yOMgCuR3||00000260| 74 64 62 6b 75 58 62 2b 70 6f 47 71 2f 38 6a 6a |tdbkuXb+poGq/8jj||00000270| 49 41 72 6b 64 37 58 57 35 4c 6c 32 2f 71 61 42 |IArkd7XW5Ll2/qaB||00000280| 71 76 2f 49 34 79 41 4b 35 48 65 31 31 75 53 35 |qv/I4yAK5He11uS5||00000290| 64 76 36 6d 67 61 72 2f 79 4f 4d 67 43 75 52 33 |dv6mgar/yOMgCuR3||000002a0| 74 64 62 6b 75 58 62 2b 70 6f 47 71 2f 38 6a 6a |tdbkuXb+poGq/8jj||000002b0| 49 41 72 6b 64 37 58 57 35 4c 6c 32 2f 71 61 42 |IArkd7XW5Ll2/qaB||000002c0| 71 76 2f 49 34 79 41 4b 35 48 65 31 31 75 53 35 |qv/I4yAK5He11uS5||000002d0| 64 76 36 6d 67 61 72 2f 79 4f 4d 67 43 75 52 33 |dv6mgar/yOMgCuR3||000002e0| 74 64 62 6b 75 58 62 2b 70 6f 47 71 2f 38 6a 6a |tdbkuXb+poGq/8jj||000002f0| 49 41 72 6b 64 37 58 57 35 4c 6c 32 2f 71 61 42 |IArkd7XW5Ll2/qaB||00000300| 71 76 2f 49 34 79 41 4b 35 48 65 31 31 75 53 35 |qv/I4yAK5He11uS5||00000310| 64 76 36 6d 67 61 72 2f 79 4f 4d 67 43 75 52 33 |dv6mgar/yOMgCuR3||00000320| 74 64 62 6b 75 58 62 2b 70 6f 47 71 2f 38 6a 6a |tdbkuXb+poGq/8jj||00000330| 49 41 72 6b 64 37 58 57 35 4c 6c 32 2f 71 61 42 |IArkd7XW5Ll2/qaB||00000340| 71 76 2f 49 34 79 41 4b 35 48 65 31 31 75 53 35 |qv/I4yAK5He11uS5||00000350| 64 76 36 6d 67 61 72 2f 79 4f 4d 67 43 75 52 33 |dv6mgar/yOMgCuR3||00000360| 74 64 62 6b 75 58 62 2b 70 6f 47 71 2f 38 6a 6a |tdbkuXb+poGq/8jj||00000370| 49 41 72 6b 64 37 58 57 35 4c 6c 32 2f 71 61 42 |IArkd7XW5Ll2/qaB||00000380| 71 76 2f 49 34 79 41 4b 35 48 65 31 31 75 53 35 |qv/I4yAK5He11uS5||00000390| 64 76 36 6d 67 61 72 2f 79 4f 4d 67 43 75 52 33 |dv6mgar/yOMgCuR3||000003a0| 74 64 62 6b 75 58 62 2b 70 6f 47 71 2f 38 6a 6a |tdbkuXb+poGq/8jj||000003b0| 49 41 72 6b 64 37 58 57 35 4c 6c 32 2f 71 61 42 |IArkd7XW5Ll2/qaB||000003c0| 71 76 2f 49 34 79 41 4b 35 48 65 31 31 75 53 35 |qv/I4yAK5He11uS5||000003d0| 64 76 36 6d 67 61 72 2f 79 4f 4d 67 43 75 52 33 |dv6mgar/yOMgCuR3||000003e0| 74 64 62 6b 75 58 62 2b 70 6f 47 71 2f 38 6a 6a |tdbkuXb+poGq/8jj||000003f0| 49 41 72 6b 64 37 58 57 35 4c 6c 32 2f 71 61 42 |IArkd7XW5Ll2/qaB|+--------+-------------------------------------------------+----------------+2019-05-19 11:16:15.662 [reactor-http-nio-2] DEBUG reactor.ipc.netty.http.server.HttpServer - [id: 0xa9b527e5, L:/0:0:0:0:0:0:0:1:9090 ! R:/0:0:0:0:0:0:0:1:58012] UNREGISTERED2019-05-19 11:16:15.665 [reactor-http-nio-3] DEBUG reactor.ipc.netty.http.server.HttpServerOperations - [id: 0x5554e091, L:/0:0:0:0:0:0:0:1:9090 - R:/0:0:0:0:0:0:0:1:58013] Increasing pending responses, now 12019-05-19 11:16:15.671 [reactor-http-nio-3] DEBUG reactor.ipc.netty.http.server.HttpServer - [id: 0x5554e091, L:/0:0:0:0:0:0:0:1:9090 - R:/0:0:0:0:0:0:0:1:58013] READ COMPLETE 注意一下关键字READ: 1024B，这里应该是底层的Reactor-Netty读取的最大数据报的长度限制，打印出来的数据报刚好也是1024B的大小，这个应该就是导致请求体被截断的根本原因；这个问题不单单会出现在请求体的获取，也会出现在响应体的写入。既然这个是共性的问题，那么项目Github上肯定有对应的Issue，找到一个互动比较长的gateway request size limit 1024B because netty default limit 1024,how to solve it? #581，从回答来看，官方建议使用ModifyRequestBodyGatewayFilterFactory和ModifyResponseBodyGatewayFilterFactory完成对应的功能。这里可以尝试借鉴一下ModifyRequestBodyGatewayFilterFactory的实现方式修改之前的代码，因为代码的逻辑比较长和复杂，解密请求体的过滤器拆分到新的类RequestEncryptionGlobalFilter，加密响应体的过滤器拆分到ResponseDecryptionGlobalFilter： RequestEncryptionGlobalFilter的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106@Slf4j@Componentpublic class RequestEncryptionGlobalFilter implements GlobalFilter, Ordered &#123; @Autowired private ObjectMapper objectMapper; private final List&lt;HttpMessageReader&lt;?&gt;&gt; messageReaders = HandlerStrategies.withDefaults().messageReaders(); @Override public int getOrder() &#123; return -2; &#125; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; return processRequest(exchange, chain); &#125; private Mono&lt;Void&gt; processRequest(ServerWebExchange exchange, GatewayFilterChain chain) &#123; ServerRequest serverRequest = new DefaultServerRequest(exchange, messageReaders); DataBufferFactory bufferFactory = exchange.getResponse().bufferFactory(); Mono&lt;String&gt; rawBody = serverRequest.bodyToMono(String.class).map(s -&gt; s); BodyInserter&lt;Mono&lt;String&gt;, ReactiveHttpOutputMessage&gt; bodyInserter = BodyInserters.fromPublisher(rawBody, String.class); HttpHeaders tempHeaders = new HttpHeaders(); tempHeaders.putAll(exchange.getRequest().getHeaders()); tempHeaders.remove(HttpHeaders.CONTENT_LENGTH); CachedBodyOutputMessage outputMessage = new CachedBodyOutputMessage(exchange, tempHeaders); return bodyInserter.insert(outputMessage, new BodyInserterContext()).then(Mono.defer(() -&gt; &#123; Flux&lt;DataBuffer&gt; body = outputMessage.getBody(); DataBufferHolder holder = new DataBufferHolder(); body.subscribe(dataBuffer -&gt; &#123; int len = dataBuffer.readableByteCount(); holder.length = len; byte[] bytes = new byte[len]; dataBuffer.read(bytes); DataBufferUtils.release(dataBuffer); String text = new String(bytes, StandardCharsets.UTF_8); JsonNode jsonNode = readNode(text); JsonNode payload = jsonNode.get(\"payload\"); String payloadText = payload.asText(); byte[] content = AesUtils.X.decrypt(payloadText); String requestBody = new String(content, StandardCharsets.UTF_8); log.info(\"修改请求体payload,修改前:&#123;&#125;,修改后:&#123;&#125;\", payloadText, requestBody); rewritePayloadNode(requestBody, jsonNode); DataBuffer data = bufferFactory.allocateBuffer(); data.write(jsonNode.toString().getBytes(StandardCharsets.UTF_8)); holder.dataBuffer = data; &#125;); ServerHttpRequestDecorator requestDecorator = new ServerHttpRequestDecorator(exchange.getRequest()) &#123; @Override public HttpHeaders getHeaders() &#123; long contentLength = tempHeaders.getContentLength(); HttpHeaders httpHeaders = new HttpHeaders(); httpHeaders.putAll(super.getHeaders()); if (contentLength &gt; 0) &#123; httpHeaders.setContentLength(contentLength); &#125; else &#123; httpHeaders.set(HttpHeaders.TRANSFER_ENCODING, \"chunked\"); &#125; return httpHeaders; &#125; @Override public Flux&lt;DataBuffer&gt; getBody() &#123; return Flux.just(holder.dataBuffer); &#125; &#125;; return chain.filter(exchange.mutate().request(requestDecorator).build()); &#125;)); &#125; private void rewritePayloadNode(String text, JsonNode root) &#123; try &#123; JsonNode node = objectMapper.readTree(text); ObjectNode objectNode = (ObjectNode) root; objectNode.set(\"payload\", node); &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; private void setPayloadTextNode(String text, JsonNode root) &#123; try &#123; ObjectNode objectNode = (ObjectNode) root; objectNode.set(\"payload\", new TextNode(text)); &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; private JsonNode readNode(String in) &#123; try &#123; return objectMapper.readTree(in); &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; private class DataBufferHolder &#123; DataBuffer dataBuffer; int length; &#125;&#125; ResponseDecryptionGlobalFilter的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113@Slf4j@Componentpublic class ResponseDecryptionGlobalFilter implements GlobalFilter, Ordered &#123; @Autowired private ObjectMapper objectMapper; @Override public int getOrder() &#123; return NettyWriteResponseFilter.WRITE_RESPONSE_FILTER_ORDER - 1; &#125; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; return processResponse(exchange, chain); &#125; private Mono&lt;Void&gt; processResponse(ServerWebExchange exchange, GatewayFilterChain chain) &#123; ServerHttpResponseDecorator responseDecorator = new ServerHttpResponseDecorator(exchange.getResponse()) &#123; @Override public Mono&lt;Void&gt; writeWith(Publisher&lt;? extends DataBuffer&gt; body) &#123; String originalResponseContentType = exchange.getAttribute(ORIGINAL_RESPONSE_CONTENT_TYPE_ATTR); HttpHeaders httpHeaders = new HttpHeaders(); httpHeaders.add(HttpHeaders.CONTENT_TYPE, originalResponseContentType); ResponseAdapter responseAdapter = new ResponseAdapter(body, httpHeaders); DefaultClientResponse clientResponse = new DefaultClientResponse(responseAdapter, ExchangeStrategies.withDefaults()); Mono&lt;String&gt; rawBody = clientResponse.bodyToMono(String.class).map(s -&gt; s); BodyInserter&lt;Mono&lt;String&gt;, ReactiveHttpOutputMessage&gt; bodyInserter = BodyInserters.fromPublisher(rawBody, String.class); CachedBodyOutputMessage outputMessage = new CachedBodyOutputMessage(exchange, exchange.getResponse().getHeaders()); return bodyInserter.insert(outputMessage, new BodyInserterContext()) .then(Mono.defer(() -&gt; &#123; Flux&lt;DataBuffer&gt; messageBody = outputMessage.getBody(); Flux&lt;DataBuffer&gt; flux = messageBody.map(buffer -&gt; &#123; CharBuffer charBuffer = StandardCharsets.UTF_8.decode(buffer.asByteBuffer()); DataBufferUtils.release(buffer); JsonNode jsonNode = readNode(charBuffer.toString()); JsonNode payload = jsonNode.get(\"payload\"); String text = payload.toString(); String content = AesUtils.X.encrypt(text); log.info(\"修改响应体payload,修改前:&#123;&#125;,修改后:&#123;&#125;\", text, content); setPayloadTextNode(content, jsonNode); return getDelegate().bufferFactory().wrap(jsonNode.toString().getBytes(StandardCharsets.UTF_8)); &#125;); HttpHeaders headers = getDelegate().getHeaders(); if (!headers.containsKey(HttpHeaders.TRANSFER_ENCODING)) &#123; flux = flux.doOnNext(data -&gt; headers.setContentLength(data.readableByteCount())); &#125; return getDelegate().writeWith(flux); &#125;)); &#125; &#125;; return chain.filter(exchange.mutate().response(responseDecorator).build()); &#125; private void setPayloadTextNode(String text, JsonNode root) &#123; try &#123; ObjectNode objectNode = (ObjectNode) root; objectNode.set(\"payload\", new TextNode(text)); &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; private JsonNode readNode(String in) &#123; try &#123; return objectMapper.readTree(in); &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; private class ResponseAdapter implements ClientHttpResponse &#123; private final Flux&lt;DataBuffer&gt; flux; private final HttpHeaders headers; @SuppressWarnings(\"unchecked\") private ResponseAdapter(Publisher&lt;? extends DataBuffer&gt; body, HttpHeaders headers) &#123; this.headers = headers; if (body instanceof Flux) &#123; flux = (Flux) body; &#125; else &#123; flux = ((Mono) body).flux(); &#125; &#125; @Override public Flux&lt;DataBuffer&gt; getBody() &#123; return flux; &#125; @Override public HttpHeaders getHeaders() &#123; return headers; &#125; @Override public HttpStatus getStatusCode() &#123; return null; &#125; @Override public int getRawStatusCode() &#123; return 0; &#125; @Override public MultiValueMap&lt;String, ResponseCookie&gt; getCookies() &#123; return null; &#125; &#125;&#125; 模拟请求： 12345678910111213141516171819202122POST /order/json HTTP/1.1Host: localhost:9090accessToken: 10086Content-Type: application/jsonUser-Agent: PostmanRuntime/7.13.0Accept: */*Cache-Control: no-cachePostman-Token: 3a830202-f3d1-450e-839f-ae8f3b88bced,b229feb1-7c8b-4d25-a039-09345f3fe8f0Host: localhost:9090cookie: customCookieName=customCookieValueaccept-encoding: gzip, deflatecontent-length: 5416Connection: keep-alivecache-control: no-cache&#123; \"serialNumber\": \"请求流水号\", \"payload\": \"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\"&#125;// 响应&#123;\"serialNumber\":\"请求流水号\",\"userId\":null,\"payload\":\"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\"&#125; 彻底解决了之前的请求或者响应报文截断的问题，笔者发现了很多博文都在(照搬)更改读取DataBuffer实例时候的代码逻辑，其实那段逻辑是不相关的，可以尝试用BufferedReader基于行读取然后用StringBuilder承载，或者像本文那样直接读取为byte数组等等，因为根本的原因是底层的Reactor-Netty的数据块读取大小限制导致获取到的DataBuffer实例里面的数据是不完整的，解决方案就是参照Spring Cloud Gateway本身提供的基础类库进行改造(暂时没发现有入口可以调整Reactor-Netty的配置)，难度也不大。 小结 刚好遇到一个需求需要做网关的加解密包括请求体和响应体的修改，这里顺便把Spring Cloud Gateway一些涉及到这方面的一些内容梳理了一遍，顺便把坑踩了并且填完。下一步尝试按照目前官方提供的可用组件修改一下实现自定义的逻辑，包括Hystrix、基于Eureka和Ribbon的负载均衡、限流等等。 (本文完 c-6-d e-a-20190518 r-a-20190519)","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://throwable.club/blog/categories/Spring-Cloud/"},{"name":"Spring Cloud Gateway","slug":"Spring-Cloud/Spring-Cloud-Gateway","permalink":"http://throwable.club/blog/categories/Spring-Cloud/Spring-Cloud-Gateway/"}],"tags":[{"name":"Spring Cloud Gateway","slug":"Spring-Cloud-Gateway","permalink":"http://throwable.club/blog/tags/Spring-Cloud-Gateway/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://throwable.club/blog/tags/Spring-Cloud/"}]},{"title":"一次MySQL死锁问题的排查与分析(一)","slug":"mysql-deadlock-troubleshoot-1st","date":"2019-05-11T14:02:25.000Z","updated":"2019-06-02T02:13:30.413Z","comments":true,"path":"2019/05/11/mysql-deadlock-troubleshoot-1st/","link":"","permalink":"http://throwable.club/2019/05/11/mysql-deadlock-troubleshoot-1st/","excerpt":"前提 笔者负责的一个系统最近有新功能上线后突然在预警模块不定时报出MySQL死锁导致事务回滚。幸亏，上游系统采用了异步推送和同步查询结合的方式，感知到推送失败及时进行了补偿。于是，笔者争取了一点时间详细分析了导致死锁的多个事务的执行时序，分析并且得出解决方案。","text":"前提 笔者负责的一个系统最近有新功能上线后突然在预警模块不定时报出MySQL死锁导致事务回滚。幸亏，上游系统采用了异步推送和同步查询结合的方式，感知到推送失败及时进行了补偿。于是，笔者争取了一点时间详细分析了导致死锁的多个事务的执行时序，分析并且得出解决方案。 死锁场景复现 首先，MySQL的服务端版本是5.7(小版本可以基本忽略)，使用了InnoDB。有一张用户数据表的schema设计如下（无关字段已经屏蔽掉）： 12345678CREATE TABLE `t_user_data`( id BIGINT UNSIGNED PRIMARY KEY AUTO_INCREMENT, user_id BIGINT UNSIGNED NOT NULL COMMENT '用户ID', data_id VARCHAR(50) NOT NULL COMMENT '数据ID', INDEX idx_user_id (user_id), INDEX idx_data_id (data_id)) COMMENT '用户数据表'; 业务代码中发生死锁的伪代码如下： 12345678process_method(dataId,userDataDtoList)&#123; start transaction: userDataDao.deleteByDataId(dataId); for dto in userDataDtoList: UserData userData = convert(dto); userDataDao.insert(dto); commit;&#125; 这里的逻辑是，如果已经存在对应dataId的数据要先进行删除，然后写入新的用户数据。 尝试用两个Session提交两个事务重现死锁问题： 时间序列 Tx-Session-1 Tx-Session-2 T1 START TRANSACTION; T2 START TRANSACTION; T3 DELETE FROM t_user_data WHERE data_id = ‘xxxxx’; T4 DELETE FROM t_user_data WHERE data_id = ‘yyyyy’; T5 INSERT INTO t_user_data(USER_ID, DATA_ID) VALUES (1, ‘xxxxx’); T6 INSERT INTO t_user_data(USER_ID, DATA_ID) VALUES (2, ‘yyyyy’); T7 Deadlock found when trying to get lock; try restarting transaction(Rollback) T8 COMMIT; 这里会出现两个现象： Tx-Session-2会话T4执行完毕之后，Tx-Session-1会话T5执行的时候，Tx-Session-1会话客户端会处于阻塞状态。 Tx-Session-2会话T6执行完毕之后，MySQL提示死锁事务被回滚，此时，Tx-Session-1会话客户端会解除阻塞。 导致死锁的原因 后面会写一篇专门的文章学习和理解MySQL的InnoDB数据引擎的锁相关知识，这里直接排查InnoDB的死锁日志。 1mysql&gt; show engine innodb status; 输出的死锁日志如下： 1234567891011121314151617181920212223242526272829303132------------------------LATEST DETECTED DEADLOCK------------------------2019-05-11 19:16:04 0x5804*** (1) TRANSACTION:TRANSACTION 3882, ACTIVE 13 sec insertingmysql tables in use 1, locked 1LOCK WAIT 3 lock struct(s), heap size 1136, 2 row lock(s), undo log entries 1MySQL thread id 32, OS thread handle 9876, query id 358 localhost ::1 doge updateINSERT INTO t_user_data(USER_ID, DATA_ID) VALUES (1, 'xxxxx')*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 33 page no 6 n bits 72 index idx_data_id of table `test`.`t_user_data` trx id 3882 lock_mode X insert intention waitingRecord lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;;*** (2) TRANSACTION:TRANSACTION 3883, ACTIVE 9 sec inserting, thread declared inside InnoDB 5000mysql tables in use 1, locked 13 lock struct(s), heap size 1136, 2 row lock(s), undo log entries 1MySQL thread id 11, OS thread handle 22532, query id 359 localhost ::1 doge updateINSERT INTO t_user_data(USER_ID, DATA_ID) VALUES (2, 'yyyyy')*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 33 page no 6 n bits 72 index idx_data_id of table `test`.`t_user_data` trx id 3883 lock_mode XRecord lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;;*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 33 page no 6 n bits 72 index idx_data_id of table `test`.`t_user_data` trx id 3883 lock_mode X insert intention waitingRecord lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;;*** WE ROLL BACK TRANSACTION (2) 这里要参考MySQL关于InnoDB锁的关于next-key锁描述那一节，注意死锁日志关键字supremum的意义： next-key锁将gap锁定在索引中最大值之上，而supremum伪记录的值高于索引中实际的任何值。supremum不是真正的索引记录，因此，实际上，此next-key锁仅锁定最大索引值之后的间隙。 两个事务的锁属性可以通过select * from information_schema.innodb_locks;进行查询，数据如下表： lock_id lock_tx_id lock_mode lock_type lock_table lock_index lock_space lock_page lock_rec lock_data 3882:33:6:1 3882 X RECORD test.t_user_data idx_data_id 33 6 1 supremum pseudo-record 3883:33:6:1 3883 X RECORD test.t_user_data idx_data_id 33 6 1 supremum pseudo-record 1DELETE FROM t_user_data WHERE data_id = '不存在的索引值'; 上面的SQL执行时候，如果条件刚好是索引列，并且查询的值是当前表(索引)中不存在的数据，根据next-key锁的描述和死锁日志中的asc supremum关键字，执行该DELETE语句的时候，会锁定目标值和高于目标值的任何值，如果条件是&quot;xxxxx&quot;，那么相当于锁定区间为(“xxxxx”,最大上界]。 next-key锁是索引记录上的记录锁(Record Lock)和索引记录之前的间隙上的间隙锁(Gap Lock)定的组合。间隙锁有两个特点： 两个事务即使锁定的区间一致（或者有部分重合），不会影响它们之间获取到锁（可以参考行锁的兼容性矩阵）。 间隙锁G会阻止非持有G的其他事务向锁定的区间中插入数据，以避免产生冲突数据。 分析到这里，就很好解释上面出现死锁的执行时序： 两个事务的DELETE语句都可以正确执行，这个时候，两者的间隙锁锁定的区域分别是(‘xxxxx’,最大上界]和(‘yyyyy’,最大上界]。 事务1执行INSERT语句的时候阻塞，是因为事务2的间隙锁不允许事务1插入索引值’xxxxx’。 事务2执行INSERT语句的时候阻塞，是因为事务1的间隙锁不允许事务1插入索引值’yyyyy’，执行到这一步，MySQL的死锁检查模块应该起效了，因为两个事务依赖的锁资源已经成环(或者成有向图)。 事务2的优先级比较低，于是抛出死锁异常并且被回滚了。 之前曾经和DBA同事聊过，发生死锁的事务是怎么衡量优先级或者怎么确定哪个事务需要回滚(释放锁资源让另一个事务可以正常提交)，但是后来没有收到很好的答复，这一点有时间再研究一下。 解决方案 参考MySQL的文档，解决方案有两个： 方案一：降低数据库的事务隔离级别，需要降低到READ COMMITED，这样子可以关闭间隙锁的扫描。（&lt;== 并不推荐这种做法，修改事务隔离级别有可能出现新的问题） 方案二：针对对应的原因修改业务代码。 这里方案二只需要把伪代码逻辑修改如下： 1234567891011process_method(dataId,userDataDtoList)&#123; List&lt;UserData&gt; userDataList = userDataDao.selectByDataId(dataId); start transaction: if userDataList is not empty: List&lt;Long&gt; ids = collectIdList(userDataList); userDataDao.deleteByIds(ids); for dto in userDataDtoList: UserData userData = convert(dto); userDataDao.insert(dto); commit;&#125; 就是先根据dataId进行查询，如果存在数据，聚合主键列表，通过主键列表进行删除，然后再进行数据插入。 小结 这并非是第一次在生产环境中出现MySQL死锁，只是这次的案例相对简单。InnoDB提供的死锁日志其实并没有提供完整的事务提交的SQL，所以对于复杂的场景需要细致结合代码和死锁日志进行排查，很多时候对应的代码逻辑是多处的。这里列举一下笔者处理死锁问题的一些步骤： 及时止损，如果可以回滚导致死锁的代码，那么最好果敢地回滚；如果重试可以解决问题并且出现死锁问题的规模不大，可以尝试短时间内进行问题排查。 通过业务系统日志迅速定位到发生死锁的代码块，JVM应用一般底层是依赖JDBC，出现死锁的时候会抛出一个SQLException的子类，异常栈的信息中带有&quot;Deadlock&quot;字样。 分析InnoDB的死锁日志，一般会列出竞争锁的多个事务的相对详细的信息，这些信息是排查死锁问题的第一手资料。 修复问题上线后注意做好监控和预警，确定问题彻底解决。 参考资料： MySQL5.7官方文档 (本文完 c-1-d e-a-20190511)","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://throwable.club/blog/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://throwable.club/blog/tags/MySQL/"}]},{"title":"Spring Cloud Gateway-自定义异常处理","slug":"spring-cloud-gateway-custom-exception-handler","date":"2019-05-11T06:26:48.000Z","updated":"2019-06-02T02:19:32.216Z","comments":true,"path":"2019/05/11/spring-cloud-gateway-custom-exception-handler/","link":"","permalink":"http://throwable.club/2019/05/11/spring-cloud-gateway-custom-exception-handler/","excerpt":"前提 我们平时在用SpringMVC的时候，只要是经过DispatcherServlet处理的请求，可以通过@ControllerAdvice和@ExceptionHandler自定义不同类型异常的处理逻辑，具体可以参考ResponseEntityExceptionHandler和DefaultHandlerExceptionResolver，底层原理很简单，就是发生异常的时候搜索容器中已经存在的异常处理器并且匹配对应的异常类型，匹配成功之后使用该指定的异常处理器返回结果进行Response的渲染，如果找不到默认的异常处理器则用默认的进行兜底(个人认为，Spring在很多功能设计的时候都有这种“有则使用自定义，无则使用默认提供”这种思想十分优雅)。 SpringMVC中提供的自定义异常体系在Spring-WebFlux中并不适用，其实原因很简单，两者底层的运行容器并不相同。WebExceptionHandler是Spring-WebFlux的异常处理器顶层接口，因此追溯到子类可以追踪到DefaultErrorWebExceptionHandler是Spring Cloud Gateway的全局异常处理器，配置类是ErrorWebFluxAutoConfiguration。","text":"前提 我们平时在用SpringMVC的时候，只要是经过DispatcherServlet处理的请求，可以通过@ControllerAdvice和@ExceptionHandler自定义不同类型异常的处理逻辑，具体可以参考ResponseEntityExceptionHandler和DefaultHandlerExceptionResolver，底层原理很简单，就是发生异常的时候搜索容器中已经存在的异常处理器并且匹配对应的异常类型，匹配成功之后使用该指定的异常处理器返回结果进行Response的渲染，如果找不到默认的异常处理器则用默认的进行兜底(个人认为，Spring在很多功能设计的时候都有这种“有则使用自定义，无则使用默认提供”这种思想十分优雅)。 SpringMVC中提供的自定义异常体系在Spring-WebFlux中并不适用，其实原因很简单，两者底层的运行容器并不相同。WebExceptionHandler是Spring-WebFlux的异常处理器顶层接口，因此追溯到子类可以追踪到DefaultErrorWebExceptionHandler是Spring Cloud Gateway的全局异常处理器，配置类是ErrorWebFluxAutoConfiguration。 为什么要自定义异常处理 先画一个假想但是贴近实际架构图，定位一下网关的作用： 网关在整个架构中的作用是： 路由服务端应用的请求到后端应用。 (聚合)后端应用的响应转发到服务端应用。 假设网关服务总是正常的前提下： 对于第1点来说，假设后端应用不能平滑无损上线，会有一定的几率出现网关路由请求到一些后端的“僵尸节点(请求路由过去的时候，应用更好在重启或者刚好停止)”，这个时候会路由会失败抛出异常，一般情况是Connection Refuse。 对于第2点来说，假设后端应用没有正确处理异常，那么应该会把异常信息经过网关转发回到服务端应用，这种情况理论上不会出现异常。 其实还有第3点隐藏的问题，网关如果不单单承担路由的功能，还包含了鉴权、限流等功能，如果这些功能开发的时候对异常捕获没有做完善的处理甚至是逻辑本身存在BUG，有可能导致异常没有被正常捕获处理，走了默认的异常处理器DefaultErrorWebExceptionHandler，默认的异常处理器的处理逻辑可能并不符合我们预期的结果。 如何自定义异常处理 我们可以先看默认的异常处理器的配置类ErrorWebFluxAutoConfiguration： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Configuration@ConditionalOnWebApplication(type = ConditionalOnWebApplication.Type.REACTIVE)@ConditionalOnClass(WebFluxConfigurer.class)@AutoConfigureBefore(WebFluxAutoConfiguration.class)@EnableConfigurationProperties(&#123; ServerProperties.class, ResourceProperties.class &#125;)public class ErrorWebFluxAutoConfiguration &#123; private final ServerProperties serverProperties; private final ApplicationContext applicationContext; private final ResourceProperties resourceProperties; private final List&lt;ViewResolver&gt; viewResolvers; private final ServerCodecConfigurer serverCodecConfigurer; public ErrorWebFluxAutoConfiguration(ServerProperties serverProperties, ResourceProperties resourceProperties, ObjectProvider&lt;ViewResolver&gt; viewResolversProvider, ServerCodecConfigurer serverCodecConfigurer, ApplicationContext applicationContext) &#123; this.serverProperties = serverProperties; this.applicationContext = applicationContext; this.resourceProperties = resourceProperties; this.viewResolvers = viewResolversProvider.orderedStream() .collect(Collectors.toList()); this.serverCodecConfigurer = serverCodecConfigurer; &#125; @Bean @ConditionalOnMissingBean(value = ErrorWebExceptionHandler.class, search = SearchStrategy.CURRENT) @Order(-1) public ErrorWebExceptionHandler errorWebExceptionHandler( ErrorAttributes errorAttributes) &#123; DefaultErrorWebExceptionHandler exceptionHandler = new DefaultErrorWebExceptionHandler( errorAttributes, this.resourceProperties, this.serverProperties.getError(), this.applicationContext); exceptionHandler.setViewResolvers(this.viewResolvers); exceptionHandler.setMessageWriters(this.serverCodecConfigurer.getWriters()); exceptionHandler.setMessageReaders(this.serverCodecConfigurer.getReaders()); return exceptionHandler; &#125; @Bean @ConditionalOnMissingBean(value = ErrorAttributes.class, search = SearchStrategy.CURRENT) public DefaultErrorAttributes errorAttributes() &#123; return new DefaultErrorAttributes( this.serverProperties.getError().isIncludeException()); &#125;&#125; 注意到两个Bean实例ErrorWebExceptionHandler和DefaultErrorAttributes都使用了@ConditionalOnMissingBean注解，也就是我们可以通过自定义实现去覆盖它们。先自定义一个CustomErrorWebFluxAutoConfiguration（除了ErrorWebExceptionHandler的自定义实现，其他直接拷贝ErrorWebFluxAutoConfiguration）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Configuration@ConditionalOnWebApplication(type = ConditionalOnWebApplication.Type.REACTIVE)@ConditionalOnClass(WebFluxConfigurer.class)@AutoConfigureBefore(WebFluxAutoConfiguration.class)@EnableConfigurationProperties(&#123;ServerProperties.class, ResourceProperties.class&#125;)public class CustomErrorWebFluxAutoConfiguration &#123; private final ServerProperties serverProperties; private final ApplicationContext applicationContext; private final ResourceProperties resourceProperties; private final List&lt;ViewResolver&gt; viewResolvers; private final ServerCodecConfigurer serverCodecConfigurer; public CustomErrorWebFluxAutoConfiguration(ServerProperties serverProperties, ResourceProperties resourceProperties, ObjectProvider&lt;ViewResolver&gt; viewResolversProvider, ServerCodecConfigurer serverCodecConfigurer, ApplicationContext applicationContext) &#123; this.serverProperties = serverProperties; this.applicationContext = applicationContext; this.resourceProperties = resourceProperties; this.viewResolvers = viewResolversProvider.orderedStream() .collect(Collectors.toList()); this.serverCodecConfigurer = serverCodecConfigurer; &#125; @Bean @ConditionalOnMissingBean(value = ErrorWebExceptionHandler.class, search = SearchStrategy.CURRENT) @Order(-1) public ErrorWebExceptionHandler errorWebExceptionHandler(ErrorAttributes errorAttributes) &#123; // TODO 这里完成自定义ErrorWebExceptionHandler实现逻辑 return null; &#125; @Bean @ConditionalOnMissingBean(value = ErrorAttributes.class, search = SearchStrategy.CURRENT) public DefaultErrorAttributes errorAttributes() &#123; return new DefaultErrorAttributes(this.serverProperties.getError().isIncludeException()); &#125;&#125; ErrorWebExceptionHandler的实现，可以直接参考DefaultErrorWebExceptionHandler，甚至直接继承DefaultErrorWebExceptionHandler，覆盖对应的方法即可。这里直接把异常信息封装成下面格式的Response返回，最后需要渲染成JSON格式： 123456&#123; \"code\": 200, \"message\": \"描述信息\", \"path\" : \"请求路径\", \"method\": \"请求方法\"&#125; 我们需要分析一下DefaultErrorWebExceptionHandler中的一些源码： 12345678910111213141516171819202122232425// 封装异常属性protected Map&lt;String, Object&gt; getErrorAttributes(ServerRequest request, boolean includeStackTrace) &#123; return this.errorAttributes.getErrorAttributes(request, includeStackTrace);&#125;// 渲染异常Responseprotected Mono&lt;ServerResponse&gt; renderErrorResponse(ServerRequest request) &#123; boolean includeStackTrace = isIncludeStackTrace(request, MediaType.ALL); Map&lt;String, Object&gt; error = getErrorAttributes(request, includeStackTrace); return ServerResponse.status(getHttpStatus(error)) .contentType(MediaType.APPLICATION_JSON_UTF8) .body(BodyInserters.fromObject(error));&#125;// 返回路由方法基于ServerResponse的对象@Overrideprotected RouterFunction&lt;ServerResponse&gt; getRoutingFunction(ErrorAttributes errorAttributes) &#123; return route(acceptsTextHtml(), this::renderErrorView).andRoute(all(), this::renderErrorResponse);&#125;// HTTP响应状态码的封装，原来是基于异常属性的status属性进行解析的protected HttpStatus getHttpStatus(Map&lt;String, Object&gt; errorAttributes) &#123; int statusCode = (int) errorAttributes.get(\"status\"); return HttpStatus.valueOf(statusCode);&#125; 确定三点： 最后封装到响应体的对象来源于DefaultErrorWebExceptionHandler#getErrorAttributes()，并且结果是一个Map&lt;String, Object&gt;实例转换成的字节序列。 原来的RouterFunction实现只支持HTML格式返回，我们需要修改为JSON格式返回(或者说支持所有格式返回)。 DefaultErrorWebExceptionHandler#getHttpStatus()是响应状态码的封装，原来的逻辑是基于异常属性getErrorAttributes()的status属性进行解析的。 自定义的JsonErrorWebExceptionHandler如下： 1234567891011121314151617181920212223242526272829303132public class JsonErrorWebExceptionHandler extends DefaultErrorWebExceptionHandler &#123; public JsonErrorWebExceptionHandler(ErrorAttributes errorAttributes, ResourceProperties resourceProperties, ErrorProperties errorProperties, ApplicationContext applicationContext) &#123; super(errorAttributes, resourceProperties, errorProperties, applicationContext); &#125; @Override protected Map&lt;String, Object&gt; getErrorAttributes(ServerRequest request, boolean includeStackTrace) &#123; // 这里其实可以根据异常类型进行定制化逻辑 Throwable error = super.getError(request); Map&lt;String, Object&gt; errorAttributes = new HashMap&lt;&gt;(8); errorAttributes.put(\"message\", error.getMessage()); errorAttributes.put(\"code\", HttpStatus.INTERNAL_SERVER_ERROR.value()); errorAttributes.put(\"method\", request.methodName()); errorAttributes.put(\"path\", request.path()); return errorAttributes; &#125; @Override protected RouterFunction&lt;ServerResponse&gt; getRoutingFunction(ErrorAttributes errorAttributes) &#123; return RouterFunctions.route(RequestPredicates.all(), this::renderErrorResponse); &#125; @Override protected HttpStatus getHttpStatus(Map&lt;String, Object&gt; errorAttributes) &#123; // 这里其实可以根据errorAttributes里面的属性定制HTTP响应码 return HttpStatus.INTERNAL_SERVER_ERROR; &#125;&#125; 配置类CustomErrorWebFluxAutoConfiguration添加JsonErrorWebExceptionHandler： 1234567891011121314@Bean@ConditionalOnMissingBean(value = ErrorWebExceptionHandler.class, search = SearchStrategy.CURRENT)@Order(-1)public ErrorWebExceptionHandler errorWebExceptionHandler(ErrorAttributes errorAttributes) &#123; JsonErrorWebExceptionHandler exceptionHandler = new JsonErrorWebExceptionHandler( errorAttributes, resourceProperties, this.serverProperties.getError(), applicationContext); exceptionHandler.setViewResolvers(this.viewResolvers); exceptionHandler.setMessageWriters(this.serverCodecConfigurer.getWriters()); exceptionHandler.setMessageReaders(this.serverCodecConfigurer.getReaders()); return exceptionHandler;&#125; 很简单，这里把异常的HTTP响应状态码统一为HttpStatus.INTERNAL_SERVER_ERROR(500)，改造的东西并不多，只要了解原来异常处理的上下文逻辑即可。 测试 测试场景一：只启动网关，下游服务不启动的情况下直接调用下游服务： 1234curl http://localhost:9090/order/host// 响应结果&#123;\"path\":\"/order/host\",\"code\":500,\"message\":\"Connection refused: no further information: localhost/127.0.0.1:9091\",\"method\":\"GET\"&#125; 测试场景二：下游服务正常启动和调用，网关自身抛出异常。 在网关应用自定义一个全局过滤器并且故意抛出异常： 123456789@Componentpublic class ErrorGlobalFilter implements GlobalFilter &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; int i = 1/0; return chain.filter(exchange); &#125;&#125; 1234curl http://localhost:9090/order/host// 响应结果&#123;\"path\":\"/order/host\",\"code\":500,\"message\":\"/ by zero\",\"method\":\"GET\"&#125; 响应结果和定制的逻辑一致，并且后台的日志也打印了对应的异常堆栈。 小结 笔者一直认为，做异常分类和按照分类处理是工程里面十分重要的一环。笔者在所在公司负责的系统中，坚持实现异常分类捕获，主要是需要区分可以重试补偿以及无法重试需要及时预警的异常，这样子才能针对可恢复异常定制自愈逻辑，对不能恢复的异常及时预警和人为介入。所以，Spring Cloud Gateway这个技术栈也必须调研其自定义异常的处理逻辑。 (本文完 c-1-d e-a-20190511)","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://throwable.club/blog/categories/Spring-Cloud/"},{"name":"Spring Cloud Gateway","slug":"Spring-Cloud/Spring-Cloud-Gateway","permalink":"http://throwable.club/blog/categories/Spring-Cloud/Spring-Cloud-Gateway/"}],"tags":[{"name":"Spring Cloud Gateway","slug":"Spring-Cloud-Gateway","permalink":"http://throwable.club/blog/tags/Spring-Cloud-Gateway/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://throwable.club/blog/tags/Spring-Cloud/"}]},{"title":"单链表中间节点搜索和快慢指针","slug":"java-algorithm-linked-list-fast-slow-pointer","date":"2019-05-09T16:41:47.000Z","updated":"2019-06-02T02:24:58.254Z","comments":true,"path":"2019/05/10/java-algorithm-linked-list-fast-slow-pointer/","link":"","permalink":"http://throwable.club/2019/05/10/java-algorithm-linked-list-fast-slow-pointer/","excerpt":"前提 今天中午吃饭的时候刷了下技术类型的公众号，看到有前辈过了Ant的高P面试，其中有一道题考查了单链表搜索位于中间的节点的算法。觉得解决方案很有趣，于是这里尝试重现一下。","text":"前提 今天中午吃饭的时候刷了下技术类型的公众号，看到有前辈过了Ant的高P面试，其中有一道题考查了单链表搜索位于中间的节点的算法。觉得解决方案很有趣，于是这里尝试重现一下。 场景 面试官：如何访问链表中间节点？ 大佬X：简单地实现，遍历一遍整个的链表，然后计算出链表的长度，进而遍历第二遍找出中间位置的数据。 面试官：要求只能遍历一次链表，那又当如何解决？ 大佬X：可以采取建立两个指针，一个指针一次遍历两个节点，另一个节点一次遍历一个节点，当快指针遍历到空节点时，慢指针指向的位置为链表的中间位置，这种解决问题的方法称为快慢指针方法。 复盘 我们先设定单链表的长度大于等于3，这样子比较容易分析算法。先简单假设一个长度为3的单链表如下： 如果我们要访问中间节点，最终搜索到的应该是n2节点，内容就是n2。 如果单链表的长度为偶数，这里假设为4，那么如下： 如果我们要访问中间节点，最终搜索到的应该是n2和n3节点，内容就是n2和n3。 先定义好节点类Node如下： 12345678910111213@Dataprivate static class Node&lt;T&gt;&#123; /** * 当前节点的值 */ private T value; /** * 下一个节点的引用 */ private Node&lt;T&gt; next;&#125; 我们可以很轻易地构建一个单链表如下： 123456789101112private static Node&lt;String&gt; buildLinkedList(int len) &#123; Node&lt;String&gt; head = new Node&lt;&gt;(); head.setValue(\"n1\"); Node&lt;String&gt; tail = head; for (int i = 1; i &lt; len; i++) &#123; Node&lt;String&gt; node = new Node&lt;&gt;(); node.setValue(\"n\" + (i + 1)); tail.setNext(node); tail = node; &#125; return head;&#125; 接着我们可以编写搜索中间节点的方法，先编写通过遍历链表进行长度计算，再遍历链表得到中间节点的方案一： 1234567891011121314151617181920212223242526272829303132333435private static List&lt;String&gt; searchByTraversal(Node&lt;String&gt; head) &#123; List&lt;String&gt; result = new ArrayList&lt;&gt;(2); Node&lt;String&gt; search = head; int len = 1; // 第一次遍历链表,计算链表长度 while (search.getNext() != null) &#123; search = search.getNext(); len++; &#125; int index = 0; int mid; search = head; // 链表长度为偶数 if ((len &amp; 1) == 0) &#123; mid = len / 2 - 1; while (search.getNext() != null) &#123; if (mid == index) &#123; result.add(search.getValue()); result.add(search.getNext().getValue()); &#125; search = search.getNext(); index++; &#125; &#125; else &#123; mid = (len - 1) / 2; while (search.getNext() != null) &#123; if (mid == index) &#123; result.add(search.getValue()); &#125; search = search.getNext(); index++; &#125; &#125; return result;&#125; 写个main方法试验一下： 12345678910public static void main(String[] args) throws Exception &#123; Node&lt;String&gt; head = buildLinkedList(11); System.out.println(searchByTraversal(head)); head = buildLinkedList(12); System.out.println(searchByTraversal(head));&#125;// 输出结果[n6][n6, n7] 假设链表的长度为n，那么进行两次遍历一共需要遍历的元素个素如下： 第一次遍历整个链表，计算长度，必须遍历n个元素。 第二次需要遍历n/2个元素(在n比较大的时候，其实加减的影响不大)。 这种方案实现，最终的时间复杂度一定会大于O(n)。所以需要考虑优化方案，只需要遍历一次链表就能定位到中间的节点值，这个就是方案二：使用快慢指针。 快慢指针，简单来说就是定义两个指针，在遍历链表的时候，快指针(fast pointer)总是遍历两个元素，而慢指针(slow pointer)总是遍历一个元素。当快指针遍历整个链表完成的时候，慢指针刚好指向链表的中间节点。算法实现如下： 1234567891011121314151617181920212223242526private static List&lt;String&gt; searchByFastSlowPointer(Node&lt;String&gt; head) &#123; List&lt;String&gt; result = new ArrayList&lt;&gt;(2); // fast pointer Node&lt;String&gt; fp = head; // slow pointer Node&lt;String&gt; sp = head; int len = 1; while (null != fp.getNext()) &#123; if (fp.getNext().getNext() != null) &#123; fp = fp.getNext().getNext(); sp = sp.getNext(); len += 2; &#125; else &#123; fp = fp.getNext(); len += 1; &#125; &#125; // 链表长度为偶数 if ((len &amp; 1) == 0) &#123; result.add(sp.getValue()); result.add(sp.getNext().getValue()); &#125; else &#123; result.add(sp.getValue()); &#125; return result;&#125; 写个main方法试验一下： 12345678910public static void main(String[] args) throws Exception &#123; Node&lt;String&gt; head = buildLinkedList(11); System.out.println(searchByFastSlowPointer(head)); head = buildLinkedList(12); System.out.println(searchByFastSlowPointer(head));&#125;// 输出结果[n6][n6, n7] 由于使用了快慢指针的方案，只做了一次链表的遍历，并且由于快指针是每次两个元素进行遍历，最终的时间复杂度要小于O(n)。 快慢指针的应用场景 快慢指针主要有如下的应用场景： 找到链表的中点。 判断链表中是否存在环。 删除链表中倒数第x个节点。 第一种情况已经作为复盘案例分析过，下面分析一下第二和第三种场景。 判断链表中是否存在环 假设链表有6个节点(head节点为n1，tail节点为n6)，已经形成环(n6的下一个节点为n1)： 使用快慢指针，快指针每次遍历会比慢指针多一个元素，这样子的话，如果链表已经成环，无论快指针和慢指针之间相隔多少个节点，快指针总是能够追上慢指针(快指针和慢指针指向同一个节点)，这个时候就可以判断链表已经成环；否则快指针进行一轮遍历之后就会跳出循环，永远不可能和慢指针“重合”。简陋的实现如下： 123456789101112131415161718192021222324252627282930// 判断链表是否存在环private static boolean cyclic(Node&lt;String&gt; head) &#123; // fast pointer Node&lt;String&gt; fp = head; // slow pointer Node&lt;String&gt; sp = head; while (fp.getNext() != null) &#123; fp = fp.getNext().getNext(); sp = sp.getNext(); if (sp.equals(fp)) &#123; return true; &#125; &#125; return false;&#125;// 生成环形链表private static Node&lt;String&gt; buildCyclicLinkedList(int len) &#123; Node&lt;String&gt; head = new Node&lt;&gt;(); head.setValue(\"n1\"); Node&lt;String&gt; tail = head; for (int i = 1; i &lt; len; i++) &#123; Node&lt;String&gt; node = new Node&lt;&gt;(); node.setValue(\"n\" + (i + 1)); tail.setNext(node); tail = node; &#125; tail.setNext(head); return head;&#125; 测试一下： 12345678910public static void main(String[] args) throws Exception &#123; Node&lt;String&gt; head = buildCyclicLinkedList(11); System.out.println(cyclic(head)); head = buildLinkedList(11); System.out.println(cyclic(head));&#125;// 输出结果truefalse 删除链表中倒数第N个节点 这个是LeetCode上的一道算法题，里面用到的是虚拟头结点加上快慢指针的方法，只进行一次遍历就能解决。这里引用获赞最多的回答里面的解决思路： 上述算法可以优化为只使用一次遍历。我们可以使用两个指针而不是一个指针。第一个指针从列表的开头向前移动n+1步，而第二个指针将从列表的开头出发。现在，这两个指针被n个结点分开。我们通过同时移动两个指针向前来保持这个恒定的间隔，直到第一个指针到达最后一个结点。此时第二个指针将指向从最后一个结点数起的第n个结点。我们重新链接第二个指针所引用的结点的next指针指向该结点的下下个结点。 算法推演图： 算法代码如下： 1234567891011121314151617public ListNode removeNthFromEnd(ListNode head, int n) &#123; ListNode dummy = new ListNode(0); dummy.next = head; ListNode first = dummy; ListNode second = dummy; // Advances first pointer so that the gap between first and second is n nodes apart for (int i = 1; i &lt;= n + 1; i++) &#123; first = first.next; &#125; // Move first to the end, maintaining the gap while (first != null) &#123; first = first.next; second = second.next; &#125; second.next = second.next.next; return dummy.next;&#125; 时间复杂度为O(L)，L为链表长度。 小结 鉴于算法比较弱，看到这些相对有实用价值的题目和解决方案，还是值得推演和学习一番。 参考资料： Leetcode，算法题目：Remove Nth Node From End of List (本文完 c-2-d e-a-20190510)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Algorithm","slug":"Java/Algorithm","permalink":"http://throwable.club/blog/categories/Java/Algorithm/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://throwable.club/blog/tags/Algorithm/"}]},{"title":"设计模式概念和七大原则","slug":"design-pattern-basic-law","date":"2019-05-05T14:53:45.000Z","updated":"2019-06-02T02:30:36.959Z","comments":true,"path":"2019/05/05/design-pattern-basic-law/","link":"","permalink":"http://throwable.club/2019/05/05/design-pattern-basic-law/","excerpt":"什么是设计模式 在GoF(Gang of Four)的书籍《Design Patterns - Elements of Reusable Object-Oriented Software(设计模式-可复用面向对象软件的基础)》中是这样定义设计模式的：Christopher Alexander说过：“每一个模式描述了一个在我们周围不断重复发生的问题以及该问题的解决方案的核心。这样，你就能一次又一次地使用该方案而不必做重复劳动” [AIS+77，第10页]。尽管Alexander所指的是城市和建筑模式，但他的思想也同样适用于面向对象设计模式，只是在面向对象的解决方案里， 我们用对象和接口代替了墙壁和门窗。两类模式的核心都在于提供了相关问题的解决方案。一般而言，设计模式有四个基本要素： 模式名称(pattern name)：一个助记名，它用一两个词来描述模式的问题、解决方案和效果。 问题(problem)：描述了应该在何时使用模式。 解决方案(solution)：描述了设计的组成成分，它们之间的相关关系以及各自的职责和协作方案。 效果(consequences)：描述了模式应用的效果以及使用模式应该权衡的问题。 设计模式的创始人很明确地指出了设计模式的基本要素，但是由于现实中浮躁、偏向过度设计等因素的干扰，开发者很多时候会重点关注第1和第3点要素(过度关注设计模式和设计模式的实现)，忽略第2和第4点要素(忽视使用设计模式的场景和目标)，导致设计出来的编码逻辑可能过于复杂或者达不到预期的效果。 总的来说，设计模式(Design Pattern)是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。也就是本来并不存在所谓设计模式，用的人多了，也便成了设计模式。","text":"什么是设计模式 在GoF(Gang of Four)的书籍《Design Patterns - Elements of Reusable Object-Oriented Software(设计模式-可复用面向对象软件的基础)》中是这样定义设计模式的：Christopher Alexander说过：“每一个模式描述了一个在我们周围不断重复发生的问题以及该问题的解决方案的核心。这样，你就能一次又一次地使用该方案而不必做重复劳动” [AIS+77，第10页]。尽管Alexander所指的是城市和建筑模式，但他的思想也同样适用于面向对象设计模式，只是在面向对象的解决方案里， 我们用对象和接口代替了墙壁和门窗。两类模式的核心都在于提供了相关问题的解决方案。一般而言，设计模式有四个基本要素： 模式名称(pattern name)：一个助记名，它用一两个词来描述模式的问题、解决方案和效果。 问题(problem)：描述了应该在何时使用模式。 解决方案(solution)：描述了设计的组成成分，它们之间的相关关系以及各自的职责和协作方案。 效果(consequences)：描述了模式应用的效果以及使用模式应该权衡的问题。 设计模式的创始人很明确地指出了设计模式的基本要素，但是由于现实中浮躁、偏向过度设计等因素的干扰，开发者很多时候会重点关注第1和第3点要素(过度关注设计模式和设计模式的实现)，忽略第2和第4点要素(忽视使用设计模式的场景和目标)，导致设计出来的编码逻辑可能过于复杂或者达不到预期的效果。 总的来说，设计模式(Design Pattern)是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。也就是本来并不存在所谓设计模式，用的人多了，也便成了设计模式。 设计模式的七大原则 面向对象的设计模式有七大基本原则： 开闭原则（Open Closed Principle，OCP） 单一职责原则（Single Responsibility Principle, SRP） 里氏代换原则（Liskov Substitution Principle，LSP） 依赖倒转原则（Dependency Inversion Principle，DIP） 接口隔离原则（Interface Segregation Principle，ISP） 合成/聚合复用原则（Composite/Aggregate Reuse Principle，CARP） 最少知识原则（Least Knowledge Principle，LKP）或者迪米特法则（Law of Demeter，LOD） 标记 设计模式原则名称 简单定义 OCP 开闭原则 对扩展开放，对修改关闭 SRP 单一职责原则 一个类只负责一个功能领域中的相应职责 LSP 里氏代换原则 所有引用基类的地方必须能透明地使用其子类的对象 DIP 依赖倒转原则 依赖于抽象，不能依赖于具体实现 ISP 接口隔离原则 类之间的依赖关系应该建立在最小的接口上 CARP 合成/聚合复用原则 尽量使用合成/聚合，而不是通过继承达到复用的目的 LOD 迪米特法则 一个软件实体应当尽可能少的与其他实体发生相互作用 其中，单一职责原则、开闭原则、迪米特法则、里氏代换原则和接口隔离原则就是我们平常熟知的SOLID。 这个表格看起来有点抽象，下面逐条分析。 开闭原则 开闭原则（Open Closed Principle，OCP）的定义是：一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。模块应尽量在不修改原（是&quot;原&quot;，指原来的代码）代码的情况下进行扩展。 开闭原则的意义 在软件的生命周期内，因为变化、升级和维护等原因需要对软件原有代码进行修改时，可能会给旧代码中引入错误，也可能会使我们不得不对整个功能进行重构，并且需要原有代码经过重新测试。当软件需要变化时，尽量通过扩展软件实体的行为来实现变化，而不是通过修改已有的代码来实现变化。 如何实现对扩展开放，对修改关闭 要实现对扩展开放，对修改关闭，即遵循开闭原则，需要对系统进行抽象化设计，抽象可以基于抽象类或者接口。一般来说需要做到几点： 通过接口或者抽象类约束扩展，对扩展进行边界限定，不允许出现在接口或抽象类中不存在的public方法，也就是扩展必须添加具体实现而不是改变具体的方法。 参数类型、引用对象尽量使用接口或者抽象类，而不是实现类，这样就能尽量保证抽象层是稳定的。 一般抽象模块设计完成(例如接口的方法已经敲定)，不允许修改接口或者抽象方法的定义。 下面通过一个例子遵循开闭原则进行设计，场景是这样：某系统的后台需要监测业务数据展示图表，如柱状图、折线图等，在未来需要支持图表的着色操作。在开始设计的时候，代码可能是这样的： 123456789101112131415161718192021222324public class BarChart &#123; public void draw()&#123; System.out.println(\"Draw bar chart...\"); &#125;&#125;public class LineChart &#123; public void draw()&#123; System.out.println(\"Draw line chart...\"); &#125;&#125;public class App &#123; public void drawChart(String type)&#123; if (type.equalsIgnoreCase(\"line\"))&#123; new LineChart().draw(); &#125;else if (type.equalsIgnoreCase(\"bar\"))&#123; new BarChart().draw(); &#125; &#125;&#125; 这样做在初期是能满足业务需要的，开发效率也十分高，但是当后面需要新增一个饼状图的时候，既要添加一个饼状图的类，原来的客户端App类的drawChart()方法也要新增一个else if分支，这样做就是修改了原有客户端类库的方法，是十分不合理的。如果这个时候，在图中加入一个颜色属性，复杂性也大大提高。基于此，需要引入一个抽象Chart类AbstractChart，App类在画图的时候总是把相关的操作委托到具体的AbstractChart的派生类实例，这样的话App类的代码就不用修改： 123456789101112131415161718192021222324252627public abstract class AbstractChart &#123; public abstract void draw();&#125;public class BarChart extends AbstractChart&#123; @Override public void draw() &#123; System.out.println(\"Draw bar chart...\"); &#125;&#125;public class LineChart extends AbstractChart &#123; @Override public void draw() &#123; System.out.println(\"Draw line chart...\"); &#125;&#125;public class App &#123; public void drawChart(AbstractChart chart)&#123; chart.draw(); &#125;&#125; 如果新加一种图，只需要新增一个AbstractChart的子类即可。客户端类App不需要改变原来的逻辑。修改后的设计符合开闭原则，因为整个系统在扩展时原有的代码没有做任何修改。 单一职责原则 单一职责原则（Single Responsibility Principle, SRP）的定义是：指一个类或者模块应该有且只有一个改变的原因。如果一个类承担的职责过多，就等于把这些职责耦合在一起了。一个职责的变化可能会削弱或者抑制这个类完成其他职责的能力。这种耦合会导致脆弱的设计，当发生变化时，设计会遭受到意想不到的破坏。而如果想要避免这种现象的发生，就要尽可能的遵守单一职责原则。此原则的核心就是解耦和增强内聚性。 单一职责原则的意义 单一职责原则告诉我们：一个类不能做太多的东西。在软件系统中，一个类(一个模块、或者一个方法)承担的职责越多，那么其被复用的可能性就会越低。一个很典型的例子就是万能类。其实可以说一句大实话：任何一个常规的MVC项目，在极端的情况下，可以用一个类(甚至一个方法)完成所有的功能。但是这样做就会严重耦合，甚至牵一发动全身。一个类承(一个模块、或者一个方法)担的职责过多，就相当于将这些职责耦合在一起，当其中一个职责变化时，可能会影响其他职责的运作，因此要将这些职责进行分离，将不同的职责封装在不同的类中，即将不同的变化原因封装在不同的类中，如果多个职责总是同时发生改变则可将它们封装在同一类中。 不过说实话，其实有的时候很难去衡量一个类的职责，主要是很难确定职责的粒度。这一点不仅仅体现在一个类或者一个模块中，也体现在采用微服务的分布式系统中。这也就是为什么我们在实施微服务拆分的时候经常会撕逼：&quot;这个功能不应该发在A服务中，它不做这个领域的东西，应该放在B服务中&quot;诸如此类的争论。存在争论是合理的，不过最好不要不了了之，而应该按照领域定义好每个服务的职责(职责的粒度最好找业务和架构专家咨询)，得出相对合理的职责分配。 下面通过一个很简单的实例说明一下单一职责原则： 在一个项目系统代码编写的时候，由于历史原因和人为的不规范，导致项目没有分层，一个Service类的伪代码是这样的： 123456789101112public class Service &#123; public UserDTO findUser(String name)&#123; Connection connection = getConnection(); PreparedStatement preparedStatement = connection.prepareStatement(\"SELECT * FROM t_user WHERE name = ?\"); preparedStatement.setObject(1, name); User user = //处理结果 UserDTO dto = new UserDTO(); //entity值拷贝到dto return dto; &#125;&#125; 这里出现一个问题，Service做了太多东西，包括数据库连接的管理，Sql的执行这些业务层不应该接触到的逻辑，更可怕的是，例如到时候如果数据库换成了Oracle，这个方法将会大改。因此，拆分出新的DataBaseUtils类用于专门管理数据库资源，Dao类用于专门执行查询和查询结果封装，改造后Service类的伪代码如下： 1234567891011121314151617181920212223public class Service &#123; private Dao dao; public UserDTO findUser(String name)&#123; User user = dao.findUserByName(name); UserDTO dto = new UserDTO(); //entity值拷贝到dto return dto; &#125;&#125;public class Dao&#123; public User findUserByName(String name)&#123; Connection connection = DataBaseUtils.getConnnection(); PreparedStatement preparedStatement = connection.prepareStatement(\"SELECT * FROM t_user WHERE name = ?\"); preparedStatement.setObject(1, name); User user = //处理结果 return user; &#125;&#125; 现在，如果有查询封装的变动只需要修改Dao类，数据库相关变动只需要修改DataBaseUtils类，每个类的职责分明。这个时候，如果我们要把底层的存储结构缓成Redis或者MongoDB怎么办，这样显然要重建整个Dao类，这种情况下，需要进行接口隔离，下面分析接口隔离原则的时候再详细分析。 里氏代换原则 里氏代换原则（Liskov Substitution Principle，LSP）的定义是：所有引用基类的地方必须能透明地使用其子类的对象，也可以简单理解为任何基类可以出现的地方，子类一定可以出现。 里氏代换原则的意义 只有当衍生类可以替换掉基类，软件单位的功能不受到影响时，基类才能真正被复用，而衍生类也能够在基类的基础上增加新的行为。里氏代换原则是对&quot;开-闭&quot;原则的补充。实现&quot;开-闭&quot;原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。当然，如果反过来，软件单位使用的是一个子类对象的话，那么它不一定能够使用基类对象。举个很简单的例子说明这个问题：如果一个方法接收Map类型参数，那么它一定可以接收Map的子类参数例如HashMap、LinkedHashMap、ConcurrentHashMap类型的参数；但是反过来，如果另一个方法只接收HashMap类型的参数，那么它一定不能接收所有Map类型的参数，否则它可以接收LinkedHashMap、ConcurrentHashMap类型的参数。 子类为什么可以替换基类的位置 其实原因很简单，只要存在继承关系，基类的所有非私有属性或者方法，子类都可以通过继承获得(白箱复用)，反过来不成立，因为子类很有可能扩充自身的非私有属性或者方法，这个时候不能用基类获取子类新增的这些属性或者方法。 里氏代换原则是实现开闭原则的基础，它告诉我们在设计程序的时候进可能使用基类进行对象的定义和引用，在运行时再决定基类的具体子类型。 举个简单的例子，假设一种会呼吸的动物作为父类，子类猪和鸟也有自身的呼吸方式： 123456789101112131415161718192021222324252627282930public abstract class Animal &#123; protected abstract void breathe();&#125;public class Bird extends Animal &#123; @Override public void breathe() &#123; System.out.println(\"Bird breathes...\"); &#125;&#125;public class Pig extends Animal &#123; @Override public void breathe() &#123; System.out.println(\"Pig breathes...\"); &#125;&#125;public class App &#123; public static void main(String[] args) throws Exception &#123; Animal bird = new Bird(); bird.breathe(); Animal pig = new Pig(); pig.breathe(); &#125;&#125; 依赖倒转原则 依赖倒转原则（Dependency Inversion Principle，DIP）的定义：程序要依赖于抽象接口，不要依赖于具体实现。简单的说就是要求对抽象进行编程，不要对实现进行编程，这样就降低了客户与实现模块间的耦合。 依赖倒转原则的意义 依赖倒转原则要求我们在程序代码中传递参数时或在关联关系中，尽量引用层次高的抽象层类，即使用接口和抽象类进行变量类型声明、参数类型声明、方法返回类型声明，以及数据类型的转换等，而不要用具体类来做这些事情。为了确保该原则的应用，一个具体类应当只实现接口或抽象类中声明过的方法，而不要给出多余的方法，否则将无法调用到在子类中增加的新方法。在引入抽象层后，系统将具有很好的灵活性，在程序中尽量使用抽象层进行编程，而将具体类写在配置文件中，这样一来，如果系统行为发生变化，只需要对抽象层进行扩展，并修改配置文件，而无须修改原有系统的源代码，在不修改的情况下来扩展系统的功能，满足开闭原则的要求。 依赖倒转原则的注意事项 高层模块不应该依赖低层模块，高层模块和低层模块都应该依赖于抽象。 抽象不应该依赖于具体，具体应该依赖于抽象。 在实现依赖倒转原则时，我们需要针对抽象层编程，而将具体类的对象通过依赖注入(DependencyInjection, DI)的方式注入到其他对象中，依赖注入是指当一个对象要与其他对象发生依赖关系时，通过抽象来注入所依赖的对象。常用的注入方式有三种，分别是：构造注入，设值注入（Setter注入）和接口注入。Spring的IOC是此实现的典范。 从Java角度看待依赖倒转原则的本质就是：面向接口(抽象)编程。 每个具体的类都应该有其接口或者基类，或者两者都具备。 类中的引用对象应该是接口或者基类。 任何具体类都不应该派生出子类。 尽量不要覆写基类中的方法。 结合里氏代换原则使用。 遵循依赖倒转原则的一个例子，场景是司机开车： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public interface Driver &#123; void drive(); void setCar(Car car);&#125;public interface Car &#123; void run();&#125;public class DefaultDriver implements Driver &#123; private Car car; @Override public void drive() &#123; car.run(); &#125; @Override public void setCar(Car car) &#123; this.car = car; &#125;&#125;public class Bmw implements Car &#123; @Override public void run() &#123; System.out.println(\"Bmw runs...\"); &#125;&#125;public class Benz implements Car &#123; @Override public void run() &#123; System.out.println(\"Benz runs...\"); &#125;&#125;public class App &#123; public static void main(String[] args) throws Exception &#123; Driver driver = new DefaultDriver(); Car car = new Benz(); driver.setCar(car); driver.drive(); car = new Bmw(); driver.setCar(car); driver.drive(); &#125;&#125; 这样实现了一个司机可以开各种类型的车，如果还有其他类型的车，只需要新加一个Car的实现即可。 接口隔离原则 接口隔离原则（Interface Segregation Principle，ISP）的定义是客户端不应该依赖它不需要的接口，类间的依赖关系应该建立在最小的接口上。简单来说就是建立单一的接口，不要建立臃肿庞大的接口。也就是接口尽量细化，同时接口中的方法尽量少。 如何看待接口隔离原则和单一职责原则 单一职责原则注重的是类和接口的职责单一，这里职责是从业务逻辑上划分的，但是在接口隔离原则要求当一个接口太大时，我们需要将它分割成一些更细小的接口，使用该接口的客户端仅需知道与之相关的方法即可。也就是说，我们在设计接口的时候有可能满足单一职责原则但是不满足接口隔离原则。 接口隔离原则的规范 使用接口隔离原则前首先需要满足单一职责原则。 接口需要高内聚，也就是提高接口、类、模块的处理能力，少对外发布public的方法。 定制服务，只提供访问者需要的方法。 接口设计是有限度的，接口的设计粒度越小，系统越灵活，但是值得注意不能过小，否则变成&quot;字节码编程&quot;。 如果有用过spring-data-redis的人就知道，RedisTemplate中持有一些列的基类，分别是ValueOperations(处理K-V)、ListOperations(处理Hash)、SetOperations(处理集合)等等。 123456public interface ValueOperations&lt;K, V&gt; &#123; void set(K key, V value); void set(K key, V value, long timeout, TimeUnit unit); //....&#125; 合成/聚合复用原则 合成/聚合复用原则（Composite/Aggregate Reuse Principle，CARP）一般也叫合成复用原则(Composite Reuse Principle, CRP)，定义是：尽量使用合成/聚合，而不是通过继承达到复用的目的。 合成/聚合复用原则就是在一个新的对象里面使用一些已有的对象，使之成为新对象的一部分；新的对象通过向内部持有的这些对象的委派达到复用已有功能的目的，而不是通过继承来获得已有的功能。 聚合(Aggregate)的概念 聚合表示一种弱的&quot;拥有&quot;关系，一般表现为松散的整体和部分的关系，其实，所谓整体和部分也可以是完全不相关的。例如A对象持有B对象，B对象并不是A对象的一部分，也就是B对象的生命周期是B对象自身管理，和A对象不相关。 合成(Composite)的概念 合成表示一种强的&quot;拥有&quot;关系，一般表现为严格的整体和部分的关系，部分和整体的生命周期是一样的。 聚合和合成的关系 这里用山羊举例说明聚合和合成的关系： 为什么要用合成/聚合来替代继承达到复用的目的 继承复用破坏包装，因为继承将基类的实现细节暴露给派生类，基类的内部细节通常对子类来说是可见的，这种复用也称为&quot;白箱复用&quot;。这里有一个明显的问题是：派生类继承自基类，如果基类的实现发生改变，将会影响到所有派生类的实现；如果从基类继承而来的实现是静态的，不可能在运行时发生改变，不够灵活。 由于合成或聚合关系可以将已有的对象，一般叫成员对象，纳入到新对象中，使之成为新对象的一部分，因此新对象可以调用已有对象的功能，这样做可以使得成员对象的内部实现细节对于新对象不可见，所以这种复用又称为&quot;黑箱&quot;复用，相对继承关系而言，其耦合度相对较低，成员对象的变化对新对象的影响不大，可以在新对象中根据实际需要有选择性地调用成员对象的操作；合成/聚合复用可以在运行时动态进行，新对象可以动态地引用与成员对象类型相同的其他对象。 如果有阅读过《Effective Java 2nd》的同学就知道，此书也建议慎用继承。一般情况下，只有明确知道派生类和基类满IS A的时候才选用继承，当满足HAS A或者不能判断的情况下应该选用合成/聚合。 下面举个很极端的例子说明一下如果在非IS A的情况下使用继承会出现什么问题： 先定义一个抽象手，手有一个摇摆的方法，然后定义左右手继承抽象手，实现摇摆方法： 1234567891011121314151617181920public abstract class AbstractHand &#123; protected abstract void swing();&#125;public class LeftHand extends AbstractHand &#123; @Override public void swing() &#123; System.out.println(\"Left hand swings...\"); &#125;&#125;public class RightHand extends AbstractHand &#123; @Override public void swing() &#123; System.out.println(\"Right hand swings...\"); &#125;&#125; 现在看起来没有任何问题，实现也十分正确，现在出现了人(Person)这个类，具备摇左右手的功能，如果不考虑IS A的关系，很有可能有人会这样做： 1234567891011121314151617181920public abstract class AbstractSwingHand extends AbstractHand&#123; @Override protected void swing() &#123; System.out.println(\" hand swings...\"); &#125;&#125;public class Person extends AbstractSwingHand &#123; public void swingLeftHand()&#123; System.out.print(\"Left \"); super.swing(); &#125; public void swingRightHand()&#123; System.out.print(\"Right \"); super.swing(); &#125;&#125; 上面Person的实现让人觉得百思不得其解，但是往往这会出现在真实的环境中，因为Hand不是Person，所以Person继承Hand一定会出现曲线实现等奇葩逻辑。Hand和Person是严格的部分和整体的关系，或者说Person和Hand是HAS A的关系，如果使用合成，逻辑将会十分清晰： 123456789101112131415161718public class Person &#123; private AbstractHand leftHand; private AbstractHand rightHand; public Person() &#123; leftHand = new LeftHand(); rightHand = new RightHand(); &#125; public void swingLeftHand()&#123; leftHand.swing(); &#125; public void swingRightHand()&#123; rightHand.swing(); &#125;&#125; 这里使用了合成，说明了Person和AbstractHand实例的生命周期是一致的。 迪米特法则 迪米特法则（Law of Demeter，LOD），有时候也叫做最少知识原则（Least Knowledge Principle，LKP），它的定义是：一个软件实体应当尽可能少地与其他实体发生相互作用。每一个软件单位对其他的单位都只有最少的知识，而且局限于那些与本单位密切相关的软件单位。迪米特法则的初衷在于降低类之间的耦合。由于每个类尽量减少对其他类的依赖，因此，很容易使得系统的功能模块功能独立，相互之间不存在（或很少有）依赖关系。迪米特法则不希望类之间建立直接的联系。如果真的有需要建立联系，也希望能通过它的友元类（中间类或者跳转类）来转达。 迪米特法则的规则 Only talk to your immediate friends(只与直接的朋友通讯)，一个对象的&quot;朋友&quot;包括他本身(this)、它持有的成员对象、入参对象、它所创建的对象。 尽量少发布public的变量和方法，一旦公开的属性和方法越多，修改的时候影响的范围越大。 “是自己的就是自己的”，如果一个方法放在本类中，既不产生新的类间依赖，也不造成负面的影响，那么次方法就应该放在本类中。 迪米特法则的意义 迪米特法则的核心观念就是类间解耦，也就降低类之间的耦合，只有类处于弱耦合状态，类的复用率才会提高。所谓降低类间耦合，实际上就是尽量减少对象之间的交互，如果两个对象之间不必彼此直接通信，那么这两个对象就不应当发生任何直接的相互作用，如果其中的一个对象需要调用另一个对象的某一个方法的话，可以通过第三者转发这个调用。简言之，就是通过引入一个合理的第三者来降低现有对象之间的耦合度。但是这样会引发一个问题，有可能产生大量的中间类或者跳转类，导致系统的复杂性提高，可维护性降低。如果一味追求极度解耦，那么最终有可能变成面向字节码编程甚至是面向二进制的0和1编程。 举个很简单的例子，体育老师要知道班里面女生的人数，他委托体育课代表点清女生的人数： 1234567891011121314151617181920212223242526272829303132public class Girl &#123; &#125;public class GroupLeader &#123; private final List&lt;Girl&gt; girls; public GroupLeader(List&lt;Girl&gt; girls) &#123; this.girls = girls; &#125; public void countGirls() &#123; System.out.println(\"The sum of girls is \" + girls.size()); &#125;&#125;public class Teacher &#123; public void command(GroupLeader leader)&#123; leader.countGirls(); &#125;&#125;public class App &#123; public static void main(String[] args) throws Exception &#123; Teacher teacher = new Teacher(); GroupLeader groupLeader = new GroupLeader(Arrays.asList(new Girl(), new Girl())); teacher.command(groupLeader); &#125;&#125; 这个例子中，体育课代表就是中间类，体育课代表对于体育老师来说就是&quot;直接的朋友&quot;，如果去掉体育课代表这个中间类，体育老师必须亲自清点女生的人数(实际上就数人数这个功能，体育老师是不必要获取所有女生的对象列表)，这样做会违反迪米特法则。 小结 说实话，设计模式的七大原则理解是比较困难的，我们在设计模式的学习和应用中经常会听到或者看到&quot;XXX模式符合XXX原则&quot;、&quot;YYY模式不符合YYY原则&quot;这样的语句。因此，为了分析设计模式的合理性和完善我们日常的编码，掌握和理解这七大原则是十分必要的。 参考 《Java设计模式》 《设计模式之禅-2nd》 《设计模式-可复用面向对象软件的基础》 (本文完 c-2-d r-a-20190505)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Design Pattern","slug":"Java/Design-Pattern","permalink":"http://throwable.club/blog/categories/Java/Design-Pattern/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Design Pattern","slug":"Design-Pattern","permalink":"http://throwable.club/blog/tags/Design-Pattern/"}]},{"title":"Spring Cloud Gateway-自定义GatewayFilter","slug":"spring-cloud-gateway-custom-gateway-filter","date":"2019-05-05T11:13:49.000Z","updated":"2019-06-11T15:21:52.913Z","comments":true,"path":"2019/05/05/spring-cloud-gateway-custom-gateway-filter/","link":"","permalink":"http://throwable.club/2019/05/05/spring-cloud-gateway-custom-gateway-filter/","excerpt":"前提 GatewayFilter的作用域是指定的路由配置，路由配置选项里面需要通过filters指定想要使用的GatewayFilter列表。我们可以通过自定义GatewayFilter，做额外的扩展，实现一些内建GatewayFilter不存在的功能，并且应用到我们的路由配置中。","text":"前提 GatewayFilter的作用域是指定的路由配置，路由配置选项里面需要通过filters指定想要使用的GatewayFilter列表。我们可以通过自定义GatewayFilter，做额外的扩展，实现一些内建GatewayFilter不存在的功能，并且应用到我们的路由配置中。 如何自定义GatewayFilter 需要定制GatewayFilter，则需要实现org.springframework.cloud.gateway.filter.factory.GatewayFilterFactory接口，GatewayFilterFactory的定义如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455@FunctionalInterfacepublic interface GatewayFilterFactory&lt;C&gt; extends ShortcutConfigurable, Configurable&lt;C&gt; &#123; String NAME_KEY = \"name\"; String VALUE_KEY = \"value\"; default GatewayFilter apply(Consumer&lt;C&gt; consumer) &#123; C config = newConfig(); consumer.accept(config); return apply(config); &#125; default Class&lt;C&gt; getConfigClass() &#123; throw new UnsupportedOperationException(\"getConfigClass() not implemented\"); &#125; @Override default C newConfig() &#123; throw new UnsupportedOperationException(\"newConfig() not implemented\"); &#125; GatewayFilter apply(C config); default String name() &#123; return NameUtils.normalizeFilterFactoryName(getClass()); &#125; @Deprecated default ServerHttpRequest.Builder mutate(ServerHttpRequest request) &#123; return request.mutate(); &#125;&#125; public interface ShortcutConfigurable &#123; default ShortcutType shortcutType() &#123; return ShortcutType.DEFAULT; &#125; default List&lt;String&gt; shortcutFieldOrder() &#123; return Collections.emptyList(); &#125; default String shortcutFieldPrefix() &#123; return \"\"; &#125; &#125;public interface Configurable&lt;C&gt; &#123; Class&lt;C&gt; getConfigClass(); C newConfig();&#125; 看起来挺复杂的，但是实际上很多都是接口的默认方法，实际上要实现的方法很少。 另一种方式是继承org.springframework.cloud.gateway.filter.factory.AbstractGatewayFilterFactory，看抽象类AbstractGatewayFilterFactory的定义： 12345678910111213141516171819202122232425public abstract class AbstractGatewayFilterFactory&lt;C&gt; extends AbstractConfigurable&lt;C&gt; implements GatewayFilterFactory&lt;C&gt; &#123; @SuppressWarnings(\"unchecked\") public AbstractGatewayFilterFactory() &#123; super((Class&lt;C&gt;) Object.class); &#125; public AbstractGatewayFilterFactory(Class&lt;C&gt; configClass) &#123; super(configClass); &#125; public static class NameConfig &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125;&#125; 泛型参数C是配置类，从现有的AbstractGatewayFilterFactory或者GatewayFilterFactory的子类实现来看，配置类一般定义为公有静态内部类。 实现GatewayFilterFactory接口或者继承AbstractGatewayFilterFactory。 对应的子类注册到Spring的容器。 路由配置中的filters属性添加对应GatewayFilter配置，注意一下，过滤器名称由GatewayFilterFactory#name()决定。 实践 下面实现GatewayFilterFactory接口和继承AbstractGatewayFilterFactory抽象类两种方式都做了尝试。 实现GatewayFilterFactory接口 实现GatewayFilterFactory接口的时候，参考了SetRequestHeaderGatewayFilterFactory，为每个请求添加自定义的请求头。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Componentpublic class CustomAddRequestHeaderGatewayFilterFactory implements GatewayFilterFactory&lt;CustomAddRequestHeaderGatewayFilterFactory.CustomAddRequestHeaderConfig&gt; &#123; private final Class&lt;CustomAddRequestHeaderConfig&gt; configClass = CustomAddRequestHeaderConfig.class; @Override public List&lt;String&gt; shortcutFieldOrder() &#123; return new ArrayList&lt;&gt;(Arrays.asList(\"headerName\", \"headerValue\")); &#125; @Override public GatewayFilter apply(CustomAddRequestHeaderConfig config) &#123; return ((exchange, chain) -&gt; &#123; ServerHttpRequest request = exchange.getRequest().mutate().headers(httpHeaders -&gt; &#123; httpHeaders.set(config.getHeaderName(), config.getHeaderValue()); &#125;).build(); return chain.filter(exchange.mutate().request(request).build()); &#125;); &#125; @Override public Class&lt;CustomAddRequestHeaderConfig&gt; getConfigClass() &#123; return configClass; &#125; @Override public CustomAddRequestHeaderConfig newConfig() &#123; return BeanUtils.instantiateClass(this.configClass); &#125; public static class CustomAddRequestHeaderConfig &#123; private String headerName; private String headerValue; public String getHeaderName() &#123; return headerName; &#125; public void setHeaderName(String headerName) &#123; this.headerName = headerName; &#125; public String getHeaderValue() &#123; return headerValue; &#125; public void setHeaderValue(String headerValue) &#123; this.headerValue = headerValue; &#125; &#125;&#125; 可以看到，其实最核心的功能操作是需要实现GatewayFilter apply(C config)方法，编写自定义的功能。注意这段Lambda表达式的逻辑： 123456return ((exchange, chain) -&gt; &#123; ServerHttpRequest request = exchange.getRequest().mutate().headers(httpHeaders -&gt; &#123; httpHeaders.set(config.getHeaderName(), config.getHeaderValue()); &#125;).build(); return chain.filter(exchange.mutate().request(request).build());&#125;); 其实，它可以简单理解为GatewayFilter接口的匿名实现。 application.yaml配置如下： 12345678910spring: cloud: gateway: routes: - id: custom_add_request_header_route uri: http://localhost:9091 predicates: - Host=localhost:9090 filters: - CustomAddRequestHeader=customHeaderName,customHeaderValue 为了配合测试，下游服务添加一个端点： 1234@GetMapping(value = \"/customAddRequestHeader\")public ResponseEntity&lt;String&gt; customAddRequestHeader(@RequestHeader(name = \"customHeaderName\") String value) &#123; return ResponseEntity.ok(value);&#125; 1234curl localhost:9090/order/customAddRequestHeader// 响应customHeaderValue 继承AbstractGatewayFilterFactory抽象类 继承AbstractGatewayFilterFactory的方式其实差不多，我们尝试做一个相对复杂的改造：对每一个请求成功(状态码为200)的响应，添加一个自定义的cookie和一个响应头。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Componentpublic class CustomResponseGatewayFilterFactory extends AbstractGatewayFilterFactory&lt;CustomResponseGatewayFilterFactory.Config&gt; &#123; public CustomResponseGatewayFilterFactory() &#123; super(Config.class); &#125; @Override public GatewayFilter apply(Config config) &#123; return ((exchange, chain) -&gt; &#123; ServerHttpResponse response = exchange.getResponse(); if (HttpStatus.OK.equals(response.getStatusCode())) &#123; for (Map.Entry&lt;String, String&gt; entry : toMap(config.getCookie()).entrySet()) &#123; response.addCookie(ResponseCookie.from(entry.getKey(), entry.getValue()).build()); &#125; for (Map.Entry&lt;String, String&gt; entry : toMap(config.getHeader()).entrySet()) &#123; response.getHeaders().add(entry.getKey(), entry.getValue()); &#125; return chain.filter(exchange.mutate().response(response).build()); &#125; else &#123; return chain.filter(exchange); &#125; &#125;); &#125; @Override public List&lt;String&gt; shortcutFieldOrder() &#123; return Collections.singletonList(NAME_KEY); &#125; private static Map&lt;String, String&gt; toMap(String value) &#123; String[] split = value.split(\"=\"); Map&lt;String, String&gt; map = new HashMap&lt;&gt;(8); map.put(split[0], split[1]); return map; &#125; public static class Config &#123; private String cookie; private String header; public String getCookie() &#123; return cookie; &#125; public void setCookie(String cookie) &#123; this.cookie = cookie; &#125; public String getHeader() &#123; return header; &#125; public void setHeader(String header) &#123; this.header = header; &#125; &#125;&#125; application.yaml配置文件如下： 12345678910111213spring: cloud: gateway: routes: - id: custom_response_route uri: http://localhost:9091 predicates: - Host=localhost:9090 filters: - name: CustomResponse args: cookie: customCookieName=customCookieValue header: customHeaderName=customHeaderValue 这里注意，filters集合下的name属性是必须的，指向AbstractGatewayFilterFactory实现类的name()方法，args属性是用于指定装配到Config类的属性。 12345678curl localhost:9090/order/remote// 响应头如下customHeaderName: customHeaderValueContent-Type: text/plain;charset=UTF-8Content-Length: 6Date: Sun, 05 May 2019 11:06:35 GMTset-cookie: customCookieName=customCookieValue 小结 自定义GatewayFilter允许我们很灵活地扩展过滤器，并且对于请求或者响应添加自定义的一些属性或者判断逻辑。GatewayFilter不是全局生效的特性，使得我们在编写路由配置的时候可以灵活组合多个已经编写好的GatewayFilter实例的功能。 (c-1-d e-a-20190505)","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://throwable.club/blog/categories/Spring-Cloud/"},{"name":"Spring Cloud Gateway","slug":"Spring-Cloud/Spring-Cloud-Gateway","permalink":"http://throwable.club/blog/categories/Spring-Cloud/Spring-Cloud-Gateway/"}],"tags":[{"name":"Spring Cloud Gateway","slug":"Spring-Cloud-Gateway","permalink":"http://throwable.club/blog/tags/Spring-Cloud-Gateway/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://throwable.club/blog/tags/Spring-Cloud/"}]},{"title":"Spring Cloud Gateway-自定义GlobalFilter","slug":"spring-cloud-gateway-custom-global-filter","date":"2019-05-05T06:43:14.000Z","updated":"2019-06-11T15:21:34.191Z","comments":true,"path":"2019/05/05/spring-cloud-gateway-custom-global-filter/","link":"","permalink":"http://throwable.club/2019/05/05/spring-cloud-gateway-custom-global-filter/","excerpt":"前提 GlobalFilter的作用域是所有的路由配置，我们可以通过自定义GlobalFilter，做额外的扩展，用来实现一些全局的功能。","text":"前提 GlobalFilter的作用域是所有的路由配置，我们可以通过自定义GlobalFilter，做额外的扩展，用来实现一些全局的功能。 如何自定义GlobalFilter org.springframework.cloud.gateway.filter.GlobalFilter的接口定义如下： 1234public interface GlobalFilter &#123; Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain);&#125; 我们只需要实现org.springframework.cloud.gateway.filter.GlobalFilter接口，并且把实现类注册到Spring的容器中即可，官方例子如下： 1234567891011121314151617181920212223242526272829303132@Bean@Order(-1)public GlobalFilter a() &#123; return (exchange, chain) -&gt; &#123; log.info(\"first pre filter\"); return chain.filter(exchange).then(Mono.fromRunnable(() -&gt; &#123; log.info(\"third post filter\"); &#125;)); &#125;;&#125;@Bean@Order(0)public GlobalFilter b() &#123; return (exchange, chain) -&gt; &#123; log.info(\"second pre filter\"); return chain.filter(exchange).then(Mono.fromRunnable(() -&gt; &#123; log.info(\"second post filter\"); &#125;)); &#125;;&#125;@Bean@Order(1)public GlobalFilter c() &#123; return (exchange, chain) -&gt; &#123; log.info(\"third pre filter\"); return chain.filter(exchange).then(Mono.fromRunnable(() -&gt; &#123; log.info(\"first post filter\"); &#125;)); &#125;;&#125; 实践 我们通过自定义实现一个GlobalFilter，实现类似Nginx的Access Log的功能，也就是对每一个请求都记录请求的一些核心参数和响应的一些核心参数。注意的是，我们实现的这个GlobalFilter是pre类型同时是post类型。 12345678910111213141516@Slf4j@Componentpublic class AccessLogGlobalFilter implements GlobalFilter &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; ServerHttpRequest request = exchange.getRequest(); String path = request.getPath().pathWithinApplication().value(); InetSocketAddress remoteAddress = request.getRemoteAddress(); return chain.filter(exchange).then(Mono.fromRunnable(() -&gt; &#123; ServerHttpResponse response = exchange.getResponse(); HttpStatus statusCode = response.getStatusCode(); log.info(\"请求路径:&#123;&#125;,远程IP地址:&#123;&#125;,响应码:&#123;&#125;\", path, remoteAddress, statusCode); &#125;)); &#125;&#125; 上面的例子中，我们只打印了： 请求的路径。 请求的远程IP地址。 响应码。 1curl http://localhost:9090/order/remote 日志输出如下： 12019-05-04 19:13:19.101 INFO 25388 --- [ctor-http-nio-7] c.t.route.support.AccessLogGlobalFilter : 请求路径:/order/remote,远程IP地址:/0:0:0:0:0:0:0:1:63861,响应码:200 OK 这样显然不够详细，我们接着尝试添加下面的参数： 如果是GET请求，则提取它的Query参数，如果是POST请求，则尝试读取RequestBody的参数，打印请求的参数。 请求方法。 目标URI。 修改代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Slf4j@Componentpublic class AccessLogGlobalFilter implements GlobalFilter &#123; private final ObjectMapper mapper = new ObjectMapper(); private final DataBufferFactory dataBufferFactory = new NettyDataBufferFactory(ByteBufAllocator.DEFAULT); @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; ServerHttpRequest request = exchange.getRequest(); String path = request.getPath().pathWithinApplication().value(); HttpMethod method = request.getMethod(); StringBuilder builder = new StringBuilder(); URI targetUri = exchange.getAttribute(ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR); if (HttpMethod.GET.equals(method)) &#123; MultiValueMap&lt;String, String&gt; queryParams = request.getQueryParams(); try &#123; builder.append(mapper.writeValueAsString(queryParams)); &#125; catch (JsonProcessingException e) &#123; log.error(e.getMessage(), e); &#125; &#125; else if (HttpMethod.POST.equals(method)) &#123; Flux&lt;DataBuffer&gt; body = request.getBody(); ServerHttpRequest serverHttpRequest = request.mutate().uri(request.getURI()).build(); body.subscribe(dataBuffer -&gt; &#123; InputStream inputStream = dataBuffer.asInputStream(); try &#123; builder.append(StreamUtils.copyToString(inputStream, StandardCharsets.UTF_8)); &#125; catch (IOException e) &#123; log.error(e.getMessage(), e); &#125; &#125;); // 重写请求体,因为请求体数据只能被消费一次 request = new ServerHttpRequestDecorator(serverHttpRequest) &#123; @Override public Flux&lt;DataBuffer&gt; getBody() &#123; return Flux.just(dataBufferFactory.wrap(builder.toString().getBytes(StandardCharsets.UTF_8))); &#125; &#125;; &#125; InetSocketAddress remoteAddress = request.getRemoteAddress(); return chain.filter(exchange.mutate().request(request).build()).then(Mono.fromRunnable(() -&gt; &#123; ServerHttpResponse response = exchange.getResponse(); HttpStatus statusCode = response.getStatusCode(); log.info(\"请求路径:&#123;&#125;,远程IP地址:&#123;&#125;,请求方法:&#123;&#125;,请求参数:&#123;&#125;,目标URI:&#123;&#125;,响应码:&#123;&#125;\", path, remoteAddress, method, builder.toString(), targetUri, statusCode); &#125;)); &#125;&#125; 1curl -X POST -d \"name=doge\" localhost:9090/order/remote 由于下游服务只接受GET方法请求，网关打印日志如下： 1请求路径:/order/remote,远程IP地址:/0:0:0:0:0:0:0:1:65158,请求方法:POST,请求参数:name=doge,目标URI:http://localhost:9091/order/remote,响应码:405 METHOD_NOT_ALLOWED 小结 其实，GlobalFilter既然会对所有的路由配置都生效，我们扩展它实现的功能是一般全局的功能。上面的例子中涉及到重新装饰请求对象，解析请求参数的操作会有一定的性能损耗，具体要看实际的应用场景。 (c-1-d e-a-20190505)","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://throwable.club/blog/categories/Spring-Cloud/"},{"name":"Spring Cloud Gateway","slug":"Spring-Cloud/Spring-Cloud-Gateway","permalink":"http://throwable.club/blog/categories/Spring-Cloud/Spring-Cloud-Gateway/"}],"tags":[{"name":"Spring Cloud Gateway","slug":"Spring-Cloud-Gateway","permalink":"http://throwable.club/blog/tags/Spring-Cloud-Gateway/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://throwable.club/blog/tags/Spring-Cloud/"}]},{"title":"Spring Cloud Gateway入坑记","slug":"spring-cloud-gateway-guide","date":"2019-05-03T10:41:44.000Z","updated":"2019-06-11T15:21:05.025Z","comments":true,"path":"2019/05/03/spring-cloud-gateway-guide/","link":"","permalink":"http://throwable.club/2019/05/03/spring-cloud-gateway-guide/","excerpt":"前提 最近在做老系统的重构，重构完成后新系统中需要引入一个网关服务，作为新系统和老系统接口的适配和代理。之前，很多网关应用使用的是Spring-Cloud-Netfilx基于Zuul1.x版本实现的那套方案，但是鉴于Zuul1.x已经停止迭代，它使用的是比较传统的阻塞(B)IO + 多线程的实现方案，其实性能不太好。后来Spring团队干脆自己重新研发了一套网关组件，这个就是本次要调研的Spring-Cloud-Gateway。 简介 Spring Cloud Gateway依赖于Spring Boot 2.0, Spring WebFlux,和Project Reactor。许多熟悉的同步类库(例如Spring-Data和Spring-Security)和同步编程模式在Spring Cloud Gateway中并不适用，所以最好先阅读一下上面提到的三个框架的文档。 Spring Cloud Gateway依赖于Spring Boot和Spring WebFlux提供的基于Netty的运行时环境，它并非构建为一个WAR包或者运行在传统的Servlet容器中。","text":"前提 最近在做老系统的重构，重构完成后新系统中需要引入一个网关服务，作为新系统和老系统接口的适配和代理。之前，很多网关应用使用的是Spring-Cloud-Netfilx基于Zuul1.x版本实现的那套方案，但是鉴于Zuul1.x已经停止迭代，它使用的是比较传统的阻塞(B)IO + 多线程的实现方案，其实性能不太好。后来Spring团队干脆自己重新研发了一套网关组件，这个就是本次要调研的Spring-Cloud-Gateway。 简介 Spring Cloud Gateway依赖于Spring Boot 2.0, Spring WebFlux,和Project Reactor。许多熟悉的同步类库(例如Spring-Data和Spring-Security)和同步编程模式在Spring Cloud Gateway中并不适用，所以最好先阅读一下上面提到的三个框架的文档。 Spring Cloud Gateway依赖于Spring Boot和Spring WebFlux提供的基于Netty的运行时环境，它并非构建为一个WAR包或者运行在传统的Servlet容器中。 专有名词 路由(Route)：路由是网关的基本组件。它由ID，目标URI，谓词(Predicate)集合和过滤器集合定义。如果谓词聚合判断为真，则匹配路由。 谓词(Predicate)：使用的是Java8中基于函数式编程引入的java.util.Predicate。使用谓词(聚合)判断的时候，输入的参数是ServerWebExchange类型，它允许开发者匹配来自HTTP请求的任意参数，例如HTTP请求头、HTTP请求参数等等。 过滤器(Filter)：使用的是指定的GatewayFilter工厂所创建出来的GatewayFilter实例，可以在发送请求到下游之前或者之后修改请求(参数)或者响应(参数)。 其实Filter还包括了GlobalFilter，不过在官方文档中没有提到。 工作原理 客户端向Spring Cloud Gateway发出请求，如果Gateway Handler Mapping模块处理当前请求如果匹配到一个目标路由配置，该请求就会转发到Gateway Web Handler模块。Gateway Web Handler模块在发送请求的时候，会把该请求通过一个匹配于该请求的过滤器链。上图中过滤器被虚线分隔的原因是：过滤器的处理逻辑可以在代理请求发送之前或者之后执行。所有pre类型的过滤器执行之后，代理请求才会创建(和发送)，当代理请求创建(和发送)完成之后，所有的post类型的过滤器才会执行。 见上图，外部请求进来后如果落入过滤器链，那么虚线左边的就是pre类型的过滤器，请求先经过pre类型的过滤器，再发送到目标被代理的服务。目标被代理的服务响应请求，响应会再次经过滤器链，也就是走虚线右侧的过滤器链，这些过滤器就是post类型的过滤器。 注意，如果在路由配置中没有明确指定对应的路由端口，那么会使用如下的默认端口： HTTP协议，使用80端口。 HTTPS协议，使用443端口。 引入依赖 建议直接通过Train版本(其实笔者考究过，Train版本的代号其实是伦敦地铁站的命名，像当前的Spring Cloud最新版本是Greenwich.SR1，Greenwich可以在伦敦地铁站的地图查到这个站点，对应的SpringBoot版本是2.1.x)引入Spring-Cloud-Gateway，因为这样可以跟上最新稳定版本的Spring-Cloud版本，另外由于Spring-Cloud-Gateway基于Netty的运行时环境启动，不需要引入带Servlet容器的spring-boot-starter-web。 父POM引入下面的配置： 123456789101112131415161718&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Greenwich.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 子模块或者需要引入Spring-Cloud-Gateway的模块POM引入下面的配置： 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 创建一个启动类即可： 1234567@SpringBootApplicationpublic class RouteServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RouteServerApplication.class, args); &#125;&#125; 网关配置 网关配置最终需要转化为一个RouteDefinition的集合，配置的定义接口如下： 123public interface RouteDefinitionLocator &#123; Flux&lt;RouteDefinition&gt; getRouteDefinitions();&#125; 通过YAML文件配置或者流式编程式配置（其实文档中还有配合Eureka的DiscoveryClient进行配置，这里暂时不研究），最终都是为了创建一个RouteDefinition的集合。 Yaml配置 配置实现是PropertiesRouteDefinitionLocator，关联着配置类GatewayProperties： 12345678spring: cloud: gateway: routes: - id: datetime_after_route # &lt;------ 这里是路由配置的ID uri: http://www.throwable.club # &lt;------ 这里是路由最终目标Server的URI(Host) predicates: # &lt;------ 谓词集合配置，多个是用and逻辑连接 - Path=/blog # &lt;------- Key(name)=Expression，键是谓词规则工厂的ID，值一般是匹配规则的正则表示 编程式流式配置 编程式和流式编程配置需要依赖RouteLocatorBuilder，目标是构造一个RouteLocator实例： 12345678@Beanpublic RouteLocator customRouteLocator(RouteLocatorBuilder builder) &#123; return builder.routes() .route(r -&gt; r.path(\"/blog\") .uri(\"http://www.throwable.club\") ) .build();&#125; 路由谓词工厂 Spring Cloud Gateway将路由(Route)作为Spring-WebFlux的HandlerMapping组件基础设施的一部分，也就是HandlerMapping进行匹配的时候，会把配置好的路由规则也纳入匹配机制之中。Spring Cloud Gateway自身包含了很多内建的路由谓词工厂。这些谓词分别匹配一个HTTP请求的不同属性。多个路由谓词工厂可以用and的逻辑组合在一起。 目前Spring Cloud Gateway提供的内置的路由谓词工厂如下： 指定日期时间规则路由谓词 按照配置的日期时间指定的路由谓词有三种可选规则： 匹配请求在指定日期时间之前。 匹配请求在指定日期时间之后。 匹配请求在指定日期时间之间。 值得注意的是，配置的日期时间必须满足ZonedDateTime的格式： 12//年月日和时分秒用'T'分隔,接着-07:00是和UTC相差的时间，最后的[America/Denver]是所在的时间地区2017-01-20T17:42:47.789-07:00[America/Denver] 例如网关的应用是2019-05-01T00:00:00+08:00[Asia/Shanghai]上线的，上线之后的请求都路由奥www.throwable.club，那么配置如下： 12345678910server port: 9090spring: cloud: gateway: routes: - id: datetime_after_route uri: http://www.throwable.club predicates: - After=2019-05-01T00:00:00+08:00[Asia/Shanghai] 此时，只要请求网关http://localhost:9090，请求就会转发到http://www.throwable.club。 如果想要只允许2019-05-01T00:00:00+08:00[Asia/Shanghai]之前的请求，那么只需要改为： 12345678910server port: 9091spring: cloud: gateway: routes: - id: datetime_before_route uri: http://www.throwable.club predicates: - Before=2019-05-01T00:00:00+08:00[Asia/Shanghai] 如果只允许两个日期时间段之间的时间进行请求，那么只需要改为： 12345678910server port: 9090spring: cloud: gateway: routes: - id: datetime_between_route uri: http://www.throwable.club predicates: - Between=2019-05-01T00:00:00+08:00[Asia/Shanghai],2019-05-02T00:00:00+08:00[Asia/Shanghai] 那么只有2019年5月1日0时到5月2日0时的请求才能正常路由。 Cookie路由谓词 CookieRoutePredicateFactory需要提供两个参数，分别是Cookie的name和一个正则表达式(value)。只有在请求中的Cookie对应的name和value和Cookie路由谓词中配置的值匹配的时候，才能匹配命中进行路由。 12345678910server port: 9090spring: cloud: gateway: routes: - id: cookie_route uri: http://www.throwable.club predicates: - Cookie=doge,throwable 请求需要携带一个Cookie，name为doge，value需要匹配正则表达式&quot;throwable&quot;才能路由到http://www.throwable.club。 这里尝试本地搭建一个订单Order服务，基于SpringBoot2.1.4搭建，启动在9091端口： 123456789101112131415// 入口类@RestController@RequestMapping(path = \"/order\")@SpringBootApplicationpublic class OrderServiceApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderServiceApplication.class, args); &#125; @GetMapping(value = \"/cookie\") public ResponseEntity&lt;String&gt; cookie(@CookieValue(name = \"doge\") String doge) &#123; return ResponseEntity.ok(doge); &#125;&#125; 订单服务application.yaml配置： 1234567891011121314151617181920spring: application: name: order-serviceserver: port: 9091``` 网关路由配置：```yamlspring: application: name: route-server cloud: gateway: routes: - id: cookie_route uri: http://localhost:9091 predicates: - Cookie=doge,throwable 1234curl http://localhost:9090/order/cookie --cookie \"doge=throwable\"//响应结果throwable Header路由谓词 HeaderRoutePredicateFactory需要提供两个参数，分别是Header的name和一个正则表达式(value)。只有在请求中的Header对应的name和value和Header路由谓词中配置的值匹配的时候，才能匹配命中进行路由。 订单服务中新增一个/header端点： 1234567891011121314@RestController@RequestMapping(path = \"/order\")@SpringBootApplicationpublic class OrderServiceApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderServiceApplication.class, args); &#125; @GetMapping(value = \"/header\") public ResponseEntity&lt;String&gt; header(@RequestHeader(name = \"accessToken\") String accessToken) &#123; return ResponseEntity.ok(accessToken); &#125;&#125; 网关的路由配置如下： 12345678spring: cloud: gateway: routes: - id: header_route uri: http://localhost:9091 predicates: - Header=accessToken,Doge 1234curl -H \"accessToken:Doge\" http://localhost:9090/order/header//响应结果Doge Host路由谓词 HostRoutePredicateFactory只需要指定一个主机名列表，列表中的每个元素支持Ant命名样式，使用.作为分隔符，多个元素之间使用,区分。Host路由谓词实际上针对的是HTTP请求头中的Host属性。 订单服务中新增一个/header端点： 1234567891011121314@RestController@RequestMapping(path = \"/order\")@SpringBootApplicationpublic class OrderServiceApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderServiceApplication.class, args); &#125; @GetMapping(value = \"/host\") public ResponseEntity&lt;String&gt; host(@RequestHeader(name = \"Host\") String host) &#123; return ResponseEntity.ok(host); &#125;&#125; 网关的路由配置如下： 12345678spring: cloud: gateway: routes: - id: host_route uri: http://localhost:9091 predicates: - Host=localhost:9090 1234curl http://localhost:9090/order/host//响应结果localhost:9091 # &lt;--------- 这里要注意一下，路由到订单服务的时候，Host会被修改为localhost:9091 其实可以定制更多样化的Host匹配模式，甚至可以支持URI模板变量。 123- Host=www.throwable.**,**.throwable.**- Host=&#123;sub&#125;.throwable.club 请求方法路由谓词 MethodRoutePredicateFactory只需要一个参数：要匹配的HTTP请求方法。 网关的路由配置如下： 12345678spring: cloud: gateway: routes: - id: method_route uri: http://localhost:9091 predicates: - Method=GET 这样配置，所有的进入到网关的GET方法的请求都会路由到http://localhost:9091。 订单服务中新增一个/get端点： 1234@GetMapping(value = \"/get\")public ResponseEntity&lt;String&gt; get() &#123; return ResponseEntity.ok(\"get\");&#125; 1234curl http://localhost:9090/order/get//响应结果get 请求路径路由谓词 PathRoutePredicateFactory需要PathMatcher模式路径列表和一个可选的标志位参数matchOptionalTrailingSeparator。这个是最常用的一个路由谓词。 12345678spring: cloud: gateway: routes: - id: path_route uri: http://localhost:9091 predicates: - Path=/order/path 1234@GetMapping(value = \"/path\")public ResponseEntity&lt;String&gt; path() &#123; return ResponseEntity.ok(\"path\");&#125; 1234curl http://localhost:9090/order/path//响应结果path 此外，可以通过{segment}占位符配置路径如/foo/1或/foo/bar或/bar/baz，如果通过这种形式配置，在匹配命中进行路由的时候，会提取路径中对应的内容并且将键值对放在ServerWebExchange.getAttributes()集合中，KEY为ServerWebExchangeUtils.URI_TEMPLATE_VARIABLES_ATTRIBUTE，这些提取出来的属性可以供GatewayFilter Factories使用。 请求查询参数路由谓词 QueryRoutePredicateFactory需要一个必须的请求查询参数(param的name)以及一个可选的正则表达式(regexp)。 12345678spring: cloud: gateway: routes: - id: query_route uri: http://localhost:9091 predicates: - Query=doge,throwabl. 这里配置的param就是doge，正则表达式是throwabl.。 1234@GetMapping(value = \"/query\")public ResponseEntity&lt;String&gt; query(@RequestParam(\"name\") String doge) &#123; return ResponseEntity.ok(doge);&#125; 1234curl http://localhost:9090/order/query?doge=throwable//响应结果throwable 远程IP地址路由谓词 RemoteAddrRoutePredicateFactory匹配规则采用CIDR符号（IPv4或IPv6）字符串的列表（最小值为1），例如192.168.0.1/16（其中192.168.0.1是远程IP地址并且16是子网掩码）。 12345678spring: cloud: gateway: routes: - id: remoteaddr_route uri: http://localhost:9091 predicates: - RemoteAddr=127.0.0.1 1234@GetMapping(value = \"/remote\")public ResponseEntity&lt;String&gt; remote() &#123; return ResponseEntity.ok(\"remote\");&#125; 1234curl http://localhost:9090/order/remote//响应结果remote 关于远程IP路由这一个路由谓词其实还有很多扩展手段，这里暂时不展开。 多个路由谓词组合 因为路由配置中的predicates属性其实是一个列表，可以直接添加多个路由规则： 12345678910spring: cloud: gateway: routes: - id: remoteaddr_route uri: http://localhost:9091 predicates: - RemoteAddr=xxxx - Path=/yyyy - Query=zzzz,aaaa 这些规则是用and逻辑组合的，例如上面的例子相当于： 12345request = ...if(request.getRemoteAddr == 'xxxx' &amp;&amp; request.getPath match '/yyyy' &amp;&amp; request.getQuery('zzzz') match 'aaaa') &#123; return true;&#125;return false; GatewayFilter工厂 路由过滤器GatewayFilter允许修改进来的HTTP请求内容或者返回的HTTP响应内容。路由过滤器的作用域是一个具体的路由配置。Spring Cloud Gateway提供了丰富的内建的GatewayFilter工厂，可以按需选用。 因为GatewayFilter工厂类实在太多，笔者这里举个简单的例子。 如果我们想对某些请求附加特殊的HTTP请求头，可以选用AddRequestHeaderX-Request-Foo:Bar，application.yml如下： 12345678spring: cloud: gateway: routes: - id: add_request_header_route uri: https://example.org filters: - AddRequestHeader=X-Request-Foo,Bar 那么所有的从网关入口的HTTP请求都会添加一个特殊的HTTP请求头：X-Request-Foo:Bar。 目前GatewayFilter工厂的内建实现如下： ID 类名 类型 功能 StripPrefix StripPrefixGatewayFilterFactory pre 移除请求URL路径的第一部分，例如原始请求路径是/order/query，处理后是/query SetStatus SetStatusGatewayFilterFactory post 设置请求响应的状态码，会从org.springframework.http.HttpStatus中解析 SetResponseHeader SetResponseHeaderGatewayFilterFactory post 设置(添加)请求响应的响应头 SetRequestHeader SetRequestHeaderGatewayFilterFactory pre 设置(添加)请求头 SetPath SetPathGatewayFilterFactory pre 设置(覆盖)请求路径 SecureHeader SecureHeadersGatewayFilterFactory pre 设置安全相关的请求头，见SecureHeadersProperties SaveSession SaveSessionGatewayFilterFactory pre 保存WebSession RewriteResponseHeader RewriteResponseHeaderGatewayFilterFactory post 重新响应头 RewritePath RewritePathGatewayFilterFactory pre 重写请求路径 Retry RetryGatewayFilterFactory pre 基于条件对请求进行重试 RequestSize RequestSizeGatewayFilterFactory pre 限制请求的大小，单位是byte，超过设定值返回413 Payload Too Large RequestRateLimiter RequestRateLimiterGatewayFilterFactory pre 限流 RequestHeaderToRequestUri RequestHeaderToRequestUriGatewayFilterFactory pre 通过请求头的值改变请求URL RemoveResponseHeader RemoveResponseHeaderGatewayFilterFactory post 移除配置的响应头 RemoveRequestHeader RemoveRequestHeaderGatewayFilterFactory pre 移除配置的请求头 RedirectTo RedirectToGatewayFilterFactory pre 重定向，需要指定HTTP状态码和重定向URL PreserveHostHeader PreserveHostHeaderGatewayFilterFactory pre 设置请求携带的属性preserveHostHeader为true PrefixPath PrefixPathGatewayFilterFactory pre 请求路径添加前置路径 Hystrix HystrixGatewayFilterFactory pre 整合Hystrix FallbackHeaders FallbackHeadersGatewayFilterFactory pre Hystrix执行如果命中降级逻辑允许通过请求头携带异常明细信息 AddResponseHeader AddResponseHeaderGatewayFilterFactory post 添加响应头 AddRequestParameter AddRequestParameterGatewayFilterFactory pre 添加请求参数，仅仅限于URL的Query参数 AddRequestHeader AddRequestHeaderGatewayFilterFactory pre 添加请求头 GatewayFilter工厂使用的时候需要知道其ID以及配置方式，配置方式可以看对应工厂类的公有静态内部类XXXXConfig。 GlobalFilter工厂 GlobalFilter的功能其实和GatewayFilter是相同的，只是GlobalFilter的作用域是所有的路由配置，而不是绑定在指定的路由配置上。多个GlobalFilter可以通过@Order或者getOrder()方法指定每个GlobalFilter的执行顺序，order值越小，GlobalFilter执行的优先级越高。 注意，由于过滤器有pre和post两种类型，pre类型过滤器如果order值越小，那么它就应该在pre过滤器链的顶层，post类型过滤器如果order值越小，那么它就应该在pre过滤器链的底层。示意图如下： 例如要实现负载均衡的功能，application.yml配置如下： 12345678spring: cloud: gateway: routes: - id: myRoute uri: lb://myservice # &lt;-------- lb特殊标记会使用LoadBalancerClient搜索目标服务进行负载均衡 predicates: - Path=/service/** 目前Spring Cloud Gateway提供的内建的GlobalFilter如下： 类名 功能 ForwardRoutingFilter 重定向 LoadBalancerClientFilter 负载均衡 NettyRoutingFilter Netty的HTTP客户端的路由 NettyWriteResponseFilter Netty响应进行写操作 RouteToRequestUrlFilter 基于路由配置更新URL WebsocketRoutingFilter Websocket请求转发到下游 内建的GlobalFilter大多数和ServerWebExchangeUtils的属性相关，这里就不深入展开。 跨域配置 网关可以通过配置来控制全局的CORS行为。全局的CORS配置对应的类是CorsConfiguration，这个配置是一个URL模式的映射。例如application.yaml文件如下： 123456789spring: cloud: gateway: globalcors: corsConfigurations: '[/**]': allowedOrigins: \"https://docs.spring.io\" allowedMethods: - GET 在上面的示例中，对于所有请求的路径，将允许来自docs.spring.io并且是GET方法的CORS请求。 Actuator端点相关 引入spring-boot-starter-actuator，需要做以下配置开启gateway监控端点： 12management.endpoint.gateway.enabled=true management.endpoints.web.exposure.include=gateway 目前支持的端点列表： ID 请求路径 HTTP方法 描述 globalfilters /actuator/gateway/globalfilters GET 展示路由配置中的GlobalFilter列表 routefilters /actuator/gateway/routefilters GET 展示绑定到对应路由配置的GatewayFilter列表 refresh /actuator/gateway/refresh POST 清空路由配置缓存 routes /actuator/gateway/routes GET 展示已经定义的路由配置列表 routes/{id} /actuator/gateway/routes/{id} GET 展示对应ID已经定义的路由配置 routes/{id} /actuator/gateway/routes/{id} POST 添加一个新的路由配置 routes/{id} /actuator/gateway/routes/{id} DELETE 删除指定ID的路由配置 其中/actuator/gateway/routes/{id}添加一个新的路由配置请求参数的格式如下： 12345678910&#123; \"id\": \"first_route\", \"predicates\": [&#123; \"name\": \"Path\", \"args\": &#123;\"doge\":\"/throwable\"&#125; &#125;], \"filters\": [], \"uri\": \"https://www.throwable.club\", \"order\": 0&#125; 小结 笔者虽然是一个底层的码畜，但是很久之前就向身边的朋友说： 反应式编程结合同步非阻塞IO或者异步非阻塞IO是目前网络编程框架的主流方向，最好要跟上主流的步伐掌握这些框架的使用，有能力最好成为它们的贡献者。 目前常见的反应式编程框架有： Reactor和RxJava2，其中Reactor在后端的JVM应用比较常见，RxJava2在安卓编写的APP客户端比较常见。 Reactor-Netty，这个是基于Reactor和Netty封装的。 Spring-WebFlux和Spring-Cloud-Gateway，其中Spring-Cloud-Gateway依赖Spring-WebFlux，而Spring-WebFlux底层依赖于Reactor-Netty。 根据这个链式关系，最好系统学习一下Reactor和Netty。 参考资料： Spring-Cloud-Gateway官方文档 Reactor官方文档 附录 选用Spring-Cloud-Gateway不仅仅是为了使用新的技术，更重要的是它的性能有了不俗的提升，基准测试项目spring-cloud-gateway-bench的结果如下： 代理组件(Proxy) 平均交互延迟(Avg Latency) 平均每秒处理的请求数(Avg Requests/Sec) Spring Cloud Gateway 6.61ms 32213.38 Linkered 7.62ms 28050.76 Zuul(1.x) 12.56ms 20800.13 None(直接调用) 2.09ms 116841.15 (本文完 c-3-d e-a-20190504)","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://throwable.club/blog/categories/Spring-Cloud/"},{"name":"Spring Cloud Gateway","slug":"Spring-Cloud/Spring-Cloud-Gateway","permalink":"http://throwable.club/blog/categories/Spring-Cloud/Spring-Cloud-Gateway/"}],"tags":[{"name":"Spring Cloud Gateway","slug":"Spring-Cloud-Gateway","permalink":"http://throwable.club/blog/tags/Spring-Cloud-Gateway/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://throwable.club/blog/tags/Spring-Cloud/"}]},{"title":"深入理解Object提供的阻塞和唤醒API","slug":"java-object-wait-notify","date":"2019-04-30T03:45:00.000Z","updated":"2019-05-01T09:27:19.720Z","comments":true,"path":"2019/04/30/java-object-wait-notify/","link":"","permalink":"http://throwable.club/2019/04/30/java-object-wait-notify/","excerpt":"","text":"深入理解Object提供的阻塞和唤醒API 前提 前段时间花了大量时间去研读JUC中同步器AbstractQueuedSynchronizer的源码实现，再结合很久之前看过的一篇关于Object提供的等待和唤醒机制的JVM实现，发现两者有不少的关联，于是决定重新研读一下Object中提供的阻塞和唤醒方法。本文阅读JDK类库源码使用的JDK版本是JDK11，因为本文内容可能不适合于其他版本。 Object提供的阻塞和唤醒API java.lang.Object作为所有非基本类型的基类，也就是说所有java.lang.Object的子类都具备阻塞和唤醒的功能。下面详细分析Object提供的阻塞和唤醒API。 阻塞等待-wait 等待-wait()方法提供了阻塞的功能，分超时和永久阻塞的版本，实际上，底层只提供了一个JNI方法： 123456789101112131415161718192021// 这个是底层提供的JNI方法，带超时的阻塞等待，响应中断，其他两个只是变体public final native void wait(long timeoutMillis) throws InterruptedException;// 变体方法1，永久阻塞，响应中断public final void wait() throws InterruptedException &#123; wait(0L);&#125;// 变体方法2，带超时的阻塞，超时时间分两段：毫秒和纳秒，实际上纳秒大于0直接毫秒加1(这么暴力...)，响应中断public final void wait(long timeoutMillis, int nanos) throws InterruptedException &#123; if (timeoutMillis &lt; 0) &#123; throw new IllegalArgumentException(\"timeoutMillis value is negative\"); &#125; if (nanos &lt; 0 || nanos &gt; 999999) &#123; throw new IllegalArgumentException(\"nanosecond timeout value out of range\"); &#125; if (nanos &gt; 0) &#123; timeoutMillis++; &#125; wait(timeoutMillis);&#125; 也就是只有一个wait(long timeoutMillis)方法是JNI接口，其他两个方法相当于： wait()等价于wait(0L)。 wait(long timeoutMillis, int nanos)在参数合法的情况下等价于wait(timeoutMillis + 1L)。 由于wait(long timeoutMillis, int nanos)是参数最完整的方法，它的API注释特别长，这里直接翻译和摘取它注释中的核心要素： 当前线程阻塞等待直到被唤醒，唤醒的情况一般有三种：notify(All)被调用、线程被中断或者在指定了超时阻塞的情况下超过了指定的阻塞时间。 当前线程必须获取此对象的监视器锁(monitor lock)，也就是调用阻塞等待方法之前一个线程必须成为此对象的监视器锁的拥有者。 调用了wait()方法之后，当前线程会把自身放到当前对象的等待集合(wait-set)，然后释放所有在此对象上的同步声明(then to relinquish any nd all synchronization claims on this object)，谨记只有当前对象上的同步声明会被释放，当前线程在其他对象上的同步锁只有在调用其wait()方法之后才会释放。 Warning：线程被唤醒之后(notify()或者中断)就会从等待集合(wait-set)中移除并且重新允许被线程调度器调度。通常情况下，这个被唤醒的线程会与其他线程竞争对象上的同步权(锁)，一旦线程重新控制了对象(regained control of the object)，它对对象的所有同步声明都恢复到以前的状态，即恢复到调用wait()方法时(笔者认为，其实准确来说，是调用wait()方法前)的状态。 如果任意线程在它调用了wait()之前，或者调用过wait()方法之后处于阻塞等待状态，一旦线程调用了Thread#interrupt()，线程就会中断并且抛出InterruptedException异常，线程的中断状态会被清除。InterruptedException异常会延迟到在第4点提到&quot;它对对象的所有同步声明都恢复到以前的状态&quot;的时候抛出。 值得注意的还有： 一个线程必须成为此对象的监视器锁的拥有者才能正常调用wait()系列方法，也就是wait()系列方法必须在同步代码块(synchronized代码块)中调用，否则会抛出IllegalMonitorStateException异常，这一点是初学者或者不了解wait()的机制的开发者经常会犯的问题。 上面的五点描述可以写个简单的同步代码块伪代码时序总结一下： 123456789101112final Object lock = new Object();synchronized(lock)&#123; 1、线程进入同步代码块，意味着获取对象监视器锁成功 while(!condition)&#123; lock.wait(); 2.线程调用wait()进行阻塞等待 break; &#125; 3.线程从wait()的阻塞等待中被唤醒，恢复到第1步之后的同步状态 4.继续执行后面的代码，直到离开同步代码块&#125; 唤醒-notify notify()方法的方法签名如下： 12@HotSpotIntrinsicCandidatepublic final native void notify(); 下面按照惯例翻译一下其API注释： 唤醒一个阻塞等待在此对象监视器上的线程，(如果存在多个阻塞线程)至于选择哪一个线程进行唤醒是任意的，取决于具体的现实，一个线程通过调用wait()方法才能阻塞在对象监视器上。 被唤醒的线程并不会马上继续执行，直到当前线程(也就是当前调用了notify()方法的线程)释放对象上的锁。被唤醒的线程会与其他线程竞争在对象上进行同步(换言之只有获得对象的同步控制权才能继续执行)，在成为下一个锁定此对象的线程时，被唤醒的线程没有可靠的特权或劣势。 此方法只有在一个线程获取了此对象监视器的所有权(the owner)的时候才能调用，具体就是：同步方法中、同步代码块中或者静态同步方法中。否则，会抛出IllegalMonitorStateException异常。 唤醒所有-notifyAll notifyAll()方法的方法签名如下： 12@HotSpotIntrinsicCandidatepublic final native void notifyAll(); 唤醒所有阻塞等待在此对象监视器上的线程，一个线程通过调用wait()方法才能阻塞在对象监视器上。 其他注释的描述和notify()方法类似。 小结 我们经常看到的资料中提到synchronized关键字的用法： 普通同步方法，同步或者说锁定的是当前实例对象。 静态同步方法，同步或者说锁定的是当前实例对象的Class对象。 同步代码块，同步或者说锁定的是括号里面的实例对象。 对于同步代码块而言，synchronized关键字抽象到字节码层面就是同步代码块中的字节码执行在monitorenter和monitorexit指令之间： 12345678910synchronized(xxxx)&#123; ...coding block&#125;↓↓↓↓↓↓↓↓↓↓monitorenter;...coding block - bytecodemonitorexit; JVM需要保证每一个monitorenter都有一个monitorexit与之相对应。任何对象都有一个monitor(实际上是ObjectMonitor)与之相关联，当且一个monitor被持有之后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor所有权，即尝试获取对象的锁。 对于同步(静态)方法而言，synchronized方法则会被翻译成普通的方法调用和返回指令，如：invokevirtual等等，在JVM字节码层面并没有任何特别的指令来实现被synchronized修饰的方法，而是在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1，表示该方法是同步方法并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示Klass做为锁对象。 其实从开发者角度简单理解，这两种方式只是在获取锁的时机有所不同。 下面重复阐述几个第一眼看起来不合理却是事实的问题(其实前文已经提及过)： 在线程进入synchronized方法或者代码块，相当于获取监视器锁成功，如果此时成功调用wait()系列方法，那么它会立即释放监视器锁，并且添加到等待集合(Wait Set)中进行阻塞等待。 由于已经有线程释放了监视器锁，那么在另一个线程进入synchronized方法或者代码块之后，它可以调用notify(All)方法唤醒等待集合中正在阻塞的线程，但是这个唤醒操作并不是调用notify(All)方法后立即生效，而是在该线程退出synchronized方法或者代码块之后才生效。 从wait()方法阻塞过程中被唤醒的线程会竞争监视器目标对象的控制权，一旦重新控制了对象，那么线程的同步状态就会恢复到步入synchronized方法或者代码块时候的状态(也就是成功获取到对象监视器锁时候的状态)，这个时候线程才能够继续执行。 为了验证这三点，可以写个简单的Demo： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class Lock &#123; @Getter private final Object lock = new Object();&#125;public class WaitMain &#123; private static final DateTimeFormatter F = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss.SSS\"); public static void main(String[] args) throws Exception &#123; final Lock lock = new Lock(); new Thread(new WaitRunnable(lock), \"WaitThread-1\").start(); new Thread(new WaitRunnable(lock), \"WaitThread-2\").start(); Thread.sleep(50); new Thread(new NotifyRunnable(lock), \"NotifyThread\").start(); Thread.sleep(Integer.MAX_VALUE); &#125; @RequiredArgsConstructor private static class WaitRunnable implements Runnable &#123; private final Lock lock; @Override public void run() &#123; synchronized (lock) &#123; System.out.println(String.format(\"[%s]-线程[%s]获取锁成功,准备执行wait方法\", F.format(LocalDateTime.now()), Thread.currentThread().getName())); while (true) &#123; try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; //ignore &#125; System.out.println(String.format(\"[%s]-线程[%s]从wait中唤醒,准备exit\", F.format(LocalDateTime.now()), Thread.currentThread().getName())); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; //ignore &#125; break; &#125; &#125; &#125; &#125; @RequiredArgsConstructor private static class NotifyRunnable implements Runnable &#123; private final Lock lock; @Override public void run() &#123; synchronized (lock) &#123; System.out.println(String.format(\"[%s]-线程[%s]获取锁成功,准备执行notifyAll方法\", F.format(LocalDateTime.now()), Thread.currentThread().getName())); lock.notifyAll(); System.out.println(String.format(\"[%s]-线程[%s]先休眠3000ms\", F.format(LocalDateTime.now()), Thread.currentThread().getName())); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; //ignore &#125; System.out.println(String.format(\"[%s]-线程[%s]准备exit\", F.format(LocalDateTime.now()), Thread.currentThread().getName())); &#125; &#125; &#125;&#125; 某个时刻的执行结果如下： 1234567[2019-04-27 23:28:17.617]-线程[WaitThread-1]获取锁成功,准备执行wait方法[2019-04-27 23:28:17.631]-线程[WaitThread-2]获取锁成功,准备执行wait方法[2019-04-27 23:28:17.657]-线程[NotifyThread]获取锁成功,准备执行notifyAll方法 &lt;-------- 这一步执行完说明WaitThread已经释放了锁[2019-04-27 23:28:17.657]-线程[NotifyThread]先休眠3000ms[2019-04-27 23:28:20.658]-线程[NotifyThread]准备exit &lt;------- 这一步后NotifyThread离开同步代码块[2019-04-27 23:28:20.658]-线程[WaitThread-1]从wait中唤醒,准备exit &lt;------- 这一步WaitThread-1解除阻塞[2019-04-27 23:28:21.160]-线程[WaitThread-2]从wait中唤醒,准备exit &lt;------- 这一步WaitThread-2解除阻塞，注意发生时间在WaitThread-1解除阻塞500ms之后，符合我们前面提到的第3点 如果结合wait()和notify()可以简单总结出一个同步代码块的伪代码如下： 12345678910111213141516171819final Object lock = new Object();// 等待synchronized(lock)&#123; 1、线程进入同步代码块，意味着获取对象监视器锁成功 while(!condition)&#123; lock.wait(); 2.线程调用wait()进行阻塞等待 break; &#125; 3.线程从wait()的阻塞等待中被唤醒，尝试恢复第1步之后的同步状态，并不会马上生效，直到notify被调用并且调用notify方法的线程已经释放锁，同时当前线程需要竞争成功 4.继续执行后面的代码，直到离开同步代码块&#125;// 唤醒synchronized(lock)&#123; 1、线程进入同步代码块，意味着获取对象监视器锁成功 lock.notify(); 2.唤醒其中一个在对象监视器上等待的线程 3.准备推出同步代码块释放锁，只有释放锁之后第2步才会生效&#125; 图解Object提供的阻塞和唤醒机制 结合前面分析过的知识点以及参考资料中的文章，重新画一个图理解一下对象监视器以及相应阻塞和唤醒API的工作示意过程： Entry Set(实际上是ObjectMonitor中的_EntryList属性)：存放等待锁并且处于阻塞状态的线程。 Wait Set(实际上是ObjectMonitor中的_WaitSet属性)：存放处于等待阻塞状态的线程。 The Owner(实际上是ObjectMonitor中的_owner属性)：指向获得对象监视器的线程，在同一个时刻只能有一个线程被The Owner持有，通俗来看，它就是监视器的控制权。 使用例子 通过Object提供的阻塞和唤醒机制举几个简单的使用例子。 维修厕所的例子 假设有以下场景：厕所只有一个卡位，厕所维修工修厕所的时候，任何人不能上厕所。当厕所维修工修完厕所的时候，上厕所的人需要&quot;得到厕所的控制权&quot;才能上厕所。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192// 厕所类public class Toilet &#123; // 厕所的锁 private final Object lock = new Object(); private boolean available; public Object getLock() &#123; return lock; &#125; public void setAvailable(boolean available) &#123; this.available = available; &#125; public boolean getAvailable() &#123; return available; &#125;&#125;// 厕所维修工@RequiredArgsConstructorpublic class ToiletRepairer implements Runnable &#123; private static final DateTimeFormatter F = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss.SSS\"); private final Toilet toilet; @Override public void run() &#123; synchronized (toilet.getLock()) &#123; System.out.println(String.format(\"[%s]-厕所维修员得到了厕所的锁,维修厕所要用5000ms...\", LocalDateTime.now().format(F))); try &#123; Thread.sleep(5000); &#125; catch (Exception e) &#123; // ignore &#125; toilet.setAvailable(true); toilet.getLock().notifyAll(); System.out.println(String.format(\"[%s]-厕所维修员维修完毕...\", LocalDateTime.now().format(F))); &#125; &#125;&#125;//上厕所的任务@RequiredArgsConstructorpublic class ToiletTask implements Runnable &#123; private static final DateTimeFormatter F = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss.SSS\"); private final Toilet toilet; private final String name; private final Random random; @Override public void run() &#123; synchronized (toilet.getLock()) &#123; System.out.println(String.format(\"[%s]-%s得到了厕所的锁...\", LocalDateTime.now().format(F), name)); while (!toilet.getAvailable()) &#123; try &#123; toilet.getLock().wait(); &#125; catch (InterruptedException e) &#123; //ignore &#125; int time = random.nextInt(3) + 1; try &#123; // 模拟上厕所用时 TimeUnit.SECONDS.sleep(time); &#125; catch (InterruptedException e) &#123; //ignore &#125; System.out.println(String.format(\"[%s]-%s上厕所用了%s秒...\", LocalDateTime.now().format(F), name, time)); &#125; &#125; &#125;&#125;// 场景入口public class Main &#123; public static void main(String[] args) throws Exception &#123; Toilet toilet = new Toilet(); Random random = new Random(); Thread toiletRepairer = new Thread(new ToiletRepairer(toilet), \"ToiletRepairer\"); Thread thread1 = new Thread(new ToiletTask(toilet, \"张三\", random), \"thread-1\"); Thread thread2 = new Thread(new ToiletTask(toilet, \"李四\", random), \"thread-2\"); Thread thread3 = new Thread(new ToiletTask(toilet, \"王五\", random), \"thread-3\"); thread1.start(); thread2.start(); thread3.start(); Thread.sleep(50); toiletRepairer.start(); Thread.sleep(Integer.MAX_VALUE); &#125;&#125; 某次执行的结果如下： 12345678[2019-04-29 01:07:25.914]-张三得到了厕所的锁...[2019-04-29 01:07:25.931]-李四得到了厕所的锁...[2019-04-29 01:07:25.931]-王五得到了厕所的锁...[2019-04-29 01:07:25.951]-厕所维修员得到了厕所的锁,维修厕所要用5000ms...[2019-04-29 01:07:30.951]-厕所维修员维修完毕...[2019-04-29 01:07:32.952]-张三上厕所用了2秒...[2019-04-29 01:07:35.952]-王五上厕所用了3秒...[2019-04-29 01:07:37.953]-李四上厕所用了2秒... 阻塞队列实现 实现一个简单固定容量的阻塞队列，接口如下： 123456public interface BlockingQueue&lt;T&gt; &#123; void put(T value) throws InterruptedException; T take() throws InterruptedException;&#125; 其中put(T value)会阻塞直到队列中有可用的容量，而take()方法会阻塞直到有元素投放到队列中。实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class DefaultBlockingQueue&lt;T&gt; implements BlockingQueue&lt;T&gt; &#123; private Object[] elements; private final Object notEmpty = new Object(); private final Object notFull = new Object(); private int count; private int takeIndex; private int putIndex; public DefaultBlockingQueue(int capacity) &#123; this.elements = new Object[capacity]; &#125; @Override public void put(T value) throws InterruptedException &#123; synchronized (notFull) &#123; while (count == elements.length) &#123; notFull.wait(); &#125; &#125; final Object[] items = this.elements; items[putIndex] = value; if (++putIndex == items.length) &#123; putIndex = 0; &#125; count++; synchronized (notEmpty) &#123; notEmpty.notify(); &#125; &#125; @SuppressWarnings(\"unchecked\") @Override public T take() throws InterruptedException &#123; synchronized (notEmpty) &#123; while (count == 0) &#123; notEmpty.wait(); &#125; &#125; final Object[] items = this.elements; T value = (T) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) &#123; takeIndex = 0; &#125; count--; synchronized (notFull) &#123; notFull.notify(); &#125; return value; &#125;&#125; 场景入口类： 12345678910111213141516171819202122232425262728public class Main &#123; public static void main(String[] args) throws Exception &#123; BlockingQueue&lt;String&gt; queue = new DefaultBlockingQueue&lt;&gt;(5); Runnable r = () -&gt; &#123; while (true) &#123; try &#123; String take = queue.take(); System.out.println(String.format(\"线程%s消费消息-%s\", Thread.currentThread().getName(), take)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;; new Thread(r, \"thread-1\").start(); new Thread(r, \"thread-2\").start(); IntStream.range(0, 10).forEach(i -&gt; &#123; try &#123; queue.put(String.valueOf(i)); &#125; catch (InterruptedException e) &#123; //ignore &#125; &#125;); Thread.sleep(Integer.MAX_VALUE); &#125;&#125; 某次执行结果如下： 12345678910线程thread-1消费消息-0线程thread-2消费消息-1线程thread-1消费消息-2线程thread-2消费消息-3线程thread-1消费消息-4线程thread-2消费消息-5线程thread-1消费消息-6线程thread-2消费消息-7线程thread-1消费消息-8线程thread-2消费消息-9 上面这个例子就是简单的单生产者-多消费者的模型。 线程池实现 这里实现一个极度简陋的固定容量的线程池，功能是：初始化固定数量的活跃线程，阻塞直到有可用的线程用于提交任务。它只有一个接口方法，接口定义如下： 1234public interface ThreadPool &#123; void execute(Runnable runnable);&#125; 具体实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public class DefaultThreadPool implements ThreadPool &#123; private final int capacity; private List&lt;Worker&gt; initWorkers; private Deque&lt;Worker&gt; availableWorkers; private Deque&lt;Worker&gt; busyWorkers; private final Object nextLock = new Object(); public DefaultThreadPool(int capacity) &#123; this.capacity = capacity; init(capacity); &#125; private void init(int capacity) &#123; initWorkers = new ArrayList&lt;&gt;(capacity); availableWorkers = new LinkedList&lt;&gt;(); busyWorkers = new LinkedList&lt;&gt;(); for (int i = 0; i &lt; capacity; i++) &#123; Worker worker = new Worker(); worker.setName(\"Worker-\" + (i + 1)); worker.setDaemon(true); initWorkers.add(worker); &#125; for (Worker w : initWorkers) &#123; w.start(); availableWorkers.add(w); &#125; &#125; @Override public void execute(Runnable runnable) &#123; if (null == runnable) &#123; return; &#125; synchronized (nextLock) &#123; while (availableWorkers.size() &lt; 1) &#123; try &#123; nextLock.wait(500); &#125; catch (InterruptedException e) &#123; //ignore &#125; &#125; Worker worker = availableWorkers.removeFirst(); busyWorkers.add(worker); worker.run(runnable); nextLock.notifyAll(); &#125; &#125; private void makeAvailable(Worker worker) &#123; synchronized (nextLock) &#123; availableWorkers.add(worker); busyWorkers.remove(worker); nextLock.notifyAll(); &#125; &#125; private class Worker extends Thread &#123; private final Object lock = new Object(); private Runnable runnable; private AtomicBoolean run = new AtomicBoolean(true); private void run(Runnable runnable) &#123; synchronized (lock) &#123; if (null != this.runnable) &#123; throw new IllegalStateException(\"Already running a Runnable!\"); &#125; this.runnable = runnable; lock.notifyAll(); &#125; &#125; @Override public void run() &#123; boolean ran = false; while (run.get()) &#123; try &#123; synchronized (lock) &#123; while (runnable == null &amp;&amp; run.get()) &#123; lock.wait(500); &#125; if (runnable != null) &#123; ran = true; runnable.run(); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; synchronized (lock) &#123; runnable = null; &#125; if (ran) &#123; ran = false; makeAvailable(this); &#125; &#125; &#125; &#125; &#125;&#125; 场景类入口： 123456789101112131415161718192021222324252627282930313233343536public class Main &#123; private static final DateTimeFormatter F = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss.SSS\"); public static void main(String[] args) throws Exception&#123; ThreadPool threadPool = new DefaultThreadPool(2); threadPool.execute(() -&gt; &#123; try &#123; System.out.println(String.format(\"[%s]-任务一开始执行持续3秒...\", LocalDateTime.now().format(F))); Thread.sleep(3000); System.out.println(String.format(\"[%s]-任务一执行结束...\", LocalDateTime.now().format(F))); &#125;catch (Exception e)&#123; //ignore &#125; &#125;); threadPool.execute(() -&gt; &#123; try &#123; System.out.println(String.format(\"[%s]-任务二开始执行持续4秒...\", LocalDateTime.now().format(F))); Thread.sleep(4000); System.out.println(String.format(\"[%s]-任务二执行结束...\", LocalDateTime.now().format(F))); &#125;catch (Exception e)&#123; //ignore &#125; &#125;); threadPool.execute(() -&gt; &#123; try &#123; System.out.println(String.format(\"[%s]-任务三开始执行持续5秒...\", LocalDateTime.now().format(F))); Thread.sleep(5000); System.out.println(String.format(\"[%s]-任务三执行结束...\", LocalDateTime.now().format(F))); &#125;catch (Exception e)&#123; //ignore &#125; &#125;); Thread.sleep(Integer.MAX_VALUE); &#125;&#125; 某次执行结果如下： 123456[2019-04-29 02:07:25.465]-任务二开始执行持续4秒...[2019-04-29 02:07:25.465]-任务一开始执行持续3秒...[2019-04-29 02:07:28.486]-任务一执行结束...[2019-04-29 02:07:28.486]-任务三开始执行持续5秒...[2019-04-29 02:07:29.486]-任务二执行结束...[2019-04-29 02:07:33.487]-任务三执行结束... 小结 鉴于笔者C语言学得不好，这里就无法深入分析JVM源码的实现，只能结合一些现有的资料和自己的理解重新梳理一下Object提供的阻塞和唤醒机制这些知识点。结合之前看过JUC同步器的源码，一时醒悟过来，JUC同步器只是在数据结构和算法层面使用Java语言对原来JVM中C语言的阻塞和唤醒机制即Object提供的那几个JNI方法进行了一次实现而已。 最后，Object提供的阻塞等待唤醒机制是JVM实现的(如果特别熟悉C语言可以通过JVM源码研究其实现，对于大部分开发者来说是黑箱)，除非是特别熟练或者是JDK版本太低尚未引入JUC包，一般情况下不应该优先选择Object，而应该考虑专门为并发设计的JUC包中的类库。 参考资料： JVM源码分析之Object.wait/notify实现-By占小狼 死磕Java并发-深入分析synchronized的实现原理 JDK11相关源码 (本文完 c-7-d e-a-20190430)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Concurrency","slug":"Java/Concurrency","permalink":"http://throwable.club/blog/categories/Java/Concurrency/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Object","slug":"Object","permalink":"http://throwable.club/blog/tags/Object/"}]},{"title":"通过micrometer实时监控线程池的各项指标","slug":"jvm-micrometer-thread-pool-monitor","date":"2019-04-14T15:45:17.000Z","updated":"2019-04-30T03:56:50.926Z","comments":true,"path":"2019/04/14/jvm-micrometer-thread-pool-monitor/","link":"","permalink":"http://throwable.club/2019/04/14/jvm-micrometer-thread-pool-monitor/","excerpt":"","text":"通过micrometer实时监控线程池的各项指标 前提 最近的一个项目中涉及到文件上传和下载，使用到JUC的线程池ThreadPoolExecutor，在生产环境中出现了某些时刻线程池满负载运作，由于使用了CallerRunsPolicy拒绝策略，导致满负载情况下，应用接口调用无法响应，处于假死状态。考虑到之前用micrometer + prometheus + grafana搭建过监控体系，于是考虑使用micrometer做一次主动的线程池度量数据采集，最终可以相对实时地展示在grafana的面板中。 实践过程 下面通过真正的实战过程做一个仿真的例子用于复盘。 代码改造 首先我们要整理一下ThreadPoolExecutor中提供的度量数据项和micrometer对应的Tag的映射关系： 线程池名称，Tag：thread.pool.name，这个很重要，用于区分各个线程池的数据，如果使用IOC容器管理，可以使用BeanName代替。 int getCorePoolSize()：核心线程数，Tag：thread.pool.core.size。 int getLargestPoolSize()：历史峰值线程数，Tag：thread.pool.largest.size。 int getMaximumPoolSize()：最大线程数(线程池线程容量)，Tag：thread.pool.max.size。 int getActiveCount()：当前活跃线程数，Tag：thread.pool.active.size。 int getPoolSize()：当前线程池中运行的线程总数(包括核心线程和非核心线程)，Tag：thread.pool.thread.count。 当前任务队列中积压任务的总数，Tag：thread.pool.queue.size，这个需要动态计算得出。 接着编写具体的代码，实现的功能如下： 1、建立一个ThreadPoolExecutor实例，核心线程和最大线程数为10，任务队列长度为10，拒绝策略为AbortPolicy。 2、提供两个方法，分别使用线程池实例模拟短时间耗时的任务和长时间耗时的任务。 3、提供一个方法用于清空线程池实例中的任务队列。 4、提供一个单线程的调度线程池用于定时收集ThreadPoolExecutor实例中上面列出的度量项，保存到micrometer内存态的收集器中。 由于这些统计的值都会跟随时间发生波动性变更，可以考虑选用Gauge类型的Meter进行记录。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123// ThreadPoolMonitorimport io.micrometer.core.instrument.Metrics;import io.micrometer.core.instrument.Tag;import org.springframework.beans.factory.InitializingBean;import org.springframework.stereotype.Service;import java.util.Collections;import java.util.concurrent.*;import java.util.concurrent.atomic.AtomicInteger;/** * @author throwable * @version v1.0 * @description * @since 2019/4/7 21:02 */@Servicepublic class ThreadPoolMonitor implements InitializingBean &#123; private static final String EXECUTOR_NAME = \"ThreadPoolMonitorSample\"; private static final Iterable&lt;Tag&gt; TAG = Collections.singletonList(Tag.of(\"thread.pool.name\", EXECUTOR_NAME)); private final ScheduledExecutorService scheduledExecutor = Executors.newSingleThreadScheduledExecutor(); private final ThreadPoolExecutor executor = new ThreadPoolExecutor(10, 10, 0, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(10), new ThreadFactory() &#123; private final AtomicInteger counter = new AtomicInteger(); @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r); thread.setDaemon(true); thread.setName(\"thread-pool-\" + counter.getAndIncrement()); return thread; &#125; &#125;, new ThreadPoolExecutor.AbortPolicy()); private Runnable monitor = () -&gt; &#123; //这里需要捕获异常,尽管实际上不会产生异常,但是必须预防异常导致调度线程池线程失效的问题 try &#123; Metrics.gauge(\"thread.pool.core.size\", TAG, executor, ThreadPoolExecutor::getCorePoolSize); Metrics.gauge(\"thread.pool.largest.size\", TAG, executor, ThreadPoolExecutor::getLargestPoolSize); Metrics.gauge(\"thread.pool.max.size\", TAG, executor, ThreadPoolExecutor::getMaximumPoolSize); Metrics.gauge(\"thread.pool.active.size\", TAG, executor, ThreadPoolExecutor::getActiveCount); Metrics.gauge(\"thread.pool.thread.count\", TAG, executor, ThreadPoolExecutor::getPoolSize); // 注意如果阻塞队列使用无界队列这里不能直接取size Metrics.gauge(\"thread.pool.queue.size\", TAG, executor, e -&gt; e.getQueue().size()); &#125; catch (Exception e) &#123; //ignore &#125; &#125;; @Override public void afterPropertiesSet() throws Exception &#123; // 每5秒执行一次 scheduledExecutor.scheduleWithFixedDelay(monitor, 0, 5, TimeUnit.SECONDS); &#125; public void shortTimeWork() &#123; executor.execute(() -&gt; &#123; try &#123; // 5秒 Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; //ignore &#125; &#125;); &#125; public void longTimeWork() &#123; executor.execute(() -&gt; &#123; try &#123; // 500秒 Thread.sleep(5000 * 100); &#125; catch (InterruptedException e) &#123; //ignore &#125; &#125;); &#125; public void clearTaskQueue() &#123; executor.getQueue().clear(); &#125;&#125;//ThreadPoolMonitorControllerimport club.throwable.smp.service.ThreadPoolMonitor;import lombok.RequiredArgsConstructor;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;/** * @author throwable * @version v1.0 * @description * @since 2019/4/7 21:20 */@RequiredArgsConstructor@RestControllerpublic class ThreadPoolMonitorController &#123; private final ThreadPoolMonitor threadPoolMonitor; @GetMapping(value = \"/shortTimeWork\") public ResponseEntity&lt;String&gt; shortTimeWork() &#123; threadPoolMonitor.shortTimeWork(); return ResponseEntity.ok(\"success\"); &#125; @GetMapping(value = \"/longTimeWork\") public ResponseEntity&lt;String&gt; longTimeWork() &#123; threadPoolMonitor.longTimeWork(); return ResponseEntity.ok(\"success\"); &#125; @GetMapping(value = \"/clearTaskQueue\") public ResponseEntity&lt;String&gt; clearTaskQueue() &#123; threadPoolMonitor.clearTaskQueue(); return ResponseEntity.ok(\"success\"); &#125;&#125; 配置如下： 12345678910server: port: 9091management: server: port: 9091 endpoints: web: exposure: include: '*' base-path: /management prometheus的调度Job也可以适当调高频率，这里默认是15秒拉取一次/prometheus端点，也就是会每次提交3个收集周期的数据。项目启动之后，可以尝试调用/management/prometheus查看端点提交的数据： 因为ThreadPoolMonitorSample是我们自定义命名的Tag，看到相关字样说明数据收集是正常的。如果prometheus的Job没有配置错误，在本地的spring-boot项目起来后，可以查下prometheus的后台： OK，完美，可以进行下一步。 grafana面板配置 确保JVM应用和prometheus的调度Job是正常的情况下，接下来重要的一步就是配置grafana面板。如果暂时不想认真学习一下prometheus的PSQL的话，可以从prometheus后台的/graph面板直接搜索对应的样本表达式拷贝进去grafana配置中就行，当然最好还是去看下prometheus的文档系统学习一下怎么编写PSQL。 基本配置： 可视化配置，把右边的标签勾选，宽度尽量调大点： 查询配置，这个是最重要的，最终图表就是靠查询配置展示的： 查询配置具体如下： A：thread_pool_active_size，Legend：-线程池活跃线程数。 B：thread_pool_largest_size，Legend：-线程池历史峰值线程数。 C：thread_pool_max_size，Legend：-线程池容量。 D：thread_pool_core_size，Legend：-线程池核心线程数。 E：thread_pool_thread_count，Legend：-线程池运行中的线程数。 F：thread_pool_queue_size，Legend：-线程池积压任务数。 最终效果 多调用几次例子中提供的几个接口，就能得到一个监控线程池呈现的图表： 小结 针对线程池ThreadPoolExecutor的各项数据进行监控，有利于及时发现使用线程池的接口的异常，如果想要快速恢复，最有效的途径是：清空线程池中任务队列中积压的任务。具体的做法是：可以把ThreadPoolExecutor委托到IOC容器管理，并且把ThreadPoolExecutor的任务队列清空的方法暴露成一个REST端点即可。像HTTP客户端的连接池如Apache-Http-Client或者OkHttp等的监控，可以用类似的方式实现，数据收集的时候可能由于加锁等原因会有少量的性能损耗，不过这些都是可以忽略的，如果真的怕有性能影响，可以尝试用反射API直接获取ThreadPoolExecutor实例内部的属性值，这样就可以避免加锁的性能损耗。 (本文完 c-2-d 20190414)","categories":[{"name":"Framework","slug":"Framework","permalink":"http://throwable.club/blog/categories/Framework/"},{"name":"Micrometer","slug":"Framework/Micrometer","permalink":"http://throwable.club/blog/categories/Framework/Micrometer/"}],"tags":[{"name":"Framework","slug":"Framework","permalink":"http://throwable.club/blog/tags/Framework/"},{"name":"Micrometer","slug":"Micrometer","permalink":"http://throwable.club/blog/tags/Micrometer/"}]},{"title":"JUC同步器框架AbstractQueuedSynchronizer源码图文分析","slug":"java-juc-aqs-source-code","date":"2019-04-07T04:06:01.000Z","updated":"2019-06-09T03:54:33.024Z","comments":true,"path":"2019/04/07/java-juc-aqs-source-code/","link":"","permalink":"http://throwable.club/2019/04/07/java-juc-aqs-source-code/","excerpt":"前提 Doug Lea大神在编写JUC(java.util.concurrent)包的时候引入了java.util.concurrent.locks.AbstractQueuedSynchronizer，Abstract Queued Synchronizer，也就是&quot;基于队列实现的抽象同步器&quot;，一般我们称之为AQS。其实Doug Lea大神编写AQS是有严谨的理论基础的，他的个人博客上有一篇论文《The java.util.concurrent Synchronizer Framework》，文章在http://ifeve.com上可以找到相关的译文(《JUC同步器框架》)，如果想要深入研究AQS必须要理解一下该论文的内容，然后详细分析一下AQS的源码实现。本文在阅读AQS源码的时候选用的JDK版本是JDK11。 AQS的主要功能 AQS是JUC包中用于构建锁或者其他同步组件(信号量、事件等)的基础框架类。AQS从它的实现上看主要提供了下面的功能： 同步状态的原子性管理。 线程的阻塞和解除阻塞。 提供阻塞线程的存储队列。 基于这三大功能，衍生出下面的附加功能： 通过中断实现的任务取消，基于线程中断实现。 可选的超时设置，也就是调用者可以选择放弃等待。 定义了Condition接口，用于支持管程形式的await/signal/signalAll操作，代替了Object类基于JNI提供的wait/notify/notifyAll。 AQS还根据同步状态的不同管理方式区分为两种不同的实现：独占状态的同步器和共享状态的同步器。","text":"前提 Doug Lea大神在编写JUC(java.util.concurrent)包的时候引入了java.util.concurrent.locks.AbstractQueuedSynchronizer，Abstract Queued Synchronizer，也就是&quot;基于队列实现的抽象同步器&quot;，一般我们称之为AQS。其实Doug Lea大神编写AQS是有严谨的理论基础的，他的个人博客上有一篇论文《The java.util.concurrent Synchronizer Framework》，文章在http://ifeve.com上可以找到相关的译文(《JUC同步器框架》)，如果想要深入研究AQS必须要理解一下该论文的内容，然后详细分析一下AQS的源码实现。本文在阅读AQS源码的时候选用的JDK版本是JDK11。 AQS的主要功能 AQS是JUC包中用于构建锁或者其他同步组件(信号量、事件等)的基础框架类。AQS从它的实现上看主要提供了下面的功能： 同步状态的原子性管理。 线程的阻塞和解除阻塞。 提供阻塞线程的存储队列。 基于这三大功能，衍生出下面的附加功能： 通过中断实现的任务取消，基于线程中断实现。 可选的超时设置，也就是调用者可以选择放弃等待。 定义了Condition接口，用于支持管程形式的await/signal/signalAll操作，代替了Object类基于JNI提供的wait/notify/notifyAll。 AQS还根据同步状态的不同管理方式区分为两种不同的实现：独占状态的同步器和共享状态的同步器。 JUC同步器框架原理 《The java.util.concurrent Synchronizer Framework》一文中其实有提及到同步器框架的伪代码： 123456789101112// acquire操作如下：while (synchronization state does not allow acquire) &#123; enqueue current thread if not already queued; possibly block current thread;&#125;dequeue current thread if it was queued;//release操作如下：update synchronization state;if (state may permit a blocked thread to acquire)&#123; unblock one or more queued threads;&#125; 翻译一下： 1234567891011121314// acquire操作如下：while(同步状态申请获取失败)&#123; if(当前线程未进入等待队列)&#123; 当前线程放入等待队列; &#125; 尝试阻塞当前线程;&#125;当前线程移出等待队列//release操作如下：更新同步状态if(同步状态足够允许一个阻塞的线程申请获取)&#123; 解除一个或者多个等待队列中的线程的阻塞状态;&#125; 为了实现上述操作，需要下面三个基本组件的相互协作： 同步状态的原子性管理。 等待队列的管理。 线程的阻塞与解除阻塞。 其实基本原理很简单，但是为了应对复杂的并发场景和并发场景下程序执行的正确性，同步器框架在上面的acquire操作和release操作中使用了死循环和CAS等操作，很多时候会让人感觉逻辑过于复杂。 同步状态管理 AQS内部内部定义了一个32位整型的state变量用于保存同步状态： 12345678910111213141516171819/** * The synchronization state. */private volatile int state;// 获取stateprotected final int getState() &#123; return state;&#125;// 直接覆盖设置stateprotected final void setState(int newState) &#123; state = newState;&#125;// CAS设置stateprotected final boolean compareAndSetState(int expect, int update) &#123; return STATE.compareAndSet(this, expect, update);&#125; 同步状态state在不同的实现中可以有不同的作用或者表示意义，它可以代表资源数、锁状态等等，遇到具体的场景我们再分析它表示的意义。 CLH队列变体 CLH锁即Craig, Landin, and Hagersten (CLH) locks，因为它底层是基于队列实现，一般也称为CLH队列锁。CLH锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程仅仅在本地变量上自旋，它不断轮询前驱的状态，假设发现前驱释放了锁就结束自旋。从实现上看，CLH锁是一种自旋锁，能确保无饥饿性，提供先来先服务的公平性。先看简单的CLH锁的一个简单实现： 123456789101112131415161718192021222324252627282930313233343536public class CLHLock implements Lock &#123; AtomicReference&lt;QueueNode&gt; tail = new AtomicReference&lt;&gt;(new QueueNode()); ThreadLocal&lt;QueueNode&gt; pred; ThreadLocal&lt;QueueNode&gt; current; public CLHLock() &#123; current = ThreadLocal.withInitial(QueueNode::new); pred = ThreadLocal.withInitial(() -&gt; null); &#125; @Override public void lock() &#123; QueueNode node = current.get(); node.locked = true; QueueNode pred = tail.getAndSet(node); this.pred.set(pred); while (pred.locked) &#123; &#125; &#125; @Override public void unlock() &#123; QueueNode node = current.get(); node.locked = false; current.set(this.pred.get()); &#125; static class QueueNode &#123; boolean locked; &#125; // 忽略其他接口方法的实现&#125; 上面是一个简单的CLH队列锁的实现，内部类QueueNode只使用了一个简单的布尔值locked属性记录了每个线程的状态，如果该属性为true，则相应的线程要么已经获取到锁，要么正在等待锁，如果该属性为false，则相应的线程已经释放了锁。新来的想要获取锁的线程必须对tail属性调用getAndSet()方法，使得自身成为队列的尾部，同时得到一个指向前驱节点的引用pred，最后线程所在节点在其前驱节点的locked属性上自旋，值得前驱节点释放锁。上面的实现是无法运行的，因为一旦自旋就会进入死循环导致CPU飙升，可以尝试使用下面将要提到的LockSupport进行改造。 CLH队列锁本质是使用队列(实际上是单向链表)存放等待获取锁的线程，等待的线程总是在其所在节点的前驱节点的状态上自旋，直到前驱节点释放资源。从实际来看，过度自旋带来的CPU性能损耗比较大，并不是理想的线程等待队列实现。 基于原始的CLH队列锁中提供的等待队列的基本原理，AQS实现一种了CLH锁队列的变体(variant)。AQS类的protected修饰的构造函数里面有一大段注释用于说明AQS实现的等待队列的细节事项，这里列举几点重要的： AQS实现的等待队列没有直接使用CLH锁队列，但是参考了其设计思路，等待节点会保存前驱节点中线程的信息，内部也会维护一个控制线程阻塞的状态值。 每个节点都设计为一个持有单独的等待线程并且&quot;带有具体的通知方式&quot;的监视器，这里所谓通知方式就是自定义唤醒阻塞线程的方式而已。 一个线程是等待队列中的第一个等待节点的持有线程会尝试获取锁，但是并不意味着它一定能够获取锁成功(这里的意思是存在公平和非公平的实现)，获取失败就要重新等待。 等待队列中的节点通过prev属性连接前驱节点，通过next属性连接后继节点，简单来说，就是双向链表的设计。 CLH队列本应该需要一个虚拟的头节点，但是在AQS中没有直接提供虚拟的头节点，而是延迟到第一次竞争出现的时候懒创建虚拟的头节点(其实也会创建尾节点，初始化时头尾节点是同一个节点)。 Condition(条件)等待队列中的阻塞线程使用的是相同的Node结构，但是提供了另一个链表用来存放，Condition等待队列的实现比非Condition等待队列复杂。 线程阻塞与唤醒 线程的阻塞和唤醒在JDK1.5之前，一般只能依赖于Object类提供的wait()、notify()和notifyAll()方法，它们都是JNI方法，由JVM提供实现，并且它们必须运行在获取监视器锁的代码块内(synchronized代码块中)，这个局限性先不谈性能上的问题，代码的简洁性和灵活性是比较低的。JDK1.5引入了LockSupport类，底层是基于Unsafe类的park()和unpark()方法，提供了线程阻塞和唤醒的功能，它的机制有点像只有一个允许使用资源的信号量java.util.concurrent.Semaphore，也就是一个线程只能通过park()方法阻塞一次，只能调用unpark()方法解除调用阻塞一次，线程就会唤醒(多次调用unpark()方法也只会唤醒一次)，可以想象是内部维护了一个0-1的计数器。 LockSupport类如果使用得好，可以提供更灵活的编码方式，这里举个简单的使用例子： 123456789101112131415161718192021222324252627282930313233343536public class LockSupportMain implements Runnable &#123; private static final DateTimeFormatter FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss.SSS\"); private Thread thread; private void setThread(Thread thread) &#123; this.thread = thread; &#125; public static void main(String[] args) throws Exception &#123; LockSupportMain main = new LockSupportMain(); Thread thread = new Thread(main, \"LockSupportMain\"); main.setThread(thread); thread.start(); Thread.sleep(2000); main.unpark(); Thread.sleep(2000); &#125; @Override public void run() &#123; System.out.println(String.format(\"%s-步入run方法,线程名称:%s\", FORMATTER.format(LocalDateTime.now()), Thread.currentThread().getName())); LockSupport.park(); System.out.println(String.format(\"%s-解除阻塞,线程继续执行,线程名称:%s\", FORMATTER.format(LocalDateTime.now()), Thread.currentThread().getName())); &#125; private void unpark() &#123; LockSupport.unpark(thread); &#125;&#125;// 某个时刻的执行结果如下：2019-02-25 00:39:57.780-步入run方法,线程名称:LockSupportMain2019-02-25 00:39:59.767-解除阻塞,线程继续执行,线程名称:LockSupportMain LockSupport类park()方法也有带超时的变体版本方法，有些适合使用阻塞超时的场景不妨可以使用。 独占线程的保存 AbstractOwnableSynchronizer是AQS的父类，一个同步器框架有可能在一个时刻被某一个线程独占，AbstractOwnableSynchronizer就是为所有的同步器实现和锁相关实现提供了基础的保存、获取和设置独占线程的功能，这个类的源码很简单： 1234567891011121314151617public abstract class AbstractOwnableSynchronizer implements java.io.Serializable &#123; private static final long serialVersionUID = 3737899427754241961L; protected AbstractOwnableSynchronizer() &#123; &#125; private transient Thread exclusiveOwnerThread; protected final void setExclusiveOwnerThread(Thread thread) &#123; exclusiveOwnerThread = thread; &#125; protected final Thread getExclusiveOwnerThread() &#123; return exclusiveOwnerThread; &#125;&#125; 它就提供了一个保存独占线程的变量对应的Setter和Getter方法，方法都是final修饰的，子类只能使用不能覆盖。 CLH队列变体的实现 这里先重点分析一下AQS中等待队列的节点AQS$Node的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081static final class Node &#123; // 标记一个节点处于共享模式下的等待 static final Node SHARED = new Node(); // 标记一个节点处于独占模式下的等待 static final Node EXCLUSIVE = null; // 取消状态 static final int CANCELLED = 1; // 唤醒状态 static final int SIGNAL = -1; // 条件等待状态 static final int CONDITION = -2; // 传播状态 static final int PROPAGATE = -3; // 等待状态，初始值为0，其他可选值是上面的4个值 volatile int waitStatus; // 当前节点前驱节点的引用 volatile Node prev; // 当前节点后继节点的引用 volatile Node next; // 当前节点持有的线程，可能是阻塞中等待唤醒的线程 volatile Thread thread; // 下一个等待节点 Node nextWaiter; // 当前操作的节点是否处于共享模式 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; // 获取当前节点的前驱节点，确保前驱节点必须存在，否则抛出NPE final Node predecessor() &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; // 空节点，主要是首次创建队列的时候创建的头和尾节点使用 Node() &#123;&#125; // 设置下一个等待节点，设置持有线程为当前线程 Node(Node nextWaiter) &#123; this.nextWaiter = nextWaiter; THREAD.set(this, Thread.currentThread()); &#125; // 设置waitStatus，设置持有线程为当前线程 Node(int waitStatus) &#123; WAITSTATUS.set(this, waitStatus); THREAD.set(this, Thread.currentThread()); &#125; // CAS更新waitStatus final boolean compareAndSetWaitStatus(int expect, int update) &#123; return WAITSTATUS.compareAndSet(this, expect, update); &#125; // CAS设置后继节点 final boolean compareAndSetNext(Node expect, Node update) &#123; return NEXT.compareAndSet(this, expect, update); &#125; // 设置前驱节点 final void setPrevRelaxed(Node p) &#123; PREV.set(this, p); &#125; // 下面是变量句柄的实现，在VarHandle出现之前使用的是Unsafe，其实底层还是照样使用Unsafe private static final VarHandle NEXT; private static final VarHandle PREV; private static final VarHandle THREAD; private static final VarHandle WAITSTATUS; static &#123; try &#123; MethodHandles.Lookup l = MethodHandles.lookup(); NEXT = l.findVarHandle(Node.class, \"next\", Node.class); PREV = l.findVarHandle(Node.class, \"prev\", Node.class); THREAD = l.findVarHandle(Node.class, \"thread\", Thread.class); WAITSTATUS = l.findVarHandle(Node.class, \"waitStatus\", int.class); &#125; catch (ReflectiveOperationException e) &#123; throw new ExceptionInInitializerError(e); &#125; &#125; &#125; 其中，变量句柄(VarHandle)是JDK9引用的新特性，其实底层依赖的还是Unsafe的方法，总体和JDK8的实现是基本一致。这里需要关注一下Node里面的几个属性： waitStatus：当前Node实例的等待状态，可选值有5个。 初始值整数0：当前节点如果不指定初始化状态值，默认值就是0，侧面说明节点正在等待队列中处于等待状态。 Node#CANCELLED整数值1：表示当前节点实例因为超时或者线程中断而被取消，等待中的节点永远不会处于此状态，被取消的节点中的线程实例不会阻塞。 Node#SIGNAL整数值-1：表示当前节点的后继节点是(或即将是)阻塞的(通过park)，当它释放或取消时，当前节点必须unpark它的后继节点。 Node#CONDITION整数值-2：表示当前节点是条件队列中的一个节点，当它转换为同步队列中的节点的时候，状态会被重新设置为0。 Node#PROPAGATE整数值-3：此状态值通常只设置到调用了doReleaseShared()方法的头节点，确保releaseShared()方法的调用可以传播到其他的所有节点，简单理解就是共享模式下节点释放的传递标记。 prev、next：当前Node实例的前驱节点引用和后继节点引用。 thread：当前Node实例持有的线程实例引用。 nextWaiter：这个值是一个比较容易令人生疑的值，虽然表面上它称为&quot;下一个等待的节点&quot;，但是实际上它有三种取值的情况。 值为静态实例Node.EXCLUSIVE(也就是null)，代表当前的Node实例是独占模式。 值为静态实例Node.SHARED，代表当前的Node实例是共享模式。 值为非Node.EXCLUSIVE和Node.SHARED的其他节点实例，代表Condition等待队列中当前节点的下一个等待节点。 Node类的等待状态waitStatus理解起来是十分费劲的，下面分析其他源码的时候会标识此状态变化的时机。 其实上面的Node类可以直接拷贝出来当成一个新建的类，然后尝试构建一个双向链表自行调试，这样子就能深刻它的数据结构。例如： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class AqsNode &#123; static final AqsNode SHARED = new AqsNode(); static final AqsNode EXCLUSIVE = null; static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; volatile int waitStatus; volatile AqsNode prev; volatile AqsNode next; volatile Thread thread; AqsNode nextWaiter; final boolean isShared() &#123; return nextWaiter == SHARED; &#125; final AqsNode predecessor() &#123; AqsNode p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; AqsNode() &#123; &#125; AqsNode(AqsNode nextWaiter) &#123; this.nextWaiter = nextWaiter; THREAD.set(this, Thread.currentThread()); &#125; AqsNode(int waitStatus) &#123; WAITSTATUS.set(this, waitStatus); THREAD.set(this, Thread.currentThread()); &#125; final boolean compareAndSetWaitStatus(int expect, int update) &#123; return WAITSTATUS.compareAndSet(this, expect, update); &#125; final boolean compareAndSetNext(AqsNode expect, AqsNode update) &#123; return NEXT.compareAndSet(this, expect, update); &#125; final void setPrevRelaxed(AqsNode p) &#123; PREV.set(this, p); &#125; private static final VarHandle NEXT; private static final VarHandle PREV; private static final VarHandle THREAD; private static final VarHandle WAITSTATUS; static &#123; try &#123; MethodHandles.Lookup l = MethodHandles.lookup(); NEXT = l.findVarHandle(AqsNode.class, \"next\", AqsNode.class); PREV = l.findVarHandle(AqsNode.class, \"prev\", AqsNode.class); THREAD = l.findVarHandle(AqsNode.class, \"thread\", Thread.class); WAITSTATUS = l.findVarHandle(AqsNode.class, \"waitStatus\", int.class); &#125; catch (ReflectiveOperationException e) &#123; throw new ExceptionInInitializerError(e); &#125; &#125; public static void main(String[] args) throws Exception &#123; AqsNode head = new AqsNode(); AqsNode next = new AqsNode(AqsNode.EXCLUSIVE); head.next = next; next.prev = head; AqsNode tail = new AqsNode(AqsNode.EXCLUSIVE); next.next = tail; tail.prev = next; List&lt;Thread&gt; threads = new ArrayList&lt;&gt;(); for (AqsNode node = head; node != null; node = node.next) &#123; threads.add(node.thread); &#125; System.out.println(threads); &#125;&#125;// 某次执行的输出：[null, Thread[main,5,main], Thread[main,5,main]] 实际上，AQS中一共存在两种等待队列，其中一种是普通的同步等待队列，这里命名为Sync-Queue，另一种是基于Sync-Queue实现的条件等待队列，这里命名为Condition-Queue。 Sync-Queue 前面已经介绍完AQS的同步等待队列节点类，下面重点分析一下同步等待队列的相关源码，下文的Sync队列、同步队列和同步等待队列是同一个东西。首先，我们通过分析Node节点得知Sync队列一定是双向链表，AQS中有两个瞬时成员变量用来存放头节点和尾节点： 12345678910111213141516171819202122232425262728293031323334353637383940414243// 头节点引用private transient volatile Node head;// 尾节点引用private transient volatile Node tail;// 变量句柄相关，用于CAS操作头尾节点private static final VarHandle STATE;private static final VarHandle HEAD;private static final VarHandle TAIL;static &#123; try &#123; MethodHandles.Lookup l = MethodHandles.lookup(); STATE = l.findVarHandle(AbstractQueuedSynchronizer.class, \"state\", int.class); HEAD = l.findVarHandle(AbstractQueuedSynchronizer.class, \"head\", Node.class); TAIL = l.findVarHandle(AbstractQueuedSynchronizer.class, \"tail\", Node.class); &#125; catch (ReflectiveOperationException e) &#123; throw new ExceptionInInitializerError(e); &#125; // 确保LockSupport类已经初始化 - 这里应该是为了修复之前一个因为LockSupport未初始化导致的BUG Class&lt;?&gt; ensureLoaded = LockSupport.class;&#125;// 初始化同步队列，注意初始化同步队列的时候，头尾节点都是指向同一个新的Node实例private final void initializeSyncQueue() &#123; Node h; if (HEAD.compareAndSet(this, null, (h = new Node()))) tail = h;&#125;// CAS设置同步队列的尾节点private final boolean compareAndSetTail(Node expect, Node update) &#123; return TAIL.compareAndSet(this, expect, update);&#125;// 设置头节点，重点注意这里：传入的节点设置成头节点之后，前驱节点和持有的线程会置为null，这是因为：// 1.头节点一定没有前驱节点。// 2.当节点被设置为头节点，它所在的线程一定是已经解除了阻塞。private void setHead(Node node) &#123; head = node; node.thread = null; node.prev = null;&#125; 当前线程加入同步等待队列和同步等待队列的初始化是同一个方法，前文提到过：同步等待队列的初始化会延迟到第一次可能出现竞争的情况，这是为了避免无谓的资源浪费，具体方法是addWaiter(Node mode)： 12345678910111213141516171819// 添加等待节点到同步等待队列，实际上初始化队列也是这个方法完成的private Node addWaiter(Node mode) &#123; // 基于当前线程创建一个新节点，节点的模式由调用者决定 Node node = new Node(mode); for (;;) &#123; Node oldTail = tail; // 尾节点不为空说明队列已经初始化过，则把新节点加入到链表中，作为新的尾节点，建立和前驱节点的关联关系 if (oldTail != null) &#123; node.setPrevRelaxed(oldTail); if (compareAndSetTail(oldTail, node)) &#123; oldTail.next = node; return node; &#125; &#125; else &#123; // 尾节点为空说明队列尚未初始化过，进行一次初始化操作 initializeSyncQueue(); &#125; &#125;&#125; 在首次调用addWaiter()方法，死循环至少执行两轮再跳出，因为同步队列必须初始化完成后(第一轮循环)，然后再把当前线程所在的新节点实例添加到等待队列中再返回(第二轮循环)当前的节点，这里需要注意的是新加入同步等待队列的节点一定是添加到队列的尾部并且会更新AQS中的tail属性为最新入队的节点实例。 假设我们使用Node.EXCLUSIVE模式入队列，手上有三个线程分别是thread-1、thread-2和thread-3，线程入队的时候都处于阻塞状态，模拟一下依次调用上面的入队方法的同步队列的整个链表的状态。 先是线程thread-1加入等待队列： 接着是线程thread-2加入等待队列： 最后是线程thread-3加入等待队列： 如果仔细研究会发现，如果所有的入队线程都处于阻塞状态的话，新入队的线程总是添加到队列的tail节点，阻塞的线程总是&quot;争抢&quot;着成为head节点，这一点和CLH队列锁的阻塞线程总是基于前驱节点自旋以获取锁的思路是一致的。下面将会分析的独占模式与共享模式，线程加入等待队列都是通过addWaiter()方法。 Condition-Queue 前面已经相对详细地介绍过同步等待队列，在AQS中还存在另外一种相对特殊和复杂的等待队列-条件等待队列。介绍条件等待队列之前，要先介绍java.util.concurrent.locks.Condition接口。 1234567891011121314151617public interface Condition &#123; // 当前线程进入等待状态直到被唤醒或者中断 void await() throws InterruptedException; // 当前线程进入等待状态，不响应中断，阻塞直到被唤醒 void awaitUninterruptibly(); // 当前线程进入等待状态直到被唤醒或者中断，阻塞带时间限制 long awaitNanos(long nanosTimeout) throws InterruptedException; // 当前线程进入等待状态直到被唤醒或者中断，阻塞带时间限制 boolean await(long time, TimeUnit unit) throws InterruptedException; // 当前线程进入等待状态直到被唤醒或者中断，阻塞带时间限制 boolean awaitUntil(Date deadline) throws InterruptedException; // 唤醒单个阻塞线程 void signal(); // 唤醒所有阻塞线程 void signalAll();&#125; Condition可以理解为Object中的wait()、notify()和notifyAll()的替代品，因为Object中的相应方法是JNI(Native)方法，由JVM实现，对使用者而言并不是十分友好(可能需要感知JVM的源码实现)，而Condition是基于数据结构和相应算法实现对应的功能，我们可以从源码上分析其实现。 Condition的实现类是AQS的公有内部类ConditionObject。ConditionObject提供的入队列方法如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class ConditionObject implements Condition, java.io.Serializable &#123; private static final long serialVersionUID = 1173984872572414699L; /** First node of condition queue. */ - 条件队列的第一个节点 private transient Node firstWaiter; /** Last node of condition queue. */ - 条件队列的最后一个节点 private transient Node lastWaiter; // 公有构造函数 public ConditionObject() &#123; &#125; // 添加条件等待节点 private Node addConditionWaiter() &#123; // 这里做一次判断，当前线程必须步入此同步器实例 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 临时节点t赋值为lastWaiter引用 Node t = lastWaiter; // If lastWaiter is cancelled, clean out. // 最后一个节点不为条件等待状态，则是取消状态 if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; // 解除所有取消等待的节点的连接 unlinkCancelledWaiters(); t = lastWaiter; &#125; // 基于当前线程新建立一个条件等待类型的节点 Node node = new Node(Node.CONDITION); // 首次创建Condition的时候，最后一个节点临时引用t为null，则把第一个节点置为新建的节点 if (t == null) firstWaiter = node; else // 已经存在第一个节点，则通过nextWaiter连接新的节点 t.nextWaiter = node; // 最后一个节点的引用更新为新节点的引用 lastWaiter = node; return node; &#125; // 从条件等待队列解除所有取消等待的节点的连接，其实就是所有取消节点移除的操作，涉及到双向链表的断链操作、第一个和最后一个节点的引用更新 private void unlinkCancelledWaiters() &#123; Node t = firstWaiter; Node trail = null; while (t != null) &#123; Node next = t.nextWaiter; // 注意这里等待状态的判断 if (t.waitStatus != Node.CONDITION) &#123; t.nextWaiter = null; if (trail == null) firstWaiter = next; else trail.nextWaiter = next; if (next == null) lastWaiter = trail; &#125; else trail = t; t = next; &#125; &#125; // 当前同步器实例持有的线程是否当前线程(currentThread()) protected boolean isHeldExclusively() &#123; throw new UnsupportedOperationException(); &#125; // 暂时不分析其他方法 &#125; 实际上，Condition的所有await()方法变体都调用addConditionWaiter()添加阻塞线程到条件队列中。我们按照分析同步等待队列的情况，分析一下条件等待队列。正常情况下，假设有2个线程thread-1和thread-2进入条件等待队列，都处于阻塞状态。 先是thread-1进入条件队列： 然后是thread-2进入条件队列： 条件等待队列看起来也并不复杂，但是它并不是单独存在和使用的，一般依赖于同步等待队列，下面的一节分析Condition的实现的时候再详细分析。 独占模式与共享模式 前文提及到，同步器涉及到独占模型和共享模式。下面就针对这两种模式详细分析一下AQS的具体实现源码。 独占模式 AQS同步器如果使用独占(EXCLUSIVE)模式，那么意味着同一个时刻，只有节点所在一个线程获取(acuqire)原子状态status成功，此时该线程可以从阻塞状态解除继续运行，而同步等待队列中的其他节点持有的线程依然处于阻塞状态。独占模式同步器的功能主要由下面的四个方法提供： acquire(int arg)；申请获取arg个原子状态status(申请成功可以简单理解为status = status - arg)。 acquireInterruptibly(int arg)：申请获取arg个原子状态status，响应线程中断。 tryAcquireNanos(int arg, long nanosTimeout)：申请获取arg个原子状态status，带超时的版本。 release(int arg)：释放arg个原子状态status(释放成功可以简单理解为status = status + arg)。 独占模式下，AQS同步器实例初始化时候传入的status值，可以简单理解为&quot;允许申请的资源数量的上限值&quot;，下面的acquire类型的方法暂时称为&quot;获取资源&quot;，而release方法暂时称为&quot;释放资源&quot;。接着我们分析前面提到的四个方法的源码，先看acquire(int arg)： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public final void acquire(int arg) &#123; // 获取资源成功或者新增一个独占类型节点到同步等待队列成功则直接返回，否则中断当前线程 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;// 此方法必须又子类覆盖，用于决定是否获取资源成功protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125;// 中断当前线程static void selfInterrupt() &#123; Thread.currentThread().interrupt();&#125;// 不可中断的独占模式下，同步等待队列中的线程获取资源的方法final boolean acquireQueued(final Node node, int arg) &#123; boolean interrupted = false; try &#123; for (;;) &#123; // 获取新入队节点的前驱节点 final Node p = node.predecessor(); // 前驱节点为头节点并且尝试获取资源成功，也就是每一轮循环都会调用tryAcquire尝试获取资源，除非阻塞或者跳出循环 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 设置新入队节点为头节点，原来的节点会从队列中断开 setHead(node); p.next = null; // help GC return interrupted; // &lt;== 注意，这个位置是跳出死循环的唯一位置 &#125; // 判断是否需要阻塞当前获取资源失败的节点中持有的线程 if (shouldParkAfterFailedAcquire(p, node)) // 阻塞当前线程，如果被唤醒则返回并清空线程的中断标记 interrupted |= parkAndCheckInterrupt(); &#125; &#125; catch (Throwable t) &#123; cancelAcquire(node); if (interrupted) selfInterrupt(); throw t; &#125;&#125;/** * 检查并且更新获取资源失败的节点的状态，返回值决定线程是否需要被阻塞。 * 这个方法是所有循环获取资源方法中信号控制的主要方法 */private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; // 这里记住ws是当前处理节点的前驱节点的等待状态 int ws = pred.waitStatus; if (ws == Node.SIGNAL) // 前驱节点状态设置成Node.SIGNAL成功，等待被release调用释放，后继节点可以安全地进入阻塞状态 return true; if (ws &gt; 0) &#123; // ws大于0只有一种情况Node.CANCELLED，说明前驱节点已经取消获取资源， // 这个时候会把所有这类型取消的前驱节点移除，找到一个非取消的节点重新通过next引用连接当前节点 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // 其他等待状态直接修改前驱节点等待状态为Node.SIGNAL pred.compareAndSetWaitStatus(ws, Node.SIGNAL); &#125; return false;&#125;// 阻塞当前线程，获取并且重置线程的中断标记位private final boolean parkAndCheckInterrupt() &#123; // 这个就是阻塞线程的实现，依赖Unsafe的API LockSupport.park(this); return Thread.interrupted();&#125; 上面的代码虽然看起来能基本理解，但是最好用图推敲一下&quot;空间上的变化&quot;： 接着分析一下release(int arg)的实现： 12345678910111213141516171819202122232425262728293031323334353637// 释放资源public final boolean release(int arg) &#123; // 尝试释放资源 if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125;// 尝试释放资源，独占模式下，尝试通过重新设置status的值从而实现释放资源的功能// 这个方法必须由子类实现protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125;// 解除传入节点(一般是头节点)的第一个后继节点的阻塞状态，当前处理节点的等待状态会被CAS更新为0private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; // 当前处理的节点(一般是头节点)状态小于0则直接CAS更新为0 if (ws &lt; 0) node.compareAndSetWaitStatus(ws, 0); Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 如果节点的第一个后继节点为null或者等待状态大于0(取消)，则从等待队列的尾节点向前遍历， // 找到最后一个不为null，并且等待状态小于等于0的节点 for (Node p = tail; p != node &amp;&amp; p != null; p = p.prev) if (p.waitStatus &lt;= 0) s = p; &#125; // 解除上面的搜索到的节点的阻塞状态 if (s != null) LockSupport.unpark(s.thread);&#125; 接着用上面的图： 上面图中thread-2晋升为头节点的第一个后继节点，等待下一个release()释放资源唤醒之就能晋升为头节点，一旦晋升为头节点也就是意味着可以解除阻塞继续运行。接着我们可以看acquire()的响应中断版本和带超时的版本。先看acquireInterruptibly(int arg)： 1234567891011121314151617181920212223242526272829303132public final void acquireInterruptibly(int arg) throws InterruptedException &#123; // 获取并且清空线程中断标记位，如果是中断状态则直接抛InterruptedException异常 if (Thread.interrupted()) throw new InterruptedException(); // 如果获取资源失败 if (!tryAcquire(arg)) doAcquireInterruptibly(arg);&#125;// 独占模式下响应中断的获取资源方法private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; // 基于当前线程新增一个独占的Node节点进入同步等待队列中 final Node node = addWaiter(Node.EXCLUSIVE); try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC return; &#125; // 获取资源失败进入阻塞状态 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 解除阻塞后直接抛出InterruptedException异常 throw new InterruptedException(); &#125; &#125; catch (Throwable t) &#123; cancelAcquire(node); throw t; &#125;&#125; doAcquireInterruptibly(int arg)方法和acquire(int arg)类似，最大的不同点在于阻塞线程解除阻塞后并不是正常继续运行，而是直接抛出InterruptedException异常。最后看tryAcquireNanos(int arg, long nanosTimeout)的实现： 1234567891011121314151617181920212223242526272829303132333435363738394041// 独占模式下尝试在指定超时时间内获取资源，响应线程中断public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);&#125;// 独占模式下带超时时间限制的获取资源方法private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; // 超时期限小于0纳秒，快速失败 if (nanosTimeout &lt;= 0L) return false; // 超时的最终期限是当前系统时钟纳秒+外部指定的nanosTimeout增量 final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC return true; &#125; // 计算出剩余的超时时间 nanosTimeout = deadline - System.nanoTime(); // 剩余超时时间小于0说明已经超时则取消获取 if (nanosTimeout &lt;= 0L) &#123; cancelAcquire(node); return false; &#125; // 这里会判断剩余超时时间大于1000纳秒的时候才会进行带超时期限的线程阻塞，否则会进入下一轮获取尝试 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; SPIN_FOR_TIMEOUT_THRESHOLD) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; catch (Throwable t) &#123; cancelAcquire(node); throw t; &#125;&#125; tryAcquireNanos(int arg, long nanosTimeout)其实和doAcquireInterruptibly(int arg)类似，它们都响应线程中断，不过tryAcquireNanos()在获取资源的每一轮循环尝试都会计算剩余可用的超时时间，只有同时满足获取失败需要阻塞并且剩余超时时间大于SPIN_FOR_TIMEOUT_THRESHOLD(1000纳秒)的情况下才会进行阻塞。 独占模式的同步器的一个显著特点就是：头节点的第一个有效(非取消)的后继节点，总是尝试获取资源，一旦获取资源成功就会解除阻塞并且晋升为头节点，原来所在节点会移除出同步等待队列，原来的队列长度就会减少1，然后头结点的第一个有效的后继节点继续开始竞争资源。 使用独占模式同步器的主要类库有： 可重入锁ReentrantLock。 读写锁ReentrantReadWriteLock中的写锁WriteLock。 共享模式 共享(SHARED)模式中的&quot;共享&quot;的含义是：同一个时刻，如果有一个节点所在线程获取(acuqire)原子状态status成功，那么它会解除阻塞被唤醒，并且会把唤醒状态传播到所有的后继节点(换言之就是唤醒整个同步等待队列中的所有节点)。共享模式同步器的功能主要由下面的四个方法提供： acquireShared(int arg)；申请获取arg个原子状态status(申请成功可以简单理解为status = status - arg)。 acquireSharedInterruptibly(int arg)：申请获取arg个原子状态status，响应线程中断。 tryAcquireSharedNanos(int arg, long nanosTimeout)：申请获取arg个原子状态status，带超时的版本。 releaseShared(int arg)：释放arg个原子状态status(释放成功可以简单理解为status = status + arg)。 先看acquireShared(int arg)的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384// 共享模式下获取资源public final void acquireShared(int arg) &#123; // 注意tryAcquireShared方法值为整型，只有小于0的时候才会加入同步等待队列 if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125;// 共享模式下尝试获取资源，此方法需要由子类覆盖protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException();&#125;// 共享模式下获取资源和处理同步等待队列的方法private void doAcquireShared(int arg) &#123; // 基于当前线程新建一个标记为共享的新节点 final Node node = addWaiter(Node.SHARED); boolean interrupted = false; try &#123; for (;;) &#123; final Node p = node.predecessor(); // 如果当前节点的前驱节点是头节点 if (p == head) &#123; // 每一轮循环都会调用tryAcquireShared尝试获取资源，除非阻塞或者跳出循环 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; // &lt;= tryAcquireShared方法&gt;=0说明直资源获取成功 // 设置头结点，并且传播获取资源成功的状态，这个方法的作用是确保唤醒状态传播到所有的后继节点 // 然后任意一个节点晋升为头节点都会唤醒其第一个有效的后继节点，起到一个链式释放和解除阻塞的动作 setHeadAndPropagate(node, r); p.next = null; // help GC return; &#125; &#125; // 判断获取资源失败是否需要阻塞，这里会把前驱节点的等待状态CAS更新为Node.SIGNAL if (shouldParkAfterFailedAcquire(p, node)) interrupted |= parkAndCheckInterrupt(); &#125; &#125; catch (Throwable t) &#123; cancelAcquire(node); throw t; &#125; finally &#123; if (interrupted) selfInterrupt(); &#125;&#125;// 设置同步等待队列的头节点，判断当前处理的节点的后继节点是否共享模式的节点，如果共享模式的节点，// propagate大于0或者节点的waitStatus为PROPAGATE则进行共享模式下的释放资源private void setHeadAndPropagate(Node node, int propagate) &#123; // h为头节点的中间变量 Node h = head; // 设置当前处理节点为头节点 setHead(node); // 这个判断条件比较复杂：入参propagate大于0 || 头节点为null || 头节点的状态为非取消 || 再次获取头节点为null || 再次获取头节点不为取消 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; // 当前节点(其实已经成为头节点)的第一个后继节点为null或者是共享模式的节点 if (s == null || s.isShared()) doReleaseShared(); &#125;&#125;// Release action for shared mode：共享模式下的释放资源动作private void doReleaseShared() &#123; for (;;) &#123; Node h = head; // 头节点不为null并且不为尾节点 if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; // 如果头节点等待状态为SIGNAL(-1)则CAS更新它为0，更新成功后唤醒和解除其后继节点的阻塞 if (ws == Node.SIGNAL) &#123; if (!h.compareAndSetWaitStatus(Node.SIGNAL, 0)) continue; // 唤醒头节点的后继节点 unparkSuccessor(h); &#125; // 如果头节点的等待状态为0，则CAS更新它为PROPAGATE(-3) else if (ws == 0 &amp;&amp; !h.compareAndSetWaitStatus(0, Node.PROPAGATE)) continue; &#125; // 头节点没有变更，则跳出循环 if (h == head) break; &#125;&#125; 其实代码的实现和独占模式有很多类似的地方，一个很大的不同点是：共享模式同步器当节点获取资源成功晋升为头节点之后，它会把自身的等待状态通过CAS更新为Node.PROPAGATE，下一个加入等待队列的新节点会把头节点的等待状态值更新回Node.SIGNAL，标记后继节点处于可以被唤醒的状态，如果遇上资源释放，那么这个阻塞的节点就能被唤醒解除阻塞。我们还是画图理解一下，先假设tryAcquireShared(int arg)总是返回小于0的值，入队两个阻塞的线程thread-1和thread-2，然后进行资源释放确保tryAcquireShared(int arg)总是返回大于0的值： 看起来和独占模式下的同步等待队列差不多，实际上真正不同的地方在于有节点解除阻塞和晋升为头节点的过程。因此我们可以先看releaseShared(int arg)的源码： 1234567891011121314// 共享模式下释放资源public final boolean releaseShared(int arg) &#123; // 尝试释放资源成功则调用前面分析过的doReleaseShared以传播唤醒状态和unpark头节点的后继节点 if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125;// 共享模式下尝试释放资源，必须由子类覆盖protected boolean tryReleaseShared(int arg) &#123; throw new UnsupportedOperationException();&#125; releaseShared(int arg)就是在tryReleaseShared(int arg)调用返回true的情况下主动调用一次doReleaseShared()从而基于头节点传播唤醒状态和unpark头节点的后继节点。接着之前的图： 接着看acquireSharedInterruptibly(int arg)的源码实现： 123456789101112131415161718192021222324252627282930// 共享模式下获取资源的方法，响应线程中断public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125;private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC return; &#125; &#125; // 和非响应线程中断的acquireShared方法类似，不过这里解除阻塞之后直接抛出异常InterruptedException if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; catch (Throwable t) &#123; cancelAcquire(node); throw t; &#125;&#125; 最后看tryAcquireSharedNanos(int arg, long nanosTimeout)的源码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 共享模式下获取资源的方法，带超时时间版本public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 注意这里只要tryAcquireShared &gt;= 0或者doAcquireSharedNanos返回true都认为获取资源成功 return tryAcquireShared(arg) &gt;= 0 || doAcquireSharedNanos(arg, nanosTimeout);&#125;private boolean doAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; // 计算超时的最终期限 final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.SHARED); try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC return true; &#125; &#125; //重新计算剩余的超时时间 nanosTimeout = deadline - System.nanoTime(); // 超时的情况下直接取消获取 if (nanosTimeout &lt;= 0L) &#123; cancelAcquire(node); return false; &#125; // 满足阻塞状态并且剩余的超时时间大于阀值1000纳秒则通过LockSupport.parkNanos()阻塞线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; SPIN_FOR_TIMEOUT_THRESHOLD) LockSupport.parkNanos(this, nanosTimeout); // 解除阻塞后判断线程的中断标记并且清空标记位，如果是处于中断状态则抛出InterruptedException if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; catch (Throwable t) &#123; cancelAcquire(node); throw t; &#125;&#125; 共享模式的同步器的一个显著特点就是：头节点的第一个有效(非取消)的后继节点，总是尝试获取资源，一旦获取资源成功就会解除阻塞并且晋升为头节点，原来所在节点会移除出同步等待队列，原来的队列长度就会减少1，重新设置头节点的过程会传播唤醒的状态，简单来说就是唤醒一个有效的后继节点，只要一个节点可以晋升为头节点，它的后继节点就能被唤醒。节点的唤醒顺序遵循类似于FIFO的原则，通俗说就是先阻塞或者阻塞时间最长则先被唤醒。 使用共享模式同步器的主要类库有： 信号量Semaphore。 倒数栅栏CountDownLatch。 Condition的实现 Condition实例的建立是在Lock接口的newCondition()方法，它是锁条件等待的实现，基于作用或者语义可以见Condition接口的相关API注释： Condition是对象监视器锁方法Object#wait()、Object#notify()和Object#notifyAll()的替代实现，对象监视器锁实现锁的时候作用的效果是每个锁对象必须使用多个wait-set(JVM内置的等待队列)，通过Object提供的方法和监视器锁结合使用就能达到Lock的实现效果。如果替换synchronized方法和语句并且结合使用Lock和Condition，就能替换并且达到对象监视器锁的效果。 Condition必须固有地绑定在一个Lock的实现类上，也就是要通过Lock的实例建立Condition实例，而且Condition的方法调用使用必须在Lock的&quot;锁定代码块&quot;中，这一点和synchronized关键字以及Object的相关JNI方法使用的情况十分相似。 前文介绍过Condition接口提供的方法以及Condition队列，也就是条件等待队列，通过PPT画图简单介绍了它的队列节点组成。实际上，条件等待队列需要结合同步等待队列使用，这也刚好对应于前面提到的Condition的方法调用使用必须在Lock的锁定代码块中。听起来很懵逼，我们慢慢分析一下ConditionObject的方法源码就能知道具体的原因。 先看ConditionObject#await()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107// 退出等待后主动进行中断当前线程private static final int REINTERRUPT = 1;// 退出等待后抛出InterruptedException异常private static final int THROW_IE = -1;/** * 可中断的条件等待实现 * 1、当前线程处于中断状态则抛出InterruptedException * 2、保存getState返回的锁状态，并且使用此锁状态调用release释放所有的阻塞线程 * 3、线程加入等待队列进行阻塞，直到signall或者中断 * 4、通过保存getState返回的锁状态调用acquire方法 * 5、第4步中阻塞过程中中断则抛出InterruptedException */public final void await() throws InterruptedException &#123; // 如果线程是中断状态则清空中断标记位并且抛出InterruptedException if (Thread.interrupted()) throw new InterruptedException(); // 当前线程所在的新节点加入条件等待队列 Node node = addConditionWaiter(); // 释放当前AQS中的所有资源返回资源的status保存值，也就是基于status的值调用release(status) - 其实这一步是解锁操作 int savedState = fullyRelease(node); // 初始化中断模式 int interruptMode = 0; // 如果节点新建的节点不位于同步队列中(理论上应该是一定不存在)，则对节点所在线程进行阻塞，第二轮循环理论上节点一定在同步等待队列中 while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); // 处理节点所在线程中断的转换操作 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; // 节点所在线程被唤醒后，如果节点所在线程没有处于中断状态，则以独占模式进行头节点竞争 // 注意这里使用的status是前面释放资源时候返回的保存下来的status if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // 下一个等待节点不空，则从等待队列中移除所有取消的等待节点 if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); // interruptMode不为0则按照中断模式进行不同的处理 if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125;// 释放当前AQS中的所有资源，其实也就是基于status的值调用release(status)// 这一步对于锁实现来说，就是一个解锁操作final int fullyRelease(Node node) &#123; try &#123; int savedState = getState(); if (release(savedState)) return savedState; throw new IllegalMonitorStateException(); &#125; catch (Throwable t) &#123; // 释放失败则标记等待状态为取消 node.waitStatus = Node.CANCELLED; throw t; &#125;&#125;// 传入的节点是否在同步队列中final boolean isOnSyncQueue(Node node) &#123; // 节点等待您状态为CONDITION或者前驱节点为null则返回false if (node.waitStatus == Node.CONDITION || node.prev == null) return false; // 因为等待队列是通过nextWaiter连接，next引用存在说明节点位于同步队列 if (node.next != null) return true; // 从同步队列的尾部向前遍历是否存在传入的节点实例 return findNodeFromTail(node);&#125;// 从同步队列的尾部向前遍历是否存在传入的节点实例private boolean findNodeFromTail(Node node) &#123; for (Node p = tail;;) &#123; if (p == node) return true; if (p == null) return false; p = p.prev; &#125;&#125;// 这是一个很复杂的判断，用了两个三目表达式，作用是如果新建的等待节点所在线程中断，// 则把节点的状态由CONDITION更新为0，并且加入到同步等待队列中，返回THROW_IE中断状态，如果加入同步队列失败，返回REINTERRUPT// 如果新建的等待节点所在线程没有中断，返回0，也就是初始状态的interruptModeprivate int checkInterruptWhileWaiting(Node node) &#123; return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0;&#125;// 节点线程中断取消等待后的转换操作final boolean transferAfterCancelledWait(Node node) &#123; // CAS更新节点的状态由CONDITION更改为0 if (node.compareAndSetWaitStatus(Node.CONDITION, 0)) &#123; // 节点加入同步等待队列 enq(node); return true; &#125; // 这里尝试自旋，直到节点加入同步等待队列成功 while (!isOnSyncQueue(node)) Thread.yield(); return false;&#125;// 等待完毕后报告中断处理，前边的逻辑得到的interruptMode如果为THROW_IE则抛出InterruptedException，如果为REINTERRUPT则中断当前线程private void reportInterruptAfterWait(int interruptMode) throws InterruptedException &#123; if (interruptMode == THROW_IE) throw new InterruptedException(); else if (interruptMode == REINTERRUPT) selfInterrupt();&#125; 其实上面的await()逻辑并不复杂，前提是理解了对象监视器锁那套等待和唤醒的机制(由JVM实现，C语言学得好的可以去看下源码)，这里只是通过算法和数据结构重新进行了一次实现。await()主要使用了两个队列：同步等待队列和条件等待队列。我们先假设有两个线程thread-1和thread-2调用了下面的代码中的process()方法： 123456789101112ReentrantLock lock = new ReentrantLock();Condition condition = lock.newCondition();public void process()&#123; try&#123; lock.lock(); condition.await(); // 省略其他逻辑... &#125;finally&#123; lock.unlock(); &#125;&#125; ReentrantLock使用的是AQS独占模式的实现，因此在调用lock()方法的时候，同步等待队列的一个瞬时快照(假设线程thread-1先加入同步等待队列)可能如下： 接着，线程thread-1所在节点是头节点的后继节点，获取锁成功，它解除阻塞后可以调用await()方法，这个时候会释放同步等待队列中的所有等待节点，也就是线程thread-2所在的节点也被释放，因此线程thread-2也会调用await()方法： 只要有线程能够到达await()方法，那么原来的同步器中的同步等待队列就会释放所有阻塞节点，表现为释放锁，然后这些释放掉的节点会加入到等待队列中，等待队列中的节点也是阻塞的，这个时候只有通过signal()或者signalAll()进行队列元素转移才有机会唤醒阻塞的线程。因此接着看signal()和signalAll()的源码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// 从等待队列中移动一个等待时间最长的线程(如果过存在的话)到锁同步等待队列中public final void signal() &#123; // 判断当前线程是否和独占线程一致，其实就是此操作需要在锁代码块中执行 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first);&#125;// 基于第一个等待节点进行Signal操作private void doSignal(Node first) &#123; do &#123; // 首节点的下一个等待节点为空，说明只剩下一个等待节点 if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; // 当前处理节点从链表从移除 first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);&#125;// 唤醒的转换操作final boolean transferForSignal(Node node) &#123; // CAS更新节点状态由CONDITION到0，更新失败则返回false不唤醒 if (!node.compareAndSetWaitStatus(Node.CONDITION, 0)) return false; // 节点作为新节点重新加入到同步等待队列 Node p = enq(node); int ws = p.waitStatus; // 取消或者更新节点等待状态为SIGNAL的节点需要解除阻塞进行重新同步，这里的操作只针对取消和状态异常的节点 if (ws &gt; 0 || !p.compareAndSetWaitStatus(ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;&#125;// 从等待队列中移动所有等待时间最长的线程(如果过存在的话)到锁同步等待队列中public final void signalAll() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignalAll(first);&#125;// 基于第一个等待节点进行SignalAll操作private void doSignalAll(Node first) &#123; // 置空lastWaiter和firstWaiter lastWaiter = firstWaiter = null; do &#123; // 获取下一个等待节点 Node next = first.nextWaiter; // 当前处理节点从链表从移除 first.nextWaiter = null; // 处理当前节点 transferForSignal(first); // 更新中间引用 first = next; &#125; while (first != null);&#125; 其实signal()或者signalAll()会对取消的节点或者短暂中间状态的节点进行解除阻塞，但是正常情况下，它们的操作结果是把阻塞等待时间最长的一个或者所有节点重新加入到AQS的同步等待队列中。例如，上面的例子调用signal()方法后如下： 这样子，相当于线程thread-1重新加入到AQS同步等待队列中，并且开始竞争头节点，一旦竞争成功，就能够解除阻塞。这个时候从逻辑上看，signal()方法最终解除了对线程thread-1的阻塞。await()的其他变体方法的原理是类似的，这里因为篇幅原因不再展开。这里小结一下Condition的显著特点： 1、同时依赖两个同步等待队列，一个是AQS提供，另一个是ConditionObject提供的。 2、await()方法会释放AQS同步等待队列中的阻塞节点，这些节点会加入到条件队列中进行阻塞。 3、signal()或者signalAll()会把条件队列中的节点重新加入AQS同步等待队列中，并不解除正常节点的阻塞状态。 4、接第3步，这些进入到AQS同步等待队列的节点会重新竞争成为头节点，其实也就是前面分析过的独占模式下的AQS的运作原理。 取消获取资源(cancelAcquire) 新节点加入等待队列失败导致任何类型的异常或者带超时版本的API调用的时候剩余超时时间小于等于零的时候，就会调用cancelAcquire()方法，用于取消该节点对应节点获取资源的操作。 1234567891011121314151617181920212223242526272829303132333435// 取消节点获取资源的操作private void cancelAcquire(Node node) &#123; // 节点为null直接返回 if (node == null) return; // 置空节点持有的线程，因为此时节点线程已经发生中断 node.thread = null; Node pred = node.prev; // 这个循环是为了获取当前节点的上一个不为取消状态的节点，也就是中间如果发生了取消的节点都直接断开 while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // 保存当前节点的上一个不为取消状态的节点的后继节点 Node predNext = pred.next; // 当前节点等待状态更新为CANCELLED node.waitStatus = Node.CANCELLED; // 如果当前节点为尾节点，则直接更新尾节点为当前节点的上一个不为取消状态的节点 if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; // 然后更新该节点的后继节点为null，因为它已经成为新的尾节点 pred.compareAndSetNext(predNext, null); &#125; else &#123; int ws; // 当前节点的上一个不为取消状态的节点已经不是头节点的情况，需要把当前取消的节点从AQS同步等待队列中断开 if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; pred.compareAndSetWaitStatus(ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) pred.compareAndSetNext(predNext, next); &#125; else &#123; // 当前节点的上一个不为取消状态的节点已经是头节点，相当于头节点之后的节点都是取消，需要唤醒当前节点的后继节点 unparkSuccessor(node); &#125; // 节点后继节点设置为自身，那么就不会影响后继节点 node.next = node; &#125;&#125; cancelAcquire()方法有多处调用，主要包括下面的情况： 1、节点线程在阻塞过程中主动中断的情况下会调用。 2、acquire的处理过程发生任何异常的情况下都会调用，包括tryAcquire()、tryAcquireShared()等。 3、新节点加入等待队列失败导致任何类型的异常或者带超时版本的API调用的时候剩余超时时间小于等于零的时候。 cancelAcquire()主要作用是把取消的节点移出同步等待队列，必须时候需要进行后继节点的唤醒。 实战篇 AQS是一个抽象的同步器基础框架，其实我们也可以直接使用它实现一些高级的并发框架。下面基于AQS实现一些非内建的功能，这两个例子来自于AQS的注释中。 metux 大学C语言课程中经常提及到的只有一个资源的metux(互斥区)，也就是说，同一个时刻，只能有一个线程获取到资源，其他获取资源的线程需要阻塞等待到前一个线程释放资源。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public class Metux implements Lock, Serializable &#123; private static class Sync extends AbstractQueuedSynchronizer &#123; @Override protected boolean tryAcquire(int arg) &#123; assert 1 == arg; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; @Override protected boolean tryRelease(int arg) &#123; assert 1 == arg; if (!isHeldExclusively()) &#123; throw new IllegalMonitorStateException(); &#125; setExclusiveOwnerThread(null); setState(0); return true; &#125; public Condition newCondition() &#123; return new ConditionObject(); &#125; public boolean isLocked() &#123; return getState() != 0; &#125; @Override public boolean isHeldExclusively() &#123; return getExclusiveOwnerThread() == Thread.currentThread(); &#125; private void readObject(ObjectInputStream s) throws IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); &#125; &#125; private final Sync sync = new Sync(); @Override public void lock() &#123; sync.acquire(1); &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; @Override public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(time)); &#125; public boolean isLocked() &#123; return sync.isLocked(); &#125; public boolean isHeldByCurrentThread() &#123; return sync.isHeldExclusively(); &#125; @Override public void unlock() &#123; sync.release(1); &#125; @Override public Condition newCondition() &#123; return sync.newCondition(); &#125; public static void main(String[] args) throws Exception &#123; final Metux metux = new Metux(); new Thread(() -&gt; &#123; metux.lock(); System.out.println(String.format(\"%s-thread-1获取锁成功休眠3秒...\", LocalDateTime.now())); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; //ignore &#125; metux.unlock(); System.out.println(String.format(\"%s-thread-1获解锁成功...\", LocalDateTime.now())); return; &#125;, \"thread-1\").start(); new Thread(() -&gt; &#123; metux.lock(); System.out.println(String.format(\"%s-thread-2获取锁成功...\",LocalDateTime.now())); return; &#125;, \"thread-2\").start(); Thread.sleep(Integer.MAX_VALUE); &#125;&#125; 某个时间的某次运行结果如下： 1232019-04-07T11:49:27.858791200-thread-1获取锁成功休眠3秒...2019-04-07T11:49:30.876567-thread-2获取锁成功...2019-04-07T11:49:30.876567-thread-1获解锁成功... 二元栅栏 二元栅栏是CountDownLatch的简化版，只允许一个线程阻塞，由另一个线程负责唤醒。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class BooleanLatch &#123; private static class Sync extends AbstractQueuedSynchronizer &#123; boolean isSignalled() &#123; return getState() != 0; &#125; @Override protected int tryAcquireShared(int ignore) &#123; return isSignalled() ? 1 : -1; &#125; @Override protected boolean tryReleaseShared(int ignore) &#123; setState(1); return true; &#125; &#125; private final Sync sync = new Sync(); public boolean isSignalled() &#123; return sync.isSignalled(); &#125; public void signal() &#123; sync.releaseShared(1); &#125; public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; public static void main(String[] args) throws Exception &#123; BooleanLatch latch = new BooleanLatch(); new Thread(()-&gt; &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; //ignore &#125; latch.signal(); &#125;).start(); System.out.println(String.format(\"[%s]-主线程进入阻塞...\", LocalDateTime.now())); latch.await(); System.out.println(String.format(\"[%s]-主线程进被唤醒...\", LocalDateTime.now())); &#125;&#125; 某个时间的某次运行结果如下： 12[2019-04-07T11:55:12.647816200]-主线程进入阻塞...[2019-04-07T11:55:15.632088]-主线程进被唤醒... 小结 在JUC的重要并发类库或者容器中，AQS起到了基础框架的作用，理解同步器的实现原理，有助于理解和分析其他并发相关类库的实现。这篇文章前后耗费了接近1个月时间编写，DEBUG过程最好使用多线程断点，否则很难模拟真实的情况。AQS里面的逻辑是相对复杂的，很敬佩并发大师Douglas S. Lea如此精巧的类库设计。 参考资料： 《The Art of Multiprocessor Programming》 《The java.util.concurrent Synchronizer Framework》 JDK11相关源码 (本文完 c-a-30-d e-a-20190407 r-a-20190609-修复示意图部分错误问题)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Concurrency","slug":"Java/Concurrency","permalink":"http://throwable.club/blog/categories/Java/Concurrency/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"AQS","slug":"AQS","permalink":"http://throwable.club/blog/tags/AQS/"}]},{"title":"特别教程-CronTrigger教程","slug":"quartz-doc-translation-cron-trigger","date":"2019-03-29T17:42:57.000Z","updated":"2019-07-15T15:57:10.103Z","comments":true,"path":"2019/03/30/quartz-doc-translation-cron-trigger/","link":"","permalink":"http://throwable.club/2019/03/30/quartz-doc-translation-cron-trigger/","excerpt":"","text":"特别教程-CronTrigger教程 介绍 cron表达式是一个已经存在了很长时间的UNIX工具，因此它的调度功能非常强大且已经经过验证。CronTrigger类的功能是基于cron的调度功能实现的。 CronTrigger使用&quot;cron表达式&quot;，可以创建诸如“每周一至周五上午8:00”或“每月最后一个星期五上午1:30”的触发调度时间表(调度计划)。 cron表达式很强大，但是它使用起来也有可能相当混乱(这里大概的意思是说cron的用法相对复杂，容易出错)。本教程旨在解决创建cron表达式的一些谜题，为用户提供一个资源，让他们可以在论坛或邮件列表中提问之前访问这个教程(减少在论坛或者邮件中的提问)。 格式 cron表达式是由空格分隔的6或7个字段组成的字符串。字段可以包含任何允许的值，以及该字段允许的特殊字符的各种组合。这些字段如下所示： 字段名称 是否必须 允许的值 允许的特殊字符 秒种(Seconds) 是 0-59 , - * / 分钟(Minutes) 是 0-59 , - * / 小时(Hours) 是 0-23 , - * / 日(Day of month) 是 1-31 , - * ? / L W 月(Month) 是 1-12 or JAN-DEC , - * / 星期(Day of week) 是 1-7 or SUN-SAT , - * ? / L # 年(Year) 否 empty(也就是不填任何值), 1970-2099 , - * / 译者注：这里可以看出一个cron表达式中年(Year)字段是非必须的，如果不填写此字段可以认为它其实就是*值。 所以cron表达式可以像这样简单：* * * * ? *，或更复杂，如这个例子所示：0/5 14,18,39,52 * ? JAN,MAR,SEP MON-FRI 2002-2010。 特殊字符 *：代表所有值 - 用于选择一个字段中的所有值。例如，分钟字段(Minutes)中的&quot;*&quot;表示 “每分钟”。 ?：代表没有具体的值 - 当你需要定义两个字段中的其中一个，另一个不需要定义id时候就十分有用(其实主要就是用在Day of month和Day of week的互斥关系中)。例如，例如我想我的触发器每月的某一日(例如第十日)触发，但是我不需要关注当天是星期几，因此我只需要把’10’设置在Day of month字段，把’?'设置在Day of week字段即可。可以参阅下面的例子来进一步了解。 -：用于指定范围值。例如Hours字段中的&quot;10-12&quot;表示&quot;10,11和12&quot;小时(就是一个范围值)。 ,：用于指定附加值。例如Day of week字段中的&quot;MON,WED,FRI&quot;表示 “星期一，星期三和星期五”。 /：用于指定增量(格式是：“初始值/增量”)。例如在Seconds字段中&quot;0/15&quot;表示秒数范围取值&quot;0,15,30和45&quot;，Seconds字段中&quot;5/15&quot;表示秒数范围取值&quot;5,20,35和50&quot;。上一个例子说明了，你可以在&quot;/&quot;前取非零值(其实也就是初始值不为0)，例如Day of month字段中&quot;1/3&quot;表示从月份的第一天起每三天(触发一次)。 L：英文单词&quot;last&quot;的缩写，含义和last一致。 W：英文单词&quot;weekday&quot;的缩写，即工作日(星期一到星期五)。 注意： 123'L'和'W'字符可以Day of month字段合并使用，也就是在Day of month字段中使用'LW'，转换为“月份的最后一个工作日”。例如：\"0 0 12 1LW * ?\"表示每个月的最后一个工作日中午12点触发。 #：用于指定月份的&quot;第n个&quot;星期XXX*(格式：n#p，表示月份的第p个星期n，n由1开始，1表示星期日)。例如，Day of week字段的中&quot;6#3&quot;表示该月的第三个星期五(6表示星期五，#3表示第三个星期)。例如：“2#1&quot;表示月份的第一个星期一，“4#5&quot;表示月份的第五个星期三。注意最后这个例子，如果你指定了”#5”，并且月份的星期数不超过5个，那么该月份不会触发任何调度。 注意： 1月份和星期缩写对应的合法字符不区分大小写。例如：MON与mon相同。 例子 这里有一些完整的例子： 表达式 含义 0 0 12 * * ? 每天中午12点（中午）触发 0 15 10 ? * * 每天上午10点15分触发 0 15 10 * * ? 每天上午10点15分触发 0 15 10 * * ? * 每天上午10点15分触发 0 15 10 * * ? 2005 2005年每天上午10点15分触发 0 * 14 * * ? 每天下午2点开始，每天下午2点59分结束 0 0/5 14 * * ? 每天下午2点开始，每天下午2点55分结束，每5分钟触发一次 0 0/5 14,18 * * ? 从下午2点开始，每天5分钟触发，结束于下午2点55分，每天5点钟触发，每天晚上6点开始，结束于下午6点55分 0 0-5 14 * * ? 每天下午2点开始，结束于下午2点05分，每分钟触发 0 10,44 14 ? 3 WED 在3月份的每个星期三下午2点10分和下午2点44分触发 0 15 10 ? * MON-FRI 每周一，周二，周三，周四和周五上午10点15分触发 0 15 10 15 * ? 在每个月的第15天上午10点15分触发 0 15 10 L * ? 在每个月的最后一天上午10点15分触发 0 15 10 L-2 * ? 在每个月的倒数第二天的上午10点15分触发 0 15 10 ? * 6L 每个月的最后一个星期五上午10点15分触发 0 15 10 ? * 6L 2002-2005 2002年，2003年，2004年和2005年每个月的最后一个星期五上午10点15分触发 0 15 10 ? * 6#3 每个月的第三个星期五上午10点15分触发 0 0 12 1/5 * ? 从每月的第一天开始，每个月每隔5天下午12点（中午）触发 0 11 11 11 11 ? 每11月11日上午11点11分触发 注意： 1请注意'?'和'*'在日(Day of month)和星期(Day of week)中的作用。 注意事项 目前不完全支持同时定义Day of week和Day of month两个字段(你必须在这两个字段其中之一使用’?’。其实这样做的目的是这两个字段是互斥的)。 你需要注意如果触发时间设置在凌晨的几个小时，你的语言环境(locale)有可能会因为“夏令时”（对于美国地区，这通常是凌晨2点之前和之后的一个小时）而发生变化 - 此时，时间迁移有可能会发生跳跃或者重复(这里是指同一个时刻重复两次，因为时间发生了回拨)，这取决于时间是向后移动还是向前移动。你可以从维基百科上查找资料确定你所在地区的具体情况，链接是：https://secure.wikimedia.org/wikipedia/en/wiki/Daylight_saving_time_around_the_world 原文链接：crontrigger","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Quartz","slug":"Middleware/Quartz","permalink":"http://throwable.club/blog/categories/Middleware/Quartz/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Quartz","slug":"Quartz","permalink":"http://throwable.club/blog/tags/Quartz/"}]},{"title":"第十二章：其他特性","slug":"quartz-doc-translation-lesson-12","date":"2019-03-29T17:42:40.000Z","updated":"2019-03-30T03:19:02.872Z","comments":true,"path":"2019/03/30/quartz-doc-translation-lesson-12/","link":"","permalink":"http://throwable.club/2019/03/30/quartz-doc-translation-lesson-12/","excerpt":"","text":"第十二章：其他特性 插件 Quartz提供了一个用于插入附加功能的接口org.quartz.spi.SchedulerPlugin。 你可以从org.quartz.plugins包中找到提供各种实用功能的Quartz插件。它们提供诸如在调度器启动时自动调度Job的功能，记录Job和Trigger相关事件的历史，并确保当JVM退出时调度器能够彻底关闭。 Job工厂 当Trigger触发时，通过Scheduler上配置的JobFactory实例化与之关联的Job。默认的JobFactory只是在Job类上(反射)调用newInstance()。你可能需要创建自己的JobFactory实现，以完成诸如让应用程序的IoC或DI容器生成/初始化Job实例等等的操作。 请参阅org.quartz.spi.JobFactory接口以及Scheduler#setJobFactory(fact)等相关方法。 Factory-Shipped Jobs(这个不知道怎么翻译) Quartz还提供了许多实用Job类型，你可以在应用程序中用于执行诸如发送电子邮件和调用EJB等Job实现。这些开箱即用的Job类型可以在org.quartz.jobs包中找到(要引入依赖quartz-jobs)。 原文链接：tutorial-lesson-12","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Quartz","slug":"Middleware/Quartz","permalink":"http://throwable.club/blog/categories/Middleware/Quartz/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Quartz","slug":"Quartz","permalink":"http://throwable.club/blog/tags/Quartz/"}]},{"title":"第十一章：高级(企业级)特性","slug":"quartz-doc-translation-lesson-11","date":"2019-03-29T17:42:36.000Z","updated":"2019-03-30T03:18:18.053Z","comments":true,"path":"2019/03/30/quartz-doc-translation-lesson-11/","link":"","permalink":"http://throwable.club/2019/03/30/quartz-doc-translation-lesson-11/","excerpt":"","text":"第十一章：高级(企业级)特性 集群 Quartz集群目前与JDBC-Jobstore（JobStoreTX或JobStoreCMT）和(&lt;–译者注：其实我觉得这里应该是&quot;或&quot;)TerracottaJobStore一起使用。功能包括负载均衡和Job故障转移（如果JobDetail的“请求恢复(request recovery)”标志设置为true）。 使用JobStoreTX或JobStoreCMT通过将org.quartz.jobStore.isClustered属性设置为true来启用集群模式。**集群中的每个实例都应该使用相同的quartz.properties文件。**这些相同的配置文件中，也允许下面几项属性配置是可以不相同的：不同的线程池大小，以及org.quartz.scheduler.instanceId设置不同的属性值。集群中的每个节点必须具有唯一的instanceId，通过将AUTO作为此属性的值，可以轻松完成此定义（这样就不需要使用不同的配置文件）。下面是注意事项： 1不要在各自独立的机器上各自开启集群模式，除非它们的时钟使用某种形式的时间同步服务（守护进程）进行同步，而这些时间同步服务（守护进程）运行得非常有规律（各个机器的时钟差距必须在一秒内）。 如果你不熟悉如何执行此操作， 请参阅`http://www.boulder.nist.gov/timefreq/service/its.htm`。 1非集群模式下，两个不同的实例千万不要使用同一套Quartz的表。否则，你一定会遇到不正常的(调度)行为，有可能会遭遇严重的数据损坏。 集群中触发机制是：Job每次只能被一个节点触发(也就是虽然集群中每台机器都跑着Quartz的调度器，但是Job需要被触发的时刻只有一台机器会进行触发)。我的意思是，如果Job有一个重复的Trigger，告诉它每10秒钟触发一次，那么在12:00:00，正好一个节点将执行这个Job，在12:00:10，也是由一个节点将执行此Job等。并不一定是每次由相同的节点执行Job - 由哪个节点执行它是随机的。负载均衡机制对于繁忙的调度程序（大量的Trigger）来说是近乎随机的。但是对于非繁忙(只有一两个Trigger)的调度器集群来说，有可能偏向于由同一个节点执行。(译者注：其实从源码上看，主要是看哪个节点先获取到独占锁。) 使用TerracottaJobStore建立Quartz集群只需要将把Scheduler的JobStore配置为TerracottaJobStore（第九章：JobStores中介绍过）即可，然后你的调度器就会被设置为集群模式。 您可能还需要考虑如何设置Terracotta服务器，特别是开启持久化特性等功能的配置选项，以及搭建一些列高可用的Terracotta服务器。 TerracottaJobStore的企业版提供了高级的&quot;Quartz Where&quot;功能，允许将作业的智能定位到适当的Quartz集群节点。 有关JobStore和Terracotta的更多信息，请访问http://www.terracotta.org/quartz。 JTA事务 正如第九章：JobStores所述，JobStoreCMT允许在较大的JTA事务中执行Quartz调度操作。 通过将org.quartz.scheduler.wrapJobExecutionInUserTransaction属性设置为true，Job也可以在JTA事务（UserTransaction）内执行。使用此选项集，一个JTA事务将在Job的execute方法被调用之前调用其begin()方法，并且在Job执行完成调用之后调用其commit()。这适用于所有的Job。 如果你希望指定每个Jobs是否包裹在JTA事务内执行，那么你应该在Job类上使用@ExecuteInJTATransaction注解。 除了Quartz自动将Job执行包装到JTA事务中，使用JobStoreCMT之后在Scheduler接口方法也可以使用事务处理。你可以明确一点：在使用Scheduler接口方法之前已经开启了一个事务。你可以直接通过使用UserTransaction或将使用调度程序的代码放在使用容器管理事务的SessionBean中来执行此操作。 原文链接：tutorial-lesson-11","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Quartz","slug":"Middleware/Quartz","permalink":"http://throwable.club/blog/categories/Middleware/Quartz/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Quartz","slug":"Quartz","permalink":"http://throwable.club/blog/tags/Quartz/"}]},{"title":"第十章：配置、资源的使用以及SchedulerFactory","slug":"quartz-doc-translation-lesson-10","date":"2019-03-29T17:42:32.000Z","updated":"2019-03-30T03:17:00.978Z","comments":true,"path":"2019/03/30/quartz-doc-translation-lesson-10/","link":"","permalink":"http://throwable.club/2019/03/30/quartz-doc-translation-lesson-10/","excerpt":"","text":"第十章：配置、资源的使用以及SchedulerFactory Quartz的架构设计是模块化的，因此要运行它需要把几个组件组合在一起使用。幸运的是，有一些工具就是为了完成这个目标。 Quartz在能够正常运作之前，下面的几个核心组件必须配置好： ThreadPool JobStore DataSources(如果需要的话) Scheduler(调度器本身，这个是核心) 线程池提供了一组Quartz在执行Job时使用的线程。线程池中的线程越多，并发运行的Job数越多。但是，太多的线程可能会破坏你的系统。大多数Quartz的用户发现，5个左右的线程是充足的 - 因为在任何给定时间，他们的Job数量少于100个，通常不会同时运行这些Job，而且这些Job是短暂的（快速完成）。其他用户认为他们需要10个，15个，50个甚至100个线程，因为他们具有数万个具有各种调度计划的Trigger，最终在任何给定时刻平均执行10到100个Job。为调度器的线程池找到正确的线程池大小完全取决于你需要使用调度器来完成什么工作(这里意思应该是需要按照工作量去定义线程池大小)。没有真正的规则，除了保持线程数量尽可能小（为了你昂贵的服务器资源） - 但需要确保线程数量已足够让你的Job按时启动。请注意，如果Trigger的触发时间到达，并且线程池中没有可用的线程，Quartz将阻塞（暂停）直到线程可用，然后Job将执行 - 也就是在它本该执行的时间点延后一个时间段执行。这甚至可能导致线程的错过触发 - 如果在调度器中配置的“错过触发阈值”的持续时间内没有可用的线程。 ThreadPool接口在org.quartz.spi包中定义，你可以按照你喜欢的方式创建ThreadPool实现。Quartz带有一个名为org.quartz.simpl.SimpleThreadPool（虽然简单，但非常令人满意）的线程池。这个ThreadPool只是在它的线程池中维护一个固定的线程集 - 永远不会增长，永远不会缩小。但是它是非常强大的，测试结果令人满意 - 几乎所有使用Quartz的人都使用这个线程池。 JobStores和DataSource在本教程的第九章：JobStores讨论过。值得注意的是，所有JobStore都实现了org.quartz.spi.JobStore接口 - 任何一个JobStore实现都不符合你的需求，那么你可以自己创建并且自行实现org.quartz.spi.JobStore接口。 最后，你需要创建你的Scheduler实例。Scheduler本身需要被赋予一个名字，告诉其RMI设置，并且设置JobStore和ThreadPool的实例。RMI设置包括调度程序是否应将自身创建为RMI的服务器对象（使其可用于远程连接），要使用的主机和端口等。StdSchedulerFactory（下面将讨论）还可以创建Scheduler实例，这些Scheduler实例可以是创建在远程程序中的Scheduler的代理(RMI存根)。 StdSchedulerFactory StdSchedulerFactory是org.quartz.SchedulerFactory接口的一个实现。它使用一组属性（java.util.Properties）来创建和初始化Quartz的Scheduler实例。属性通常存储在文件中并从文件中加载，但也可以由程序创建并直接传递到工厂类实例。简单地调用工厂中的getScheduler()将生成Scheduler实例，并初始化它（和它的ThreadPool，JobStore和DataSource）并返回一个公共接口org.quartz.Scheduler的句柄。 在Quartz发行版的&quot;docs/config&quot;目录中有一些示例配置（包括属性的描述）。你可以在Quartz文档的“参考”部分的“配置”手册中找到完整的文档。 DirectSchedulerFactory DirectSchedulerFactory是另一个SchedulerFactory实现。对于希望编程式创建其Scheduler实例的用户是有用的。通常不鼓励使用它，原因如下： （1）DirectSchedulerFactory要求用户更好地了解他们正在做什么。 （2）它不允许声明性配置(不能使用配置文件) - 换句话说，你需要硬编码Scheduler实例的所有属性项。 日志 Quartz使用SLF4J框架来满足所有的日志记录需求。为了“调整”日志记录设置（例如输出量以及输出位置），你需要了解SLF4J框架，这超出了本文档的范围。 如果需要捕获Trigger启动和Job执行的额外信息，可以启用org.quartz.plugins.history.LoggingJobHistoryPlugin或org.quartz.plugins.history.LoggingTriggerHistoryPlugin。 原文链接：tutorial-lesson-10","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Quartz","slug":"Middleware/Quartz","permalink":"http://throwable.club/blog/categories/Middleware/Quartz/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Quartz","slug":"Quartz","permalink":"http://throwable.club/blog/tags/Quartz/"}]},{"title":"第九章：JobStores","slug":"quartz-doc-translation-lesson-9","date":"2019-03-29T17:42:29.000Z","updated":"2019-03-30T03:14:52.702Z","comments":true,"path":"2019/03/30/quartz-doc-translation-lesson-9/","link":"","permalink":"http://throwable.club/2019/03/30/quartz-doc-translation-lesson-9/","excerpt":"","text":"第九章：JobStores JobStore负责记录你提供到调度器的所有“工作数据”：所有的Job、所有的Trigger、所有的Calendar(org.quartz.Calendar)等等。为你的Quartz调度器选择一个合适的JobStore是一个重要的步骤。幸运的是，一旦你明白不同的JobStore之间的差异，那么作出合适的选择是十分简单的。 你声明你提供给用于生成调度器实例对应的SchedulerFactory实例时候用到的属性文件（或对象）中，应该指定你的调度器应使用哪个类型的JobStore（以及它的相关配置）。注意一点： 1切勿在代码中直接使用JobStore实例。由于某些原因，许多使用者试图这样做。JobStore应该只用于Quartz的后台。你必须告诉Quartz（通过配置）使用哪个类型的JobStore，你在代码中应该只能使用Scheduler接口。 RAMJobStore RAMJobStore是使用最简单的JobStore，它也是性能最高的（在CPU时间方面）。RAMJobStore的功能显然和它的名字相关：它将其所有数据保存在RAM(内存)中，这就是为什么它是闪电般的快，也是为什么它的的配置这么简单。缺点是当你的应用程序结束（或崩溃）时，所有调度信息都将丢失 - 这意味着RAMJobStore无法履行作业和Trigger上的“非易失性”设置。对于某些应用程序，这是可以接受的 - 甚至是所需的行为，但对于其他应用程序，这可能是灾难性的。 要使用RAMJobStore（并假设您使用的是StdSchedulerFactory），只需将Quartz的JobStore类属性配置指定为org.quartz.simpl.RAMJobStore： 1org.quartz.jobStore.class = org.quartz.simpl.RAMJobStore 除此之外没有其他需要担心的配置项。 JDBCJobStore JDBCJobStore的命名也相当恰当 - 它通过JDBC将其所有数据保存在数据库中。因此，它配置比RAMJobStore要复杂一点，而且也不是那么快。但是，它性能下降并不是很糟糕，特别是如果你使用的数据库表在相应的主键或者外键加上索引。在相对主流的并且有一个像样的局域网（在调度器和数据库之间）的机器上，检索和更新一个触发中的Trigger的时间通常将小于10毫秒。 JDBCJobStore几乎可以在任何类型的任何数据库中使用，已被广泛应用于Oracle，PostgreSQL，MySQL，MS SQLServer，HSQLDB和DB2。要使用JDBCJobStore，必须首先创建一组数据库表以供Quartz使用。你可以在Quartz发行版的&quot;docs/dbTables&quot;目录中找到表创建SQL脚本。如果你的数据库类型尚未有脚本，请查看其中一个脚本，然后以数据库所需的任何方式进行修改。需要注意的一点是，在这些脚本中，所有的表都以前缀&quot;QRTZ_“开始（如表&quot;QRTZ_TRIGGERS&quot;和&quot;QRTZ_JOB_DETAIL”）。你可以通知JDBCJobStore表的前缀是什么（在你的Quartz属性配置中），也就是你也可以修改这个表前缀的值。对于多个调度程序实例，使用不同的前缀可能有助于同一个数据库中的多个调度器实例创建多组表。 创建表后，在配置和启动JDBCJobStore之前，你还有一个重要的决定。你需要确定应用程序需要哪种类型的事务。如果你不需要将调度命令（例如添加和删除Trigger）绑定到其他代码逻辑的事务中，那么可以通过使用JobStoreTX对JobStore进行事务管理（这是最常见的选择）。 如果你需要Quartz与其他事务（即J2EE应用程序服务器）一起工作，那么你应该使用JobStoreCMT - 在这种情况下，Quartz将让应用程序服务器容器管理事务。 最后一个难题是设置一个DataSource，使得JDBCJobStore可以从中获取数据库的连接。定义Quartz的DataSource有下面的几种方式。一种方法是让Quartz创建和管理DataSource本身 - 通过提供数据库的所有连接信息。另一种方法是通过提供JDBCJobStore的DataSource的JNDI名称，让Quartz使用由Quartz正在运行的应用程序服务器来管理DataSource。有关属性的详细信息，请参阅发行版本中&quot;docs/config&quot;文件夹中的示例配置文件。 要使用JDBCJobStore（假设你使用的是StdSchedulerFactory），首先需要将Quartz配置文件中的的JobStore类属性设置为org.quartz.impl.jdbcjobstore.JobStoreTX或org.quartz.impl.jdbcjobstore.JobStoreCMT - 具体可以参考上一段文字的描述，不过决定权还是在你手中。 配置Quartz以使用JobStoreTx： 1org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX 接下来，你需要为JobStore选择一个DriverDelegate。DriverDelegate负责执行特定数据库可能需要的任何JDBC相关的工作。StdJDBCDelegate是一个使用“vanilla(原意识香草味的，这里大概的意思是原生的)”JDBC代码（和SQL语句）来工作的。如果Quartz没有为你的数据库类型提供特定的DriverDelegate，请尝试使用此DriverDelegate - 我们仅仅为那些使用StdJDBCDelegate(几乎是最常使用)出现了问题的数据库类型提供了特殊的订造的DriverDelegate。其他DriverDelegate可以在&quot;org.quartz.impl.jdbcjobstore&quot;包或其子包中找到。其他DriverDelegate包括DB2v6Delegate（用于DB2版本6及更早版本），HSQLDBDelegate（用于HSQLDB），MSSQLDelegate（用于Microsoft SQLServer），PostgreSQLDelegate（用于PostgreSQL）），WeblogicDelegate（用于使用Weblogic创建的JDBC驱动程序）。 一旦你选择了DriverDelegate后，将其类名设置为JDBCJobStore的对应属性以便JDBCJobStore能够使用它。 为JDBCJobStore配置DriverDelegate： 1org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate 接下来，你需要通知JobStore你正在使用的表前缀（如上所述）。 配置JDBCJobStore对应的表前缀： 1org.quartz.jobStore.tablePrefix = QRTZ_ 最后，你需要设置JobStore应该使用哪个DataSource。DataSource的命名也必须在Quartz配置文件中的属性中定义。在这种情况下，我们指定Quartz应该使用DataSource名称&quot;myDS&quot;（在配置属性中的其他位置也是用这个名称去定义）。 配置JDBCJobStore对应的DataSource： 1org.quartz.jobStore.dataSource = myDS 注意事项一： 1如果你的调度器一直处于忙碌的状态(满负载)（正在执行的Job数量几乎与线程池大小相同），那么你应该将DataSource中的连接数设置为线程池容量+2。 注意事项二： 1可以将\"org.quartz.jobStore.useProperties\"配置参数设置为\"true\"（默认为false），以指示JDBCJobStore将JobDataMap中的所有值都作为字符串，从而JobDataMap中的属性可以作为键值对存储，而不是使用BLOB类型，因为BLOB类型是为了以其序列化形式存储更多复杂的对象。从长远来看，这是更安全的，因为你避免了将非String类序列化为BLOB类型的版本问题。 TerracottaJobStore TerracottaJobStore提供了一种伸缩性和鲁棒性的手段，它并不使用数据库。这意味着你的数据库可以免受Quartz的负载，可以将数据库所有资源分配给应用程序的其余部分。 TerracottaJobStore可以运行在群集或非群集环境在集群或者非集群环境下，TerracottaJobStore都可以为应用程序的作业数据提供存储介质，即便是应用程序重启的间隙，因为数据是存储在Terracotta服务器中。它的性能比基于使用数据库的JDBCJobStore要好得多（约一个数量级），但比RAMJobStore要慢。 要使用TerracottaJobStore（假设你使用的是StdSchedulerFactory），只需将配置文件中的类名称org.quartz.jobStore.class = org.terracotta.quartz.TerracottaJobStore指定为Quartz的JobStore类属性，并添加一个额外的配置项来指定Terracotta服务器的位置即可： 使用TerracottaJobStore配置Quartz： 12org.quartz.jobStore.class = org.terracotta.quartz.TerracottaJobStoreorg.quartz.jobStore.tcConfigUrl = localhost:9510 更多关于JobStore和Terracotta的内容可以参阅http://www.terracotta.org/quartz。 原文链接：tutorial-lesson-09","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Quartz","slug":"Middleware/Quartz","permalink":"http://throwable.club/blog/categories/Middleware/Quartz/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Quartz","slug":"Quartz","permalink":"http://throwable.club/blog/tags/Quartz/"}]},{"title":"第八章：Scheduler监听器","slug":"quartz-doc-translation-lesson-8","date":"2019-03-29T17:42:23.000Z","updated":"2019-03-30T03:12:30.851Z","comments":true,"path":"2019/03/30/quartz-doc-translation-lesson-8/","link":"","permalink":"http://throwable.club/2019/03/30/quartz-doc-translation-lesson-8/","excerpt":"","text":"第八章：Scheduler监听器 SchedulerListener和TriggerListener或JobListener十分相似，它接收调度器的相关事件，调度器的相关事件不一定和特定的Trigger或者Job相关。 与Scheduler相关的事件包括：添加Job/Trigger、删除Job/Trigger、调度器中的严重错误以及关闭调度器的通知等等。 org.quartz.SchedulerListener接口： 1234567891011121314151617181920212223242526public interface SchedulerListener &#123; public void jobScheduled(Trigger trigger); public void jobUnscheduled(String triggerName, String triggerGroup); public void triggerFinalized(Trigger trigger); public void triggersPaused(String triggerName, String triggerGroup); public void triggersResumed(String triggerName, String triggerGroup); public void jobsPaused(String jobName, String jobGroup); public void jobsResumed(String jobName, String jobGroup); public void schedulerError(String msg, SchedulerException cause); public void schedulerStarted(); public void schedulerInStandbyMode(); public void schedulerShutdown(); public void schedulingDataCleared();&#125; SchedulerListener也是通过ListenerManager注册到调度器。SchedulerListener实例几乎可以是任何实现了org.quartz.SchedulerListener接口的对象(&lt;–译者吐槽：这句话怎么看都觉得有点多余)。 添加SchedulerListener： 1scheduler.getListenerManager().addSchedulerListener(mySchedListener); 删除SchedulerListener： 1scheduler.getListenerManager().removeSchedulerListener(mySchedListener); 原文链接：tutorial-lesson-08","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Quartz","slug":"Middleware/Quartz","permalink":"http://throwable.club/blog/categories/Middleware/Quartz/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Quartz","slug":"Quartz","permalink":"http://throwable.club/blog/tags/Quartz/"}]},{"title":"第七章：Trigger监听器和Job监听器","slug":"quartz-doc-translation-lesson-7","date":"2019-03-29T17:42:16.000Z","updated":"2019-03-30T03:11:08.047Z","comments":true,"path":"2019/03/30/quartz-doc-translation-lesson-7/","link":"","permalink":"http://throwable.club/2019/03/30/quartz-doc-translation-lesson-7/","excerpt":"","text":"第七章：Trigger监听器和Job监听器 监听器（listener）是你创建的对象，主要作用是接收和处理调度器回调的事件(event)。TriggerListener接收到与触发器（Trigger）相关的事件，JobListener接收与调度任务(Job)相关的事件。 与触发器相关的事件包括：触发器正要触发，触发器错失触发，触发器触发完成（调度任务已被触发开始执行，触发器完成当次触发）。 org.quartz.TriggerListener接口： 12345678910111213public interface TriggerListener &#123; public String getName(); public void triggerFired(Trigger trigger, JobExecutionContext context); public boolean vetoJobExecution(Trigger trigger, JobExecutionContext context); public void triggerMisfired(Trigger trigger); public void triggerComplete(Trigger trigger, JobExecutionContext context, int triggerInstructionCode);&#125; 与调度任务相关的事件包括：Job即将执行时的通知以及Job执行完成时的通知。 org.quartz.JobListener接口： 123456789101112public interface JobListener &#123; public String getName(); public void jobToBeExecuted(JobExecutionContext context); public void jobExecutionVetoed(JobExecutionContext context); public void jobWasExecuted(JobExecutionContext context, JobExecutionException jobException);&#125; 使用自定义的监听器 要创建一个Listener，只需创建一个实现org.quartz.TriggerListener或org.quartz.JobListener接口实现的实例。然后，Listener需要在运行时注册到调度器中。Listener必须指定一个名称（通过实现JobListener接口的getName()方法来传入监听器的名字）。 为了方便起见，自定义监听器也可以继承自JobListenerSupport类或TriggerListenerSupport类，并且只需覆盖你感兴趣的方法。 Listener通过调度器的ListenerManager进行注册，可以通过一个匹配器(Matcher)实例去匹配监听你感兴趣的Job或者Trigger。注意下面的事项： 1Listener在运行时才注册到调度器中，并且不与Job或者触发器一起存储在JobStore中。这是因为通常监听器是直接集成到应用程序之中(这里的意思大概是监听器中会有应用程序里面相关的逻辑)。因此每当应用程序启动的时候，所有的监听器需要重新注册到调度器中。 添加匹配的特定Job的JobListener： 1scheduler.getListenerManager().addJobListener(myJobListener, KeyMatcher.jobKeyEquals(new JobKey(\"myJobName\", \"myJobGroup\"))); 你可能需要为匹配器和关键类使用静态导入，这将使你定义匹配器的逻辑更简洁： 1234567import static org.quartz.JobKey.*;import static org.quartz.impl.matchers.KeyMatcher.*;import static org.quartz.impl.matchers.GroupMatcher.*;import static org.quartz.impl.matchers.AndMatcher.*;import static org.quartz.impl.matchers.OrMatcher.*;import static org.quartz.impl.matchers.EverythingMatcher.*;...etc. 使用静态导入后上面的例子变成这样： 1scheduler.getListenerManager().addJobListener(myJobListener, jobGroupEquals(\"myJobGroup\")); 添加对两个特定Group的所有Job感兴趣的JobListener： 1scheduler.getListenerManager().addJobListener(myJobListener, or(jobGroupEquals(\"myJobGroup\"), jobGroupEquals(\"yourGroup\"))); 添加对所有Job感兴趣的JobListener： 1scheduler.getListenerManager().addJobListener(myJobListener, allJobs()); 注册TriggerListener的工作原理和JobListener基本相同。 大多数Quartz的使用者并不使用Listener。但是当应用程序有获取任务调度相关的事件通知的需求时，如果使用了Listener可以避免在Job的逻辑里面加入额外的通知逻辑，这一点对于使用者而言是很方便的。 原文链接：tutorial-lesson-07","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Quartz","slug":"Middleware/Quartz","permalink":"http://throwable.club/blog/categories/Middleware/Quartz/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Quartz","slug":"Quartz","permalink":"http://throwable.club/blog/tags/Quartz/"}]},{"title":"第六章：CronTrigger","slug":"quartz-doc-translation-lesson-6","date":"2019-03-29T17:42:12.000Z","updated":"2019-03-30T03:07:32.697Z","comments":true,"path":"2019/03/30/quartz-doc-translation-lesson-6/","link":"","permalink":"http://throwable.club/2019/03/30/quartz-doc-translation-lesson-6/","excerpt":"","text":"第六章：CronTrigger CronTrigger通常比SimpleTrigger更有用，如果你需要一个基于类似日历的概念重复出现的工作调度计划，而不是SimpleTrigger的精确指定时间间隔。使用CronTrigger，你可以指定任务触发的时间表，例如“每周五中午”或“每个工作日和上午9:30”，甚至“每周一至周五上午9:00至10点之间每5分钟”和1月份的星期五”。即使如此，和SimpleTrigger一样，CronTrigger有一个startTime，它指定何时生效，以及一个（可选的）endTime，用于指定何时停止任务调度。 Cron表达式 Cron-Expressions用于配置CronTrigger的实例。Cron表达式是由七个子表达式组成的字符串，用于描述调度计划的各个细节。这些子表达式用空格分隔，各个部分表示如下： 1.Seconds 2.Minutes 3.Hours 4.Day-of-Month 5.Month 6.Day-of-Week 7.Year (optional field -&gt; 可选的) 一个完整的Cron-Expressions的例子是字符串&quot;0 0 12 ? * WED&quot; - 这意味着“每个星期三下午12:00”。单个子表达式可以包含范围值、&quot;/“或列表。例如，可以用&quot;MON-FRI”、“MON,WED,FRI&quot;或甚至&quot;MON-WED,SAT&quot;代替前一个（例如&quot;WED”）示例中的星期几字段。 通配符（'*'，在官方文档中是''，估计是官方文档有误，cron不支持空字符串）可用于说明该字段可以取任何值。因此，前一个例子的Month字段中的’‘字符仅仅是“每个月”。因此，Day-of-Month字段中的’'显然意味着“每周的每一天”。 所有字段都有一组可以指定的有效值。这些值应该是相当明显的 - 例如Seconds和Minutes只允许数字0到59，Hours只允许数字0到23。Day-of-Month可以是1-31的任何值，但是你需要注意在给定的月份中有多少天！Month可以指定为0到11之间的值，或者使用字符串JAN，FEB，MAR，APR，MAY，JUN，JUL，AUG，SEP，OCT，NOV和DEC。Day-of-Week可以指定为1到7（1 = 星期日）之间的值，或者使用字符串SUN，MON，TUE，WED，THU，FRI和SAT。 '/'字符可用于指定值的增量。例如，如果在Minutes字段中输入&quot;0/15&quot;，则表示“从第0分钟开始开始，每隔15分钟”。如果你在Minutes字段中使用&quot;3/20&quot;，则意味着“从第3分钟开始，每隔20分钟” - 换句话说，它与Minutes字段中定义的&quot;3,243,43&quot;意义相同。请注意&quot;/35&quot;的细微之处并不代表“每35分钟” - 这意味着“从第0分钟开始，每隔35分钟” - 或者换句话说，与指定&quot;0,35&quot;相同。 ‘?‘字符只允许使用在Day-of-Month和Day-of-Week字段中。用于表示“没有特定的值”。当您需要在Day-of-Month和Day-of-Week两个字段之一定义其中一个字段的确切值，那么另一个字段可以用’?’，这点十分有用。请参阅下面的示例（和CronTrigger JavaDoc）以进行说明。 ‘L’字符只允许用于Day-of-Month和Day-of-Week字段中。这个字符其实就是’last’的缩写，但是在Day-of-Month和Day-of-Week各自的字段中有不同的含义。例如，Day-of-Month字段中的&quot;L&quot;表示“月的最后一天” - 例如1月31日，非闰年2月28日。如果在Day-of-Week字段中使用它，它只是意味着&quot;7&quot;或&quot;SAT&quot;。但是在使用了Day-of-Month前提下，在Day-of-Week中使用’L’，就意味着“xxx月的最后一个星期xxx”，例如&quot;6L&quot;或&quot;FRIL&quot;都意味着“月的最后一个星期五”。你还可以指定月份最后一天的偏移量，例如&quot;L-3&quot;，这意味着一个月份的倒数第三天。当使用’L’选项时，切记不要指定列表或范围值，因为你会得到混乱或者意外的结果。 'W’用于指定给定日期最相近的工作日（星期一至星期五）。例如，如果将&quot;15W&quot;指定为Day-of-Month字段的值，则意思是：“距离本月15日最近的工作日”。 '#‘用于指定月份的“第n个”星期XXX，格式是’n#p’，表示月的第p个星期n。例如，Day-of-Week字段中的&quot;6＃3&quot;或&quot;FRI＃3&quot;的值表示“月的第三个星期五”。 以下是一些表达式及其含义的示例 - 你可以在JavaDoc的org.quartz.CronExpression中找到更多的资料。 译者注：这里有疑惑的就是’*‘和’?'的区别，总结如下： 问号(?)的作用是指明该字段“没有特定的值”，星号(*)指明该字段“代表所有可能值”。 星号(*)和其它值，比如数字，都是给该字段指明特定的值，只不过用星号(*)代表所有可能值。 Cron-Expression对日期和星期字段的处理规则是它们必须互斥，即只能且必须有一个字段有特定的值，另一个字段必须是“没有特定的值”。 问号(?)就是用来对日期和星期字段做互斥的。 Cron表达式示例 CronTrigger示例1 - 创建一个触发器的表达式，每5分钟就会触发一次 &quot;0 0/5 * * * ?&quot; CronTrigger示例2 - 创建一个触发器的表达式，每5分钟触发一次，分钟后10秒（即上午10时10分，上午10:05:10等）。 &quot;10 0/5 * * * ?&quot; CronTrigger示例3 - 创建一个触发器的表达式，在每个星期三和星期五的10:30，11:30，12:30和13:30创建触发器的表达式。 &quot;0 30 10-13 ? * WED,FRI&quot; CronTrigger示例4 - 创建一个触发器的表达式，每个月5日和20日上午8点至10点之间每半小时触发一次。请注意，触发器将不会在上午10点开始，仅在8:00，8:30，9:00和9:30 &quot;0 0/30 8-9 5,20 * ?&quot; 请注意，一些调度要求太复杂，无法用单一触发表示 - 例如“每上午9:00至10:00之间每5分钟，下午1:00至晚上10点之间每20分钟”一次。在这种情况下的解决方案是简单地创建两个触发器，并用它们来触发相同的Job。 构建CronTrigger CronTrigger实例使用TriggerBuilder（用于设置触发器的主要属性）和CronScheduleBuilder（对于CronTrigger特定的属性）构建。要以DSL风格使用这些构建器，请使用静态导入： 123import static org.quartz.TriggerBuilder.*;import static org.quartz.CronScheduleBuilder.*;import static org.quartz.DateBuilder.*: 建立一个触发器，每天上午8点至下午5点之间每隔一分钟触发一次： 12345trigger = newTrigger() .withIdentity(\"trigger3\", \"group1\") .withSchedule(cronSchedule(\"0 0/2 8-17 * * ?\")) .forJob(\"myJob\", \"group1\") .build(); 建立一个触发器，将在上午10:42每天触发一次： 12345trigger = newTrigger() .withIdentity(\"trigger3\", \"group1\") .withSchedule(dailyAtHourAndMinute(10, 42)) .forJob(myJobKey) .build(); 或者： 12345trigger = newTrigger() .withIdentity(\"trigger3\", \"group1\") .withSchedule(cronSchedule(\"0 42 10 * * ?\")) .forJob(myJobKey) .build(); 建立一个触发器，将在星期三上午10:42在TimeZone（系统默认值）之外触发： 123456trigger = newTrigger() .withIdentity(\"trigger3\", \"group1\") .withSchedule(weeklyOnDayAndHourAndMinute(DateBuilder.WEDNESDAY, 10, 42)) .forJob(myJobKey) .inTimeZone(TimeZone.getTimeZone(\"America/Los_Angeles\")) .build(); 或者： 123456trigger = newTrigger() .withIdentity(\"trigger3\", \"group1\") .withSchedule(cronSchedule(\"0 42 10 ? * WED\")) .inTimeZone(TimeZone.getTimeZone(\"America/Los_Angeles\")) .forJob(myJobKey) .build(); CronTrigger Misfire说明 以下错过触发配置可以用于通知Quartz当CronTrigger发生错失触发时应该做什么。（Misfire策略的介绍可以参考第四章：关于Trigger的更多细节）。这些策略以常量的形式在CronTrigger接口中定义（常量上包括描述其行为的JavaDoc）。这些常量包括： 123MISFIRE_INSTRUCTION_IGNORE_MISFIRE_POLICYMISFIRE_INSTRUCTION_DO_NOTHINGMISFIRE_INSTRUCTION_FIRE_NOW 所有触发器都可以使用Trigger.MISFIRE_INSTRUCTION_SMART_POLICY错过触发策略，它就是所有触发器默认的错失触发策略。“SMART POLICY”策略在使用了CronTrigger的情况下解释为MISFIRE_INSTRUCTION_FIRE_NOW。CronTrigger.updateAfterMisfire()方法的JavaDoc解释了此行为的确切细节。 在构建CronTriggers时，你可以将misfire指令指定为cron schedule(cron 调度)的一部分（通过CronSchedulerBuilder）： 123456trigger = newTrigger() .withIdentity(\"trigger3\", \"group1\") .withSchedule(cronSchedule(\"0 0/2 8-17 * * ?\") ..withMisfireHandlingInstructionFireAndProceed()) .forJob(\"myJob\", \"group1\") .build(); 原文链接：tutorial-lesson-06","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Quartz","slug":"Middleware/Quartz","permalink":"http://throwable.club/blog/categories/Middleware/Quartz/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Quartz","slug":"Quartz","permalink":"http://throwable.club/blog/tags/Quartz/"}]},{"title":"第五章：SimpleTrigger","slug":"quartz-doc-translation-lesson-5","date":"2019-03-29T17:42:07.000Z","updated":"2019-03-30T03:05:59.962Z","comments":true,"path":"2019/03/30/quartz-doc-translation-lesson-5/","link":"","permalink":"http://throwable.club/2019/03/30/quartz-doc-translation-lesson-5/","excerpt":"","text":"第五章：SimpleTrigger SimpleTrigger可以满足的调度需求是：在具体的时间点执行一次，或者在具体的时间点执行并且以指定的间隔重复执行若干次（其实永远重复也可以）。比如，你有一个Trigger，你可以设置它在2015年1月13日的上午11:23:54准时触发，或者在当前这个时间点触发，并且每隔2秒触发一次，一共重复5次。 根据描述，你可能已经发现了，SimpleTrigger的属性包括：开始时间、结束时间、重复次数以及重复的间隔。这些属性的含义与你所期望的是一致的，只是关于结束时间有一些地方需要注意。 重复次数，可以是0、正整数，以及常量SimpleTrigger.REPEAT_INDEFINITELY(实际值为-1，即无限重复执行次数)。重复的间隔，必须是0，或者long型的正数，单位是毫秒。注意，如果重复间隔为0，Trigger将会以重复次数并发执行(或者以Scheduler可以处理的近似并发数并发执行)。 如果你还不熟悉Quartz的DateBuilder类，了解后你会发现使用它可以非常方便地构造基于startTime(或endTime)的调度策略。 endTime属性的值会覆盖设置重复次数的属性值；比如，你可以创建一个Trigger，在终止时间之前每隔10秒执行一次，你不需要去计算在开始时间和终止时间之间的重复次数，只需要设置终止时间并将重复次数设置为REPEAT_INDEFINITELY(当然，你也可以将重复次数设置为一个很大的值，并保证该值比Trigger在终止时间之前实际触发的次数要大即可)。 SimpleTrigger实例通过TriggerBuilder设置主要的属性，通过SimpleScheduleBuilder设置与SimpleTrigger相关的属性。要使用这些builder的静态方法，需要静态导入： 123import static org.quartz.TriggerBuilder.*;import static org.quartz.SimpleScheduleBuilder.*;import static org.quartz.DateBuilder.*: 下面的例子，是基于简单调度(simple schedule)创建的Trigger。建议都看一下，因为每个例子都包含一个不同的实现： 指定时间开始触发，不重复触发： 12345SimpleTrigger trigger = (SimpleTrigger) newTrigger() .withIdentity(\"trigger1\", \"group1\") .startAt(myStartTime) // some Date .forJob(\"job1\", \"group1\") // identify job with name, group strings .build(); 指定时间触发，每隔10秒触发一次，重复10次： 12345678trigger = newTrigger() .withIdentity(\"trigger3\", \"group1\") .startAt(myTimeToStartFiring) // if a start time is not given (if this line were omitted), \"now\" is implied .withSchedule(simpleSchedule() .withIntervalInSeconds(10) .withRepeatCount(10)) // note that 10 repeats will give a total of 11 firings .forJob(myJob) // identify job with handle to its JobDetail itself .build(); 5分钟以后开始触发，仅触发一次： 12345trigger = (SimpleTrigger) newTrigger() .withIdentity(\"trigger5\", \"group1\") .startAt(futureDate(5, IntervalUnit.MINUTE)) // use DateBuilder to create a date in the future .forJob(myJobKey) // identify job with its JobKey .build(); 立即触发，每个5分钟触发一次，直到22:00： 1234567trigger = newTrigger() .withIdentity(\"trigger7\", \"group1\") .withSchedule(simpleSchedule() .withIntervalInMinutes(5) .repeatForever()) .endAt(dateOf(22, 0, 0)) .build(); 建立一个触发器，将在下一个小时的整点触发，然后每2小时重复触发一次： 1234567891011trigger = newTrigger() .withIdentity(\"trigger8\") // because group is not specified, \"trigger8\" will be in the default group .startAt(evenHourDate(null)) // get the next even-hour (minutes and seconds zero (\"00:00\")) .withSchedule(simpleSchedule() .withIntervalInHours(2) .repeatForever()) // note that in this example, 'forJob(..)' is not called which is valid // if the trigger is passed to the scheduler along with the job .build(); scheduler.scheduleJob(trigger, job); 请查阅TriggerBuilder和SimpleScheduleBuilder提供的方法，以便了解对上述示例中未提到的选项。 1TriggerBuilder(以及Quartz的其它builder)会为那些没有被显式设置的属性选择合理的默认值。比如：如果你没有调用withIdentity(..)方法，TriggerBuilder会为Trigger生成一个随机的名称；如果没有调用startAt(..)方法，则默认使用当前时间，即Trigger立即生效。 SimpleTrigger Misfire策略 SimpleTrigger有几个misfire相关的策略，告诉quartz当misfire发生的时候应该如何处理。(Misfire策略的介绍可以参考第四章：关于Trigger的更多细节)。这些策略以常量的形式在SimpleTrigger中定义(JavaDoc中介绍了它们的功能)。这些策略包括： SimpleTrigger的Misfire策略常量： 1234567MISFIRE_INSTRUCTION_SMART_POLICY MISFIRE_INSTRUCTION_IGNORE_MISFIRE_POLICYMISFIRE_INSTRUCTION_FIRE_NOWMISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_EXISTING_REPEAT_COUNTMISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_REMAINING_REPEAT_COUNTMISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_REMAINING_COUNTMISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_EXISTING_COUNT 译者补充：其实这些错过触发策略基本都可以从名称得出它们的实际操作，总结如下： MISFIRE_INSTRUCTION_IGNORE_MISFIRE_POLICY：这个不是忽略已经错失的触发的意思，而是说忽略MisFire策略。它会在资源合适的时候，重新触发所有的MisFire的错过触发，并且不会影响现有的调度时间。比如，SimpleTrigger每15秒执行一次，而中间有5分钟时间它都MisFire了，一共错失了20次触发，5分钟后，假设资源充足了，并且任务允许并发，它会被一次性并发触发20次。 MISFIRE_INSTRUCTION_FIRE_NOW：忽略已经MisFire的触发，并且立即触发一次。这通常只适用于只执行一次的任务。 MISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_EXISTING_REPEAT_COUNT：将startTime设置当前时间，立即重新触发，包括MisFire的触发。 MISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_REMAINING_REPEAT_COUNT：将startTime设置当前时间，立即重新触发，不包括MisFire的触发。 MISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_EXISTING_COUNT：在下一次调度时间点触发，包括MisFire的的触发。 MISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_REMAINING_COUNT：在下一次调度时间点触发，不包括MisFire的的触发。 MISFIRE_INSTRUCTION_SMART_POLICY：默认策略，大致意思是“把处理逻辑交给聪明的Quartz去决定”。 如果是只执行一次的调度，使用MISFIRE_INSTRUCTION_FIRE_NOW。 如果是无限次的调度(repeatCount是无限的)，使用MISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_REMAINING_COUNT。 否则，使用MISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_EXISTING_REPEAT_COUNT。 其实，错过触发的策略相对复杂，可以参考Quartz Scheduler Misfire Instructions Explained。 回顾一下，所有的Trigger都有一个Trigger.MISFIRE_INSTRUCTION_SMART_POLICY策略可以使用，该策略也是所有Trigger的默认策略。 如果使用smart policy，SimpleTrigger会根据实例的配置及状态，在所有MISFIRE策略中动态选择一种Misfire策略。可以从SimpleTrigger.updateAfterMisfire()的JavaDoc中解释了该动态行为的具体细节。 在使用SimpleTrigger构造Trigger时，misfire策略作为简单调度(simple schedule)的一部分进行配置(通过SimpleSchedulerBuilder设置)，例子如下： 1234567trigger = newTrigger() .withIdentity(\"trigger7\", \"group1\") .withSchedule(simpleSchedule() .withIntervalInMinutes(5) .repeatForever() .withMisfireHandlingInstructionNextWithExistingCount()) .build(); 原文链接：tutorial-lesson-05","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Quartz","slug":"Middleware/Quartz","permalink":"http://throwable.club/blog/categories/Middleware/Quartz/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Quartz","slug":"Quartz","permalink":"http://throwable.club/blog/tags/Quartz/"}]},{"title":"第四章：关于Trigger的更多细节","slug":"quartz-doc-translation-lesson-4","date":"2019-03-29T17:42:03.000Z","updated":"2019-03-29T17:52:30.915Z","comments":true,"path":"2019/03/30/quartz-doc-translation-lesson-4/","link":"","permalink":"http://throwable.club/2019/03/30/quartz-doc-translation-lesson-4/","excerpt":"","text":"第四章：关于Trigger的更多细节 与Job一样，Trigger也很容易使用，但是还有一些扩展选项需要理解，以便更好地使用Qartz。Trigger也有很多类型，我们可以根据实际需要来选择。 最常用的两种Trigger会分别在第五章：SimpleTrigger和第六章：CronTrigger中讲到。 Trigger的公共属性 所有类型的Trigger都有TriggerKey这个属性，表示Trigger的身份（唯一标识）；除此之外，Trigger还有很多其它的公共属性。这些属性，在构建Trigger的时候可以通过TriggerBuilder设置。Trigger的公共属性有： jobKey属性：当Trigger触发时被执行的Job的身份（唯一标识）； startTime属性：设置trigger第一次触发的时间点，该属性的值是java.util.Date类型，表示某个指定的时间点；有些类型的Trigger，会在设置的startTime时立即触发，有些类型的Trigger，表示其触发是在startTime之后开始生效。比如，现在是1月份，你设置了一个Trigger–“在每个月的第5天执行”，然后你将startTime属性设置为4月1号，则该Trigger第一次触发会是在几个月以后了(即4月5号)。 endTime属性：表示Trigger失效的时间点，该属性的值是java.util.Date类型。比如，”每月第5天执行”的trigger，如果其endTime是7月1号，则其最后一次执行时间是6月5号。 其它的属性，会在下文中解释。 Priority(优先级) 有时候，当你有很多Trigger实例（或者你的Quartz线程池中只有有少量工作线程，不足以触发所有的触发器）时，Quartz可能没有足够的资源来立即触发所有计划同时触发的触发器。在这种情况下，你可能想要控制哪些Trigger可以优先使用（在当前可用的）Quartz工作线程。为此，你可以在触发器上设置优先级属性。如果N个触发器同时触发，但当前只有Z个工作线程可用，则首先执行具有最高优先级的Z个触发器。如果您没有在触发器上设置优先级，那么它将使用默认优先级5。priority属性的值可以是任意整数，正数或者负数都是允许的。 注意：只有同时触发的Trigger之间才会比较优先级。10:59触发的Trigger总是在11:00触发的Trigger之前执行。 注意：如果Trigger是可恢复的，在恢复后再调度时，优先级与原Trigger是一样的。 Misfire Instructions(错过触发策略) Trigger还有一个重要的属性misfire（这里应该称为“错过触发策略”更合理，本质就是一次处理触发器错失触发的策略）；如果Scheduler关闭了，或者Quartz线程池中没有可用的线程来执行jJb，此时持久性的Trigger就会错过(miss)其触发时间，即错过触发(misfire)。不同类型的Trigger，有不同的misfire机制。它们默认都使用“智能机制(smart policy)”，即根据Trigger的类型和配置动态调整行为。当Scheduler启动的时候，查询所有错过触发(misfire)的持久化的Trigger。然后根据它们各自的misfire机制更新Trigger的信息。当你在项目中使用Quartz时，你应该对各种类型的Trigger的misfire机制都比较熟悉，这些misfire机制在JavaDoc中有说明。关于misfire机制的细节，会在讲到具体的Trigger时再作介绍。 Calendar(日历) Quartz的org.quartz.Calendar对象(不是java.util.Calendar对象)可以在定义和存储Trigger的时候与Trigger进行关联。Calendar用于从Trigger的调度计划中排除时间段。比如，可以创建一个Trigger，每个工作日的上午9:30执行，然后增加一个Calendar，排除掉所有的业务假期(也就是工作日中的法定假期)。 任何实现了Calendar接口的可序列化对象都可以作为Calendar对象，Calendar接口如下： 123456789package org.quartz;public interface Calendar &#123; public boolean isTimeIncluded(long timeStamp); public long getNextIncludedTime(long timeStamp);&#125; 译者吐槽：这里贴出来的Calendar接口的源码估计是老版本的org.quartz.Calendar接口，对比了下2.2.x版本的同一个接口并不是长这样的。 注意到这些方法的参数类型为long。你也许猜到了，他们就是毫秒单位的时间戳。即Calendar排除时间段的单位可以精确到毫秒。你也许对“排除一整天”的Calendar比较感兴趣。Quartz提供的org.quartz.impl.HolidayCalendar类可以很方便地实现。 Calendar必须先实例化，然后通过addCalendar()方法注册到Scheduler。如果使用HolidayCalendar，实例化后，需要调用addExcludedDate(Date date)方法从调度计划中排除时间段。以下示例是将同一个Calendar实例用于多个Trigger： 123456789101112131415161718192021222324HolidayCalendar cal = new HolidayCalendar();cal.addExcludedDate( someDate );cal.addExcludedDate( someOtherDate );sched.addCalendar(\"myHolidays\", cal, false);Trigger t = newTrigger() .withIdentity(\"myTrigger\") .forJob(\"myJob\") .withSchedule(dailyAtHourAndMinute(9, 30)) // execute job daily at 9:30 .modifiedByCalendar(\"myHolidays\") // but not on holidays .build();// .. schedule job with triggerTrigger t2 = newTrigger() .withIdentity(\"myTrigger2\") .forJob(\"myJob2\") .withSchedule(dailyAtHourAndMinute(11, 30)) // execute job daily at 11:30 .modifiedByCalendar(\"myHolidays\") // but not on holidays .build();// .. schedule job with trigger2 接下来的几个章节将介绍触发器的构建/构建细节。现在，只要明确上面的代码会创建两个触发器，每个触发器都计划每天触发一次。但是，在日历（Calendar）排除的期间内发生的任何触发都将被跳过。 请参阅org.quartz.impl.calendar包，了解适合你的Calendar实现。 原文链接：tutorial-lesson-04","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Quartz","slug":"Middleware/Quartz","permalink":"http://throwable.club/blog/categories/Middleware/Quartz/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Quartz","slug":"Quartz","permalink":"http://throwable.club/blog/tags/Quartz/"}]},{"title":"第三章：Job和JobDetail的更多细节","slug":"quartz-doc-translation-lesson-3","date":"2019-03-29T17:41:59.000Z","updated":"2019-03-29T17:51:04.624Z","comments":true,"path":"2019/03/30/quartz-doc-translation-lesson-3/","link":"","permalink":"http://throwable.club/2019/03/30/quartz-doc-translation-lesson-3/","excerpt":"","text":"第三章：Job和JobDetail的更多细节 正如你在第二章：Quartz API、调度任务以及触发器看到的，org.quartz.Job很容易实现，在接口中只有一个execute方法。本节主要关注：Job的特点、Job接口的execute方法以及JobDetail。 你定义了一个实现Job接口的类，这个类仅仅表明该Job需要完成什么类型的任务，除此之外，Quartz还需要知道该Job实例所包含的属性；这将由JobDetail类来完成。 JobDetail实例是通过JobBuilder类创建的，导入该类下的所有静态方法，会让你编码时有DSL的感觉： 1import static org.quartz.JobBuilder.*; 让我们先看看Job的特征（nature）以及Job实例的生命期。不妨先回头看看第一章：使用Quartz中的代码片段： 12345678910111213141516// define the job and tie it to our HelloJob class JobDetail job = newJob(HelloJob.class) .withIdentity(\"myJob\", \"group1\") // name \"myJob\", group \"group1\" .build(); // Trigger the job to run now, and then every 40 seconds Trigger trigger = newTrigger() .withIdentity(\"myTrigger\", \"group1\") .startNow() .withSchedule(simpleSchedule() .withIntervalInSeconds(40) .repeatForever()) .build(); // Tell quartz to schedule the job using our trigger sched.scheduleJob(job, trigger); 现在这样定义下面这样的一个调度任务类“HelloJob”： 12345678910public class HelloJob implements Job &#123; public HelloJob() &#123; &#125; public void execute(JobExecutionContext context) throws JobExecutionException&#123; System.err.println(\"Hello! HelloJob is executing.\"); &#125; &#125; 可以看到，我们传给Scheduler一个JobDetail实例，因为我们在创建JobDetail时，将要执行的Job的类名(类型)传给了JobDetail，所以Scheduler就知道了要执行何种类型的Job；每次当Scheduler执行Job时，在调用其execute(…)方法之前会创建该类的一个新的实例；执行完毕，对该实例的引用就被丢弃了，实例会被垃圾回收；这种执行策略带来的一个后果是，Job必须有一个无参的构造函数（当使用默认的JobFactory时）；另一个后果是，在Job类中，不应该定义有状态的数据属性，因为在Job的多次执行中，这些属性的值不会保留。 译者注：这里又一次强调了Job是无状态的。另外，可以实现自定义的JobFactory来改变获取Job实例的方式，例如从Spring的IOC容器中获取，这样就不用每次新建一个Job实例再执行。 那么如何给Job实例增加属性或配置呢？如何在Job的多次执行中，跟踪Job的状态呢？答案就是:JobDataMap，JobDetail对象的一部分。 JobDataMap JobDataMap中可以包含不限量的（序列化的）数据对象，在Job实例执行的时候，可以使用其中的数据；JobDataMap是java.util.Map接口的一个实现，额外增加了一些便于存取基本类型的数据的方法。 将Job加入到Scheduler之前，在构建JobDetail时，可以将数据放入JobDataMap，如下示例： 123456// define the job and tie it to our DumbJob class JobDetail job = newJob(DumbJob.class) .withIdentity(\"myJob\", \"group1\") // name \"myJob\", group \"group1\" .usingJobData(\"jobSays\", \"Hello World!\") .usingJobData(\"myFloatValue\", 3.141f) .build(); 在Job的执行过程中，可以从JobDataMap中取出数据，如下示例： 123456789101112131415161718public class DumbJob implements Job &#123; public DumbJob() &#123; &#125; public void execute(JobExecutionContext context) throws JobExecutionException &#123; JobKey key = context.getJobDetail().getKey(); JobDataMap dataMap = context.getJobDetail().getJobDataMap(); String jobSays = dataMap.getString(\"jobSays\"); float myFloatValue = dataMap.getFloat(\"myFloatValue\"); System.err.println(\"Instance \" + key + \" of DumbJob says: \" + jobSays + \", and val is: \" + myFloatValue); &#125; &#125; **如果您使用具备持久化特性的JobStore（在本教程的JobStore部分中进行了讨论），您应该谨慎决定放置在JobDataMap中的内容，因为其中的对象将被序列化，因此它们容易出现类版本问题。**显然，标准的Java类型应该是非常安全的，但除此之外，任何时候有人改变你已经序列化了实例的类的定义时，都必须注意不要打破兼容性。另外，你可以强制要求JDBC-JobStore和JobDataMap只允许在JobDataMap中存储基本类型和字符串类型，这样可以避免后续的序列化问题。 如果你在Job的实现类中，为JobDataMap中存储的数据的key增加set方法（如在上面示例中，增加setJobSays(String val)方法），那么Quartz的默认JobFactory实现在Job被实例化的时候会自动调用这些set方法，这样你就不需要在execute()方法中显式地从JobDataMap中取数据了。 如果你有一个存储在调度器中的调度任务，供多个触发器定期/重复使用，但每次独立触发，则希望为作业提供不同的数据输入，可以为触发器定义与之关联的JobDataMap。 在Job执行时，JobExecutionContext中的JobDataMap为我们提供了很多的便利。它是JobDetail中的JobDataMap和Trigger中的JobDataMap的数据并集，但是如果存在相同的数据，则后添加者会覆盖之前添加的Key相同的值（毕竟就是一个java.util.Map的实例）。 以下是在作业执行期间从JobExecutionContext的合并JobDataMap获取数据的简单示例： 1234567891011121314151617181920public class DumbJob implements Job &#123; public DumbJob() &#123; &#125; public void execute(JobExecutionContext context) throws JobExecutionException &#123; JobKey key = context.getJobDetail().getKey(); JobDataMap dataMap = context.getMergedJobDataMap(); // Note the difference from the previous example String jobSays = dataMap.getString(\"jobSays\"); float myFloatValue = dataMap.getFloat(\"myFloatValue\"); ArrayList state = (ArrayList)dataMap.get(\"myStateData\"); state.add(new Date()); System.err.println(\"Instance \" + key + \" of DumbJob says: \" + jobSays + \", and val is: \" + myFloatValue); &#125; &#125; 如果你希望使用JobFactory实现数据的自动“注入”功能，则示例代码为： 1234567891011121314151617181920212223242526272829303132333435public class DumbJob implements Job &#123; String jobSays; float myFloatValue; ArrayList state; public DumbJob() &#123; &#125; public void execute(JobExecutionContext context) throws JobExecutionException &#123; JobKey key = context.getJobDetail().getKey(); JobDataMap dataMap = context.getMergedJobDataMap(); // Note the difference from the previous example state.add(new Date()); System.err.println(\"Instance \" + key + \" of DumbJob says: \" + jobSays + \", and val is: \" + myFloatValue); &#125; public void setJobSays(String jobSays) &#123; this.jobSays = jobSays; &#125; public void setMyFloatValue(float myFloatValue) &#123; myFloatValue = myFloatValue; &#125; public void setState(ArrayList state) &#123; state = state; &#125;&#125; 你会注意到该类的整体代码更长，但execute()方法中的代码更简洁清晰。而且，虽然代码更多了，但如果你的IDE可以自动生成Setter方法，你就不需要写代码调用相应的方法从JobDataMap中获取数据了，所以你实际需要编写的代码更少了。当前，如何选择，由你决定。 Job实例 很多使用者对于Job实例到底由什么构成感到很迷惑。我们将尝试在这里解释一下，并且在下面的部分中解释关于调度任务状态和并发性相关内容。 您可以创建一个单独的Job类，并通过创建JobDetails的多个实例（每个实例具有自己的属性集和JobDataMap），最后，将所有的Job实例都添加加到Scheduler中。 例如，你可以创建一个实现Job接口的类，名为“SalesReportJob”。该Job需要一个参数（通过JobDataMap传入）指定销售报告应该基于的销售人员的名称。然后，你可以创建多个Job实例（JobDetails），比如“SalesReportForJoe”、“SalesReportForMike”，将“joe”和“mike”作为JobDataMap的数据传给对应的Job实例。 当触发器触发时，它所关联的JobDetail（实例定义）将被加载，并且它引用的作业类将通过Scheduler上配置的JobFactory实例化。默认的JobFactory只是在作业类上调用newInstance()，然后尝试调用该类的匹配JobDataMap中的键的名称的setter方法。你可能希望创建自己的JobFactory实现来完成诸如让应用程序的IoC或DI容器生成/初始化Job实例等事情。 在Quartz的描述语言中，我们将每个存储的JobDetail称为“Job定义”或“JobDetail实例”，并将每个正在执行的作业称为“Job实例”或“Job定义的实例”。通常，如果我们只使用“Job”这个词，我们就是指一个命名定义，或者JobDetail。当我们指的是实现工作界面的类时，我们通常使用术语“Job类”。 Job的状态和并发性 关于Job状态数据（也就是JobDataMap）和并发性还有一些内容需要补充。有几个注释可以添加到你的Job类中，这些注解会影响Job的状态和并发性。 @DisallowConcurrentExecution是一个注解，可以添加到Job类中，告诉Quartz不要同时执行给定Job定义（指给定Job类）的多个实例。 注意这里的措词。拿前一小节的例子来说，如果“SalesReportJob”类上有该注解，则同一时刻仅允许执行一个“SalesReportForJoe”实例，但可以并发地执行“SalesReportForMike”类的一个实例。所以该限制是针对JobDetail的，而不是Job类。但是我们认为（在设计Quartz的时候）应该将该注解放在Job类上，因为Job类的改变经常会导致其行为发生变化。 @PersistJobDataAfterExecution是一个注解，可以添加到Job类中，告诉Quartz在execute()方法成功完成后（不抛出异常）更新JobDetail的JobDataMap的存储副本数据，使得该Job（即JobDetail）在下一次执行的时候，JobDataMap中是更新后的数据，而不是更新前的旧数据。像 @DisallowConcurrentExecution注解一样，尽管注解是加在Job类上的，但其限制作用是针对Job实例的，而不是Job类的。由Job类来承载该注解，是因为此注解的功能会影响类的编码方式（例如，‘有状态’需要被执行方法内的代码明确’理解’–&gt; 这里原文是e.g. the ‘statefulness’ will need to be explicitly ‘understood’ by the code within the execute method）。 如果你使用了@PersistJobDataAfterExecution注解，我们强烈建议你同时使用@DisallowConcurrentExecution注解，因为当同一个Job（JobDetail）的两个实例被并发执行时，由于竞争，JobDataMap中存储的数据很可能是不确定的。 Job的其他属性 通过JobDetail对象，可以给Job实例配置的其它属性有： Durability：持久化特性，布尔值。如果一个Job是非持久的，当没有活跃的Trigger与之关联的时候，会被自动地从Scheduler中删除。也就是说，非持久的Job的生命期是由Trigger的存在与否决定的。 RequestsRecovery - 请求恢复特性，布尔值。如果一个Job是可恢复的，并且在其执行的时候，Scheduler发强制关闭（hard shutdown)（比如运行的进程崩溃了或者服务器宕机了），则当Scheduler重新启动的时候，该Job会被重新执行。此时，该Job的JobExecutionContext.isRecovering()返回true。 这两个属性在JobBuilder中都有相应的设置方法。 JobExecutionException 最后，我们需要通知你关于该Job.execute(..)方法的一些细节。唯一可以从execute方法抛出的异常（包括RuntimeExceptions）是JobExecutionException。因此，通常应该用“try-catch”块来包装execute方法的全部内容。你还应该花一些时间查看JobExecutionException的文档，因为你的Job可以使用该异常告诉Scheduler，你希望如何来处理发生的异常。 原文链接：tutorial-lesson-03","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Quartz","slug":"Middleware/Quartz","permalink":"http://throwable.club/blog/categories/Middleware/Quartz/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Quartz","slug":"Quartz","permalink":"http://throwable.club/blog/tags/Quartz/"}]},{"title":"第一章：使用Quartz","slug":"quartz-doc-translation-lesson-1","date":"2019-03-29T17:39:58.000Z","updated":"2019-03-29T17:49:36.863Z","comments":true,"path":"2019/03/30/quartz-doc-translation-lesson-1/","link":"","permalink":"http://throwable.club/2019/03/30/quartz-doc-translation-lesson-1/","excerpt":"","text":"第一章：使用Quartz 内容 在使用此调度器(Scheduler)之前，它需要被实例化(谁猜到这一点了? &lt;-- 这里估计是官方的调皮)。为了实例化调度器，你需要用到SchedulerFactory。一些Quartz的使用者可能会在JNDI存储中保留SchedulerFactory的实例，其他使用者可能会觉得直接初始化会更加简单（例如下面的示例）。 一旦调度器完成了实例化，就可以启动(start)、暂停(stand-by)、停止(shutdown)。注意：一旦调度器被停止，它就不能够重新启动，除非重新实例化另一个调度器实例。所有的触发器(Trigger)不会触发任务(也就是任务不会执行)，除非调度器已经启动。但是如果调度器(虽然已经启动)处于暂停状态，所有的触发器也不会触发任务。 下面是一个代码片段，实例化并启动一个调度器，调度执行一个任务： 12345678910111213141516171819202122SchedulerFactory schedFact = new org.quartz.impl.StdSchedulerFactory(); Scheduler sched = schedFact.getScheduler(); sched.start(); // define the job and tie it to our HelloJob class JobDetail job = newJob(HelloJob.class) .withIdentity(\"myJob\", \"group1\") .build(); // Trigger the job to run now, and then every 40 seconds Trigger trigger = newTrigger() .withIdentity(\"myTrigger\", \"group1\") .startNow() .withSchedule(simpleSchedule() .withIntervalInSeconds(40) .repeatForever()) .build(); // Tell quartz to schedule the job using our trigger sched.scheduleJob(job, trigger); 正如你所见，使用Quartz是十分简单的。在下一节第二章：Quartz API、调度任务以及触发器中我们将会概述一下调度任务、触发器以及Quartz的API，以便你可以更全面地了解这个例子。 原文链接：tutorial-lesson-01","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Quartz","slug":"Middleware/Quartz","permalink":"http://throwable.club/blog/categories/Middleware/Quartz/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Quartz","slug":"Quartz","permalink":"http://throwable.club/blog/tags/Quartz/"}]},{"title":"第二章：Quartz API、调度任务以及触发器","slug":"quartz-doc-translation-lesson-2","date":"2019-03-29T17:39:58.000Z","updated":"2019-03-29T17:49:20.500Z","comments":true,"path":"2019/03/30/quartz-doc-translation-lesson-2/","link":"","permalink":"http://throwable.club/2019/03/30/quartz-doc-translation-lesson-2/","excerpt":"","text":"第二章：Quartz API、调度任务以及触发器 Quartz API 下面是Quartz API中的关键接口： Scheduler：与调度器交互的主要API(实际上这个就是调度器)。 Job：org.quartz.Job，希望由调度器执行的组件，是一个接口，也就是我们使用的时候被调度的任务需要实现此接口。 JobDetail：org.quartz.JobDetail，调度任务详情，用于定义调度任务。 Trigger：org.quartz.Trigger，也就是触发器，它是一个定义了给定调度任务将被执行的时间表的组件。 JobBuilder：org.quartz.JobBuilder，用于定义或者构建JobDetail实例。 TriggerBuilder：org.quartz.TriggerBuilder，用于定义或者构建Trigger实例。 其实Job就是使用者需要实现的调度任务接口，它以JobDetail的形式存放在Quartz管理的内存或者表里面。 Scheduler的生命期，从SchedulerFactory创建它的实例时开始，到Scheduler的实例调用shutdown()方法时结束。Scheduler被创建后，可以添加、删除和查询JobDetail和Trigger，以及执行其它们与调度相关的操作（如暂停Trigger）。但是，Scheduler只有在调用start()方法后，才会真正地触发Trigger（Trigger运作之后才能fire具体的Job），见第一章：使用Quartz。 Quartz提供的“Builder”类，可以认为是一种领域特定语言（DSL，Domain Specific Language)。其实这些Builder就是流式的API。上一章你已经看过相应的例子，这里再贴出来一次： 12345678910111213141516// define the job and tie it to our HelloJob class JobDetail job = newJob(HelloJob.class) .withIdentity(\"myJob\", \"group1\") // name \"myJob\", group \"group1\" .build(); // Trigger the job to run now, and then every 40 seconds Trigger trigger = newTrigger() .withIdentity(\"myTrigger\", \"group1\") .startNow() .withSchedule(simpleSchedule() .withIntervalInSeconds(40) .repeatForever()) .build(); // Tell quartz to schedule the job using our trigger sched.scheduleJob(job, trigger); 定义JobDetail的代码使用的是从JobBuilder静态导入的方法。同样，定义Trigger的代码使用的是从TriggerBuilder静态导入的方法 。 另外，也导入了SimpleSchedulerBuilder类的静态方法。DSL的静态导入可以通过以下导入语句来实现： 123456import static org.quartz.JobBuilder.*;import static org.quartz.SimpleScheduleBuilder.*;import static org.quartz.CronScheduleBuilder.*;import static org.quartz.CalendarIntervalScheduleBuilder.*;import static org.quartz.TriggerBuilder.*;import static org.quartz.DateBuilder.*; SchedulerBuilder接口的各种实现类，可以定义不同类型的调度计划（schedule）；DateBuilder类包含很多方法，可以很方便地构造表示不同时间点的java.util.Date实例（如定义下一个小时为偶数的时间点，如果当前时间为9:43:27，则定义的时间为10:00:00）。 其实就是SchedulerBuilder是策略接口，它的子类提供了多种不同类型的调度计划的实现，DateBuilder内部的多数方法依赖于Calendar，它主要功能是用来快速定义一个具体的时刻，因为有时候Cron表达式可能不满足特定的场景，这个时候DateBuilder可以派上用场。 Jobs and Triggers 一个调度任务就是一个实现了org.quartz.Job接口(只有一个简单的接口方法execute)的类： The Job Interface： 1234567package org.quartz; public interface Job &#123; public void execute(JobExecutionContext context) throws JobExecutionException; &#125; 当Job的一个Trigger被触发（稍后会讲到）时，execute()方法由Scheduler的一个工作线程调用。传递给execute()方法的JobExecutionContext对象中保存着该Job运行时的一些信息 ，执行Job的Scheduler的引用，触发Job的Trigger的引用，JobDetail对象引用，以及一些其它信息（如果使用了Spring的话，可以传入Spring的上下文对象ApplicationContext）。 JobDetail对象是在将Job加入Scheduler时，由客户端程序（你的程序）创建的。它包含Job的各种属性设置，以及用于存储Job实例状态信息的JobDataMap。本节是对Job实例的简单介绍，更多的细节将在下一节讲到。 Trigger用于触发Job的执行。当你准备调度一个Job时，你创建一个Trigger的实例，然后设置调度相关的属性。Trigger也有一个相关联的JobDataMap，用于给Job传递一些触发相关的参数。Quartz自带了各种不同类型的Trigger，最常用的主要是SimpleTrigger(间隔一定时间(重复)执行)和CronTrigger(基于Cron表达式构建调度计划)。 SimpleTrigger主要用于一次性执行的Job（只在某个特定的时间点执行一次），或者Job在特定的时间点执行，重复执行N次，每次执行间隔T个时间单位。CronTrigger在基于日历的调度上非常有用，如“每个星期五的正午”，或者“每月的第十天的上午10:15”等。 为什么既有Job，又有Trigger呢？很多任务调度器并不区分Job和Trigger。有些调度器只是简单地通过一个执行时间和一些Job标识符来定义一个Job；其它的一些调度器将Quartz中描述的Job和Trigger对象合二为一。在开发Quartz的时候，我们认为将触发器和要调度的任务分离是合理的。在我们看来，这可以带来很多好处。 例如，Job被创建后，可以保存在Scheduler中，与Trigger是独立的，同一个Job可以有多个Trigger；这种松耦合的另一个好处是，当与Scheduler中的Job关联的Trigger都过期时，可以配置Job稍后被重新调度，而不用重新定义Job；还有，可以修改或者替换Trigger，而不用重新定义与之关联的Job。 译者注：上面这段内容十分重要，在Quartz中，调度任务和触发器是独立分离的，并且可以总结出一点：Quartz中Job是无状态的，有状态的是Trigger。因此我们在做一个调度任务查询列表展示的时候应该展示的是触发器的状态，而不应该是调度任务的状态；至于调度任务是否执行成功，只能通过添加监听器或者查看日志去判断或者说调度任务的运行状态应该交由开发者去监控和管理。 Identities Identities其实就是调度任务和触发器的身份标识。当Job和Trigger注册到Quartz的调度器中的时候需要定义相应的识别标记(其实就是JobKey和TriggerKey)。调度任务和触发器（JobKey和TriggerKey）的识别标记中允许使用“分组(group)”，这对于组织你的工作和触发诸如“报告工作”和“维护工作”等类别是有用的。作业或触发器的键的名称部分必须在组内是惟一的—换句话说，作业或触发器的完整键（或标识符）是名称（name）和组别（group）的复合。这里可以先这样理解，JobKey(name和group)是JobDetail的联合主键，TriggerKey(name和group)是Trigger的联合主键。 你现在对调度任务和触发器有了大致的了解，你可以在第三章：Job和JobDetail的更多细节和第四章：关于Trigger的更多细节了解到更多关于它们的使用方式。 原文链接：tutorial-lesson-02","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Quartz","slug":"Middleware/Quartz","permalink":"http://throwable.club/blog/categories/Middleware/Quartz/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Quartz","slug":"Quartz","permalink":"http://throwable.club/blog/tags/Quartz/"}]},{"title":"Quartz官方文档翻译","slug":"quartz-doc-translation-entry","date":"2019-03-29T17:38:00.000Z","updated":"2019-03-30T03:29:44.793Z","comments":true,"path":"2019/03/30/quartz-doc-translation-entry/","link":"","permalink":"http://throwable.club/2019/03/30/quartz-doc-translation-entry/","excerpt":"","text":"Quartz官方文档翻译 2018年5月的时候，因为要理解Quartz的相关东西，当时翻阅过它的文档顺便把它翻译了出来，已经忘记了这个事，好在存档还在硬盘上。其中有部分章节为了节省时间使用了机翻然后人工润色，目前阅读起来应该没有障碍。 这段时间太忙(996，快ICU了)，先对基础教程部分重新排版和二次润色，剩下的其他文档有空再补一下。 术语： Scheduler：调度器。 SchedulerFactory：调度器工厂。 Trigger：触发器。 Job：(调度)任务或者作业，在Quartz中体现为JobDetail。 在后面的翻译中，因为个人习惯，可能会中英互用，映射关系为： Scheduler === 调度器 SchedulerFactory === 调度器工厂 Trigger === 触发器 Job、JobDetail === (调度)任务 fire === 触发 基础篇 第一章：使用Quartz 第二章：Quartz API、调度任务以及触发器 第三章：Job和JobDetail的更多细节 第四章：关于Trigger的更多细节 第五章：SimpleTrigger 第六章：CronTrigger 第七章：Trigger监听器和Job监听器 第八章：Scheduler监听器 第九章：JobStores 第十章：配置、资源的使用以及SchedulerFactory 第十一章：高级(企业级)特性 第十二章：其他特性 特别教程 特别教程-CronTrigger教程 其他 to be continue… (e-a-20170526 c-14-d r-a-20180330)","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Quartz","slug":"Middleware/Quartz","permalink":"http://throwable.club/blog/categories/Middleware/Quartz/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Quartz","slug":"Quartz","permalink":"http://throwable.club/blog/tags/Quartz/"}]},{"title":"谈谈对分布式事务的一点理解和解决方案","slug":"j-action-about-distributed-transaction","date":"2019-03-23T03:09:08.000Z","updated":"2019-03-24T03:47:01.156Z","comments":true,"path":"2019/03/23/j-action-about-distributed-transaction/","link":"","permalink":"http://throwable.club/2019/03/23/j-action-about-distributed-transaction/","excerpt":"","text":"谈谈对分布式事务的一点理解和解决方案 前提 最近，工作中要为现在的老系统做拆分和升级，刚好遇到了分布式事务、幂等控制、异步消息乱序和补偿方案等问题，刚好基于实践结合个人的看法记录一下一些方案和思路。 分布式事务 首先，做系统拆分的时候几乎都会遇到分布式事务的问题，一个仿真的案例如下： 项目初期，由于用户体量不大，订单模块和钱包模块共库共应用(大war包时代)，模块调用可以简化为本地事务操作，这样做只要不是程序本身的BUG，基本可以避免数据不一致。后面因为用户体量越发增大，基于容错、性能、功能共享等考虑，把原来的应用拆分为订单微服务和钱包微服务，两个服务之间通过非本地事务操(这里可以是HTTP或者消息队列等)进行数据同步，这个时候就很有可能由于异常场景出现数据不一致的情况。 事务中直接RPC调用达到强一致性 以上面的订单微服务请求钱包微服务进行扣款并更新订单状态为扣款这个调用过程为例，假设采用HTTP同步调用，项目如果由经验不足的开发者开发这个逻辑，可能会出现下面的伪代码： 123456789[订单微服务请求钱包微服务进行扣款并更新订单状态]处理订单微服务请求钱包微服务进行扣款并更新订单状态方法()&#123; [开启事务] 1、查询订单 2、HTTP调用钱包微服务扣款 3、更新订单状态为扣款成功 [提交事务]&#125; 这是一个从肉眼上看起来没有什么问题的解决方法，HTTP调用直接嵌入到事务代码块内部，猜想最初开发者的想法是：HTTP调用失败抛出异常会导致事务回滚，用户重试即可；HTTP调用成功，事务正常提交，业务正常完成。这种做法看似可取，但是带来了极大的隐患，根本原因是：事务中嵌入了RPC调用。假设两种比较常见的情况： 1、上面方法中第2步由于钱包微服务本身各种原因导致扣款接口响应极慢，会导致上面的处理方法事务(准确来说是数据库连接)长时间挂起，持有的数据库连接无法释放，会导致数据库连接池的连接耗尽，很容易导致订单微服务的其他依赖数据库的接口无法响应。 2、钱包微服务是单节点部署(并不是所有的公司微服务都做得很完善)，升级期间应用停机，上面方法中第2步接口调用直接失败，这样会导致短时间内所有的事务都回滚，相当于订单微服务的扣款入口是不可用的。 3、网络是不可靠的，HTTP调用或者接受响应的时候如果出现网络闪断有可能出现了服务间状态不能互相明确的情况，例如订单微服务调用钱包微服务成功，接受响应的时候出现网络问题，会出现扣款成功但是订单状态没有更新的可能(订单微服务事务回滚)。 尽管现在有Hystrix等框架可以基于线程池隔离调用或者基于熔断器快速失败，但是这是收效甚微的。因此，个人认为事务中直接RPC调用达到强一致性是完全不可取的，如果使用了这种方式实现&quot;分布式事务&quot;建议整改，否则只能每天祈求下游服务或者网络不出现任何问题。 事务中进行异步消息推送 使用消息队列进行服务之间的调用也是常见的方式之一，但是使用消息队列交互本质是异步的，无法感知下游消息消费方是否正常处理消息。用前一节的例子，假设采用消息队列异步调用，项目如果由经验不足的开发者开发这个逻辑，可能会出现下面的伪代码： 123456789[订单微服务请求钱包微服务进行扣款并更新订单状态]处理订单微服务请求钱包微服务进行扣款并更新订单状态方法()&#123; [开启事务] 1、查询订单 2、推送钱包微服务扣款消息(推送消息) 3、更新订单状态为扣款成功 [提交事务]&#125; 上面的处理方法如果抽象一点表示如下： 12345678910111213141516方法()&#123; DataSource dataSource = xx; Connection con = dataSource.getConnection(); con.setAutoCommit(false); try&#123; 1、SQL操作; 2、推送消息; 3、SQL操作; con.commit(); &#125;catch(Exception e)&#123; con.rollback(); &#125;finally&#123; 释放其他资源; release(con); &#125;&#125; 这样做，在正常情况下，也就是能够正常调用消息队列中间件推送消息成功的情况下，事务是能够正确提交的。但是存在两个明显的问题： 1、消息队列中间件出现了异常，无法正常调用，常见的情况是网络原因或者消息队列中间件不可用，会导致异常从而使得事务回滚。这种情况看起来似乎合情合理，但是仔细想：为什么消息队列中间件调用异常会导致业务事务回滚，如果中间件不恢复，这个接口调用岂不是相当于不可用？ 2、如果消息队列中间件正常，消息正常推送，但是第3步由于SQL存在语法错误导致事务回滚，这样就会出现了下游微服务被调用成功，本地事务却回滚的问题，导致了上下游系统数据不一致。 总的来说：事务中进行异步消息推送是一种并不可靠的实现。 目前业界提供的解决方案 业界目前主流的分布式事务解决方案主要有：多阶段提交方案(2PC、3PC)、补偿事务(TCC)和消息事务(主要是RocketMQ，基本思想也是多阶段提交方案，其他消息队列中间件并没有实现分布式事务)。这些方案的原理在此处不展开，目前网络中相应资料比较多，小结一下它们的特点： 多阶段提交方案：常见的有二阶段和三阶段提交事务，需要额外的资源管理器来协调事务，数据一致性强，但是实现方案比较复杂，对性能的牺牲比较大(主要是需要对资源锁定，等待所有事务提交才能解锁)，不适用于高并发的场景，目前比较知名的有阿里开源的fescar。 补偿事务：一般也叫TCC，因为每个事务操作都需要提供三个操作尝试(Try)、确认(Confirm)和补偿/撤销(Cancel)，数据一致性的强度比多阶段提交方案低，但是实现的复杂度会有所降低，比较明显的缺陷是每个业务事务需要实现三组操作，有可能出现过多的补偿方案的代码；另外有很多场景TCC是不合适的。 消息事务：这里只谈RocketMQ的实现，一个事务的执行流程包括：发送预消息、执行本地事务、确认消息发送成功。它的消息中间件存储了下游无法消费成功的消息，并且不断重试推送下游消费消息，而生产者(上游)需要提供一个check接口，用于检查成功发送预消息但是未确认最终消息发送状态的事务的状态。 项目实践中最终使用的方案 个人所在的公司的技术栈中没有使用RocketMQ，主要使用RabbitMQ，所以需要针对RabbitMQ做消息事务的适配。目前业务系统中消息异步交互存在三种场景： 1、消息推送实时性高，可以接受丢失。 2、消息推送实时性低，不能丢失。 3、消息推送实时性高，不能丢失。 最终敲定使用了本地消息表的解决方案，这个方案十分简单： 主要思路是： 1、需要发送到消费方的消息的保存和业务处理绑定在同一个本地事务中，需要额外建立一张本地消息表。 2、本地事务提交之后，可以在事务外对本地消息表进行查询并且进行消息推送，或者采用定时调度轮询本地消息表进行消息推送。 3、下游服务消费消息成功可以回调一个确认到上游服务，这样就可以从上游服务的本地消息表删除对应的消息记录。 伪代码如下： 1234567891011121314151617181920212223242526272829303132333435[消息推送实时性高，可以接受丢失-这种情况下可以不需要写入本地消息表 - start]处理方法()&#123; [本地事务开始] 1、处理业务操作 [本地事务提交] 2、组装推送消息并且进行推送&#125;[消息推送实时性高，可以接受丢失-这种情况下可以不需要写入本地消息表 - end][消息推送实时性低，不能丢失 - start]处理方法()&#123; [本地事务开始] 1、处理业务操作 2、组装推送消息并且写入到本地消息表 [本地事务提交]&#125;消息推送调度模块()&#123; 3、查询本地消息表待推送数据进行推送&#125;[消息推送实时性低，不能丢失 - end][消息推送实时性高，不能丢失 - start]处理方法()&#123; [本地事务开始] 1、处理业务操作 2、组装推送消息并且写入到本地消息表 [本地事务提交] 3、消息推送&#125;消息推送调度模块()&#123; 4、查询本地消息表待推送数据进行推送&#125;[消息推送实时性高，不能丢失 - end] 对于&quot;消息推送实时性高，可以接受丢失&quot;这种情况，实际上不用依赖本地消息表，只要在业务操作事务提交之后组装和推送消息即可，这种情况会存在因为消息队列中间件不可用或者本地应用宕机导致消息丢失的问题(本质是因为数据是内存态，非持久化)，可靠性不高，但是绝大多数情况下是没有问题的。如果使用spring-tx的声明式事务@Transactional或者编程式事务TransactionTemplate，可以使用事务同步器实现嵌入于业务操作事务代码块中的RPC操作延后到事务提交后执行，这样子RPC调用的代码物理位置就可以放置在事务代码块内，例如： 12345678910@Transactional(rollbackFor = RuntimeException.class)public void process()&#123; 1.处理业务逻辑 TransactionSynchronizationManager.getSynchronizations().add(new TransactionSynchronizationAdapter() &#123; @Override public void afterCommit() &#123; 2.进行消息推送 &#125; &#125;);&#125; 对于使用到本地消息表的场景，需要警惕下面几个问题： 1、注意本地消息表尽量不要长时间积压数据，推送成功的数据需要及时删除。 2、本地消息表的数据在查询并且推送的时候，需要设计最大重试次数上限，达到上限仍然推送失败的记录需要进行预警和人为干预。 3、如果入库的消息体比较大，查询可能消耗的IO比较大，需要考虑拆分单独的一张消息内容表用于存放消息体内容，而经常更变的列应该单独拆分到另外一张表。 例如本地消息表的设计如下： 1234567891011121314151617181920212223242526CREATE TABLE `t_local_message`( id BIGINT PRIMARY KEY COMMENT '主键', module INT NOT NULL COMMENT '消息模块', tag VARCHAR(20) NOT NULL COMMENT '消息标签', business_key VARCHAR(60) NOT NULL COMMENT '业务键', queue VARCHAR(60) NOT NULL COMMENT '队列', exchange VARCHAR(60) NOT NULL COMMENT '交换器', exchange_type VARCHAR(10) NOT NULL COMMENT '交换器类型', routing_key VARCHAR(60) NOT NULL COMMENT '路由键', retry_times TINYINT NOT NULL DEFAULT 0 COMMENT '重试次数', create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建日期时间', edit_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改日期时间', seq_no VARCHAR(60) NOT NULL COMMENT '流水号', message_status TINYINT NOT NULL DEFAULT 0 COMMENT '消息状态', INDEX idx_business_key(business_key), INDEX idx_create_time(create_time), UNIQUE uniq_seq_no(seq_no))COMMENT '本地消息表';CREATE TABLE `t_local_message_content`( id BIGINT PRIMARY KEY COMMENT '主键', message_id BIGINT NOT NULL COMMENT '本地消息表主键', message_content TEXT COMMENT '消息内容', UNIQUE uniq_message_id(message_id))COMMENT '本地消息内容表'; 分布式事务小结 个人认为，解决分布式事务的最佳实践就是： 规避使用强一致性的分布式事务实现，基本观念就是放弃ACID投奔BASE。 推荐使用消息队列进行系统间的解耦，消息推送方为了确保消息推送成功可以独立附加消息表把需要推送的消息和业务操作绑定在同一个事务内，使用异步或者调度的方式进行推送。 消息推送方(上游)需要确保消息正确投递到消息队列中间件，消息消费或者补偿方案由消息消费方(下游)自行解决，关于这一点后文一个章节专门解释。 其实，对于一致性和实时性要求相对较高的分布式事务的实现，使用消息队列解耦也有对应的解决方案。 幂等控制 幂等(idempotence)这个术语原文来自于HTTP/1.1协议中的定义： Methods can also have the property of “idempotence” in that (aside from error or expiration issues) the side-effects of N &gt; 0 identical requests is the same as for a single request. 简单来说就是：除了错误或者过期的请求(换言之就是成功的请求)，无论多次调用还是单次调用最终得到的效果是一致的。通俗来说，有一次调用成功，采用相同的请求参数无论调用多少次(重复提交)都应该返回成功。 下游服务对外提供服务接口，必须承诺实现接口的幂等性，这一点在分布式系统中极其重要。 对于HTTP调用，承诺幂等性可以避免表单或者请求操作重复提交造成业务数据重复。 对于异步消息调用，承诺幂等性通过对消息去重处理也是用于避免重复消费造成业务数据重复。 目前实践中对于幂等的处理使用了下面三个方面的控制： 1、实现幂等的接口调用时入口使用分布式锁，使用了主流的Redisson，控制锁的粒度和锁的等待、持有时间在合理范围(笔者所在行业要求数据必须准确无误，所以几乎用悲观锁设计所有核心接口，宁愿慢也不能错，实际上如果冲突比较低的时候为了性能优化可以考虑使用乐观锁)。 2、业务逻辑上的防重，例如创建订单的接口先做一步通过订单号查询库表中是否已经存在对应的订单，如果存在则不做处理直接返回成功。 3、数据库表设计对逻辑上唯一的业务键做唯一索引，这个是通过数据库层面做最后的保障。 举一个基于消息消费幂等控制的伪代码例子： 1234567[处理消息消费]listen(request)&#123; 1、通过业务键构建分布式锁的KEY 2、通过Redisson构建分布式锁并且加锁 3、加锁代码中执行业务逻辑(包括去重判断、事务操作和非事务操作等) 4、finally代码块中释放分布式锁&#125; 补偿方案 补偿方案主要是HTTP同步调用的补偿和异步消息消费失败的补偿。 HTTP同步调用补偿 一般情况下，HTTP同步调用会得到下游系统的同步结果，对结果的处理存在下面几种常见的情况： 1、同步结果返回正常，得到了和下游约定的最终状态，交互结束，一般认为成功就是最终状态，不需要补偿。 2、同步结果返回正常，得到了和下游约定的非最终状态，需要定时补偿到最终状态或到达重试上限自行标记为最终状态。 3、同步结果返回异常，最常见的是下游服务不可用返回HTTP状态码为5XX。 首先要有一个简单的认知：短时间内的HTTP重试通常情况下都是无效的。如果是瞬时的网络抖动，短时间内HTTP同步重试是可行的，大部分情况下是下游服务无法响应、下游服务重启中或者复杂的网络情况导致短时间内无法恢复，这个时候做HTTP同步重试调用往往是无效的。 如果面对的场景是内部低并发量的系统之间的进行HTTP交互，可以考虑使用基于指数退避的算法进行重试，举个例子： 123451、第一次调用失败，马上进行第二次重试2、第二次重试失败，线程休眠2秒3、第三次重试失败，线程休眠4秒(2^2)4、第四次重试失败，线程休眠8秒(2^3)5、第五次重试失败，抛出异常 如果上面的例子中使用了Hystrix控制超时为1秒包裹着要执行的HTTP命令进行调用，上面的重试过程最大耗时小于20秒，在低并发的内部系统之间的交互是可以接受的。 但是，如果面对的是并发比较高、用户体验优先级比较高的场景，这样做显然是不合理的。为了稳妥起见，可以采取相对传统而有效的方案：HTTP调用的调用信息快照内容保存到一张本地重试表中，这个保存操作绑定在业务处理的事务中，通过定时调度对未调用成功的记录进行重试。这个方案和上文提到保证消息推送成功的方案类似，举一个仿真的例子： 123456789101112[下单接口请求下游钱包服务扣钱的过程]process()&#123; [事务代码块-start] 1、处理业务逻辑，保存订单信息，订单状态为扣钱处理中 2、组装将要向下游钱包服务发起的HTTP调用信息，保存在本地表中 [事务代码块-end] 3、事务外进行HTTP调用(OkHttp客户端或者Apache的Http客户端)，调用成功更新订单状态为扣钱成功&#125;定时调度()&#123; 4、定时查询订单状态为扣钱处理中的订单进行HTTP调用，调用成功更新订单状态为扣钱成功&#125; 异步消息消费失败补偿 异步消息消费失败的场景发生只能在消息消费方，也就是下游服务。从降低成本的目的上看，消息消费失败的补偿应该由消息处理的一方(消费者)自行承担，画一个系统交互图理解一下： 如果由上游服务进行补偿，存在两个明显的问题： 1、消息补偿模块需要在所有的上游服务中编写，这是不合理的。 2、一旦下游消费出现生产问题需要上游补偿，需要先定位出对应的消息是哪个上游服务推送，然后通过该上游服务进行补偿，处理生产问题的复杂度提高。 在最近的一些项目实践中，确定在使用异步消息交互的时候，补偿统一由消息消费方实现。最简单的方式也是使用类似本地消息表的方式，把消费失败的消息入库，并且进行重试，到达重试上限依然失败则进行预警和人工介入即可。简单的流程图如下： 异步消息乱序解决 异步消息乱序是使用消息队列进行异步交互场景中需要考虑和解决的问题。下面举一些可能不合乎实际但是能够说明问题的例子。 场景一：上游某个服务向用户服务通过消息队列异步修改用户的性别信息，假设消息简化如下： 123456队列：user-service.modify.sex.qeue消息:&#123; \"userId\": 长整型, \"sex\": 字符串,可选值是MAN、WOMAN和UNKNOW&#125; 用户服务一共使用了10个消费者线程监听user-service.modify.sex.qeue队列。假设上游服务先后向user-service.modify.sex.qeue队列推送下面两条消息： 1234567891011第一条消息：&#123; \"userId\": 1, \"sex\": \"MAN\"&#125; 第二条消息：&#123; \"userId\": 1, \"sex\": \"WOMAN\"&#125; 上面的消息推送和下游处理有比较高几率出现下面的情况： 原本用户ID为1的用户先把性别改为MAN(第一次请求)，后来改为WOMAN(第二次请求)，最终看到更新后的性别有可能是MAN，这显然是不合理的。这个不是很合理的例子想说明的问题是：通过异步消息交互，下游服务处理消息的时序有可能和上游发送消息的时序并不一致，这样有可能导致业务状态错乱。对于解决这个问题，提供几个可行的思路： 方案一：并发要求不高的情况下，可以充分利用消息队列FIFO的特性(这一点RabbitMQ实现了，其他消息队列中间件不确定)，把下游服务的消费线程设置为1即可，那么上游推送的消息和下游消费消息的时序是一致的(这个方案有缺陷，因为分布式多节点部署，下游服务节点会超过两个，因此消费者线程一定会大于1)。 方案二：使用HTTP调用，这个要前端或者APP客户端配合，请求设计成串行的即可。 方案三：这是一个实验性方案，个人只在Demo中尝试过，采用取模或者Hash对队列进行分片，上面的例子基于用户ID % 10取模建立queue_0到queue_9一共10个队列，下游启动10个消费者线程，queue_0到queue_9每个队列只启动一个消费线程(例如下游服务有双节点，节点1消费queue_0到queue_4，节点2消费queue_5到queue_9)，这样子能够保证单个用户ID的性别更新操作是串行的。 场景二：没有时序要求的异步消息处理，但是要求最终展示的时候是有时序的。这样说可能有点抽象，举个例子：在借呗上借了10000元，还款的时候，用户是分多次还清(例如还款方案一：2000,3000,5000；还款方案二：1000,1000，1000，7000等等)，每次还的钱都不一样，最终要求账单展示的时候是按照用户的还款操作顺序。 假设借呗的上游服务和它通过异步消息交互。详细分析一下：这个场景其实对于借呗(主要是考虑收回用户的还款这个目的)来说，对用户还款的顺序并不需要感知，只需要考虑用户是否还清，但是使用异步交互，有可能导致下游无法正确得知用户还款的操作顺序。 解决方案很简单：推送消息的时候附加一个带有增长或者减少趋势的标记位即可，例如使用带有时间戳的标记位或者使用Snowflake算法生成自增趋势的长整型数作为流水号，之后按照流水号排序即可得到消息操作的顺序(这个流水号下游需要保存)，但是实际消息处理的时候并不需要感知消息的时序。 异步消息结合状态驱动 个人认为：异步消息结合状态驱动是可以相对完善地解决分布式事务，结合预处理(例如预扣除或者预增长)可以满足比较高一致性和实时性。先引出一个经常用来讨论分布式事务强一致性的转账场景。 解决这个问题如果使用同步调用(其实像TCC、2PC或者3PC等本质都是同步调用)，在允许性能损失的情况下是能够达到比较高的一致性。这一节并不讨论同步调用的情况下怎么做，重点研究一下在使用消息队列的情况下，如何从BASE的角度&quot;达到比较高的一致性&quot;。先把这个例子抽象化，假设两个系统的账户表都设计成这样： 123456789CREATE TABLE `t_account`( id BIGINT PRIMARY KEY COMMENT '主键', user_id BIGINT NOT NULL COMMENT '用户ID', balance DECIMAL(10,2) NOT NULL DEFAULT 0 COMMENT '账户余额', create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', edit_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间', version BIGINT NOT NULL DEFAULT 0 COMMENT '版本' // 省略索引)COMMENT '账户表'; 两个系统都可以建立一张表结构相似的金额变更流水表，上游系统用于做预扣操作和流水记录，下游系统用于做流水记录，接着我们可以梳理出新的交互时序逻辑如下： 1234567891011121314151617181920[A系统本地事务-start]1、A系统t_account表X用户余额减去10002、A系统流水表写入一条用户X的预扣1000的记录，标记状态为处理中，生成全局唯一的流水号记为SEQ_NO[A系统本地事务-end]3、A系统通过消息队列推送一条用户X扣减1000的消息(一定要附带流水号SEQ_NO)到消息队列中间件(这里可以用上文提到的技巧确保消息推送成功)[B系统本地事务-start]4、B系统t_account表X用户余额加上10005、B系统流水表写入一条用户X的余额变更(增加)1000的记录 &lt;= 注意这里B系统的流水只能insert不能update[B系统本地事务-end]6、B系统推送处理X用户余额处理成功的消息到消息队列中间件，一定要附带流水号SEQ_NO(这里可以用上文提到的技巧确保消息推送成功)[A系统本地事务-start]7、A系统更新流水表中X用户流水号为SEQ_NO的预扣记录的状态为处理成功(这一步一定要做好幂等控制，可以考虑用SEQ_NO作为分布式锁的KEY)[A系统本地事务-end]其他：[A系统流水表处理中的记录需要定时轮询和重试]1、定时调度重试A系统流水表中状态为处理中的记录[A-B系统日切对账模块]1、日切，用A系统中处理成功的T-1日流水记录和B系统中的流水表所有T-1日的记录进行对账 上面的步骤看起来比较多，而且还需要编写对账和重试模块。其实，在上下游系统、消息队列中间件都正常运作的情况下，上面的这套交互方案可承受的并发量远比同步方案高，出现了服务或者消息队列中间件不可用的情况下，由于流水表有未处理的本地记录，在这些问题恢复之后可以重试，可靠性也是比较高的。另外，重试和对账的模块，对于所有涉及金额交易的处理都是必须的，这一点其实选用同步或者异步交互方式并没有关系(时序图只展示了一般和正常交互情况下的调用时序，异常情况例如超额转账、调用链中某个环节失败等细节等暂不分析)。 小结 你会发觉，通篇文章有很多方案都是使用了待处理内容写入本地表 + 事务外实时触发 + 定时调度补偿这个模式，其实我想表达的就是这个模式是目前分布式解决方案中一个相对通用的模式，可以基本满足分布式事务、同步异步补偿、实时非实时触发等多种复杂场景的处理。这个模式也存在一些明显的问题(如果实践过的话一般会遇到)： 1、库表(本地消息表)设计不合理或者处理不合理容易成为数据库的瓶颈。 2、补偿或者本地表入库处理的逻辑代码容易冗余和腐化。 3、极端情况下，异常恢复的场景存在拖垮服务的隐患。 其实，更多的时候需要结合现有的系统或者场景进行分析。毕竟，架构是迭代出来，而不是设计出来的。 (本文完 r-a-20190324 c-14-d 最近还是996)","categories":[{"name":"In Action","slug":"In-Action","permalink":"http://throwable.club/blog/categories/In-Action/"},{"name":"Distributed Transaction","slug":"In-Action/Distributed-Transaction","permalink":"http://throwable.club/blog/categories/In-Action/Distributed-Transaction/"}],"tags":[{"name":"In Action","slug":"In-Action","permalink":"http://throwable.club/blog/tags/In-Action/"},{"name":"Distributed Transaction","slug":"Distributed-Transaction","permalink":"http://throwable.club/blog/tags/Distributed-Transaction/"}]},{"title":"zuul源码分析-探究原生zuul的工作原理","slug":"java-netflix-zuul-implementation","date":"2019-03-14T15:21:08.000Z","updated":"2019-03-14T15:22:08.287Z","comments":true,"path":"2019/03/14/java-netflix-zuul-implementation/","link":"","permalink":"http://throwable.club/2019/03/14/java-netflix-zuul-implementation/","excerpt":"","text":"zuul源码分析-探究原生zuul的工作原理 前提 最近在项目中使用了SpringCloud，基于Zuul搭建了一个提供加解密、鉴权等功能的网关服务。鉴于之前没怎么使用过Zuul，于是顺便仔细阅读了它的源码。实际上，Zuul原来提供的功能是很单一的：通过一个统一的Servlet入口(ZuulServlet，或者Filter入口，使用ZuulServletFilter)拦截所有的请求，然后通过内建的com.netflix.zuul.IZuulFilter链对请求做拦截和过滤处理。ZuulFilter和javax.servlet.Filter的原理相似，但是它们本质并不相同。javax.servlet.Filter在Web应用中是独立的组件，ZuulFilter是ZuulServlet处理请求时候调用的，后面会详细分析。 源码环境准备 Zuul的项目地址是https://github.com/Netflix/zuul，它是著名的&quot;开源框架提供商&quot;Netflix的作品，项目的目的是：Zuul是一个网关服务，提供动态路由、监视、弹性、安全性等。在SpringCloud中引入了zuul，配合Netflix的另一个负载均衡框架Ribbon和Netflix的另一个提供服务发现与注册框架Eureka，可以实现服务的动态路由。值得注意的是，zuul在2.x甚至3.x的分支中已经引入了netty，框架的复杂性大大提高。但是当前的SpringCloud体系并没有升级zuul的版本，目前使用的是zuul1.x的最高版本1.3.1。 因此我们需要阅读它的源码的时候可以选择这个发布版本。值得注意的是，由于这些版本的发布时间已经比较久，有部分插件或者依赖包可能找不到，笔者在构建zuul1.3.1的源码的时候发现这几个问题： 1、nebula.netflixoss插件的旧版本已经不再支持，所有build.gradle文件中的nebula.netflixoss插件的版本修改为5.2.0。 2、2017年的时候Gradle支持的版本是2.x，笔者这里选择了gradle-2.14，选择高版本的Gradle有可能在构建项目的时候出现jetty插件不支持。 3、Jdk最好使用1.8，Gradle构建文件中的sourceCompatibility、targetCompatibility、languageLevel等配置全改为1.8。 另外，如果使用IDEA进行构建，注意配置项目的Jdk和Java环境，所有配置改为Jdk1.8，Gradle构建成功后如下： zuul-1.3.1中提供了一个Web应用的Sample项目，我们直接运行zuul-simple-webapp的Gradle配置中的Tomcat插件即可启动项目，开始Debug之旅： 源码分析 ZuulFilter的加载 从Zuul的源码来看，ZuulFilter的加载模式可能跟我们想象的大有不同，Zuul设计的初衷是ZuulFilter是存放在Groovy文件中，可以实现基于最后修改时间进行热加载。我们先看看Zuul核心类之一com.netflix.zuul.filters.FilterRegistry(Filter的注册中心，实际上是ZuulFilter的全局缓存)： 1234567891011121314151617181920212223242526272829303132333435public class FilterRegistry &#123; // 饿汉式单例，确保全局只有一个ZuulFilter的缓存 private static final FilterRegistry INSTANCE = new FilterRegistry(); public static final FilterRegistry instance() &#123; return INSTANCE; &#125; //缓存字符串到ZuulFilter实例的映射关系，如果是从文件加载，字符串key的格式是：文件绝对路径 + 文件名，当然也可以自实现 private final ConcurrentHashMap&lt;String, ZuulFilter&gt; filters = new ConcurrentHashMap&lt;String, ZuulFilter&gt;(); private FilterRegistry() &#123; &#125; public ZuulFilter remove(String key) &#123; return this.filters.remove(key); &#125; public ZuulFilter get(String key) &#123; return this.filters.get(key); &#125; public void put(String key, ZuulFilter filter) &#123; this.filters.putIfAbsent(key, filter); &#125; public int size() &#123; return this.filters.size(); &#125; public Collection&lt;ZuulFilter&gt; getAllFilters() &#123; return this.filters.values(); &#125;&#125; 实际上Zuul使用了简单粗暴的方式(直接使用ConcurrentHashMap)缓存了ZuulFilter，这些缓存除非主动调用remove方法，否则不会自动清理。Zuul提供默认的动态代码编译器，接口是DynamicCodeCompiler，目的是把代码编译为Java的类，默认实现是GroovyCompiler，功能就是把Groovy代码编译为Java类。还有一个比较重要的工厂类接口是FilterFactory，它定义了ZuulFilter类生成ZuulFilter实例的逻辑，默认实现是DefaultFilterFactory，实际上就是利用Class#newInstance()反射生成ZuulFilter实例。接着，我们可以进行分析FilterLoader的源码，这个类的作用就是加载文件中的ZuulFilter实例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114public class FilterLoader &#123; //静态final实例，注意到访问权限是包许可，实际上就是饿汉式单例 final static FilterLoader INSTANCE = new FilterLoader(); private static final Logger LOG = LoggerFactory.getLogger(FilterLoader.class); //缓存Filter名称(主要是从文件加载，名称为绝对路径 + 文件名的形式)-&gt;Filter最后修改时间戳的映射 private final ConcurrentHashMap&lt;String, Long&gt; filterClassLastModified = new ConcurrentHashMap&lt;String, Long&gt;(); //缓存Filter名字-&gt;Filter代码的映射，实际上这个Map只使用到get方法进行存在性判断，一直是一个空的结构 private final ConcurrentHashMap&lt;String, String&gt; filterClassCode = new ConcurrentHashMap&lt;String, String&gt;(); //缓存Filter名字-&gt;Filter名字的映射，用于存在性判断 private final ConcurrentHashMap&lt;String, String&gt; filterCheck = new ConcurrentHashMap&lt;String, String&gt;(); //缓存Filter类型名称-&gt;List&lt;ZuulFilter&gt;的映射 private final ConcurrentHashMap&lt;String, List&lt;ZuulFilter&gt;&gt; hashFiltersByType = new ConcurrentHashMap&lt;String, List&lt;ZuulFilter&gt;&gt;(); //前面提到的ZuulFilter全局缓存的单例 private FilterRegistry filterRegistry = FilterRegistry.instance(); //动态代码编译器实例，Zuul提供的默认实现是GroovyCompiler static DynamicCodeCompiler COMPILER; //ZuulFilter的工厂类 static FilterFactory FILTER_FACTORY = new DefaultFilterFactory(); //下面三个方法说明DynamicCodeCompiler、FilterRegistry、FilterFactory可以被覆盖 public void setCompiler(DynamicCodeCompiler compiler) &#123; COMPILER = compiler; &#125; public void setFilterRegistry(FilterRegistry r) &#123; this.filterRegistry = r; &#125; public void setFilterFactory(FilterFactory factory) &#123; FILTER_FACTORY = factory; &#125; //饿汉式单例获取自身实例 public static FilterLoader getInstance() &#123; return INSTANCE; &#125; //返回所有缓存的ZuulFilter实例的总数量 public int filterInstanceMapSize() &#123; return filterRegistry.size(); &#125; //通过ZuulFilter的类代码和Filter名称获取ZuulFilter实例 public ZuulFilter getFilter(String sCode, String sName) throws Exception &#123; //检查filterCheck是否存在相同名字的Filter，如果存在说明已经加载过 if (filterCheck.get(sName) == null) &#123; //filterCheck中放入Filter名称 filterCheck.putIfAbsent(sName, sName); //filterClassCode中不存在加载过的Filter名称对应的代码 if (!sCode.equals(filterClassCode.get(sName))) &#123; LOG.info(\"reloading code \" + sName); //从全局缓存中移除对应的Filter filterRegistry.remove(sName); &#125; &#125; ZuulFilter filter = filterRegistry.get(sName); //如果全局缓存中不存在对应的Filter，就使用DynamicCodeCompiler加载代码，使用FilterFactory实例化ZuulFilter //注意加载的ZuulFilter类不能是抽象的，必须是继承了ZuulFilter的子类 if (filter == null) &#123; Class clazz = COMPILER.compile(sCode, sName); if (!Modifier.isAbstract(clazz.getModifiers())) &#123; filter = (ZuulFilter) FILTER_FACTORY.newInstance(clazz); &#125; &#125; return filter; &#125; //通过文件加加载ZuulFilter public boolean putFilter(File file) throws Exception &#123; //Filter名称为文件的绝对路径+文件名(这里其实绝对路径已经包含文件名，这里再加文件名的目的不明确) String sName = file.getAbsolutePath() + file.getName(); //如果文件被修改过则从全局缓存从移除对应的Filter以便重新加载 if (filterClassLastModified.get(sName) != null &amp;&amp; (file.lastModified() != filterClassLastModified.get(sName))) &#123; LOG.debug(\"reloading filter \" + sName); filterRegistry.remove(sName); &#125; //下面的逻辑和上一个方法类似 ZuulFilter filter = filterRegistry.get(sName); if (filter == null) &#123; Class clazz = COMPILER.compile(file); if (!Modifier.isAbstract(clazz.getModifiers())) &#123; filter = (ZuulFilter) FILTER_FACTORY.newInstance(clazz); List&lt;ZuulFilter&gt; list = hashFiltersByType.get(filter.filterType()); //这里说明了一旦文件有修改，hashFiltersByType中对应的当前文件加载出来的Filter类型的缓存要移除，原因见下一个方法 if (list != null) &#123; hashFiltersByType.remove(filter.filterType()); //rebuild this list &#125; filterRegistry.put(file.getAbsolutePath() + file.getName(), filter); filterClassLastModified.put(sName, file.lastModified()); return true; &#125; &#125; return false; &#125; //通过Filter类型获取同类型的所有ZuulFilter public List&lt;ZuulFilter&gt; getFiltersByType(String filterType) &#123; List&lt;ZuulFilter&gt; list = hashFiltersByType.get(filterType); if (list != null) return list; list = new ArrayList&lt;ZuulFilter&gt;(); //如果hashFiltersByType缓存被移除，这里从全局缓存中加载所有的ZuulFilter，按照指定类型构建一个新的列表 Collection&lt;ZuulFilter&gt; filters = filterRegistry.getAllFilters(); for (Iterator&lt;ZuulFilter&gt; iterator = filters.iterator(); iterator.hasNext(); ) &#123; ZuulFilter filter = iterator.next(); if (filter.filterType().equals(filterType)) &#123; list.add(filter); &#125; &#125; //注意这里会进行排序，是基于filterOrder Collections.sort(list); // sort by priority //这里总是putIfAbsent，这就是为什么上个方法可以放心地在修改的情况下移除指定Filter类型中的全部缓存实例的原因 hashFiltersByType.putIfAbsent(filterType, list); return list; &#125;&#125; 上面的几个方法和缓存容器都比较简单，这里实际上有加载和存放动作的方法只有putFilter，这个方法正是Filter文件管理器FilterFileManager依赖的，接着看FilterFileManager的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public class FilterFileManager &#123; private static final Logger LOG = LoggerFactory.getLogger(FilterFileManager.class); String[] aDirectories; int pollingIntervalSeconds; Thread poller; boolean bRunning = true; //文件名过滤器，Zuul中的默认实现是GroovyFileFilter，只接受.groovy后缀的文件 static FilenameFilter FILENAME_FILTER; static FilterFileManager INSTANCE; private FilterFileManager() &#123; &#125; public static void setFilenameFilter(FilenameFilter filter) &#123; FILENAME_FILTER = filter; &#125; //init方法是核心静态方法，它具备了配置，预处理和激活后台轮询线程的功能 public static void init(int pollingIntervalSeconds, String... directories) throws Exception, IllegalAccessException, InstantiationException&#123; if (INSTANCE == null) INSTANCE = new FilterFileManager(); INSTANCE.aDirectories = directories; INSTANCE.pollingIntervalSeconds = pollingIntervalSeconds; INSTANCE.manageFiles(); INSTANCE.startPoller(); &#125; public static FilterFileManager getInstance() &#123; return INSTANCE; &#125; public static void shutdown() &#123; INSTANCE.stopPoller(); &#125; void stopPoller() &#123; bRunning = false; &#125; //启动后台轮询守护线程，每休眠pollingIntervalSeconds秒则进行一次文件扫描尝试更新Filter void startPoller() &#123; poller = new Thread(\"GroovyFilterFileManagerPoller\") &#123; public void run() &#123; while (bRunning) &#123; try &#123; sleep(pollingIntervalSeconds * 1000); //预处理文件，实际上是ZuulFilter的预加载 manageFiles(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;; //设置为守护线程 poller.setDaemon(true); poller.start(); &#125; //根据指定目录路径获取目录，主要需要转换为ClassPath public File getDirectory(String sPath) &#123; File directory = new File(sPath); if (!directory.isDirectory()) &#123; URL resource = FilterFileManager.class.getClassLoader().getResource(sPath); try &#123; directory = new File(resource.toURI()); &#125; catch (Exception e) &#123; LOG.error(\"Error accessing directory in classloader. path=\" + sPath, e); &#125; if (!directory.isDirectory()) &#123; throw new RuntimeException(directory.getAbsolutePath() + \" is not a valid directory\"); &#125; &#125; return directory; &#125; //遍历配置目录，获取所有配置目录下的所有满足FilenameFilter过滤条件的文件 List&lt;File&gt; getFiles() &#123; List&lt;File&gt; list = new ArrayList&lt;File&gt;(); for (String sDirectory : aDirectories) &#123; if (sDirectory != null) &#123; File directory = getDirectory(sDirectory); File[] aFiles = directory.listFiles(FILENAME_FILTER); if (aFiles != null) &#123; list.addAll(Arrays.asList(aFiles)); &#125; &#125; &#125; return list; &#125; //遍历指定文件列表，调用FilterLoader单例中的putFilter void processGroovyFiles(List&lt;File&gt; aFiles) throws Exception, InstantiationException, IllegalAccessException &#123; for (File file : aFiles) &#123; FilterLoader.getInstance().putFilter(file); &#125; &#125; //获取指定目录下的所有文件，调用processGroovyFiles，个人认为这两个方法没必要做单独封装 void manageFiles() throws Exception, IllegalAccessException, InstantiationException &#123; List&lt;File&gt; aFiles = getFiles(); processGroovyFiles(aFiles); &#125; 分析完FilterFileManager源码之后，Zuul中基于文件加载ZuulFilter的逻辑已经十分清晰：后台启动一个守护线程，定时轮询指定文件夹里面的文件，如果文件存在变更，则尝试更新指定的ZuulFilter缓存，FilterFileManager的init方法调用的时候在启动后台线程之前会进行一次预加载。 RequestContext 在分析ZuulFilter的使用之前，有必要先了解Zuul中的请求上下文对象RequestContext。首先要有一个共识：每一个新的请求都是由一个独立的线程处理(这个线程是Tomcat里面起的线程)，换言之，请求的所有参数(Http报文信息解析出来的内容，如请求头、请求体等等)总是绑定在处理请求的线程中。RequestContext的设计就是简单直接有效，它继承于ConcurrentHashMap&lt;String, Object&gt;，所以参数可以直接设置在RequestContext中，Zuul没有设计一个类似于枚举的类控制RequestContext的可选参数，因此里面的设置值和提取值的方法都是硬编码的，例如： 12345678910111213141516public HttpServletRequest getRequest() &#123; return (HttpServletRequest) get(\"request\");&#125;public void setRequest(HttpServletRequest request) &#123; put(\"request\", request);&#125;public HttpServletResponse getResponse() &#123; return (HttpServletResponse) get(\"response\");&#125;public void setResponse(HttpServletResponse response) &#123; set(\"response\", response);&#125;... 看起来很暴力并且不怎么优雅，但是实际上是高效的。RequestContext一般使用静态方法RequestContext#getCurrentContext()进行初始化，我们分析一下它的初始化流程： 1234567891011121314151617181920212223242526272829//保存RequestContext自身类型protected static Class&lt;? extends RequestContext&gt; contextClass = RequestContext.class;//静态对象private static RequestContext testContext = null;//静态final修饰的ThreadLocal实例，用于存放所有的RequestContext，每个RequestContext都会绑定在自身请求的处理线程中//注意这里的ThreadLocal实例的initialValue()方法，当ThreadLocal的get()方法返回null的时候总是会调用initialValue()方法protected static final ThreadLocal&lt;? extends RequestContext&gt; threadLocal = new ThreadLocal&lt;RequestContext&gt;() &#123; @Override protected RequestContext initialValue() &#123; try &#123; return contextClass.newInstance(); &#125; catch (Throwable e) &#123; throw new RuntimeException(e); &#125; &#125;&#125;;public RequestContext() &#123; super();&#125;public static RequestContext getCurrentContext() &#123; //这里混杂了测试的代码，暂时忽略 if (testContext != null) return testContext; //当ThreadLocal的get()方法返回null的时候总是会调用initialValue()方法，所以这里是\"无则新建RequestContext\"的逻辑 RequestContext context = threadLocal.get(); return context;&#125; 注意上面的ThreadLocal覆盖了初始化方法initialValue()，ThreadLocal的初始化方法总是在ThreadLocal#get()方法返回null的时候调用，实际上静态方法RequestContext#getCurrentContext()的作用就是：如果ThreadLocal中已经绑定了RequestContext静态实例就直接获取绑定在线程中的RequestContext实例，否则新建一个RequestContext实例存放在ThreadLocal(绑定到当前的请求线程中)。了解这一点后面分析ZuulServletFilter和ZuulServlet的时候就很简单了。 ZuulFilter 抽象类com.netflix.zuul.ZuulFilter是Zuul里面的核心组件，它是用户扩展Zuul行为的组件，用户可以实现不同类型的ZuulFilter、定义它们的执行顺序、实现它们的执行方法达到定制化的目的，SpringCloud的netflix-zuul就是一个很好的实现包。ZuulFilter实现了IZuulFilter接口，我们先看这个接口的定义： 123456public interface IZuulFilter &#123; boolean shouldFilter(); Object run() throws ZuulException;&#125; 很简单，shouldFilter()方法决定是否需要执行(也就是执行时机由使用者扩展，甚至可以禁用)，而run()方法决定执行的逻辑。接着看ZuulFilter的源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public abstract class ZuulFilter implements IZuulFilter, Comparable&lt;ZuulFilter&gt; &#123; //netflix的配置组件，实际上就是基于配置文件提取的指定key的值 private final AtomicReference&lt;DynamicBooleanProperty&gt; filterDisabledRef = new AtomicReference&lt;&gt;(); //定义Filter的类型 abstract public String filterType(); //定义当前Filter实例执行的顺序 abstract public int filterOrder(); //是否静态的Filter，静态的Filter是无状态的 public boolean isStaticFilter() &#123; return true; &#125; //禁用当前Filter的配置属性的Key名称 //Key=zuul.$&#123;全类名&#125;.$&#123;filterType&#125;.disable public String disablePropertyName() &#123; return \"zuul.\" + this.getClass().getSimpleName() + \".\" + filterType() + \".disable\"; &#125; //判断当前的Filter是否禁用，通过disablePropertyName方法从配置中读取，默认是不禁用，也就是启用 public boolean isFilterDisabled() &#123; filterDisabledRef.compareAndSet(null, DynamicPropertyFactory.getInstance().getBooleanProperty(disablePropertyName(), false)); return filterDisabledRef.get().get(); &#125; //这个是核心方法，执行Filter，如果Filter不是禁用、并且满足执行时机则调用run方法，返回执行结果，记录执行轨迹 public ZuulFilterResult runFilter() &#123; ZuulFilterResult zr = new ZuulFilterResult(); if (!isFilterDisabled()) &#123; if (shouldFilter()) &#123; Tracer t = TracerFactory.instance().startMicroTracer(\"ZUUL::\" + this.getClass().getSimpleName()); try &#123; Object res = run(); zr = new ZuulFilterResult(res, ExecutionStatus.SUCCESS); &#125; catch (Throwable e) &#123; t.setName(\"ZUUL::\" + this.getClass().getSimpleName() + \" failed\"); zr = new ZuulFilterResult(ExecutionStatus.FAILED); //注意这里只保存异常的实例，即使执行抛出异常 zr.setException(e); &#125; finally &#123; t.stopAndLog(); &#125; &#125; else &#123; zr = new ZuulFilterResult(ExecutionStatus.SKIPPED); &#125; &#125; return zr; &#125; //实现Comparable，基于filterOrder升序排序，也就是filterOrder越大，执行优先度越低 public int compareTo(ZuulFilter filter) &#123; return Integer.compare(this.filterOrder(), filter.filterOrder()); &#125;&#125; 这里注意几个地方，第一个是filterOrder()方法和compareTo(ZuulFilter filter)方法，子类实现ZuulFilter时候，filterOrder()方法返回值越大，或者说Filter的顺序系数越大，ZuulFilter执行的优先度越低。第二个地方是可以通过zuul.${全类名}.${filterType}.disable=false通过类名和Filter类型禁用对应的Filter。第三个值得注意的地方是Zuul中定义了四种类型的ZuulFilter，后面分析ZuulRunner的时候再详细展开。ZuulFilter实际上就是使用者扩展的核心组件，通过实现ZuulFilter的方法可以在一个请求处理链中的特定位置执行特定的定制化逻辑。第四个值得注意的地方是runFilter()方法执行不会抛出异常，如果出现异常，Throwable实例会保存在ZuulFilterResult对象中返回到外层方法，如果正常执行，则直接返回runFilter()方法的结果。 FilterProcessor 前面花大量功夫分析完ZuulFilter基于Groovy文件的加载机制(在SpringCloud体系中并没有使用此策略，因此，我们持了解的态度即可)以及RequestContext的设计，接着我们分析FilterProcessor去了解如何使用加载好的缓存中的ZuulFilter。我们先看FilterProcessor的基本属性： 12345678910111213141516171819202122232425public class FilterProcessor &#123; static FilterProcessor INSTANCE = new FilterProcessor(); protected static final Logger logger = LoggerFactory.getLogger(FilterProcessor.class); private FilterUsageNotifier usageNotifier; public FilterProcessor() &#123; usageNotifier = new BasicFilterUsageNotifier(); &#125; public static FilterProcessor getInstance() &#123; return INSTANCE; &#125; public static void setProcessor(FilterProcessor processor) &#123; INSTANCE = processor; &#125; public void setFilterUsageNotifier(FilterUsageNotifier notifier) &#123; this.usageNotifier = notifier; &#125; ...&#125; 像之前分析的几个类一样，FilterProcessor设计为单例，提供可以覆盖单例实例的方法。需要注意的一点是属性usageNotifier是FilterUsageNotifier类型，FilterUsageNotifier接口的默认实现是BasicFilterUsageNotifier(FilterProcessor的一个静态内部类)，BasicFilterUsageNotifier依赖于Netflix的一个工具包servo-core，提供基于内存态的计数器统计每种ZuulFilter的每一次调用的状态ExecutionStatus。枚举ExecutionStatus的可选值如下： 1、SUCCESS，代表该Filter处理成功，值为1。 2、SKIPPED，代表该Filter跳过处理，值为-1。 3、DISABLED，代表该Filter禁用，值为-2。 4、SUCCESS，代表该FAILED处理出现异常，值为-3。 当然，使用者也可以覆盖usageNotifier属性。接着我们看FilterProcessor中真正调用ZuulFilter实例的核心方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182//指定Filter类型执行该类型下的所有ZuulFilterpublic Object runFilters(String sType) throws Throwable &#123; //尝试打印Debug日志 if (RequestContext.getCurrentContext().debugRouting()) &#123; Debug.addRoutingDebug(\"Invoking &#123;\" + sType + \"&#125; type filters\"); &#125; boolean bResult = false; //获取所有指定类型的ZuulFilter List&lt;ZuulFilter&gt; list = FilterLoader.getInstance().getFiltersByType(sType); if (list != null) &#123; for (int i = 0; i &lt; list.size(); i++) &#123; ZuulFilter zuulFilter = list.get(i); Object result = processZuulFilter(zuulFilter); //如果处理结果是Boolean类型尝试做或操作，其他类型结果忽略 if (result != null &amp;&amp; result instanceof Boolean) &#123; bResult |= ((Boolean) result); &#125; &#125; &#125; return bResult;&#125;//执行ZuulFilter，这个就是ZuulFilter执行逻辑public Object processZuulFilter(ZuulFilter filter) throws ZuulException &#123; RequestContext ctx = RequestContext.getCurrentContext(); boolean bDebug = ctx.debugRouting(); final String metricPrefix = \"zuul.filter-\"; long execTime = 0; String filterName = \"\"; try &#123; long ltime = System.currentTimeMillis(); filterName = filter.getClass().getSimpleName(); RequestContext copy = null; Object o = null; Throwable t = null; if (bDebug) &#123; Debug.addRoutingDebug(\"Filter \" + filter.filterType() + \" \" + filter.filterOrder() + \" \" + filterName); copy = ctx.copy(); &#125; //简单调用ZuulFilter的runFilter方法 ZuulFilterResult result = filter.runFilter(); ExecutionStatus s = result.getStatus(); execTime = System.currentTimeMillis() - ltime; switch (s) &#123; case FAILED: t = result.getException(); //记录调用链中当前Filter的名称，执行结果状态和执行时间 ctx.addFilterExecutionSummary(filterName, ExecutionStatus.FAILED.name(), execTime); break; case SUCCESS: o = result.getResult(); //记录调用链中当前Filter的名称，执行结果状态和执行时间 ctx.addFilterExecutionSummary(filterName, ExecutionStatus.SUCCESS.name(), execTime); if (bDebug) &#123; Debug.addRoutingDebug(\"Filter &#123;\" + filterName + \" TYPE:\" + filter.filterType() + \" ORDER:\" + filter.filterOrder() + \"&#125; Execution time = \" + execTime + \"ms\"); Debug.compareContextState(filterName, copy); &#125; break; default: break; &#125; if (t != null) throw t; //这里做计数器的统计 usageNotifier.notify(filter, s); return o; &#125; catch (Throwable e) &#123; if (bDebug) &#123; Debug.addRoutingDebug(\"Running Filter failed \" + filterName + \" type:\" + filter.filterType() + \" order:\" + filter.filterOrder() + \" \" + e.getMessage()); &#125; //这里做计数器的统计 usageNotifier.notify(filter, ExecutionStatus.FAILED); if (e instanceof ZuulException) &#123; throw (ZuulException) e; &#125; else &#123; ZuulException ex = new ZuulException(e, \"Filter threw Exception\", 500, filter.filterType() + \":\" + filterName); //记录调用链中当前Filter的名称，执行结果状态和执行时间 ctx.addFilterExecutionSummary(filterName, ExecutionStatus.FAILED.name(), execTime); throw ex; &#125; &#125;&#125; 上面介绍了FilterProcessor中的processZuulFilter(ZuulFilter filter)方法主要提供ZuulFilter执行的一些度量相关记录(例如Filter执行耗时摘要，会形成一个链，记录在一个字符串中)和ZuulFilter的执行方法，ZuulFilter执行结果可能是成功或者异常，前面提到过，如果抛出异常Throwable实例会保存在ZuulFilterResult中，在processZuulFilter(ZuulFilter filter)发现ZuulFilterResult中的Throwable实例不为null则直接抛出，否则返回ZuulFilter正常执行的结果。另外，FilterProcessor中通过指定Filter类型执行所有对应类型的ZuulFilter的runFilters(String sType)方法，我们知道了runFilters(String sType)方法如果处理结果是Boolean类型尝试做或操作，其他类型结果忽略，可以理解为此方法的返回值是没有很大意义的。参考SpringCloud里面对ZuulFilter的返回值处理一般是直接塞进去当前线程绑定的RequestContext中，选择特定的ZuulFilter子类对前面的ZuulFilter产生的结果进行处理。FilterProcessor基于runFilters(String sType)方法提供了其他指定filterType的方法： 12345678910111213141516171819202122232425262728293031323334353637public void postRoute() throws ZuulException &#123; try &#123; runFilters(\"post\"); &#125; catch (ZuulException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new ZuulException(e, 500, \"UNCAUGHT_EXCEPTION_IN_POST_FILTER_\" + e.getClass().getName()); &#125;&#125;public void preRoute() throws ZuulException &#123; try &#123; runFilters(\"pre\"); &#125; catch (ZuulException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new ZuulException(e, 500, \"UNCAUGHT_EXCEPTION_IN_PRE_FILTER_\" + e.getClass().getName()); &#125;&#125;public void error() &#123; try &#123; runFilters(\"error\"); &#125; catch (Throwable e) &#123; logger.error(e.getMessage(), e); &#125;&#125;public void route() throws ZuulException &#123; try &#123; runFilters(\"route\"); &#125; catch (ZuulException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new ZuulException(e, 500, \"UNCAUGHT_EXCEPTION_IN_ROUTE_FILTER_\" + e.getClass().getName()); &#125;&#125; 上面提供的方法很简单，无法是指定参数为post、pre、error、route对runFilters(String sType)方法进行调用，至于这些FilterType的执行位置见下一个小节的分析。 ZuulServletFilter和ZuulServlet Zuul本来就是设计为Servlet规范组件的一个类库，ZuulServlet就是javax.servlet.http.HttpServlet的实现类，而ZuulServletFilter是javax.servlet.Filter的实现类。这两个类都依赖到ZuulRunner完成ZuulFilter的调用，它们的实现逻辑是完全一致的，我们只需要看其中一个类的实现，这里挑选ZuulServlet： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class ZuulServlet extends HttpServlet &#123; private static final long serialVersionUID = -3374242278843351500L; private ZuulRunner zuulRunner; @Override public void init(ServletConfig config) throws ServletException &#123; super.init(config); String bufferReqsStr = config.getInitParameter(\"buffer-requests\"); boolean bufferReqs = bufferReqsStr != null &amp;&amp; bufferReqsStr.equals(\"true\") ? true : false; zuulRunner = new ZuulRunner(bufferReqs); &#125; @Override public void service(javax.servlet.ServletRequest servletRequest, javax.servlet.ServletResponse servletResponse) throws ServletException, IOException &#123; try &#123; //实际上委托到ZuulRunner的init方法 init((HttpServletRequest) servletRequest, (HttpServletResponse) servletResponse); //初始化RequestContext实例 RequestContext context = RequestContext.getCurrentContext(); //设置RequestContext中zuulEngineRan=true context.setZuulEngineRan(); try &#123; preRoute(); &#125; catch (ZuulException e) &#123; error(e); postRoute(); return; &#125; try &#123; route(); &#125; catch (ZuulException e) &#123; error(e); postRoute(); return; &#125; try &#123; postRoute(); &#125; catch (ZuulException e) &#123; error(e); return; &#125; &#125; catch (Throwable e) &#123; error(new ZuulException(e, 500, \"UNHANDLED_EXCEPTION_\" + e.getClass().getName())); &#125; finally &#123; RequestContext.getCurrentContext().unset(); &#125; &#125; void postRoute() throws ZuulException &#123; zuulRunner.postRoute(); &#125; void route() throws ZuulException &#123; zuulRunner.route(); &#125; void preRoute() throws ZuulException &#123; zuulRunner.preRoute(); &#125; void init(HttpServletRequest servletRequest, HttpServletResponse servletResponse) &#123; zuulRunner.init(servletRequest, servletResponse); &#125; //这里会先设置RequestContext实例中的throwable属性为执行抛出的Throwable实例 void error(ZuulException e) &#123; RequestContext.getCurrentContext().setThrowable(e); zuulRunner.error(); &#125;&#125; ZuulServletFilter和ZuulServlet不相同的地方仅仅是初始化和处理方法的方法签名(参数列表和方法名)，其他逻辑甚至是代码是一模一样，使用过程中我们需要了解javax.servlet.http.HttpServlet和javax.servlet.Filter的作用去选择到底使用ZuulServletFilter还是ZuulServlet。上面的代码可以看到，ZuulServlet初始化的时候可以配置初始化布尔值参数buffer-requests，这个参数默认为false，它是ZuulRunner实例化的必须参数。ZuulServlet中的调用ZuulFilter的方法都委托到ZuulRunner实例去完成，但是我们可以从service(servletRequest, servletResponse)方法看出四种FilterType(pre、route、post、error)的ZuulFilter的执行顺序，总结如下： 1、pre、route、post都不抛出异常，顺序是：pre-&gt;route-&gt;post，error不执行。 2、pre抛出异常，顺序是：pre-&gt;error-&gt;post。 3、route抛出异常，顺序是：pre-&gt;route-&gt;error-&gt;post。 4、post抛出异常，顺序是：pre-&gt;route-&gt;post-&gt;error。 注意，一旦出现了异常，会把抛出的Throwable实例设置到绑定到当前请求线程的RequestContext实例中的throwable属性。还需要注意在service(servletRequest, servletResponse)的finally块中调用了RequestContext.getCurrentContext().unset();，实际上是从RequestContext的ThreadLocal实例中移除当前的RequestContext实例，这样做可以避免ThreadLocal使用不当导致内存泄漏。 接着看ZuulRunner的源码： 1234567891011121314151617181920212223242526272829303132333435363738public class ZuulRunner &#123; private boolean bufferRequests; public ZuulRunner() &#123; this.bufferRequests = true; &#125; public ZuulRunner(boolean bufferRequests) &#123; this.bufferRequests = bufferRequests; &#125; public void init(HttpServletRequest servletRequest, HttpServletResponse servletResponse) &#123; RequestContext ctx = RequestContext.getCurrentContext(); if (bufferRequests) &#123; ctx.setRequest(new HttpServletRequestWrapper(servletRequest)); &#125; else &#123; ctx.setRequest(servletRequest); &#125; ctx.setResponse(new HttpServletResponseWrapper(servletResponse)); &#125; public void postRoute() throws ZuulException &#123; FilterProcessor.getInstance().postRoute(); &#125; public void route() throws ZuulException &#123; FilterProcessor.getInstance().route(); &#125; public void preRoute() throws ZuulException &#123; FilterProcessor.getInstance().preRoute(); &#125; public void error() &#123; FilterProcessor.getInstance().error(); &#125;&#125; postRoute()、route()、preRoute()、error()都是直接委托到FilterProcessor中完成的，实际上就是执行对应类型的所有ZuulFilter实例。这里需要注意的是，初始化ZuulRunner时候，HttpServletResponse会被包装为com.netflix.zuul.http.HttpServletResponseWrapper实例，它是Zuul实现的javax.servlet.http.HttpServletResponseWrapper的子类，主要是添加了一个属性status用来记录Http状态码。如果初始化参数bufferRequests为true，HttpServletRequest会被包装为com.netflix.zuul.http.HttpServletRequestWrapper，它是Zuul实现的javax.servlet.http.HttpServletRequestWrapper的子类，这个包装类主要是把请求的表单参数和请求体都缓存在实例属性中，这样在一些特定场景中可以提高性能。如果没有特殊需要，这个参数bufferRequests一般设置为false。 Zuul简单的使用例子 我们做一个很简单的例子，场景是：对于每个POST请求，使用pre类型的ZuulFilter打印它的请求体，然后使用post类型的ZuulFilter，响应结果硬编码为字符串&quot;Hello World!&quot;。我们先为CounterFactory、`TracerFactory添加两个空的子类，因为Zuul处理逻辑中依赖到这两个组件实现数据度量： 123456789101112131415public class DefaultTracerFactory extends TracerFactory &#123; @Override public Tracer startMicroTracer(String name) &#123; return null; &#125;&#125;public class DefaultCounterFactory extends CounterFactory &#123; @Override public void increment(String name) &#123; &#125;&#125; 接着我们分别继承ZuulFilter，实现一个pre类型的用于打印请求参数的Filter，命名为PrintParameterZuulFilter，实现一个post类型的用于返回字符串&quot;Hello World!&quot;的Filter，命名为SendResponseZuulFilter： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class PrintParameterZuulFilter extends ZuulFilter &#123; @Override public String filterType() &#123; return \"pre\"; &#125; @Override public int filterOrder() &#123; return 0; &#125; @Override public boolean shouldFilter() &#123; RequestContext context = RequestContext.getCurrentContext(); HttpServletRequest request = context.getRequest(); return \"POST\".equalsIgnoreCase(request.getMethod()); &#125; @Override public Object run() throws ZuulException &#123; RequestContext context = RequestContext.getCurrentContext(); HttpServletRequest request = context.getRequest(); if (null != request.getContentType()) &#123; if (request.getContentType().contains(\"application/json\")) &#123; try &#123; ServletInputStream inputStream = request.getInputStream(); String result = StreamUtils.copyToString(inputStream, Charset.forName(\"UTF-8\")); System.out.println(String.format(\"请求URI为:%s,请求参数为:%s\", request.getRequestURI(), result)); &#125; catch (IOException e) &#123; throw new ZuulException(e, 500, \"从输入流中读取请求参数异常\"); &#125; &#125; else if (request.getContentType().contains(\"application/x-www-form-urlencoded\")) &#123; StringBuilder params = new StringBuilder(); Enumeration&lt;String&gt; parameterNames = request.getParameterNames(); while (parameterNames.hasMoreElements()) &#123; String name = parameterNames.nextElement(); params.append(name).append(\"=\").append(request.getParameter(name)).append(\"&amp;\"); &#125; String result = params.toString(); System.out.println(String.format(\"请求URI为:%s,请求参数为:%s\", request.getRequestURI(), result.substring(0, result.lastIndexOf(\"&amp;\")))); &#125; &#125; return null; &#125;&#125;public class SendResponseZuulFilter extends ZuulFilter &#123; @Override public String filterType() &#123; return \"post\"; &#125; @Override public int filterOrder() &#123; return 0; &#125; @Override public boolean shouldFilter() &#123; RequestContext context = RequestContext.getCurrentContext(); HttpServletRequest request = context.getRequest(); return \"POST\".equalsIgnoreCase(request.getMethod()); &#125; @Override public Object run() throws ZuulException &#123; RequestContext context = RequestContext.getCurrentContext(); String output = \"Hello World!\"; try &#123; context.getResponse().getWriter().write(output); &#125; catch (IOException e) &#123; throw new ZuulException(e, 500, e.getMessage()); &#125; return true; &#125;&#125; 接着，我们引入嵌入式Tomcat，简单地创建一个Servlet容器，Maven依赖为： 12345678910111213141516171819202122232425&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-core&lt;/artifactId&gt; &lt;version&gt;8.5.34&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;version&gt;8.5.34&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-jasper&lt;/artifactId&gt; &lt;version&gt;8.5.34&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-jasper-el&lt;/artifactId&gt; &lt;version&gt;8.5.34&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-jsp-api&lt;/artifactId&gt; &lt;version&gt;8.5.34&lt;/version&gt; &lt;/dependency&gt; 添加带main方法的类把上面的组件和Tomcat的组件组装起来： 123456789101112131415161718192021222324252627282930313233343536373839404142public class ZuulMain &#123; private static final String WEBAPP_DIRECTORY = \"src/main/webapp/\"; private static final String ROOT_CONTEXT = \"\"; public static void main(String[] args) throws Exception &#123; Tomcat tomcat = new Tomcat(); File tempDir = File.createTempFile(\"tomcat\" + \".\", \".8080\"); tempDir.delete(); tempDir.mkdir(); tempDir.deleteOnExit(); //创建临时目录,这一步必须先设置,如果不设置默认在当前的路径创建一个'tomcat.8080文件夹' tomcat.setBaseDir(tempDir.getAbsolutePath()); tomcat.setPort(8080); StandardContext ctx = (StandardContext) tomcat.addWebapp(ROOT_CONTEXT, new File(WEBAPP_DIRECTORY).getAbsolutePath()); WebResourceRoot resources = new StandardRoot(ctx); resources.addPreResources(new DirResourceSet(resources, \"/WEB-INF/classes\", new File(\"target/classes\").getAbsolutePath(), \"/\")); ctx.setResources(resources); ctx.setDefaultWebXml(new File(\"src/main/webapp/WEB-INF/web.xml\").getAbsolutePath()); // FixBug: no global web.xml found for (LifecycleListener ll : ctx.findLifecycleListeners()) &#123; if (ll instanceof ContextConfig) &#123; ((ContextConfig) ll).setDefaultWebXml(ctx.getDefaultWebXml()); &#125; &#125; //这里添加两个度量父类的空实现 CounterFactory.initialize(new DefaultCounterFactory()); TracerFactory.initialize(new DefaultTracerFactory()); //这里添加自实现的ZuulFilter FilterRegistry.instance().put(\"printParameterZuulFilter\", new PrintParameterZuulFilter()); FilterRegistry.instance().put(\"sendResponseZuulFilter\", new SendResponseZuulFilter()); //这里添加ZuulServlet Context context = tomcat.addContext(\"/zuul\", null); Tomcat.addServlet(context, \"zuul\", new ZuulServlet()); //设置Servlet的路径 context.addServletMappingDecoded(\"/*\", \"zuul\"); tomcat.start(); tomcat.getServer().await(); &#125;&#125; 执行main方法，Tomcat正常启动后打印出熟悉的日志如下： 接下来，用POSTMAN请求模拟一下请求： 小结 Zuul虽然在它的Github仓库中的简介中说它是一个提供动态路由、监视、弹性、安全性等的网关框架，但是实际上它原生并没有提供这些功能，这些功能是需要使用者扩展ZuulFilter实现的，例如基于负载均衡的动态路由需要配置Netflix自己家的Ribbon实现。Zuul在设计上的扩展性什么良好，ZuulFilter就像插件一个可以通过类型、排序系数构建一个调用链，通过Filter或者Servlet做入口，嵌入到Servlet(Web)应用中。不过，在Zuul后续的版本如2.x和3.x中，引入了Netty，基于TCP做底层的扩展，但是编码和使用的复杂度大大提高。也许这就是SpringCloud在netflix-zuul组件中选用了zuul1.x的最后一个发布版本1.3.1的原因吧。springcloud-netflix中使用到Netflix的zuul(动态路由)、robbin(负载均衡)、eureka(服务注册与发现)、hystrix(熔断)等核心组件，这里立个flag先逐个组件分析其源码，逐个击破后再对springcloud-netflix做一次完整的源码分析。 (本文完 c-5-d r-a-20190310 最近996，不能经常更新，顺便祝自己生日快乐…)","categories":[{"name":"Framework","slug":"Framework","permalink":"http://throwable.club/blog/categories/Framework/"},{"name":"Zuul","slug":"Framework/Zuul","permalink":"http://throwable.club/blog/categories/Framework/Zuul/"}],"tags":[{"name":"Framework","slug":"Framework","permalink":"http://throwable.club/blog/tags/Framework/"},{"name":"Zuul","slug":"Zuul","permalink":"http://throwable.club/blog/tags/Zuul/"}]},{"title":"ThreadLocal源码分析-黄金分割数的使用","slug":"java-concurrency-threadlocal-source-code","date":"2019-02-17T11:18:09.000Z","updated":"2019-06-23T15:25:45.729Z","comments":true,"path":"2019/02/17/java-concurrency-threadlocal-source-code/","link":"","permalink":"http://throwable.club/2019/02/17/java-concurrency-threadlocal-source-code/","excerpt":"前提 最近接触到的一个项目要兼容新老系统，最终采用了ThreadLocal(实际上用的是InheritableThreadLocal)用于在子线程获取父线程中共享的变量。问题是解决了，但是后来发现对ThreadLocal的理解不够深入，于是顺便把它的源码阅读理解了一遍。在谈到ThreadLocal之前先买个关子，先谈谈黄金分割数。本文在阅读ThreadLocal源码的时候是使用JDK8(1.8.0_181)。","text":"前提 最近接触到的一个项目要兼容新老系统，最终采用了ThreadLocal(实际上用的是InheritableThreadLocal)用于在子线程获取父线程中共享的变量。问题是解决了，但是后来发现对ThreadLocal的理解不够深入，于是顺便把它的源码阅读理解了一遍。在谈到ThreadLocal之前先买个关子，先谈谈黄金分割数。本文在阅读ThreadLocal源码的时候是使用JDK8(1.8.0_181)。 黄金分割数与斐波那契数列 首先复习一下斐波那契数列，下面的推导过程来自某搜索引擎的wiki： 斐波那契数列：1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, … 通项公式：假设F(n)为该数列的第n项（n ∈ N*），那么这句话可以写成如下形式：F(n) = F(n-1) + F(n-2)。 有趣的是，这样一个完全是自然数的数列，通项公式却是用无理数来表达的。而且当n趋向于无穷大时，前一项与后一项的比值越来越逼近0.618（或者说后一项与前一项的比值小数部分越来越逼近0.618），而这个值0.618就被称为黄金分割数。证明过程如下： 黄金分割数的准确值为(根号5 - 1)/2，约等于0.618。 黄金分割数的应用 黄金分割数被广泛使用在美术、摄影等艺术领域，因为它具有严格的比例性、艺术性、和谐性，蕴藏着丰富的美学价值，能够激发人的美感。当然，这些不是本文研究的方向，我们先尝试求出无符号整型和带符号整型的黄金分割数的具体值： 12345678public static void main(String[] args) throws Exception &#123; //黄金分割数 * 2的32次方 = 2654435769 - 这个是无符号32位整数的黄金分割数对应的那个值 long c = (long) ((1L &lt;&lt; 32) * (Math.sqrt(5) - 1) / 2); System.out.println(c); //强制转换为带符号为的32位整型，值为-1640531527 int i = (int) c; System.out.println(i);&#125; 通过一个线段图理解一下： 也就是2654435769为32位无符号整数的黄金分割值，而-1640531527就是32位带符号整数的黄金分割值。而ThreadLocal中的哈希魔数正是1640531527(十六进制为0x61c88647)。为什么要使用0x61c88647作为哈希魔数？这里提前说一下ThreadLocal在ThreadLocalMap(ThreadLocal在ThreadLocalMap以Key的形式存在)中的哈希求Key下标的规则： 哈希算法：keyIndex = ((i + 1) * HASH_INCREMENT) &amp; (length - 1) 其中，i为ThreadLocal实例的个数，这里的HASH_INCREMENT就是哈希魔数0x61c88647，length为ThreadLocalMap中可容纳的Entry(K-V结构)的个数(或者称为容量)。在ThreadLocal中的内部类ThreadLocalMap的初始化容量为16，扩容后总是2的幂次方，因此我们可以写个Demo模拟整个哈希的过程： 1234567891011121314151617181920public class Main &#123; private static final int HASH_INCREMENT = 0x61c88647; public static void main(String[] args) throws Exception &#123; hashCode(4); hashCode(16); hashCode(32); &#125; private static void hashCode(int capacity) throws Exception &#123; int keyIndex; for (int i = 0; i &lt; capacity; i++) &#123; keyIndex = ((i + 1) * HASH_INCREMENT) &amp; (capacity - 1); System.out.print(keyIndex); System.out.print(\" \"); &#125; System.out.println(); &#125;&#125; 上面的例子中，我们分别模拟了ThreadLocalMap容量为4,16,32的情况下，不触发扩容，并且分别&quot;放入&quot;4,16,32个元素到容器中，输出结果如下： 1233 2 1 0 7 14 5 12 3 10 1 8 15 6 13 4 11 2 9 0 7 14 21 28 3 10 17 24 31 6 13 20 27 2 9 16 23 30 5 12 19 26 1 8 15 22 29 4 11 18 25 0 每组的元素经过散列算法后恰好填充满了整个容器，也就是实现了完美散列。实际上，这个并不是偶然，其实整个哈希算法可以转换为多项式证明：证明(x - y) * HASH_INCREMENT != 2^n * (n m)，在x != y，n != m，HASH_INCREMENT为奇数的情况下恒成立，具体证明可以自行完成。HASH_INCREMENT赋值为0x61c88647的API文档注释如下： 连续生成的哈希码之间的差异(增量值)，将隐式顺序线程本地id转换为几乎最佳分布的乘法哈希值，这些不同的哈希值最终生成一个2的幂次方的哈希表。 ThreadLocal是什么 下面引用ThreadLocal的API注释： This class provides thread-local variables. These variables differ from their normal counterparts in that each thread that accesses one (via its get or set method) has its own, independently initialized copy of the variable. ThreadLocal instances are typically private static fields in classes that wish to associate state with a thread (e.g., a user ID or Transaction ID) 稍微翻译一下：ThreadLocal提供线程局部变量。这些变量与正常的变量不同，因为每一个线程在访问ThreadLocal实例的时候（通过其get或set方法）都有自己的、独立初始化的变量副本。ThreadLocal实例通常是类中的私有静态字段，使用它的目的是希望将状态（例如，用户ID或事务ID）与线程关联起来。 ThreadLocal由Java界的两个大师级的作者编写，Josh Bloch和Doug Lea。Josh Bloch是JDK5语言增强、Java集合(Collection)框架的创办人以及《Effective Java》系列的作者。Doug Lea是JUC(java.util.concurrent)包的作者，Java并发编程的泰斗。所以，ThreadLocal的源码十分值得学习。 ThreadLocal的原理 ThreadLocal虽然叫线程本地(局部)变量，但是实际上它并不存放任何的信息，可以这样理解：它是线程(Thread)操作ThreadLocalMap中存放的变量的桥梁。它主要提供了初始化、set()、get()、remove()几个方法。这样说可能有点抽象，下面画个图说明一下在线程中使用ThreadLocal实例的set()和get()方法的简单流程图。 假设我们有如下的代码，主线程的线程名字是main(也有可能不是main)： 123456789public class Main &#123; private static final ThreadLocal&lt;String&gt; LOCAL = new ThreadLocal&lt;&gt;(); public static void main(String[] args) throws Exception&#123; LOCAL.set(\"doge\"); System.out.println(LOCAL.get()); &#125;&#125; 线程实例和ThreadLocal实例的关系如下： 上面只描述了单线程的情况并且因为是主线程忽略了Thread t = new Thread()这一步，如果有多个线程会稍微复杂一些，但是原理是不变的，ThreadLocal实例总是通过Thread.currentThread()获取到当前操作线程实例，然后去操作线程实例中的ThreadLocalMap类型的成员变量，因此它是一个桥梁，本身不具备存储功能。 ThreadLocal源码分析 对于ThreadLocal的源码，我们需要重点关注set()、get()、remove()几个方法。 ThreadLocal的内部属性 12345678910111213//获取下一个ThreadLocal实例的哈希魔数private final int threadLocalHashCode = nextHashCode();//原子计数器，主要到它被定义为静态private static AtomicInteger nextHashCode = new AtomicInteger();//哈希魔数(增长数)，也是带符号的32位整型值黄金分割值的取正private static final int HASH_INCREMENT = 0x61c88647;//生成下一个哈希魔数private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125; 这里需要注意一点，threadLocalHashCode是一个final的属性，而原子计数器变量nextHashCode和生成下一个哈希魔数的方法nextHashCode()是静态变量和静态方法，静态变量只会初始化一次。换而言之，每新建一个ThreadLocal实例，它内部的threadLocalHashCode就会增加0x61c88647。举个例子： 123456//t1中的threadLocalHashCode变量为0x61c88647ThreadLocal t1 = new ThreadLocal();//t2中的threadLocalHashCode变量为0x61c88647 + 0x61c88647ThreadLocal t2 = new ThreadLocal();//t3中的threadLocalHashCode变量为0x61c88647 + 0x61c88647 + 0x61c88647ThreadLocal t3 = new ThreadLocal(); threadLocalHashCode是下面的ThreadLocalMap结构中使用的哈希算法的核心变量，对于每个ThreadLocal实例，它的threadLocalHashCode是唯一的。 内部类ThreadLocalMap的基本结构和源码分析 ThreadLocal内部类ThreadLocalMap使用了默认修饰符，也就是包(包私有)可访问的。ThreadLocalMap内部定义了一个静态类Entry。我们重点看下ThreadLocalMap的源码，先看成员和结构部分： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * ThreadLocalMap是一个定制的散列映射，仅适用于维护线程本地变量。 * 它的所有方法都是定义在ThreadLocal类之内。 * 它是包私有的，所以在Thread类中可以定义ThreadLocalMap作为变量。 * 为了处理非常大(指的是值)和长时间的用途，哈希表的Key使用了弱引用(WeakReferences)。 * 引用的队列(弱引用)不再被使用的时候，对应的过期的条目就能通过主动删除移出哈希表。 */static class ThreadLocalMap &#123; //注意这里的Entry的Key为WeakReference&lt;ThreadLocal&lt;?&gt;&gt; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; //这个是真正的存放的值 Object value; // Entry的Key就是ThreadLocal实例本身，Value就是输入的值 Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; //初始化容量，必须是2的幂次方 private static final int INITIAL_CAPACITY = 16; //哈希(Entry)表，必须时扩容，长度必须为2的幂次方 private Entry[] table; //哈希表中元素(Entry)的个数 private int size = 0; //下一次需要扩容的阈值，默认值为0 private int threshold; //设置下一次需要扩容的阈值，设置值为输入值len的三分之二 private void setThreshold(int len) &#123; threshold = len * 2 / 3; &#125; // 以len为模增加i private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0); &#125; // 以len为模减少i private static int prevIndex(int i, int len) &#123; return ((i - 1 &gt;= 0) ? i - 1 : len - 1); &#125;&#125; 这里注意到十分重要的一点：ThreadLocalMap$Entry是WeakReference(弱引用)，并且键值Key为ThreadLocal&lt;?&gt;实例本身，这里使用了无限定的泛型通配符。 接着看ThreadLocalMap的构造函数： 1234567891011121314151617181920212223242526272829303132333435// 构造ThreadLocal时候使用，对应ThreadLocal的实例方法void createMap(Thread t, T firstValue)ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; // 哈希表默认容量为16 table = new Entry[INITIAL_CAPACITY]; // 计算第一个元素的哈希码 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY);&#125;// 构造InheritableThreadLocal时候使用，基于父线程的ThreadLocalMap里面的内容进行提取放入新的ThreadLocalMap的哈希表中// 对应ThreadLocal的静态方法static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap)private ThreadLocalMap(ThreadLocalMap parentMap) &#123; Entry[] parentTable = parentMap.table; int len = parentTable.length; setThreshold(len); table = new Entry[len]; // 基于父ThreadLocalMap的哈希表进行拷贝 for (Entry e : parentTable) &#123; if (e != null) &#123; @SuppressWarnings(\"unchecked\") ThreadLocal&lt;Object&gt; key = (ThreadLocal&lt;Object&gt;) e.get(); if (key != null) &#123; Object value = key.childValue(e.value); Entry c = new Entry(key, value); int h = key.threadLocalHashCode &amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; &#125; &#125; &#125;&#125; 这里注意一下，ThreadLocal的set()方法调用的时候会懒初始化一个ThreadLocalMap并且放入第一个元素。而ThreadLocalMap的私有构造是提供给静态方法ThreadLocal#createInheritedMap()使用的。 接着看ThreadLocalMap提供给ThreadLocal使用的一些实例方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227// 如果Key在哈希表中找不到哈希槽的时候会调用此方法private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; // 这里会通过nextIndex尝试遍历整个哈希表，如果找到匹配的Key则返回Entry // 如果哈希表中存在Key == null的情况，调用expungeStaleEntry进行清理 while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125;// 1.清空staleSlot对应哈希槽的Key和Value// 2.对staleSlot到下一个空的哈希槽之间的所有可能冲突的哈希表部分槽进行重哈希，置空Key为null的槽// 3.注意返回值是staleSlot之后的下一个空的哈希槽的哈希码private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // expunge entry at staleSlot // 清空staleSlot对应哈希槽的Key和Value tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null // 下面的过程是对staleSlot到下一个空的哈希槽之间的所有可能冲突的哈希表部分槽进行重哈希，置空Key为null的槽 Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i;&#125;// 这里个方法比较长，作用是替换哈希码为staleSlot的哈希槽中Entry的值private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; // Back up to check for prior stale entry in current run. // We clean out whole runs at a time to avoid continual // incremental rehashing due to garbage collector freeing // up refs in bunches (i.e., whenever the collector runs). int slotToExpunge = staleSlot; // 这个循环主要是为了找到staleSlot之前的最前面的一个Key为null的哈希槽的哈希码 for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; // Find either the key or trailing null slot of run, whichever // occurs first // 遍历staleSlot之后的哈希槽，如果Key匹配则用输入值替换 for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); // If we find key, then we need to swap it // with the stale entry to maintain hash table order. // The newly stale slot, or any other stale slot // encountered above it, can then be sent to expungeStaleEntry // to remove or rehash all of the other entries in run. if (k == key) &#123; e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; // Start expunge at preceding stale entry if it exists if (slotToExpunge == staleSlot) slotToExpunge = i; cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; // If we didn't find stale entry on backward scan, the // first stale entry seen while scanning for key is the // first still present in the run. if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; // Key匹配不了，则新创建一个哈希槽 // If key not found, put new entry in stale slot tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // 这里如果当前的staleSlot和找到前置的slotToExpunge不一致会进行一次清理 // If there are any other stale entries in run, expunge them if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);&#125;// 对当前哈希表中所有的Key为null的Entry调用expungeStaleEntryprivate void expungeStaleEntries() &#123; Entry[] tab = table; int len = tab.length; for (int j = 0; j &lt; len; j++) &#123; Entry e = tab[j]; if (e != null &amp;&amp; e.get() == null) expungeStaleEntry(j); &#125;&#125;// 清理第i个哈希槽之后的n个哈希槽，如果遍历的时候发现Entry的Key为null，则n会重置为哈希表的长度，expungeStaleEntry有可能会重哈希使得哈希表长度发生变化private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; do &#123; i = nextIndex(i, len); Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) &#123; n = len; removed = true; i = expungeStaleEntry(i); &#125; &#125; while ( (n &gt;&gt;&gt;= 1) != 0); return removed;&#125;/** * 这个方法主要给`ThreadLocal#get()`调用，通过当前ThreadLocal实例获取哈希表中对应的Entry * */private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; // 计算Entry的哈希值 int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else // 注意这里，如果e为null或者Key对不上，会调用getEntryAfterMiss return getEntryAfterMiss(key, i, e);&#125;// 重哈希，必要时进行扩容private void rehash() &#123; // 清理所有空的哈希槽，并且进行重哈希 expungeStaleEntries(); // Use lower threshold for doubling to avoid hysteresis // 哈希表的哈希元素个数大于3/4阈值时候触发扩容 if (size &gt;= threshold - threshold / 4) resize();&#125;// 扩容，简单的扩大2倍的容量 private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (Entry e : oldTab) &#123; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; // Help the GC &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab;&#125;// 基于ThreadLocal作为key，对当前的哈希表设置值，此方法由`ThreadLocal#set()`调用private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); // 变量哈希表 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); // Key匹配，直接设置值 if (k == key) &#123; e.value = value; return; &#125; // 如果Entry的Key为null，则替换该Key为当前的key，并且设置值 if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; // 清理当前新设置元素的哈希槽下标到sz段的哈希槽，如果清理成功并且sz大于阈值则触发扩容 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; 简单来说，ThreadLocalMap是ThreadLocal真正的数据存储容器，实际上ThreadLocal数据操作的复杂部分的所有逻辑都在ThreadLocalMap中进行，而ThreadLocalMap实例是Thread的成员变量，在ThreadLocal#set()方法首次调用的时候设置到当前执行的线程实例中。如果在同一个线程中使用多个ThreadLocal实例，实际上，每个ThreadLocal实例对应的是ThreadLocalMap的哈希表中的一个哈希槽。举个例子，在主函数主线程中使用多个ThreadLocal实例： 12345678910111213141516public class ThreadLocalMain &#123; private static final ThreadLocal&lt;Integer&gt; TL_1 = new ThreadLocal&lt;&gt;(); private static final ThreadLocal&lt;String&gt; TL_2 = new ThreadLocal&lt;&gt;(); private static final ThreadLocal&lt;Long&gt; TL_3 = new ThreadLocal&lt;&gt;(); public static void main(String[] args) throws Exception &#123; TL_1.set(1); TL_2.set(\"1\"); TL_3.set(1L); Field field = Thread.class.getDeclaredField(\"threadLocals\"); field.setAccessible(true); Object o = field.get(Thread.currentThread()); System.out.println(o); &#125;&#125; 实际上，主线程的threadLocals属性中的哈希表中一般不止我们上面定义的三个ThreadLocal，因为加载主线程的时候还有可能在其他地方使用到ThreadLocal，笔者某次Debug的结果如下： 用PPT画图简化一下： 上图threadLocalHashCode属性一行的表是为了标出每个Entry的哈希槽的哈希值，实际上，threadLocalHashCode是ThreadLocal@XXXX中的一个属性，这是很显然的，本来threadLocalHashCode就是ThreadLocal的一个成员变量。 上面只是简单粗略对ThreadLocalMap的源码进行了流水账的分析，下文会作一些详细的图，说明一下ThreadLocal和ThreadLocalMap中的一些核心操作的过程。 ThreadLocal的创建 从ThreadLocal的构造函数来看，ThreadLocal实例的构造并不会做任何操作，只是为了得到一个ThreadLocal的泛型实例，后续可以把它作为ThreadLocalMap$Entry的键： 1234567891011121314151617// 注意threadLocalHashCode在每个新`ThreadLocal`实例的构造同时已经确定了private final int threadLocalHashCode = nextHashCode();private static AtomicInteger nextHashCode = new AtomicInteger();private static final int HASH_INCREMENT = 0x61c88647;private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125;// 通过Supplier去覆盖initialValue方法public static &lt;S&gt; ThreadLocal&lt;S&gt; withInitial(Supplier&lt;? extends S&gt; supplier) &#123; return new SuppliedThreadLocal&lt;&gt;(supplier);&#125;// 默认公有构造函数public ThreadLocal() &#123;&#125; 注意threadLocalHashCode在每个新ThreadLocal实例的构造同时已经确定了，这个值也是Entry哈希表的哈希槽绑定的哈希值。 TreadLocal的set方法 ThreadLocal中set()方法的源码如下: 12345678910111213141516171819202122public void set(T value) &#123; //设置值前总是获取当前线程实例 Thread t = Thread.currentThread(); //从当前线程实例中获取threadLocals属性 ThreadLocalMap map = getMap(t); if (map != null) //threadLocals属性不为null则覆盖key为当前的ThreadLocal实例，值为value map.set(this, value); else //threadLocals属性为null，则创建ThreadLocalMap，第一个项的Key为当前的ThreadLocal实例，值为value createMap(t, value);&#125;// 这里看到获取ThreadLocalMap实例时候总是从线程实例的成员变量获取ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;// 创建ThreadLocalMap实例的时候，会把新实例赋值到线程实例的threadLocals成员void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 上面的过程源码很简单，设置值的时候总是先获取当前线程实例并且操作它的变量threadLocals。步骤是： 获取当前运行线程的实例。 通过线程实例获取线程实例成员threadLocals(ThreadLocalMap)，如果为null，则创建一个新的ThreadLocalMap实例赋值到threadLocals。 通过threadLocals设置值value，如果原来的哈希槽已经存在值，则进行覆盖。 TreadLocal的get方法 ThreadLocal中get()方法的源码如下: 123456789101112131415161718192021222324252627282930313233 public T get() &#123; //获取当前线程的实例 Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; //根据当前的ThreadLocal实例获取ThreadLocalMap中的Entry，使用的是ThreadLocalMap的getEntry方法 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T) e.value; return result; &#125; &#125; //线程实例中的threadLocals为null，则调用initialValue方法，并且创建ThreadLocalMap赋值到threadLocals return setInitialValue();&#125;private T setInitialValue() &#123; // 调用initialValue方法获取值 T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); // ThreadLocalMap如果未初始化则进行一次创建，已初始化则直接设置值 if (map != null) map.set(this, value); else createMap(t, value); return value;&#125;protected T initialValue() &#123; return null;&#125; initialValue()方法默认返回null，如果ThreadLocal实例没有使用过set()方法直接使用get()方法，那么ThreadLocalMap中的此ThreadLocal为Key的项会把值设置为initialValue()方法的返回值。如果想改变这个逻辑可以对initialValue()方法进行覆盖。 TreadLocal的remove方法 ThreadLocal中remove()方法的源码如下: 1234567public void remove() &#123; //获取Thread实例中的ThreadLocalMap ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) //根据当前ThreadLocal作为Key对ThreadLocalMap的元素进行移除 m.remove(this);&#125; ThreadLocal.ThreadLocalMap的初始化 我们可以关注一下java.lang.Thread类里面的变量： 1234567public class Thread implements Runnable &#123; //传递ThreadLocal中的ThreadLocalMap变量 ThreadLocal.ThreadLocalMap threadLocals = null; //传递InheritableThreadLocal中的ThreadLocalMap变量 ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;&#125; 也就是，ThreadLocal需要存放和获取的数据实际上绑定在Thread实例的成员变量threadLocals中，并且是ThreadLocal#set()方法调用的时候才进行懒加载的，可以结合上一节的内容理解一下，这里不展开。 什么情况下ThreadLocal的使用会导致内存泄漏 其实ThreadLocal本身不存放任何的数据，而ThreadLocal中的数据实际上是存放在线程实例中，从实际来看是线程内存泄漏，底层来看是Thread对象中的成员变量threadLocals持有大量的K-V结构，并且线程一直处于活跃状态导致变量threadLocals无法释放被回收。threadLocals持有大量的K-V结构这一点的前提是要存在大量的ThreadLocal实例的定义，一般来说，一个应用不可能定义大量的ThreadLocal，所以一般的泄漏源是线程一直处于活跃状态导致变量threadLocals无法释放被回收。但是我们知道，·ThreadLocalMap·中的Entry结构的Key用到了弱引用(·WeakReference&lt;ThreadLocal&lt;?&gt;&gt;·)，当没有强引用来引用ThreadLocal实例的时候，JVM的GC会回收ThreadLocalMap中的这些Key，此时，ThreadLocalMap中会出现一些Key为null，但是Value不为null的Entry项，这些Entry项如果不主动清理，就会一直驻留在ThreadLocalMap中。也就是为什么ThreadLocal中get()、set()、remove()这些方法中都存在清理ThreadLocalMap实例key为null的代码块。总结下来，内存泄漏可能出现的地方是： 1、大量地(静态)初始化ThreadLocal实例，初始化之后不再调用get()、set()、remove()方法。 2、初始化了大量的ThreadLocal，这些ThreadLocal中存放了容量大的Value，并且使用了这些ThreadLocal实例的线程一直处于活跃的状态。 ThreadLocal中一个设计亮点是ThreadLocalMap中的Entry结构的Key用到了弱引用。试想如果使用强引用，等于ThreadLocalMap中的所有数据都是与Thread的生命周期绑定，这样很容易出现因为大量线程持续活跃导致的内存泄漏。使用了弱引用的话，JVM触发GC回收弱引用后，ThreadLocal在下一次调用get()、set()、remove()方法就可以删除那些ThreadLocalMap中Key为null的值，起到了惰性删除释放内存的作用。 其实ThreadLocal在设置内部类ThreadLocal.ThreadLocalMap中构建的Entry哈希表已经考虑到内存泄漏的问题，所以ThreadLocal.ThreadLocalMap$Entry类设计为弱引用，类签名为static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt;。之前一篇文章介绍过，如果弱引用关联的对象如果置为null，那么该弱引用会在下一次GC时候回收弱引用关联的对象。举个例子： 1234567891011public class ThreadLocalMain &#123; private static ThreadLocal&lt;Integer&gt; TL_1 = new ThreadLocal&lt;&gt;(); public static void main(String[] args) throws Exception &#123; TL_1.set(1); TL_1 = null; System.gc(); Thread.sleep(300); &#125;&#125; 这种情况下，TL_1这个ThreadLocal在主动GC之后，线程绑定的ThreadLocal.ThreadLocalMap实例中的Entry哈希表中原来的TL_1所在的哈希槽Entry的引用持有值referent(继承自WeakReference)会变成null，但是Entry中的value是强引用，还存放着TL_1这个ThreadLocal未回收之前的值。这些被&quot;孤立&quot;的哈希槽Entry就是前面说到的要惰性删除的哈希槽。 ThreadLocal的最佳实践 其实ThreadLocal的最佳实践很简单： 每次使用完ThreadLocal实例，都调用它的remove()方法，清除Entry中的数据。 调用remove()方法最佳时机是线程运行结束之前的finally代码块中调用，这样能完全避免操作不当导致的内存泄漏，这种主动清理的方式比惰性删除有效。 父子线程数据传递InheritableThreadLocal 留待下一篇文章编写，因为InheritableThreadLocal只能通过父子线(1-&gt;1)程传递变量，线程池里面的线程有可能是多个父线程共享的(也就是1个父线程提交的任务有可能由线程池中的多个子线程执行)，因此有可能出现问题。阿里为了解决这个问题编写过一个框架-transmittable-thread-local，解决了父线程和线程池中线程的变量传递问题。 小结 ThreadLocal线程本地变量是线程实例传递和存储共享变量的桥梁，真正的共享变量还是存放在线程实例本身的属性中。ThreadLocal里面的基本逻辑并不复杂，但是一旦涉及到性能影响、内存回收(弱引用)和惰性删除等环节，其实它考虑到的东西还是相对全面而且有效的。 (本文完 e-a-20190217 c-7-d)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Concurrency","slug":"Java/Concurrency","permalink":"http://throwable.club/blog/categories/Java/Concurrency/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"http://throwable.club/blog/tags/ThreadLocal/"}]},{"title":"JDK安全模块JCE核心Cipher使用详解","slug":"java-security-cipher","date":"2019-02-16T15:04:21.000Z","updated":"2019-02-16T15:05:55.251Z","comments":true,"path":"2019/02/16/java-security-cipher/","link":"","permalink":"http://throwable.club/2019/02/16/java-security-cipher/","excerpt":"","text":"JDK安全模块JCE核心Cipher使用详解 前提 javax.crypto.Cipher，翻译为密码，其实叫做密码器更加合适。Cipher是JCA(Java Cryptographic Extension，Java加密扩展)的核心，提供基于多种加解密算法的加解密功能。在不了解Cipher之前，我们在完成一些需要加解密的模块的时候总是需要到处拷贝代码，甚至有些错误的用法也被无数次拷贝，踩坑之后又要拷贝补坑的代码。为什么不尝试理解Cipher然后合理地使用呢？ Cipher初始化transformation(转换模式)的一些知识补充 转换模式transformation一般由三个部分组成，格式是：算法/工作模式/填充模式(algorithm/mode/padding)。例如：DES/CBC/PKCS5Padding。 算法 算法就是指具体加解密算法的名称英文字符串，例如&quot;SHA-256&quot;、&quot;RSA&quot;等，这里不对具体算法的实现原理做具体展开。 工作模式 工作模式其实主要是针对分组密码。分组密码是将明文消息编码表示后的数字（简称明文数字）序列，划分成长度为n的组（可看成长度为n的矢量），每组分别在密钥的控制下变换成等长的输出数字（简称密文数字）序列。工作模式的出现主要基于下面原因： 当需要加密的明文长度十分大(例如文件内容)，由于硬件或者性能原因需要分组加密。 多次使用相同的密钥对多个分组加密，会引发许多安全问题。 从本质上讲，工作模式是一项增强密码算法或者使算法适应具体应用的技术，例如将分组密码应用于数据块组成的序列或者数据流。目前主要包括下面五种由NIST定义的工作模式： 模式 名称 描述 典型应用 电子密码本(ECB) Electronic CodeBook 用相同的密钥分别对明文分组独立加密 单个数据的安全传输(例如一个加密密钥) 密码分组链接(CBC) Cipher Block Chaining 加密算法的输入是上一个密文组合下一个明文组的异或 面向分组的通用传输或者认证 密文反馈(CFB) Cipher FeedBack 一次处理s位，上一块密文作为加密算法的输入，产生的伪随机数输出与明文异或作为下一单元的密文 面向分组的通用传输或者认证 输出反馈(OFB) Output FeedBack 与CFB类似，只是加密算法的输入是上一次加密的输出，并且使用整个分组 噪声信道上的数据流的传输(如卫星通信) 计数器(CTR) Counter 每个明文分组都与一个经过加密的计数器相异或。对每个后续分组计数器递增 面向分组的通用传输或者用于高速需求 上面五种工作模式可以用于3DES和AES在内的任何分组密码，至于选择哪一种工作模式需要结合实际情况分析。 填充模式 Padding指的是：块加密算法要求原文数据长度为固定块大小的整数倍，如果原文数据长度大于固定块大小，则需要在固定块填充数据直到整个块的数据是完整的。例如我们约定块的长度为128，但是需要加密的原文长度为129，那么需要分成两个加密块，第二个加密块需要填充127长度的数据，填充模式决定怎么填充数据。 对数据在加密时进行填充、解密时去除填充则是通信双方需要重点考虑的因素。对原文进行填充，主要基于以下原因： 首先，考虑安全性。由于对原始数据进行了填充，使原文能够“伪装”在填充后的数据中，使得攻击者很难找到真正的原文位置。 其次，由于块加密算法要求原文数据长度为固定块大小的整数倍，如果加密原文不满足这个条件，则需要在加密前填充原文数据至固定块大小的整数倍。 另外，填充也为发送方与接收方提供了一种标准的形式以约束加密原文的大小。只有加解密双方知道填充方式，才可知道如何准确移去填充的数据并进行解密。 常用的填充方式至少有5种，不同编程语言实现加解密时用到的填充多数来自于这些方式或它们的变种方式。以下五种填充模式摘抄自参考资料的论文： 1.填充数据为填充字节序列的长度： 这种填充方式中，填充字符串由一个字节序列组成，每个字节填充该字节序列的长度。假定块长度为8，原文数据长度为9，则填充字节数 等于0x07；如果明文数据长度为8的整数倍，则填充字节数为0x08。填充字符串如下： 原文数据1: FF FF FF FF FF FF FF FF FF 填充后数据1:FF FF FF FF FF FF FF FF FF 07 07 07 07 07 07 07 ========================================================== 原文数据2:FF FF FF FF FF FF FF FF 填充后数据2:FF FF FF FF FF FF FF FF 08 08 08 08 08 08 08 08 2.填充数据为0x80后加0x00： 这种填充方式中，填充字符串的第一个字节数是0x80，后面的每个字节是0x00。假定块长度为8，原文数据长度为9或者为8的整数倍，则 填充字符串如下： 原文数据1: FF FF FF FF FF FF FF FF FF 填充后数据1:FF FF FF FF FF FF FF FF FF 80 00 00 00 00 00 00 ========================================================== 原文数据2:FF FF FF FF FF FF FF FF 填充后数据2:FF FF FF FF FF FF FF FF 80 00 00 00 00 00 00 00 3.填充数据的最后一个字节为填充字节序列的长度： 这种填充方式中，填充字符串的最后一个字节为该序列的长度，而前面的字节可以是0x00，也可以是随机的字节序列。假定块长度为8，原文数据长度为9或者为8的整数倍，则填充字符串如下： 原文数据1:FF FF FF FF FF FF FF FF FF 填充后数据1:FF FF FF FF FF FF FF FF FF 00 00 00 00 00 00 07或FF FF FF FF FF FF FF FF FF 0A B0 0C 08 05 09 07 =============================================================================== 原文数据2:FF FF FF FF FF FF FF FF 填充后数据2:FF FF FF FF FF FF FF FF 00 00 00 00 00 00 00 08或FF FF FF FF FF FF FF FF 80 06 AB EA 03 02 01 08 4.填充数据为空格： 这种填充方式中，填充字符串的每个字节为空格对应的字节数0x20。假定块长度为8，原文数据长度为9或者为8的整数倍，则填充字符串如下： 原文数据1: FF FF FF FF FF FF FF FF FF 填充后数据1:FF FF FF FF FF FF FF FF FF 20 20 20 20 20 20 20 =============================================================================== 原文数据2:FF FF FF FF FF FF FF FF 填充后数据2:FF FF FF FF FF FF FF FF 20 20 20 20 20 20 20 20 5.填充数据为0x00： 这种填充方式中，填充字符串的每个字节为0x00。假定块长度为8，原文数据长度为9或者8的整数倍，则填充字符串如下： 原文数据1: FF FF FF FF FF FF FF FF FF 填充后数据1:FF FF FF FF FF FF FF FF FF 00 00 00 00 00 00 00 =============================================================================== 原文数据2:FF FF FF FF FF FF FF FF 填充后数据2:FF FF FF FF FF FF FF FF 00 00 00 00 00 00 00 00 transformation小结 SunJCE Provider支持的Cipher的部分详细信息如下： algorithm(算法) mode(工作模式) padding(填充模式) AES EBC、CBC、PCBC、CTR、CTS、CFB、CFB8-CFB128等 NoPadding、ISO10126Padding、PKCS5Padding AESWrap EBC NoPadding ARCFOUR EBC NoPadding Blowfish、DES、DESede、RC2 EBC、CBC、PCBC、CTR、CTS、CFB、CFB8-CFB128等 NoPadding、ISO10126Padding、PKCS5Padding DESedeWrap CBC NoPadding PBEWithMD5AndDES、PBEWithMD5AndTripleDES、PBEWithSHA1AndDESede、PBEWithSHA1AndRC2_40 CBC PKCS5Padding RSA ECB、NONE NoPadding、PKCS1Padding等 Java原生支持的Padding(Cipher)汇总如下： 填充模式 描述 NoPadding 不采用填充模式 ISO10126Padding XML加密语法和处理文档中有详细描述 OAEPPadding, OAEPWith&lt;digest&gt;And&lt;mgf&gt;Padding PKCS1中定义的最优非对称加密填充方案，digest代表消息摘要类型，mgf代表掩码生成函数，例如：OAEPWithMD5AndMGF1Padding或者OAEPWithSHA-512AndMGF1Padding PKCS1Padding PKCS1，RSA算法使用 PKCS5Padding PKCS5，RSA算法使用 SSL3Padding 见SSL Protocol Version 3.0的定义 其他Padding需要第三方Provider提供。 Cipher的属性和方法 Cipher的七个主要公有属性 1、ENCRYPT_MODE，整型值1，加密模式，用于Cipher的初始化。 2、DECRYPT_MODE，整型值2，解密模式，用于Cipher的初始化。 3、WRAP_MODE，整型值3，包装密钥模式，用于Cipher的初始化。 4、UNWRAP_MODE，整型值4，解包装密钥模式，用于Cipher的初始化。 5、PUBLIC_KEY，整型值1，解包装密钥模式下指定密钥类型为公钥。 6、PRIVATE_KEY，整型值2，解包装密钥模式下指定密钥类型为私钥。 7、SECRET_KEY，整型值3，解包装密钥模式下指定密钥类型为密钥，主要用于不是非对称加密的密钥(只有一个密钥，不包含私钥和公钥)。 getInstance方法 Cipher提供三个静态工厂方法getInstance()用于构建其实例，三个方法如下： 1234567891011121314public static final Cipher getInstance(String transformation) throws NoSuchAlgorithmException, NoSuchPaddingExceptionpublic static final Cipher getInstance(String transformation, String provider) throws NoSuchAlgorithmException, NoSuchProviderException, NoSuchPaddingExceptionpublic static final Cipher getInstance(String transformation, Provider provider) throws NoSuchAlgorithmException, NoSuchPaddingException 其中transformation，这里称为转换(模式)，是核心参数，见前面一个小节的解析。另外，有两个工厂方法要求必须传入java.security.Provider的全类名或者实例，因为Cipher要从对应的提供商中获取指定转换模式的实现，第一个工厂方法只有单参数transformation，它会从现成所有的java.security.Provider中匹配取出第一个满足transformation的服务，从中实例化CipherSpi(要理解Cipher委托到内部持有的CipherSpi实例完成具体的加解密功能)。实际上Cipher实例的初始化必须依赖于转换模式和提供商。 init方法 init()方法一共有八个变体方法，此方法主要用于初始化Cipher。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//额外参数是Key(密钥)public final void init(int opmode, Key key) throws InvalidKeyException//额外参数是Key(密钥)和SecureRandom(随机源)public final void init(int opmode, Key key, SecureRandom random) throws InvalidKeyException//额外参数是Key(密钥)和AlgorithmParameterSpec(算法参数透明定义)public final void init(int opmode, Key key, AlgorithmParameterSpec params) throws InvalidKeyException, InvalidAlgorithmParameterException //额外参数是Key(密钥)、AlgorithmParameterSpec(算法参数透明定义)和SecureRandom(随机源)public final void init(int opmode, Key key, AlgorithmParameterSpec params, SecureRandom random) throws InvalidKeyException, InvalidAlgorithmParameterException//额外参数是Key(密钥)、AlgorithmParameters(算法参数)public final void init(int opmode, Key key, AlgorithmParameters params) throws InvalidKeyException, InvalidAlgorithmParameterException//额外参数是Key(密钥)、AlgorithmParameters(算法参数)、SecureRandom(随机源)public final void init(int opmode, Key key, AlgorithmParameters params, SecureRandom random) throws InvalidKeyException, InvalidAlgorithmParameterException//额外参数是Certificate(证书)public final void init(int opmode, Certificate certificate) throws InvalidKeyException//额外参数是Certificate(证书)、SecureRandom(随机源)public final void init(int opmode, Certificate certificate, SecureRandom random) throws InvalidKeyException opmode(操作模式)是必须参数，可选值是ENCRYPT_MODE、DECRYPT_MODE、WRAP_MODE和UNWRAP_MODE。Key类型参数如果不是非对称加密，对应的类型是SecretKey，如果是非对称加密，可以是PublicKey或者PrivateKey。SecureRandom是随机源，因为有些算法需要每次加密结果都不相同，这个时候需要依赖系统或者传入的随机源，一些要求每次加解密结果相同的算法如AES不能使用此参数。Certificate是带有密钥的证书实现。算法参数主要包括IV(initialization vector，初始化向量)等等。 wrap方法和unwrap方法 wrap方法用于包装一个密钥。 123public final byte[] wrap(Key key) throws IllegalBlockSizeException, InvalidKeyException wrap方法使用的时候需要注意Cipher的opmode要初始化为WRAP_MODE。 unwrap方法用于解包装一个密钥。 12345public final Key unwrap(byte[] wrappedKey, String wrappedKeyAlgorithm, int wrappedKeyType) throws InvalidKeyException, NoSuchAlgorithmException unwrap方法使用的时候需要注意Cipher的opmode要初始化为UNWRAP_MODE，在调用unwrap方法时候，需要指定之前包装密钥的算法和Key的类型。 其实wrap和unwrap是一个互逆的操作： wrap方法的作用是把原始的密钥通过某种加密算法包装为加密后的密钥，这样就可以避免在传递密钥的时候泄漏了密钥的明文。 unwrap方法的作用是把包装(加密)后的密钥解包装为原始的密钥，得到密钥的明文。 1234567891011121314151617181920212223242526272829303132333435363738394041public enum EncryptUtils &#123; /** * 单例 */ SINGLETON; private static final String SECRECT = \"passwrod\"; public String wrap(String keyString) throws Exception &#123; KeyGenerator keyGenerator = KeyGenerator.getInstance(\"AES\"); //初始化密钥生成器，指定密钥长度为128，指定随机源的种子为指定的密钥(这里是\"passward\") keyGenerator.init(128, new SecureRandom(SECRECT.getBytes())); SecretKey secretKey = keyGenerator.generateKey(); SecretKeySpec secretKeySpec = new SecretKeySpec(secretKey.getEncoded(), \"AES\"); Cipher cipher = Cipher.getInstance(\"AES\"); cipher.init(Cipher.WRAP_MODE, secretKeySpec); SecretKeySpec key = new SecretKeySpec(keyString.getBytes(), \"AES\"); byte[] bytes = cipher.wrap(key); return Hex.encodeHexString(bytes); &#125; public String unwrap(String keyString) throws Exception &#123; byte[] rawKey = Hex.decodeHex(keyString); KeyGenerator keyGenerator = KeyGenerator.getInstance(\"AES\"); //初始化密钥生成器，指定密钥长度为128，指定随机源的种子为指定的密钥(这里是\"passward\") keyGenerator.init(128, new SecureRandom(SECRECT.getBytes())); SecretKey secretKey = keyGenerator.generateKey(); SecretKeySpec secretKeySpec = new SecretKeySpec(secretKey.getEncoded(), \"AES\"); Cipher cipher = Cipher.getInstance(\"AES\"); cipher.init(Cipher.UNWRAP_MODE, secretKeySpec); SecretKey key = (SecretKey) cipher.unwrap(rawKey, \"AES\", Cipher.SECRET_KEY); return new String(key.getEncoded()); &#125; public static void main(String[] args) throws Exception &#123; String wrapKey = EncryptUtils.SINGLETON.wrap(\"doge\"); System.out.println(wrapKey); System.out.println(EncryptUtils.SINGLETON.unwrap(wrapKey)); &#125;&#125; 上面的例子是通过AES对密钥进行包装和解包装，调用main方法，输出： 1277050742188d4b97a1d401db902b864ddoge update方法 update方法有多个变体，其实意义相差无几： 123456789101112131415public final byte[] update(byte[] input)public final byte[] update(byte[] input, int inputOffset, int inputLen)public final int update(byte[] input, int inputOffset, int inputLen, byte[] output) throws ShortBufferExceptionpublic final int update(ByteBuffer input, ByteBuffer output) throws ShortBufferException update方法主要用于部分加密或者部分解密，至于加密或是解密取决于Cipher初始化时候的opmode。即使它有多个变体，但是套路是一样的：依赖于一个输入的缓冲区(带有需要被加密或者被解密的数据)、返回值或者参数是一个输出的缓冲区，一些额外的参数可以通过偏移量和长度控制加密或者解密操作的数据段。部分加密或者解密操作完毕后，必须要调用Cipher#doFinal()方法来结束加密或者解密操作。 doFinal方法 doFinal()方法也存在多个变体： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * 结束多部分加密或者解密操作。 * 此方法需要在update调用链执行完毕之后调用，返回的结果是加密或者解密结果的一部分。 * 此方法正常调用结束之后Cipher会重置为初始化状态。 */public final byte[] doFinal() throws IllegalBlockSizeException, BadPaddingException/** * 结束多部分加密或者解密操作。 * 此方法需要在update调用链执行完毕之后调用，传入的output作为缓冲区接收加密或者解密结果的一部分。 * 此方法正常调用结束之后Cipher会重置为初始化状态。 */public final int doFinal(byte[] output, int outputOffset) throws IllegalBlockSizeException, ShortBufferException, BadPaddingException /** * 结束单部分加密或者解密操作。 * 此方法接收需要加密或者解密的完整报文，返回处理结果 * 此方法正常调用结束之后Cipher会重置为初始化状态。 */public final byte[] doFinal(byte[] input) throws IllegalBlockSizeException, BadPaddingException/** * 结束单部分或者多部分加密或者解密操作。 * 参数inputOffset为需要加解密的报文byte数组的起始位置，inputLen为需要加密或者解密的字节长度 * 此方法正常调用结束之后Cipher会重置为初始化状态。 */public final byte[] doFinal(byte[] input, int inputOffset, int inputLen) throws IllegalBlockSizeException, BadPaddingException /** * 结束单部分或者多部分加密或者解密操作。 * 参数inputOffset为需要加解密的报文byte数组的起始位置，inputLen为需要加密或者解密的字节长度，output用于接收加解密的结果 * 此方法正常调用结束之后Cipher会重置为初始化状态。 */public final int doFinal(byte[] input, int inputOffset, int inputLen, byte[] output) throws ShortBufferException, IllegalBlockSizeException, BadPaddingException /** * 结束单部分或者多部分加密或者解密操作。 * 参数inputOffset为需要加解密的报文byte数组的起始位置，inputLen为需要加密或者解密的字节长度， * output用于接收加解密的结果，outputOffset用于设置output的起始位置 * 此方法正常调用结束之后Cipher会重置为初始化状态。 */public final int doFinal(byte[] input, int inputOffset, int inputLen, byte[] output, int outputOffset) throws ShortBufferException, IllegalBlockSizeException, BadPaddingException /** * 结束单部分或者多部分加密或者解密操作。 * 参数input为输入缓冲区，output为输出缓冲区 * 此方法正常调用结束之后Cipher会重置为初始化状态。 */public final int doFinal(ByteBuffer input, ByteBuffer output) throws ShortBufferException, IllegalBlockSizeException, BadPaddingException doFinal()主要功能是结束单部分或者多部分加密或者解密操作。单部分加密或者解密适用于需要处理的报文长度较短无需分块的情况，这个时候直接使用byte[] doFinal(byte[] input)方法即可。多部分加密或者解密适用于需要处理的报文长度长度较大，需要进行分块的情况，这个时候需要调用多次update方法变体进行部分块的加解密，最后调用doFinal方法变体进行部分加解密操作的结束。举个例子，例如处理块的大小为8，实际需要加密的报文长度为23，那么需要分三块进行加密，前面2块长度为8的报文需要调用update进行部分加密，部分加密的结果可以从update的返回值获取到，最后的7长度(其实一般会填充到长度为块长度8)的报文则调用doFinal进行加密，结束整个部分加密的操作。另外，值得注意的是只要Cipher正常调用完任一个doFinal变体方法(过程中不抛出异常)，那么Cipher会重置为初始化状态，可以继续使用，这个可复用的特性可以降低创建Cipher实例的性能损耗。 updateADD方法 首先ADD的意思是Additional Authentication Data(额外的身份认证数据)。updateADD()也有三个方法变体： 1234567public final void updateAAD(byte[] src)public final void updateAAD(byte[] src, int offset, int len)public final void updateAAD(ByteBuffer src) 它的方法变体都只依赖一个输入缓冲区，带有额外的身份认证数据，一般使用在GCM或者CCM加解密算法中。如果使用此方法，它的调用必须在Cipher的update和doFinal变体方法之前调用，其实理解起来也很简单，身份验证必须在实际的加解密操作之前进行。目前，updateADD的资料比较少，笔者在生产环境找那个也尚未实践过，所以不做展开分析。 其他方法 其他方法主要是Getter方法，用于获取Cipher的相关信息。 public final Provider getProvider()：获取Cipher的提供商。 public final String getAlgorithm()：获取Cipher使用的算法名称。 public final int getBlockSize()：分组加密中，每一组都有固定的长度，也称为块，此方法是返回块的大小（以字节为单位）。 public final int getOutputSize(int inputLen)：根据给定的输入长度inputLen（以字节为单位），返回保存下一个update或doFinal操作结果所需的输出缓冲区长度（以字节为单位）。 public final byte[] getIV()：返回Cipher中的初始化向量的字节数组。 public final AlgorithmParameters getParameters()：返回Cipher使用的算法参数。 public final ExemptionMechanism getExemptionMechanism()：返回Cipher使用的豁免(exemption)机制对象。 public static final int getMaxAllowedKeyLength(String transformation)：根据所安装的JCE策略文件，返回指定转换的最大密钥长度。 public static final AlgorithmParameterSpec getMaxAllowedParameterSpec(String transformation)：根据JCE策略文件，返回Cipher指定transformation下最大的AlgorithmParameterSpec对象。 Cipher的工作流程 下面画一个图来详细分析一下Cipher的工作流程： 当然上图只分析了Cipher的使用过程，其实还有一个重要的步骤就是密钥的处理，但是密钥的处理和具体的算法使用是相关的，所以图中没有体现。再放一张官方描述Cipher加载的流程： 主要过程包括： 1、创建Cipher实例，这个时候会从平台中所有的提供商(Provider)中根据transformation匹配第一个可以使用的CipherSpi实例，&quot;算法/工作模式/填充模式&quot;必须完全匹配才能选中。 在${JAVA_HONE}/jre/lib/security中的java.security文件中可以看到默认加载的提供商。如果需要添加额外或者自实现的Provider，可以通过java.security.Security的静态方法addProvider添加。 2、通过Cipher实例的init方法初始化Cipher，主要参数是opmode和密钥。 3、根据初始化的方式和是否需要分组处理，选择合适的方法进行调用，一般以doFinal()方法作结得到返回结果。 Cipher的使用 为了方便Cipher的使用，最好先引入apache-codec依赖，这样能简化Hex、Base64等操作。 12345&lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;version&gt;1.11&lt;/version&gt;&lt;/dependency&gt; 大多数情况下，加密后的byte数组的中元素取值不在Unicode码点的范围内，表面上看到的就是乱码，实际上它们是有意义的，因此需要考虑把这种byte数组转换为非乱码的字符串以便传输，常见的方式有Hex(二进制转换为十六进制)、Base64等等。下面举例中没有针对异常类型进行处理统一外抛，切勿模仿，还有，所有的字符串转化为字节数组都没有指定字符编码，因此只能使用非中文的明文进行处理。 加密模式 加密模式下，Cipher只能用于加密，主要由init()方法中的opmode决定。举个例子： 123456789101112131415public String encryptByAes(String content, String password) throws Exception &#123; //这里指定了算法为AES_128，工作模式为EBC，填充模式为NoPadding Cipher cipher = Cipher.getInstance(\"AES_128/ECB/NoPadding\"); KeyGenerator keyGenerator = KeyGenerator.getInstance(\"AES\"); //因为AES要求密钥的长度为128，我们需要固定的密码，因此随机源的种子需要设置为我们的密码数组 keyGenerator.init(128, new SecureRandom(password.getBytes())); SecretKey secretKey = keyGenerator.generateKey(); SecretKeySpec secretKeySpec = new SecretKeySpec(secretKey.getEncoded(), \"AES\"); //基于加密模式和密钥初始化Cipher cipher.init(Cipher.ENCRYPT_MODE, secretKeySpec); //单部分加密结束，重置Cipher byte[] bytes = cipher.doFinal(content.getBytes()); //加密后的密文由二进制序列转化为十六进制序列，依赖apache-codec包 return Hex.encodeHexString(bytes);&#125; 其实整个过程Cipher的使用都很简单，比较复杂的反而是密钥生成的过程。上面的例子需要注意，因为使用了填充模式为NoPadding，输入的需要加密的报文长度必须是16(128bit)的倍数。 解密模式 解密模式的使用大致和加密模式是相同的，把处理过程逆转过来就行： 12345678910111213141516public String decryptByAes(String content, String password) throws Exception &#123; //这里要把十六进制的序列转化回二进制的序列，依赖apache-codec包 byte[] bytes = Hex.decodeHex(content); //这里指定了算法为AES_128，工作模式为EBC，填充模式为NoPadding Cipher cipher = Cipher.getInstance(\"AES_128/ECB/NoPadding\"); KeyGenerator keyGenerator = KeyGenerator.getInstance(\"AES\"); //因为AES要求密钥的长度为128，我们需要固定的密码，因此随机源的种子需要设置为我们的密码数组 keyGenerator.init(128, new SecureRandom(password.getBytes())); SecretKey secretKey = keyGenerator.generateKey(); SecretKeySpec secretKeySpec = new SecretKeySpec(secretKey.getEncoded(), \"AES\"); //基于解密模式和密钥初始化Cipher cipher.init(Cipher.DECRYPT_MODE, secretKeySpec); //单部分加密结束，重置Cipher byte[] result = cipher.doFinal(bytes); return new String(result);&#125; 上面的例子需要注意，因为使用了填充模式为NoPadding，输入的需要加密的报文长度必须是16(128bit)的倍数。 包装密钥模式和解包装密钥模式 密钥的包装和解包装模式是一对互逆的操作，主要作用是通过算法对密钥进行加解密，从而提高密钥泄漏的难度。 1234567891011121314151617181920212223242526272829303132333435363738394041public enum EncryptUtils &#123; /** * 单例 */ SINGLETON; private static final String SECRECT = \"passwrod\"; public String wrap(String keyString) throws Exception &#123; KeyGenerator keyGenerator = KeyGenerator.getInstance(\"AES\"); //初始化密钥生成器，指定密钥长度为128，指定随机源的种子为指定的密钥(这里是\"passward\") keyGenerator.init(128, new SecureRandom(SECRECT.getBytes())); SecretKey secretKey = keyGenerator.generateKey(); SecretKeySpec secretKeySpec = new SecretKeySpec(secretKey.getEncoded(), \"AES\"); Cipher cipher = Cipher.getInstance(\"AES\"); cipher.init(Cipher.WRAP_MODE, secretKeySpec); SecretKeySpec key = new SecretKeySpec(keyString.getBytes(), \"AES\"); byte[] bytes = cipher.wrap(key); return Hex.encodeHexString(bytes); &#125; public String unwrap(String keyString) throws Exception &#123; byte[] rawKey = Hex.decodeHex(keyString); KeyGenerator keyGenerator = KeyGenerator.getInstance(\"AES\"); //初始化密钥生成器，指定密钥长度为128，指定随机源的种子为指定的密钥(这里是\"passward\") keyGenerator.init(128, new SecureRandom(SECRECT.getBytes())); SecretKey secretKey = keyGenerator.generateKey(); SecretKeySpec secretKeySpec = new SecretKeySpec(secretKey.getEncoded(), \"AES\"); Cipher cipher = Cipher.getInstance(\"AES\"); cipher.init(Cipher.UNWRAP_MODE, secretKeySpec); SecretKey key = (SecretKey) cipher.unwrap(rawKey, \"AES\", Cipher.SECRET_KEY); return new String(key.getEncoded()); &#125; public static void main(String[] args) throws Exception &#123; String wrapKey = EncryptUtils.SINGLETON.wrap(\"doge\"); System.out.println(wrapKey); System.out.println(EncryptUtils.SINGLETON.unwrap(wrapKey)); &#125;&#125; 分组(部分)加密和分组解密 当一个需要加密的报文十分长的时候，我们可以考虑把报文切割成多个小段，然后针对每个小段进行加密，这就是分组加密。分组解密的过程类同，可以看作是分组加密的逆向过程。下面还是用AES算法为例举个例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687import org.apache.commons.codec.binary.Hex;import javax.crypto.Cipher;import javax.crypto.KeyGenerator;import javax.crypto.SecretKey;import javax.crypto.spec.SecretKeySpec;import java.security.SecureRandom;/** * @author throwable * @version v1.0 * @description * @since 2018/8/15 1:06 */public enum Part &#123; /** * SINGLETON */ SINGLETON; private static final String PASSWORD = \"throwable\"; private Cipher createCipher() throws Exception &#123; return Cipher.getInstance(\"AES\"); &#125; public String encrypt(String content) throws Exception &#123; Cipher cipher = createCipher(); KeyGenerator keyGenerator = KeyGenerator.getInstance(\"AES\"); //因为AES要求密钥的长度为128，我们需要固定的密码，因此随机源的种子需要设置为我们的密码数组 keyGenerator.init(128, new SecureRandom(PASSWORD.getBytes())); SecretKey secretKey = keyGenerator.generateKey(); SecretKeySpec secretKeySpec = new SecretKeySpec(secretKey.getEncoded(), \"AES\"); //基于加密模式和密钥初始化Cipher cipher.init(Cipher.ENCRYPT_MODE, secretKeySpec); byte[] raw = content.getBytes(); StringBuilder builder = new StringBuilder(); //[0,9] byte[] first = cipher.update(raw, 0, 10); builder.append(Hex.encodeHexString(first)); //[10,19] byte[] second = cipher.update(raw, 10, 10); builder.append(Hex.encodeHexString(second)); //[20,25] byte[] third = cipher.update(raw, 20, 6); builder.append(Hex.encodeHexString(third)); //多部分加密结束，得到最后一段加密的结果，重置Cipher byte[] bytes = cipher.doFinal(); String last = Hex.encodeHexString(bytes); builder.append(last); return builder.toString(); &#125; public String decrypt(String content) throws Exception &#123; byte[] raw = Hex.decodeHex(content); Cipher cipher = createCipher(); KeyGenerator keyGenerator = KeyGenerator.getInstance(\"AES\"); //因为AES要求密钥的长度为128，我们需要固定的密码，因此随机源的种子需要设置为我们的密码数组 keyGenerator.init(128, new SecureRandom(PASSWORD.getBytes())); SecretKey secretKey = keyGenerator.generateKey(); SecretKeySpec secretKeySpec = new SecretKeySpec(secretKey.getEncoded(), \"AES\"); //基于解密模式和密钥初始化Cipher cipher.init(Cipher.DECRYPT_MODE, secretKeySpec); StringBuilder builder = new StringBuilder(); //[0,14] byte[] first = cipher.update(raw, 0, 15); builder.append(new String(first)); //[15,29] byte[] second = cipher.update(raw, 15, 15); builder.append(new String(second)); //[30,31] byte[] third = cipher.update(raw, 30, 2); builder.append(new String(third)); //多部分解密结束，得到最后一段解密的结果，重置Cipher byte[] bytes = cipher.doFinal(); builder.append(new String(bytes)); return builder.toString(); &#125; public static void main(String[] args) throws Exception&#123; String raw = \"abcdefghijklmnopqrstyuwxyz\"; String e = Part.SINGLETON.encrypt(raw); System.out.println(e); System.out.println(Part.SINGLETON.decrypt(e)); &#125;&#125; 上面的分段下标已经在注释中给出，分段的规则由实际情况考虑，一般AES加解密报文不大的时候可以直接单部分加解密即可，这里仅仅是为了做展示。 查看当前JDK中Cipher的所有提供商 我们可以直接查看当前的使用的JDK中Cipher的所有提供商和支持的加解密服务，简单写个main函数就行： 1234567891011121314151617181920import java.security.Provider;import java.security.Security;import java.util.Set;public class Main &#123; public static void main(String[] args) throws Exception &#123; Provider[] providers = Security.getProviders(); if (null != providers) &#123; for (Provider provider : providers) &#123; Set&lt;Provider.Service&gt; services = provider.getServices(); for (Provider.Service service : services) &#123; if (\"Cipher\".equals(service.getType())) &#123; System.out.println(String.format(\"provider:%s,type:%s,algorithm:%s\", service.getProvider(), service.getType(), service.getAlgorithm())); &#125; &#125; &#125; &#125; &#125;&#125; 笔者编写这篇文章的时候使用的JDK是JDK8的最后一个更新的版本8u181(1.8.0_181)，运行main函数输出如下： 12345678910provider:SunJCE version 1.8,type:Cipher,algorithm:RSAprovider:SunJCE version 1.8,type:Cipher,algorithm:DESprovider:SunJCE version 1.8,type:Cipher,algorithm:DESedeprovider:SunJCE version 1.8,type:Cipher,algorithm:DESedeWrapprovider:SunJCE version 1.8,type:Cipher,algorithm:PBEWithMD5AndDESprovider:SunJCE version 1.8,type:Cipher,algorithm:PBEWithMD5AndTripleDESprovider:SunJCE version 1.8,type:Cipher,algorithm:PBEWithSHA1AndDESedeprovider:SunJCE version 1.8,type:Cipher,algorithm:PBEWithSHA1AndRC2_40provider:SunJCE version 1.8,type:Cipher,algorithm:PBEWithSHA1AndRC2_128.....输出内容太多忽略剩余部分 扩展 因为Java原生支持的transformation是有限的，有些时候我们需要使用一些算法其他工作模式或者填充模式原生无法支持，这个时候我们需要引入第三方的Provider甚至自己实现Provider。常见的第三方Provider是bouncycastle(BC)，目前BC的最新依赖为： 12345&lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcprov-jdk15on&lt;/artifactId&gt; &lt;version&gt;1.60&lt;/version&gt;&lt;/dependency&gt; 举个例子，Java原生是不支持AESWRAP算法的，因此可以引入BC的依赖，再使用转换模式AESWRAP。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import org.apache.commons.codec.binary.Hex;import org.bouncycastle.jce.provider.BouncyCastleProvider;import javax.crypto.Cipher;import javax.crypto.KeyGenerator;import javax.crypto.SecretKey;import javax.crypto.spec.SecretKeySpec;import java.security.MessageDigest;import java.security.SecureRandom;import java.security.Security;public enum EncryptUtils &#123; /** * SINGLETON */ SINGLETON; private static final String SECRET = \"throwable\"; private static final String CHARSET = \"UTF-8\"; //装载BC提供商 static &#123; Security.addProvider(new BouncyCastleProvider()); &#125; private Cipher createAesCipher() throws Exception &#123; return Cipher.getInstance(\"AESWRAP\"); &#125; public String encryptByAes(String raw) throws Exception &#123; Cipher aesCipher = createAesCipher(); KeyGenerator keyGenerator = KeyGenerator.getInstance(\"AESWRAP\"); keyGenerator.init(128, new SecureRandom(SECRET.getBytes(CHARSET))); SecretKey secretKey = keyGenerator.generateKey(); SecretKeySpec secretKeySpec = new SecretKeySpec(secretKey.getEncoded(), \"AESWRAP\"); aesCipher.init(Cipher.ENCRYPT_MODE, secretKeySpec); byte[] bytes = aesCipher.doFinal(raw.getBytes(CHARSET)); return Hex.encodeHexString(bytes); &#125; public String decryptByAes(String raw) throws Exception &#123; byte[] bytes = Hex.decodeHex(raw); Cipher aesCipher = createAesCipher(); KeyGenerator keyGenerator = KeyGenerator.getInstance(\"AESWRAP\"); keyGenerator.init(128, new SecureRandom(SECRET.getBytes(CHARSET))); SecretKey secretKey = keyGenerator.generateKey(); SecretKeySpec secretKeySpec = new SecretKeySpec(secretKey.getEncoded(), \"AESWRAP\"); aesCipher.init(Cipher.DECRYPT_MODE, secretKeySpec); return new String(aesCipher.doFinal(bytes), CHARSET); &#125; public static void main(String[] args) throws Exception &#123; String raw = \"throwable-a-doge\"; String en = EncryptUtils.SINGLETON.encryptByAes(raw); System.out.println(en); String de = EncryptUtils.SINGLETON.decryptByAes(en); System.out.println(de); &#125;&#125; 上面的例子需要注意，因为使用了AESWRAP算法，输入的需要加密的报文长度必须是8的倍数。 小结 熟练掌握Cipher的用法、转换模式transformation的一些知识之后，影响我们编写加解密模块代码的主要因素就是加解密算法的原理或者使用，这些需要我们去学习专门的加解密算法相关的知识。另外，有些时候我们发现不同平台或者不同语言使用同一个加密算法不能相互解密加密，其实原因很简单，绝大部分原因是工作模式选取或者填充模式选取的不同导致的，排除掉这两点，剩下的可能性就是算法的实现不相同，依据这三点因素(或者说就是transformation这唯一的因素)去判断和寻找解决方案即可。关于加解密算法原理、工作模式等相关知识可以参考下面的资料。 参考资料： 《密码编码学与网络安全-原理与实践(第六版)》 《信息安全原理与实践(第2版)》 《关于加密数据的填充方式的研究》 JDK8文档 另外，一些特殊的方法例如Ciper#updateADD()暂时没遇到使用场景，这里就不写没实践过的Demo。 (本文完 e-a-20190216 c-7-d)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Security","slug":"Security","permalink":"http://throwable.club/blog/tags/Security/"}]},{"title":"项目架构级别规约框架Archunit调研","slug":"java-archunit-research","date":"2019-02-16T12:12:58.000Z","updated":"2019-02-16T14:44:09.160Z","comments":true,"path":"2019/02/16/java-archunit-research/","link":"","permalink":"http://throwable.club/2019/02/16/java-archunit-research/","excerpt":"","text":"项目架构级别规约框架Archunit调研 背景 最近在做一个新项目的时候引入了一个架构方面的需求，就是需要检查项目的编码规范、模块分类规范、类依赖规范等，刚好接触到，正好做个调研。 很多时候，我们会制定项目的规范，例如： 硬性规定项目包结构中service层不能引用controller层的类(这个例子有点极端)。 硬性规定定义在controller包下的Controller类的类名称以&quot;Controller&quot;结尾，方法的入参类型命名以&quot;Request&quot;结尾，返回参数命名以&quot;Response&quot;结尾。 枚举类型必须放在common.constant包下，以类名称Enum结尾。 还有很多其他可能需要定制的规范，最终可能会输出一个文档。但是，谁能保证所有参数开发的人员都会按照文档的规范进行开发？为了保证规范的实行，Archunit以单元测试的形式通过扫描类路径(甚至Jar)包下的所有类，通过单元测试的形式对各个规范进行代码编写，如果项目代码中有违背对应的单测规范，那么单元测试将会不通过，这样就可以从CI/CD层面彻底把控项项目架构和编码规范。 简介 Archunit是一个免费、简单、可扩展的类库，用于检查Java代码的体系结构。提供检查包和类的依赖关系、调用层次和切面的依赖关系、循环依赖检查等其他功能。它通过导入所有类的代码结构，基于Java字节码分析实现这一点。的主要关注点是使用任何普通的Java单元测试框架自动测试代码体系结构和编码规则。 引入依赖 一般来说，目前常用的测试框架是Junit4，需要引入Junit4和archunit： 123456789101112&lt;dependency&gt; &lt;groupId&gt;com.tngtech.archunit&lt;/groupId&gt; &lt;artifactId&gt;archunit&lt;/artifactId&gt; &lt;version&gt;0.9.3&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 由于junit4中依赖到slf4j，因此最好在测试依赖中引入一个slf4j的实现，例如logback： 123456&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 如何使用 主要从下面的两个方面介绍一下的使用： 指定参数进行类扫描。 内建规则定义。 指定参数进行类扫描 需要对代码或者依赖规则进行判断前提是要导入所有需要分析的类，类扫描导入依赖于ClassFileImporter，底层依赖于ASM字节码框架针对类文件的字节码进行解析，性能会比基于反射的类扫描框架高很多。ClassFileImporter的构造可选参数为ImportOption(s)，扫描规则可以通过ImportOption接口实现，默认提供可选的规则有： 12345678// 不包含测试类ImportOption.Predefined.DONT_INCLUDE_TESTS// 不包含Jar包里面的类ImportOption.Predefined.DONT_INCLUDE_JARS// 不包含Jar和Jrt包里面的类，JDK9的特性ImportOption.Predefined.DONT_INCLUDE_ARCHIVES 举个例子，我们实现一个自定义的ImportOption实现，用于指定需要排除扫描的包路径： 123456789101112131415161718192021public class DontIncludePackagesImportOption implements ImportOption &#123; private final Set&lt;Pattern&gt; EXCLUDED_PATTERN; public DontIncludePackagesImportOption(String... packages) &#123; EXCLUDED_PATTERN = new HashSet&lt;&gt;(8); for (String eachPackage : packages) &#123; EXCLUDED_PATTERN.add(Pattern.compile(String.format(\".*/%s/.*\", eachPackage.replace(\"/\", \".\")))); &#125; &#125; @Override public boolean includes(Location location) &#123; for (Pattern pattern : EXCLUDED_PATTERN) &#123; if (location.matches(pattern)) &#123; return false; &#125; &#125; return true; &#125;&#125; ImportOption接口只有一个方法： 1boolean includes(Location location) 其中，Location包含了路径信息、是否Jar文件等判断属性的元数据，方便使用正则表达式或者直接的逻辑判断。 接着我们可以通过上面实现的DontIncludePackagesImportOption去构造ClassFileImporter实例： 123456ImportOptions importOptions = new ImportOptions() // 不扫描jar包 .with(ImportOption.Predefined.DONT_INCLUDE_JARS) // 排除不扫描的包 .with(new DontIncludePackagesImportOption(\"com.sample..support\"));ClassFileImporter classFileImporter = new ClassFileImporter(importOptions); 得到ClassFileImporter实例后我们可以通过对应的方法导入项目中的类： 123456789101112131415161718192021222324252627282930313233// 指定类型导入单个类public JavaClass importClass(Class&lt;?&gt; clazz)// 指定类型导入多个类public JavaClasses importClasses(Class&lt;?&gt;... classes)public JavaClasses importClasses(Collection&lt;Class&lt;?&gt;&gt; classes)// 通过指定路径导入类public JavaClasses importUrl(URL url)public JavaClasses importUrls(Collection&lt;URL&gt; urls)public JavaClasses importLocations(Collection&lt;Location&gt; locations)// 通过类路径导入类public JavaClasses importClasspath()public JavaClasses importClasspath(ImportOptions options)// 通过文件路径导入类public JavaClasses importPath(String path)public JavaClasses importPath(Path path)public JavaClasses importPaths(String... paths)public JavaClasses importPaths(Path... paths)public JavaClasses importPaths(Collection&lt;Path&gt; paths)// 通过Jar文件对象导入类public JavaClasses importJar(JarFile jar)public JavaClasses importJars(JarFile... jarFiles)public JavaClasses importJars(Iterable&lt;JarFile&gt; jarFiles)// 通过包路径导入类 - 这个是比较常用的方法public JavaClasses importPackages(Collection&lt;String&gt; packages)public JavaClasses importPackages(String... packages)public JavaClasses importPackagesOf(Class&lt;?&gt;... classes)public JavaClasses importPackagesOf(Collection&lt;Class&lt;?&gt;&gt; classes) 导入类的方法提供了多维度的参数，用起来会十分便捷。例如想导入com.sample包下面的所有类，只需要这样： 12345678910111213141516public class ClassFileImporterTest &#123; @Test public void testImportBootstarpClass() throws Exception &#123; ImportOptions importOptions = new ImportOptions() // 不扫描jar包 .with(ImportOption.Predefined.DONT_INCLUDE_JARS) // 排除不扫描的包 .with(new DontIncludePackagesImportOption(\"com.sample..support\")); ClassFileImporter classFileImporter = new ClassFileImporter(importOptions); long start = System.currentTimeMillis(); JavaClasses javaClasses = classFileImporter.importPackages(\"com.sample\"); long end = System.currentTimeMillis(); System.out.println(String.format(\"Found %d classes,cost %d ms\", javaClasses.size(), end - start)); &#125;&#125; 得到的JavaClasses是JavaClass的集合，可以简单类比为反射中Class的集合，后面使用的代码规则和依赖规则判断都是强依赖于JavaClasses或者JavaClass。 内建规则定义 类扫描和类导入完成之后，我们需要定检查规则，然后应用于所有导入的类，这样子就能完成对所有的类进行规则的过滤 - 或者说把规则应用于所有类并且进行断言。 规则定义依赖于ArchRuleDefinition类，创建出来的规则是ArchRule实例，规则实例的创建过程一般使用ArchRuleDefinition类的流式方法，这些流式方法定义上符合人类思考的思维逻辑，上手比较简单，举个例子： 123456789ArchRule archRule = ArchRuleDefinition.noClasses() // 在service包下的所有类 .that().resideInAPackage(\"..service..\") // 不能调用controller包下的任意类 .should().accessClassesThat().resideInAPackage(\"..controller..\") // 断言描述 - 不满足规则的时候打印出来的原因 .because(\"不能在service包中调用controller中的类\"); // 对所有的JavaClasses进行判断archRule.check(classes); 上面展示了自定义新的ArchRule的例子，中已经为我们内置了一些常用的ArchRule实现，它们位于GeneralCodingRules中： NO_CLASSES_SHOULD_ACCESS_STANDARD_STREAMS：不能调用System.out、System.err或者(Exception.)printStackTrace。 NO_CLASSES_SHOULD_THROW_GENERIC_EXCEPTIONS：类不能直接抛出通用异常Throwable、Exception或者RuntimeException。 NO_CLASSES_SHOULD_USE_JAVA_UTIL_LOGGING：不能使用java.util.logging包路径下的日志组件。 更多内建的ArchRule或者通用的内置规则使用，可以参考官方例子。 基本使用例子 基本使用例子，主要从一些常见的编码规范或者项目规范编写规则对项目所有类进行检查。 包依赖关系检查 123ArchRule archRule = ArchRuleDefinition.noClasses() .that().resideInAPackage(\"..com.source..\") .should().dependOnClassesThat().resideInAPackage(\"..com.target..\"); 123ArchRule archRule = ArchRuleDefinition.classes() .that().resideInAPackage(\"..com.foo..\") .should().onlyAccessClassesThat().resideInAnyPackage(\"..com.source..\", \"..com.foo..\"); 类依赖关系检查 123ArchRule archRule = ArchRuleDefinition.classes() .that().haveNameMatching(\".*Bar\") .should().onlyBeAccessed().byClassesThat().haveSimpleName(\"Bar\"); 类包含于包的关系检查 123ArchRule archRule = ArchRuleDefinition.classes() .that().haveSimpleNameStartingWith(\"Foo\") .should().resideInAPackage(\"com.foo\"); 继承关系检查 123ArchRule archRule = ArchRuleDefinition.classes() .that().implement(Collection.class) .should().haveSimpleNameEndingWith(\"Connection\"); 123ArchRule archRule = ArchRuleDefinition.classes() .that().areAssignableTo(EntityManager.class) .should().onlyBeAccessed().byAnyPackage(\"..persistence..\"); 注解检查 123ArchRule archRule = ArchRuleDefinition.classes() .that().areAssignableTo(EntityManager.class) .should().onlyBeAccessed().byClassesThat().areAnnotatedWith(Transactional.class) 逻辑层调用关系检查 例如项目结构如下： 12345678- com.myapp.controller SomeControllerOne.class SomeControllerTwo.class- com.myapp.service SomeServiceOne.class SomeServiceTwo.class- com.myapp.persistence SomePersistenceManager 例如我们规定： 包路径com.myapp.controller中的类不能被其他层级包引用。 包路径com.myapp.service中的类只能被com.myapp.controller中的类引用。 包路径com.myapp.persistence中的类只能被com.myapp.service中的类引用。 编写规则如下： 12345678layeredArchitecture() .layer(\"Controller\").definedBy(\"..controller..\") .layer(\"Service\").definedBy(\"..service..\") .layer(\"Persistence\").definedBy(\"..persistence..\") .whereLayer(\"Controller\").mayNotBeAccessedByAnyLayer() .whereLayer(\"Service\").mayOnlyBeAccessedByLayers(\"Controller\") .whereLayer(\"Persistence\").mayOnlyBeAccessedByLayers(\"Service\") 循环依赖关系检查 例如项目结构如下： 123456789- com.myapp.moduleone ClassOneInModuleOne.class ClassTwoInModuleOne.class- com.myapp.moduletwo ClassOneInModuleTwo.class ClassTwoInModuleTwo.class- com.myapp.modulethree ClassOneInModuleThree.class ClassTwoInModuleThree.class 例如我们规定：com.myapp.moduleone、com.myapp.moduletwo和com.myapp.modulethree三个包路径中的类不能形成一个循环依赖缓，例如： 1ClassOneInModuleOne -&gt; ClassOneInModuleTwo -&gt; ClassOneInModuleThree -&gt; ClassOneInModuleOne 编写规则如下： 1slices().matching(\"com.myapp.(*)..\").should().beFreeOfCycles() 核心API 把API分为三层，最重要的是&quot;Core&quot;层、&quot;Lang&quot;层和&quot;Library&quot;层。 Core层API ArchUnit的Core层API大部分类似于Java原生反射API，例如JavaMethod和JavaField对应于原生反射中的Method和Field，它们提供了诸如getName()、getMethods()、getType()和getParameters()等方法。 此外ArchUnit扩展一些API用于描述依赖代码之间关系，例如JavaMethodCall， JavaConstructorCall或JavaFieldAccess。还提供了例如Java类与其他Java类之间的导入访问关系的API如JavaClass#getAccessesFromSelf()。 而需要导入类路径下或者Jar包中已经编译好的Java类，ArchUnit提供了ClassFileImporter完成此功能： 1JavaClasses classes = new ClassFileImporter().importPackages(\"com.mycompany.myapp\"); Lang层API Core层的API十分强大，提供了需要关于Java程序静态结构的信息，但是直接使用Core层的API对于单元测试会缺乏表现力，特别表现在架构规则方面。 出于这个原因，ArchUnit提供了Lang层的API，它提供了一种强大的语法来以抽象的方式表达规则。Lang层的API大多数是采用流式编程方式定义方法，例如指定包定义和调用关系的规则如下： 123456ArchRule rule = classes() // 定义在service包下的所欲类 .that().resideInAPackage(\"..service..\") // 只能被controller包或者service包中的类访问 .should().onlyBeAccessed().byAnyPackage(\"..controller..\", \"..service..\"); 编写好规则后就可以基于导入所有编译好的类进行扫描： 123JavaClasses classes = new ClassFileImporter().importPackage(\"com.myapp\");ArchRule rule = // 定义的规则rule.check(classes); Library层API Library层API通过静态工厂方法提供了更多复杂而强大的预定义规则，入口类是： 1com.tngtech.archunit.library.Architectures 目前，这只能为分层架构提供方便的检查，但将来可能会扩展为六边形架构\\管道和过滤器，业务逻辑和技术基础架构的分离等样式。 还有其他几个相对强大的功能： 代码切片功能，入口是com.tngtech.archunit.library.dependencies.SlicesRuleDefinition。 一般编码规则，入口是com.tngtech.archunit.library.GeneralCodingRules。 PlantUML组件支持，功能位于包路径com.tngtech.archunit.library.plantuml下。 编写复杂的规则 一般来说，内建的规则不一定能够满足一些复杂的规范校验规则，因此需要编写自定义的规则。这里仅仅举一个前文提到的相对复杂的规则： 定义在controller包下的Controller类的类名称以&quot;Controller&quot;结尾，方法的入参类型命名以&quot;Request&quot;结尾，返回参数命名以&quot;Response&quot;结尾。 官方提供的自定义规则的例子如下： 123456789101112131415161718192021222324DescribedPredicate&lt;JavaClass&gt; haveAFieldAnnotatedWithPayload = new DescribedPredicate&lt;JavaClass&gt;(\"have a field annotated with @Payload\")&#123; @Override public boolean apply(JavaClass input) &#123; boolean someFieldAnnotatedWithPayload = // iterate fields and check for @Payload return someFieldAnnotatedWithPayload; &#125; &#125;;ArchCondition&lt;JavaClass&gt; onlyBeAccessedBySecuredMethods = new ArchCondition&lt;JavaClass&gt;(\"only be accessed by @Secured methods\") &#123; @Override public void check(JavaClass item, ConditionEvents events) &#123; for (JavaMethodCall call : item.getMethodCallsToSelf()) &#123; if (!call.getOrigin().isAnnotatedWith(Secured.class)) &#123; String message = String.format( \"Method %s is not @Secured\", call.getOrigin().getFullName()); events.add(SimpleConditionEvent.violated(call, message)); &#125; &#125; &#125; &#125;;classes().that(haveAFieldAnnotatedWithPayload).should(onlyBeAccessedBySecuredMethods); 我们只需要模仿它的实现即可，具体如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class ArchunitTest &#123; @Test public void controller_class_rule() &#123; JavaClasses classes = new ClassFileImporter().importPackages(\"club.throwable\"); DescribedPredicate&lt;JavaClass&gt; predicate = new DescribedPredicate&lt;JavaClass&gt;(\"定义在club.throwable.controller包下的所有类\") &#123; @Override public boolean apply(JavaClass input) &#123; return null != input.getPackageName() &amp;&amp; input.getPackageName().contains(\"club.throwable.controller\"); &#125; &#125;; ArchCondition&lt;JavaClass&gt; condition1 = new ArchCondition&lt;JavaClass&gt;(\"类名称以Controller结尾\") &#123; @Override public void check(JavaClass javaClass, ConditionEvents conditionEvents) &#123; String name = javaClass.getName(); if (!name.endsWith(\"Controller\")) &#123; conditionEvents.add(SimpleConditionEvent.violated(javaClass, String.format(\"当前控制器类[%s]命名不以\\\"Controller\\\"结尾\", name))); &#125; &#125; &#125;; ArchCondition&lt;JavaClass&gt; condition2 = new ArchCondition&lt;JavaClass&gt;(\"方法的入参类型命名以\\\"Request\\\"结尾，返回参数命名以\\\"Response\\\"结尾\") &#123; @Override public void check(JavaClass javaClass, ConditionEvents conditionEvents) &#123; Set&lt;JavaMethod&gt; javaMethods = javaClass.getMethods(); String className = javaClass.getName(); // 其实这里要做严谨一点需要考虑是否使用了泛型参数，这里暂时简化了 for (JavaMethod javaMethod : javaMethods) &#123; Method method = javaMethod.reflect(); Class&lt;?&gt;[] parameterTypes = method.getParameterTypes(); for (Class parameterType : parameterTypes) &#123; if (!parameterType.getName().endsWith(\"Request\")) &#123; conditionEvents.add(SimpleConditionEvent.violated(method, String.format(\"当前控制器类[%s]的[%s]方法入参不以\\\"Request\\\"结尾\", className, method.getName()))); &#125; &#125; Class&lt;?&gt; returnType = method.getReturnType(); if (!returnType.getName().endsWith(\"Response\")) &#123; conditionEvents.add(SimpleConditionEvent.violated(method, String.format(\"当前控制器类[%s]的[%s]方法返回参数不以\\\"Response\\\"结尾\", className, method.getName()))); &#125; &#125; &#125; &#125;; ArchRuleDefinition.classes() .that(predicate) .should(condition1) .andShould(condition2) .because(\"定义在controller包下的Controller类的类名称以\\\"Controller\\\"结尾，方法的入参类型命名以\\\"Request\\\"结尾，返回参数命名以\\\"Response\\\"结尾\") .check(classes); &#125;&#125; 因为导入了所有需要的编译好的类的静态属性，基本上是可以编写所有能够想出来的规约，更多的内容或者实现可以自行摸索。 小结 通过最近的一个项目引入了Archunit，并且进行了一些编码规范和架构规范的规约，起到了十分明显的效果。之前口头或者书面文档的规范可以通过单元测试直接控制，项目构建的时候强制必须执行单元测试，只有所有单测通过才能构建和打包(禁止使用-Dmaven.test.skip=true参数)，起到了十分明显的成效。 参考资料： User Guide (e-a-2019216 c-1-d)","categories":[{"name":"Framework","slug":"Framework","permalink":"http://throwable.club/blog/categories/Framework/"},{"name":"Archunit","slug":"Framework/Archunit","permalink":"http://throwable.club/blog/categories/Framework/Archunit/"}],"tags":[{"name":"Framework","slug":"Framework","permalink":"http://throwable.club/blog/tags/Framework/"},{"name":"Archunit","slug":"Archunit","permalink":"http://throwable.club/blog/tags/Archunit/"}]},{"title":"深入理解JDK中的Reference原理和源码实现","slug":"java-reference","date":"2019-02-16T06:36:10.000Z","updated":"2019-02-16T06:51:54.552Z","comments":true,"path":"2019/02/16/java-reference/","link":"","permalink":"http://throwable.club/2019/02/16/java-reference/","excerpt":"","text":"深入理解JDK中的Reference原理和源码实现 前提 这篇文章主要基于JDK11的源码和最近翻看的《深入理解Java虚拟机-2nd》一书的部分内容，对JDK11中的Reference(引用)做一些总结。值得注意的是，通过笔者对比一下JDK11和JDK8对于java.lang.ref包的相关实现，发现代码变化比较大，因此本文的源码分析可能并不适合于JDK11之外的JDK版本。 Reference的简介和分类 在JDK1.2之前，Java中的引用的定义是十分传统的：如果reference类型的数据中存储的数值代表的是另一块内存的起始地址，就称这块内存代表着一个引用。在这种定义之下，一个对象只有被引用和没有被引用两种状态。 实际上，我们更希望存在这样的一类对象：当内存空间还足够的时候，这些对象能够保留在内存空间中；如果当内存空间在进行了垃圾收集之后还是非常紧张，则可以抛弃这些对象。基于这种特性，可以满足很多系统的缓存功能的使用场景。 java.lang.ref包是JDK1.2引入的，包结构和类分布如下： 12345678910- java.lang.ref - Cleaner.class - Finalizer.class - FinalizerHistogram.class - FinalReference.class - PhantomReference.class - Reference.class - ReferenceQueue.class - SoftReference.classs - WeakReference.class 引入此包的作用是对引用的概念进行了扩充，将引用分为强引用(Strong Reference)、软引用(Soft Reference)、弱引用(Weak Reference)和虚引用(Phantom Reference)四种类型的引用，还有一种比较特殊的引用是析构引用(Final Reference)，它是一种特化的虚引用。四种引用的强度按照下面的次序依次减弱： 1StrongReference &gt; SoftReference &gt; WeakReference &gt; PhantomReference 值得注意的是： 强引用没有对应的类型表示，也就是说强引用是普遍存在的，如Object object = new Object();。 软引用、弱引用和虚引用都是java.lang.ref.Reference的直接子类。 直到JDK11为止，只存在四种引用，这些引用是由JVM创建，因此直接继承java.lang.ref.Reference创建自定义的引用类型是无效的，但是可以直接继承已经存在的引用类型，如java.lang.ref.Cleaner就是继承自java.lang.ref.PhantomReference。 特殊的java.lang.ref.Reference的子类java.lang.ref.FinalReference和Object#finalize()有关，java.lang.ref.Finalizer是java.lang.ref.FinalReference子类，下文会详细分析这些内容。 Reference Reference就是引用，对JVM的垃圾收集活动敏感(当然，强引用可能对垃圾收集活动是不敏感的)，Reference的继承关系或者实现是由JDK定制，引用实例是由JVM创建，所以自行继承Reference实现自定义的引用类型是无意义的，但是可以继承已经存在的引用类型，如SoftReference等。Reference类文件的注释也比较简短，但是方法和变量的注释十分详细，特别是用图表表明了状态跃迁的过程，这里先看类文件头注释： Abstract base class for reference objects. This class defines the operations common to all reference objects. Because reference objects are implemented in close cooperation with the garbage collector, this class may not be subclassed directly. 翻译一下大意是：Reference是所有引用对象的基类。这个类定义了所有引用对象的通用操作。因为引用对象是与垃圾收集器紧密协作而实现的，所以这个类可能不能直接子类化。 Reference的状态集合 Reference源码中并不存在一个成员变量用于描述Reference的状态，它是通过组合判断referent、discovered、queue、next成员的存在性或者顺序&quot;拼凑出&quot;对应的状态，注释中描述如下： 12345678910111213141516171819202122232425262728293031一个引用对象可以同时存在两种状态：- 第一组状态：\"active\", \"pending\", or \"inactive\"- 第二组状态：\"registered\", \"enqueued\", \"dequeued\", or \"unregistered\"Active：当前引用实例处于Active状态，会收到垃圾收集器的特殊处理。在垃圾收集器检测到referent的可达性已更改为适当状态之后的某个时间，垃圾收集器会\"通知\"当前引用实例改变其状态为\"pending\"或者\"inactive\"。此时的判断条件是：referent != null; discovered = null或者实例位于GC的discovered列表中。Pending：当前的引用实例是pending-Reference列表的一个元素，等待被ReferenceHandler线程处理。pending-Reference列表通过应用实例的discovered字段进行关联。此时的判断条件是：referent = null; discovered = pending-Reference列表中的下一个元素Inactive：当前的引用实例处于非Active和非Pending状态。此时的判断条件是：referent = null (同时discovered = null)Registered：当前的引用实例创建的时候关联到一个引用队列实例，但是引用实例暂未加入到队列中。此时的判断条件是：queue = 传入的ReferenceQueue实例Enqueued：当前的引用实例已经添加到和它关联的引用队列中但是尚未移除(remove)，也就是调用了ReferenceQueue.enqueued()后的Reference实例就会处于这个状态。此时的判断条件是：queue = ReferenceQueue.ENQUEUE; next = 引用列表中的下一个引用实例，或者如果当前引用实例是引用列表中的最后一个元素，则它会进入Inactive状态Dequeued：当前的引用实例曾经添加到和它关联的引用队列中并且已经移除(remove)。此时的判断条件是：queue = ReferenceQueue.NULL; next = 当前的引用实例Unregistered：当前的引用实例不存在关联的引用队列，也就是创建引用实例的时候传入的queue为null。此时的判断条件是：queue = ReferenceQueue.NULL 状态跃迁的时序图如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051* Initial states:* [active/registered]* [active/unregistered] [1]** Transitions:* clear* [active/registered] -------&gt; [inactive/registered]* | |* | | enqueue [2]* | GC enqueue [2] |* | -----------------|* | |* v |* [pending/registered] --- v* | | ReferenceHandler* | enqueue [2] |---&gt; [inactive/enqueued]* v | |* [pending/enqueued] --- |* | | poll/remove* | poll/remove |* | |* v ReferenceHandler v* [pending/dequeued] ------&gt; [inactive/dequeued]*** clear/enqueue/GC [3]* [active/unregistered] ------* | |* | GC |* | |--&gt; [inactive/unregistered]* v |* [pending/unregistered] ------* ReferenceHandler** Terminal states:* [inactive/dequeued]* [inactive/unregistered]** Unreachable states (because enqueue also clears):* [active/enqeued]* [active/dequeued]** [1] Unregistered is not permitted for FinalReferences.** [2] These transitions are not possible for FinalReferences, making* [pending/enqueued] and [pending/dequeued] unreachable, and* [inactive/registered] terminal.** [3] The garbage collector may directly transition a Reference* from [active/unregistered] to [inactive/unregistered],* bypassing the pending-Reference list. 注释中还强调了几点： 初始化状态：[active/registered]和[active/unregistered](这种情况只限于FinalReferences)。 终结状态：[inactive/dequeued]和[inactive/unregistered]。 不可能出现的状态：[active/enqeued]和[active/dequeued]。 上面的图看起来可能比较抽象，ReferenceHandler其实是Reference中静态代码块中初始化的线程实例，主要作用是：处理pending状态的引用实例，使它们入队列并走向[inactive/dequeued]状态。另外，上面的线框图是分两部分，其中上半部分是使用了ReferenceQueue，后半部分是没有使用ReferenceQueue(或者说使用了ReferenceQueue.NULL)。这里尝试用PPT画一下简化的状态跃迁图： Reference源码分析 先看Reference的构造函数和成员变量： 123456789101112131415public abstract class Reference&lt;T&gt; &#123; private T referent; volatile ReferenceQueue&lt;? super T&gt; queue; volatile Reference next; private transient Reference&lt;T&gt; discovered; Reference(T referent) &#123; this(referent, null); &#125; Reference(T referent, ReferenceQueue&lt;? super T&gt; queue) &#123; this.referent = referent; this.queue = (queue == null) ? ReferenceQueue.NULL : queue; &#125;&#125; 构造描述： 构造函数依赖于一个泛型的referent成员以及一个ReferenceQueue&lt;? super T&gt;的队列，如果ReferenceQueue实例为null，则使用ReferenceQueue.NULL。 成员变量描述： referent：Reference保存的引用指向的对象，下面直接称为referent。 12// GC特殊处理的对象private T referent; /* Treated specially by GC */ queue：Reference对象关联的队列，也就是引用队列，对象如果即将被垃圾收集器回收，此队列作为通知的回调队列，也就是当Reference实例持有的对象referent要被回收的时候，Reference实例会被放入引用队列，那么程序执行的时候可以从引用队列得到或者监控相应的Reference实例。 123456789/* The queue this reference gets enqueued to by GC notification or by * calling enqueue(). * * When registered: the queue with which this reference is registered. * enqueued: ReferenceQueue.ENQUEUE * dequeued: ReferenceQueue.NULL * unregistered: ReferenceQueue.NULL */volatile ReferenceQueue&lt;? super T&gt; queue; next：下一个Reference实例的引用，Reference实例通过此构造单向的链表。 123456789/* The link in a ReferenceQueue's list of Reference objects. * * When registered: null * enqueued: next element in queue (or this if last) * dequeued: this (marking FinalReferences as inactive) * unregistered: null */@SuppressWarnings(\"rawtypes\")volatile Reference next; discovered：注意这个属性由transient修饰，基于状态表示不同链表中的下一个待处理的对象，主要是pending-reference列表的下一个元素，通过JVM直接调用赋值。 12345/* When active: next element in a discovered reference list maintained by GC (or this if last)* pending: next element in the pending list (or null if last)* otherwise: NULL*/transient private Reference&lt;T&gt; discovered; /* used by VM */ 实例方法(和ReferenceHandler线程不相关的方法)： 1234567891011121314151617181920212223242526272829303132// 获取持有的referent实例@HotSpotIntrinsicCandidatepublic T get() &#123; return this.referent;&#125;// 把持有的referent实例置为nullpublic void clear() &#123; this.referent = null;&#125;// 判断是否处于enqeued状态public boolean isEnqueued() &#123; return (this.queue == ReferenceQueue.ENQUEUED);&#125;// 入队参数，同时会把referent置为nullpublic boolean enqueue() &#123; this.referent = null; return this.queue.enqueue(this);&#125;// 覆盖clone方法并且抛出异常，也就是禁止clone@Overrideprotected Object clone() throws CloneNotSupportedException &#123; throw new CloneNotSupportedException();&#125;// 确保给定的引用实例是强可达的@ForceInlinepublic static void reachabilityFence(Object ref) &#123;&#125; ReferenceHandler线程 ReferenceHandler线程是由Reference静态代码块中建立并且运行的线程，它的运行方法中依赖了比较多的本地(native)方法，ReferenceHandler线程的主要功能是处理pending链表中的引用对象： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293// ReferenceHandler直接继承于Thread覆盖了run方法private static class ReferenceHandler extends Thread &#123; // 静态工具方法用于确保对应的类型已经初始化 private static void ensureClassInitialized(Class&lt;?&gt; clazz) &#123; try &#123; Class.forName(clazz.getName(), true, clazz.getClassLoader()); &#125; catch (ClassNotFoundException e) &#123; throw (Error) new NoClassDefFoundError(e.getMessage()).initCause(e); &#125; &#125; static &#123; // 确保Cleaner这个类已经初始化 // pre-load and initialize Cleaner class so that we don't // get into trouble later in the run loop if there's // memory shortage while loading/initializing it lazily. ensureClassInitialized(Cleaner.class); &#125; ReferenceHandler(ThreadGroup g, String name) &#123; super(g, null, name, 0, false); &#125; // 注意run方法是一个死循环执行processPendingReferences public void run() &#123; while (true) &#123; processPendingReferences(); &#125; &#125;&#125;/* 原子获取(后)并且清理VM中的pending引用链表 * Atomically get and clear (set to null) the VM's pending-Reference list. */private static native Reference&lt;Object&gt; getAndClearReferencePendingList();/* 检验VM中的pending引用对象链表是否有剩余元素 * Test whether the VM's pending-Reference list contains any entries. */private static native boolean hasReferencePendingList();/* 等待直到pending引用对象链表不为null，此方法阻塞的具体实现又VM实现 * Wait until the VM's pending-Reference list may be non-null. */private static native void waitForReferencePendingList();// 锁对象，用于控制等待pending对象时候的加锁和开始处理这些对象时候的解锁private static final Object processPendingLock = new Object();// 正在处理pending对象的时候，这个变量会更新为true，处理完毕或者初始化状态为false，用于避免重复处理或者重复等待private static boolean processPendingActive = false;// 这个是死循环中的核心方法，功能是处理pending链表中的引用元素private static void processPendingReferences() &#123; // Only the singleton reference processing thread calls // waitForReferencePendingList() and getAndClearReferencePendingList(). // These are separate operations to avoid a race with other threads // that are calling waitForReferenceProcessing(). // （1）等待 waitForReferencePendingList(); Reference&lt;Object&gt; pendingList; synchronized (processPendingLock) &#123; // （2）获取并清理，标记处理中状态 pendingList = getAndClearReferencePendingList(); processPendingActive = true; &#125; // （3）通过discovered(下一个元素)遍历pending链表进行处理 while (pendingList != null) &#123; Reference&lt;Object&gt; ref = pendingList; pendingList = ref.discovered; ref.discovered = null; // 如果是Cleaner类型执行执行clean方法并且对锁对象processPendingLock进行唤醒所有阻塞的线程 if (ref instanceof Cleaner) &#123; ((Cleaner)ref).clean(); // Notify any waiters that progress has been made. // This improves latency for nio.Bits waiters, which // are the only important ones. synchronized (processPendingLock) &#123; processPendingLock.notifyAll(); &#125; &#125; else &#123; // 非Cleaner类型并且引用队列不为ReferenceQueue.NULL则进行入队操作 ReferenceQueue&lt;? super Object&gt; q = ref.queue; if (q != ReferenceQueue.NULL) q.enqueue(ref); &#125; &#125; // （4）当次循环结束之前再次唤醒锁对象processPendingLock上阻塞的所有线程 // Notify any waiters of completion of current round. synchronized (processPendingLock) &#123; processPendingActive = false; processPendingLock.notifyAll(); &#125;&#125; ReferenceHandler线程启动的静态代码块如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243static &#123; // ThreadGroup继承当前执行线程(一般是主线程)的线程组 ThreadGroup tg = Thread.currentThread().getThreadGroup(); for (ThreadGroup tgn = tg; tgn != null; tg = tgn, tgn = tg.getParent()); // 创建线程实例，命名为Reference Handler，配置最高优先级和后台运行(守护线程)，然后启动 Thread handler = new ReferenceHandler(tg, \"Reference Handler\"); /* If there were a special system-only priority greater than * MAX_PRIORITY, it would be used here */ handler.setPriority(Thread.MAX_PRIORITY); handler.setDaemon(true); handler.start(); // 注意这里覆盖了全局的jdk.internal.misc.JavaLangRefAccess实现 // provide access in SharedSecrets SharedSecrets.setJavaLangRefAccess(new JavaLangRefAccess() &#123; @Override public boolean waitForReferenceProcessing() throws InterruptedException&#123; return Reference.waitForReferenceProcessing(); &#125; @Override public void runFinalization() &#123; Finalizer.runFinalization(); &#125; &#125;);&#125;// 如果正在处理pending链表中的引用对象或者监测到VM中的pending链表中还有剩余元素则基于锁对象processPendingLock进行等待private static boolean waitForReferenceProcessing() throws InterruptedException&#123; synchronized (processPendingLock) &#123; if (processPendingActive || hasReferencePendingList()) &#123; // Wait for progress, not necessarily completion. processPendingLock.wait(); return true; &#125; else &#123; return false; &#125; &#125;&#125; 由于ReferenceHandler线程是Reference的静态代码创建的，所以只要Reference这个父类被初始化，该线程就会创建和运行，由于它是守护线程，除非JVM进程终结，否则它会一直在后台运行(注意它的run()方法里面使用了死循环)。 ReferenceQueue JDK中对ReferenceQueue的文档描述是比较少的，类文件只有一句简单的注释： Reference queues, to which registered reference objects are appended by the garbage collector after the appropriate reachability changes are detected. 翻译一下大意为：引用队列，垃圾收集器在检测到适当的可达性更改后将已注册的引用对象追加到该队列。 从源码上看，实际上ReferenceQueue只是名义上的引用队列，它只保存了Reference链表的头(head)节点，并且提供了出队、入队和移除等操作，而Reference实际上本身提供单向链表的功能，也就是Reference通过成员属性next构建单向链表，而链表的操作是委托给ReferenceQueue完成，这里的逻辑有点绕。ReferenceQueue的源码比较少，这里全量贴出标注一下注释： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146public class ReferenceQueue&lt;T&gt; &#123; public ReferenceQueue() &#123; &#125; // 内部类Null类继承自ReferenceQueue，覆盖了enqueue方法返回false private static class Null extends ReferenceQueue&lt;Object&gt; &#123; boolean enqueue(Reference&lt;?&gt; r) &#123; return false; &#125; &#125; // ReferenceQueue.NULL和ReferenceQueue.ENQUEUED都是内部类Null的新实例 static final ReferenceQueue&lt;Object&gt; NULL = new Null(); static final ReferenceQueue&lt;Object&gt; ENQUEUED = new Null(); // 静态内部类，作为锁对象 private static class Lock &#123; &#125;; // 锁实例 private final Lock lock = new Lock(); // 引用链表的头节点 private volatile Reference&lt;? extends T&gt; head; // 引用队列长度，入队则增加1，出队则减少1 private long queueLength = 0; // 入队操作，只会被Reference实例调用 boolean enqueue(Reference&lt;? extends T&gt; r) &#123; /* Called only by Reference class */ // 加锁 synchronized (lock) &#123; // Check that since getting the lock this reference hasn't already been // enqueued (and even then removed) // 如果引用实例持有的队列为ReferenceQueue.NULL或者ReferenceQueue.ENQUEUED则入队失败返回false ReferenceQueue&lt;?&gt; queue = r.queue; if ((queue == NULL) || (queue == ENQUEUED)) &#123; return false; &#125; assert queue == this; // Self-loop end, so if a FinalReference it remains inactive. // 如果链表没有元素，则此引用实例直接作为头节点，否则把前一个引用实例作为下一个节点 r.next = (head == null) ? r : head; // 当前实例更新为头节点，也就是每一个新入队的引用实例都是作为头节点，已有的引用实例会作为后继节点 head = r; // 队列长度增加1 queueLength++; // Update r.queue *after* adding to list, to avoid race // with concurrent enqueued checks and fast-path poll(). // Volatiles ensure ordering. // 当前引用实例已经入队，那么它本身持有的引用队列实例置为ReferenceQueue.ENQUEUED r.queue = ENQUEUED; // 特殊处理FinalReference，VM进行计数 if (r instanceof FinalReference) &#123; VM.addFinalRefCount(1); &#125; // 唤醒所有等待的线程 lock.notifyAll(); return true; &#125; &#125; // 引用队列的poll操作，此方法必须在加锁情况下调用 private Reference&lt;? extends T&gt; reallyPoll() &#123; /* Must hold lock */ Reference&lt;? extends T&gt; r = head; if (r != null) &#123; r.queue = NULL; // Update r.queue *before* removing from list, to avoid // race with concurrent enqueued checks and fast-path // poll(). Volatiles ensure ordering. @SuppressWarnings(\"unchecked\") Reference&lt;? extends T&gt; rn = r.next; // Handle self-looped next as end of list designator. // 更新next节点为头节点，如果next节点为自身，说明已经走过一次出队，则返回null head = (rn == r) ? null : rn; // Self-loop next rather than setting to null, so if a // FinalReference it remains inactive. // 当前头节点变更为环状队列，考虑到FinalReference尚为inactive和避免重复出队的问题 r.next = r; // 队列长度减少1 queueLength--; // 特殊处理FinalReference，VM进行计数 if (r instanceof FinalReference) &#123; VM.addFinalRefCount(-1); &#125; return r; &#125; return null; &#125; // 队列的公有poll操作，主要是加锁后调用reallyPoll public Reference&lt;? extends T&gt; poll() &#123; if (head == null) return null; synchronized (lock) &#123; return reallyPoll(); &#125; &#125; // 移除引用队列中的下一个引用元素，实际上也是依赖于reallyPoll的Object提供的阻塞机制 public Reference&lt;? extends T&gt; remove(long timeout) throws IllegalArgumentException, InterruptedException&#123; if (timeout &lt; 0) &#123; throw new IllegalArgumentException(\"Negative timeout value\"); &#125; synchronized (lock) &#123; Reference&lt;? extends T&gt; r = reallyPoll(); if (r != null) return r; long start = (timeout == 0) ? 0 : System.nanoTime(); for (;;) &#123; lock.wait(timeout); r = reallyPoll(); if (r != null) return r; if (timeout != 0) &#123; long end = System.nanoTime(); timeout -= (end - start) / 1000_000; if (timeout &lt;= 0) return null; start = end; &#125; &#125; &#125; &#125; // remove，超时时间为0，实际上就是lock.wait(0)就是永久阻塞直至唤醒 public Reference&lt;? extends T&gt; remove() throws InterruptedException &#123; return remove(0); &#125; // foreach void forEach(Consumer&lt;? super Reference&lt;? extends T&gt;&gt; action) &#123; for (Reference&lt;? extends T&gt; r = head; r != null;) &#123; action.accept(r); @SuppressWarnings(\"unchecked\") Reference&lt;? extends T&gt; rn = r.next; if (rn == r) &#123; if (r.queue == ENQUEUED) &#123; // still enqueued -&gt; we reached end of chain r = null; &#125; else &#123; // already dequeued: r.queue == NULL; -&gt; // restart from head when overtaken by queue poller(s) r = head; &#125; &#125; else &#123; // next in chain r = rn; &#125; &#125; &#125; &#125; ReferenceQueue的源码十分简单，还是重新提一下，它只存储了Reference链表的头节点，真正的Reference链表的所有节点是存储在Reference实例本身，通过属性next拼接的，ReferenceQueue提供了对Reference链表的入队、poll、remove等操作。 判断对象的可达性和对象是否存活 判断对象的可达性和对象是否存活是两个比较困难的问题，笔者C语言学得比较烂，否则会重点翻看一下JVM的实现，目前只能参考一些资料来说明这个问题。 可达性算法 主流商用语言包括Java都是使用可达性分析(Reachability Analysis)算法来判定对象是否存活的。这个算法的基本思路是通过一系列的称为&quot;GC Roots&quot;(GC根集)的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC根集没有任何引用链相连(从图论的角度看，也就是从GC根集到这个对象是不可达的)时，则证明此对象是不可用的。不可用的对象&quot;有机会&quot;被判定为可以回收的对象。 在Java语言中，可以作为GC根集的对象包括下面几种： 虚拟机栈(栈帧中的本地变量表)中引用的对象。 方法区中常量引用的对象(在JDK1.8之后不存在方法区，也就是有可能是metaspace中常量引用的对象)。 本地方法栈中JNI(即一般常说的Native方法)引用的对象。 finalize函数 即使在可达性分析算法中判定为不可达的对象，也并非一定会判定为可以被回收的&quot;死亡&quot;对象。一个对象判定为&quot;死亡&quot;至少需要经历两次标记的过程。 第一次标记：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那么它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。JVM会把以下两种情况认为对象没有必要执行finalize()方法： 对象没有覆盖继承自Object类的finalize()方法。 对象的finalize()方法已经被JVM调用过。 如果一个对象被判定为有必要执行finalize()方法，那么这个对象将会被放置在一个叫F-Queue的队列之中，并且稍后由一个优先级低的Finalizer线程去取该队列的元素，&quot;尝试执行&quot;元素的finalize()方法。这里之所以叫尝试执行是因为JVM会保证触发满足条件的对象的finalize()方法，但是并不承诺会等待它执行结束，这是因为：如果一个对象在执行finalize()方法耗时较长，甚至发生了死循环，将会导致F-Queue的队列中的其他元素永远处于等待状态，极端情况下有可能导致整个内存回收系统崩溃。 finalize()方法是对象逃脱死亡命运的最后一次机会，因为稍后的GC将会对F-Queue队列中的对象进行第二次小规模的标记，如果对象在finalize()方法执行过程中成功拯救自己–也就是对象自身重新与引用链的任何一个对象建立关联即可，最常见的就是把自身(this关键字)赋值给某个类变量或者对象的成员属性，那么在第二次小规模的标记时候将会把&quot;自我拯救&quot;成功的对象移出&quot;即将回收&quot;的集合。如果对象在finalize()方法执行过程中没有&quot;逃逸&quot;，那么它最终就会被回收。参考《深入理解Java虚拟机-2nd》的&quot;对象自我拯救的例子&quot;： 1234567891011121314151617181920212223242526272829303132333435363738394041public class FinalizeEscapeGc &#123; private static FinalizeEscapeGc SAVE_HOOK = null; public void isAlive() &#123; System.out.println(\"Yes,I am still alive :)\"); &#125; public static void main(String[] args) throws Exception &#123; SAVE_HOOK = new FinalizeEscapeGc(); SAVE_HOOK = null; System.gc(); Thread.sleep(500); if (SAVE_HOOK != null) &#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println(\"No,I am not alive :(\"); &#125; // 下面的这段代码和上面的一致 SAVE_HOOK = null; System.gc(); Thread.sleep(500); if (SAVE_HOOK != null) &#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println(\"No,I am not alive :(\"); &#125; &#125; @Override protected void finalize() throws Throwable &#123; super.finalize(); System.out.println(\"FinalizeEscapeGc finalize invoke...\"); FinalizeEscapeGc.SAVE_HOOK = this; &#125;&#125;// 输出结果FinalizeEscapeGc finalize invoke...Yes,I am still alive :)No,I am not alive :( 注意： finalize()方法的错误使用有可能是内存回收系统崩溃的根源，一般情况下谨慎思考是否真的需要覆盖此方法。 任意一个对象只能通过finalize()方法自我拯救一次。 Finalizer守护线程 前面提到的Finalizer守护线程和F-Queue队列其实在JDK中有具体的实现类java.lang.ref.Finalizer。F-Queue队列只是《深入理解Java虚拟机-2nd》中的一个名词描述，实际上笔者没有找到相关的资料，这里我们通过分析JDK和JVM相关的源码去理解这个F-Queue队列吧。先看java.lang.ref.Finalizer的源码，代码比较少全量贴出： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172final class Finalizer extends FinalReference&lt;Object&gt; &#123; /* Package-private; must be in same package as the Reference class */ // Finalizer关联的ReferenceQueue，其实Finalizer是一个特殊的Reference实现 private static ReferenceQueue&lt;Object&gt; queue = new ReferenceQueue&lt;&gt;(); /** Head of doubly linked list of Finalizers awaiting finalization. */ // 等待finalization的所有Finalizer实例链表的头节点，这里称此链表为unfinalized链表 private static Finalizer unfinalized = null; /** Lock guarding access to unfinalized list. */ // unfinalized链表的锁，静态final，全局的锁实例 private static final Object lock = new Object(); // 中间变量，分别记录unfinalized链表中当前执行元素的下一个节点和前一个节点 private Finalizer next, prev; private Finalizer(Object finalizee) &#123; super(finalizee, queue); // push onto unfinalized // 这里主要是更新unfinalized链表的头节点，新增的元素总是会变成头节点 synchronized (lock) &#123; if (unfinalized != null) &#123; this.next = unfinalized; unfinalized.prev = this; &#125; unfinalized = this; &#125; &#125; static ReferenceQueue&lt;Object&gt; getQueue() &#123; return queue; &#125; /* Invoked by VM */ 这个方法由JVM激活，也就是链表的元素入队是由JVM控制的，见下文分析 static void register(Object finalizee) &#123; new Finalizer(finalizee); &#125; private void runFinalizer(JavaLangAccess jla) &#123; synchronized (lock) &#123; // 当前元素已经处理过，直接返回 if (this.next == this) // already finalized return; // unlink from unfinalized // 下面的逻辑是当前需要执行的元素从链表中移除，并且更新prev和next的值，相当于重建链表的部分节点 if (unfinalized == this) unfinalized = this.next; else this.prev.next = this.next; if (this.next != null) this.next.prev = this.prev; this.prev = null; this.next = this; // mark as finalized &#125; try &#123; // 获取对象执行一次finalize方法 Object finalizee = this.get(); if (finalizee != null &amp;&amp; !(finalizee instanceof java.lang.Enum)) &#123; jla.invokeFinalize(finalizee); // Clear stack slot containing this variable, to decrease // the chances of false retention with a conservative GC // 清空变量引用从而减少保守GC导致变量保留的可能性 finalizee = null; &#125; &#125; catch (Throwable x) &#123; &#125; // 执行完毕会做一次情况防止重复执行 super.clear(); &#125; /* Create a privileged secondary finalizer thread in the system thread * group for the given Runnable, and wait for it to complete. * * This method is used by runFinalization. * * It could have been implemented by offloading the work to the * regular finalizer thread and waiting for that thread to finish. * The advantage of creating a fresh thread, however, is that it insulates * invokers of that method from a stalled or deadlocked finalizer thread. */ // 这里其实不用畏惧注释太多，它只是一个候选方法，新建一个线程直接调用包裹在Runnable的runFinalization方法，主要是提供给主动调用的上层方法调用的 private static void forkSecondaryFinalizer(final Runnable proc) &#123; AccessController.doPrivileged( new PrivilegedAction&lt;&gt;() &#123; public Void run() &#123; ThreadGroup tg = Thread.currentThread().getThreadGroup(); for (ThreadGroup tgn = tg; tgn != null; tg = tgn, tgn = tg.getParent()); Thread sft = new Thread(tg, proc, \"Secondary finalizer\", 0, false); sft.start(); try &#123; sft.join(); &#125; catch (InterruptedException x) &#123; Thread.currentThread().interrupt(); &#125; return null; &#125;&#125;); &#125; /* Called by Runtime.runFinalization() */ // 这个方法是给Runtime.runFinalization()委托调用的，其实就是主动取出queue的元素强制调用其finalize方法 static void runFinalization() &#123; if (VM.initLevel() == 0) &#123; return; &#125; forkSecondaryFinalizer(new Runnable() &#123; private volatile boolean running; public void run() &#123; // in case of recursive call to run() if (running) return; final JavaLangAccess jla = SharedSecrets.getJavaLangAccess(); running = true; for (Finalizer f; (f = (Finalizer)queue.poll()) != null;) f.runFinalizer(jla); &#125; &#125;); &#125; // 真正的Finalizer线程 private static class FinalizerThread extends Thread &#123; private volatile boolean running; FinalizerThread(ThreadGroup g) &#123; super(g, null, \"Finalizer\", 0, false); &#125; public void run() &#123; // in case of recursive call to run() if (running) return; // Finalizer thread starts before System.initializeSystemClass // is called. Wait until JavaLangAccess is available while (VM.initLevel() == 0) &#123; // delay until VM completes initialization try &#123; VM.awaitInitLevel(1); &#125; catch (InterruptedException x) &#123; // ignore and continue &#125; &#125; final JavaLangAccess jla = SharedSecrets.getJavaLangAccess(); running = true; // 注意这里是死循环 for (;;) &#123; try &#123; // 注意这里是调用`Reference#remove()`的永久阻塞版本，只有`Reference#enqueue()`被调用才会解除阻塞 // `Reference#remove()`解除阻塞说明元素已经完成入队，由ReferenceHandler线程完成 Finalizer f = (Finalizer)queue.remove(); // 实际上就是调用对象的finalize方法 f.runFinalizer(jla); &#125; catch (InterruptedException x) &#123; // ignore and continue &#125; &#125; &#125; &#125; static &#123; ThreadGroup tg = Thread.currentThread().getThreadGroup(); for (ThreadGroup tgn = tg; tgn != null; tg = tgn, tgn = tg.getParent()); // 静态代码块中声明线程，优先级是最高优先级-2，守护线程，实际上这里优先级不一定会生效 Thread finalizer = new FinalizerThread(tg); finalizer.setPriority(Thread.MAX_PRIORITY - 2); finalizer.setDaemon(true); finalizer.start(); &#125;&#125; 上面的注释已经很明显标注出来，这里小结一下内容。 Finalizer是FinalReference的子类，而FinalReference是Reference的实现，所以它的工作原理和其他引用类似，对象的状态更变和由ReferenceHandler线程密切相关。 Finalizer内部维护了一个链表，每当JVM调用静态注册方法就会新建一个Finalizer实例加入到链表的头节点中，头节点元素为unfinalized，这里称此链表为unfinalized链表。 Finalizer线程由Finalizer静态代码块构建并且运行，它是守护线程，优先级是最高优先级-2，它的作用就是提取unfinalized链表的元素并且执行元素对象的finalize()方法，过程中还会涉及到线程的阻塞、唤醒，以及unfinalized链表的重建等工作。 由于静态方法Finalizer#register(Object finalizee)是由JVM调用的，所以我们必须要分析一些JVM的源码，参考的是OpenJDK主分支的代码，文件是instanceKlass.cpp： 123456789101112131415instanceOop InstanceKlass::register_finalizer(instanceOop i, TRAPS) &#123; if (TraceFinalizerRegistration) &#123; tty-&gt;print(\"Registered \"); i-&gt;print_value_on(tty); tty-&gt;print_cr(\" (\" INTPTR_FORMAT \") as finalizable\", p2i(i)); &#125; instanceHandle h_i(THREAD, i); // Pass the handle as argument, JavaCalls::call expects oop as jobjects JavaValue result(T_VOID); JavaCallArguments args(h_i); // 这里Universe::finalizer_register_method()获取到的就是Finalizer#register方法句柄 methodHandle mh (THREAD, Universe::finalizer_register_method()); JavaCalls::call(&amp;result, mh, &amp;args, CHECK_NULL); return h_i();&#125; 最后调用的是javaCalls.cpp： 12345678void JavaCalls::call(JavaValue* result, const methodHandle&amp; method, JavaCallArguments* args, TRAPS) &#123; // Check if we need to wrap a potential OS exception handler around thread // This is used for e.g. Win32 structured exception handlers assert(THREAD-&gt;is_Java_thread(), \"only JavaThreads can make JavaCalls\"); // Need to wrap each and every time, since there might be native code down the // stack that has installed its own exception handlers os::os_exception_wrapper(call_helper, result, method, args, THREAD);&#125; 简单来看就是把创建对象过程中，如果有必要注册Finalizer(一般是覆盖了finalize()方法)，则基于当前线程通过Finalizer#register(Object finalizee)把当前新建的实例注册到Finalizer自身维护的链表中(如果没理解错，所谓的F-Queue就是这个链表了)，等待后台Finalizer线程轮询并且执行链表中对象的finalize()方法。 各类引用以及它们的使用场景 这里提到的各类引用目前就是四种：强引用(StrongReference)、软引用(SoftReference)、弱引用(WeakReference)和虚引用(PhantomReference)。其实还有特殊的引用类型FinalReference，它是包私有的，并且只有一个子类型Finalizer。 StrongReference StrongReference也就是强引用，它是使用最普遍的一种引用，java.lang.ref包下没有强引用对应的类型。一个比较明确的强引用定义就是：所有和GC Root之间存在引用链的对象都具备强引用。举个简单例子：形如Object o = new Object();在方法体中使用new关键字声明的对象一般就是强引用。如果一个对象具备强引用，垃圾回收器绝不会回收它。当内存空间不足，JVM宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会出现回收具有强引用的对象来解决内存不足的情况。当然，如果有共享的成员变量在方法退出之前置为null，相当于断绝成员变量和GC Root的引用链，在合适的时机是有利于GC后具备强引用的对象的回收，例如： 123456private Object shareValue = XXX;public void methodA()&#123; //do something shareValue = null;&#125; 后来有人过度信奉类似上面的这个实践，出现了一条比较诡异的编码实践：强引用使用完毕后都要置为null方便对象回收。但是实际上，这个实践并不是在任何场景都是合理的。 SoftReference SoftReference也就是软引用，它是用来描述一些&quot;还有用但是非必须&quot;的对象。对于软引用关联着的对象，在JVM应用即将发生内存溢出异常之前，将会把这些软引用关联的对象列进去回收对象范围之中进行第二次回收。如果这次回收之后还是没有足够的内存，才会抛出内存溢出异常。简单来说就是： 如果内存空间足够，垃圾回收器就不会回收软引用关联着的对象。 如果内存空间不足，垃圾回收器在将要抛出内存溢出异常之前会回收软引用关联着的对象。 举个简单的使用例子： 12345678910111213141516171819202122232425// VM参数：-Xmx4m -Xms4mpublic class SoftReferenceMain &#123; public static void main(String[] args) throws Exception &#123; ReferenceQueue&lt;SoftReferenceObject&gt; queue = new ReferenceQueue&lt;&gt;(); SoftReferenceObject object = new SoftReferenceObject(); SoftReference&lt;SoftReferenceObject&gt; reference = new SoftReference&lt;&gt;(object, queue); object = null; System.gc(); Thread.sleep(500); System.out.println(reference.get()); &#125; private static class SoftReferenceObject &#123; int[] array = new int[120_000]; @Override public String toString() &#123; return \"SoftReferenceObject\"; &#125; &#125;&#125;// 运行后输出结果null 上面的例子故意把JVM的启动的最大Heap内存和初始Heap内存设置为4MB，使用这个对象初始化一个比较大的整型数组并且关系到一个软引用对象中，GC之后，发现软引用关联的对象被回收了。 WeakReference WeakReference也就是弱引用，弱引用和软引用类似，它是用来描述&quot;非必须&quot;的对象的，它的强度比软引用要更弱一些。被弱引用关联的对象只能生存到下一次垃圾收集发生之前，简言之就是：一旦发生GC必定回收被弱引用关联的对象，不管当前的内存是否足够。 举个例子： 123456789101112131415161718192021222324public class WeakReferenceMain &#123; public static void main(String[] args) throws Exception &#123; ReferenceQueue&lt;WeakReferenceObject&gt; queue = new ReferenceQueue&lt;&gt;(); WeakReferenceObject object = new WeakReferenceObject(); System.out.println(object); WeakReference&lt;WeakReferenceObject&gt; reference = new WeakReference&lt;&gt;(object, queue); object = null; System.gc(); Thread.sleep(500); System.out.println(reference.get()); &#125; private static class WeakReferenceObject &#123; @Override public String toString() &#123; return \"WeakReferenceObject\"; &#125; &#125;&#125;// 运行后输出结果WeakReferenceObjectnull 上面的例子中没有设定JVM的堆内存，因此不存在内存不足的情况，可见弱引用关联的对象在GC之后被回收了。弱引用适合用来做对内存敏感的缓存，很常用的WeakHashMap就是基于弱引用实现的。 PhantomReference PhantomReference也就是虚引用，也叫幽灵引用或者幻影引用，它是所有引用类型中最弱的一种。一个对象是否关联到虚引用，完全不会影响该对象的生命周期，也无法通过虚引用来获取一个对象的实例(PhantomReference覆盖了Reference#get()并且总是返回null)。为对象设置一个虚引用的唯一目的是：能在此对象被垃圾收集器回收的时候收到一个系统通知。PhantomReference有两个比较常用的子类是java.lang.ref.Cleaner和jdk.internal.ref.Cleaner，其中前者提供的功能是开发者用于在引用对象回收的时候触发一个动作(java.lang.ref.Cleaner$Cleanable)，后者用于DirectByteBuffer对象回收的时候对于堆外内存的回收，可以翻看前面描述java.lang.ref.Reference#processPendingReferences()源码的时候，ReferenceHandler线程会对pending链表中的jdk.internal.ref.Cleaner类型引用对象调用其clean()方法。PhantomReference本身使用场景比较少，这里举一下java.lang.ref.Cleaner注释中的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class PhantomReferenceMain &#123; public static void main(String[] args) throws Exception &#123; try (CleaningExample o = new CleaningExample(11))&#123; &#125; CleaningExample o2 = new CleaningExample(22); System.gc(); Thread.sleep(300); &#125;&#125;class CleaningExample implements AutoCloseable &#123; private Cleaner cleaner = Cleaner.create(); private final State state; private final Cleaner.Cleanable cleanable; public CleaningExample(int s) &#123; state = new State(s); cleanable = cleaner.register(this, state); &#125; class State implements Runnable &#123; private final int s; public State(int s) &#123; this.s = s; &#125; @Override public void run() &#123; System.out.println(\"State runnable in action.State value = \" + s); &#125; &#125; @Override public void close() throws Exception &#123; cleanable.clean(); &#125;&#125; 实际上，沙面的代码执行完毕只会输出&quot;State runnable in action.State value = 11&quot;，并没有输出&quot;State runnable in action.State value = 22&quot;，这是因为无法预测强引用对象被回收的时机。java.lang.ref.Cleaner主要是用于预防实现了AutoCloseable接口的实例忘记调用close()方法在对象被垃圾收集器回收的时候(内存回收)做一个兜底的清理工作，在JDK9之后，java.lang.ref.Cleaner主要是为了替代已经标识为过期的Object#finalize()方法。 扩展阅读：可以注意阅读一下《Effective Java 3rd》的第8小节，摘抄部分内容如下：终结方法（Finalizer）是不可预知的，很多时候是危险的，而且一般情况下是不必要的。…在Java 9中，终结方法已经被遗弃了，但它们仍被Java类库使用，相应用来替代终结方法的是清理方法（cleaner）。比起终结方法，清理方法相对安全点，但仍是不可以预知的，运行慢的，而且一般情况下是不必要的。 JDK9中有很多原来使用覆盖Object#finalize()方法的清理工作实现都替换为java.lang.ref.Cleaner，但是仍然不鼓励使用这种方式。 Reference和ReferenceQueue配合使用 前面基本介绍完了所有类型引用以及相关的源码，但是尚未提供例子说明Reference和ReferenceQueue是怎么配合使用的。举个例子： 123456789101112131415161718192021222324252627282930public class ReferenceQueueMain &#123; public static void main(String[] args) throws Exception &#123; ReferenceQueue&lt;WeakReferenceObject&gt; queue = new ReferenceQueue&lt;&gt;(); WeakReferenceObject object = new WeakReferenceObject(); WeakReference&lt;WeakReferenceObject&gt; weakReference = new WeakReference&lt;&gt;(object, queue); System.out.println(weakReference); object = null; System.gc(); Thread.sleep(500); while (true) &#123; Reference&lt;? extends WeakReferenceObject&gt; reference = queue.poll(); if (null == reference) &#123; Thread.sleep(100); &#125; else &#123; System.out.println(reference); System.out.println(reference.get()); break; &#125; &#125; &#125; private static class WeakReferenceObject &#123; @Override public String toString() &#123; return \"WeakReferenceObject\"; &#125; &#125;&#125; 运行后输出结果是： 123java.lang.ref.WeakReference@6537cf78java.lang.ref.WeakReference@6537cf78null 可见轮询ReferenceQueue实例得到的弱引用实例和创建的是一致的，只是它持有的关联的对象已经被回收，得到null。上面的ReferenceQueue#poll()方法也可以替换为ReferenceQueue#remove()，这样子就不用写在死循环中，因为ReferenceQueue#remove()会阻塞到有元素可以出队。通过轮询绑定到Reference实例的ReferenceQueue实例，就可以得知Reference实例当前的状态并且判断它关联的我们真正关注的对象是否被回收。 小结 Reference是非强引用的其他三种引用的共同父类。 ReferenceQueue只存储了引用链表的头节点，提供了引用链表的操作，实际上，引用链表是Reference实例内部变量存储的。 ReferenceHandler守护线程线程由Reference的静态代码块创建和运行，作用是处理pending链表的引用元素使之状态变更，伴随着ReferenceQueue的相关操作。 Finalizer守护线程是由Finalizer类的静态代码块创建和运行的，作用是处理Finalizer类内部维护的F-Queue链表(链表元素入队操作由JVM实现)的元素调用关联对象的finalize()方法。 ReferenceHandler守护线程线和Finalizer守护线程共同协作才能使引用类型对象内存回收系统的工作能够正常进行。 四种引用类型的总结： 引用类型 被垃圾收集器回收的时机 主要用途 生存周期 强引用 直到内存溢出也不会回收 普遍对象的状态 从创建到JVM实例终止运行 软引用 垃圾回收并且内存不足时 有用但非必须的对象缓存 从创建到垃圾回收并且内存不足时 弱引用 垃圾回收时 非必须的对象缓存 上一次垃圾回收结束到下一次垃圾回收开始 虚引用 - 关联的对象被垃圾收集器回收时候得到一个系统通知 - 参考资料： JDK11部分源码。 《深入理解Java虚拟机-2nd》- 这本书算是国内书籍写得比较良心的一本了，不过有很多小的问题或者笔误之处，需要自行发现和修正。 (过年比较懒，很久没发文 e-a-20190215 c-14-d)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Reference","slug":"Reference","permalink":"http://throwable.club/blog/tags/Reference/"}]},{"title":"JSR310新日期API(五)-在主流框架中使用新日期时间类","slug":"java-jsr310-framework-integration","date":"2019-01-07T16:02:48.000Z","updated":"2019-01-07T16:03:12.352Z","comments":true,"path":"2019/01/08/java-jsr310-framework-integration/","link":"","permalink":"http://throwable.club/2019/01/08/java-jsr310-framework-integration/","excerpt":"","text":"JSR310新日期API(五)-在主流框架中使用新日期时间类 前提 前面的几篇文章已经基本介绍完了JSR-310日期时间类库的基本使用，这篇文章主要介绍在主流的框架中如何使用这些类库。因为涉及到数据库操作，先准备好一张表和对应的实体。 12345678CREATE TABLE `t_user`( id BIGINT PRIMARY KEY COMMENT '主键', username VARCHAR(10) COMMENT '姓名', birthday DATE COMMENT '生日', create_time DATETIME COMMENT '创建时间', KEY idx_name(`username`), KEY idx_create_time(`create_time`))COMMENT '用户表'; 12345678@Datapublic class User&#123; private Long id; private String name; private LocalDate birthday; private OffsetDateTime createTime;&#125; 这里如果不考虑时区的影响，createTime也可以使用LocalDateTime类型。另外，为了连接测试数据库，这里引入’光’连接池的依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt;&lt;/dependency&gt; JDBC中使用JSR-310日期时间类库 说实话，由于JDBC类库在方法参数或者返回值类型很久没更新，对于带日期时间的属性，统一使用java.sql.Timestamp类型，对于日期类型的属性则统一使用java.sql.Date，因此需要进行类型转换。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839public class JdbcSample &#123; public static void main(String[] args) throws Exception &#123; HikariConfig config = new HikariConfig(); config.setMaximumPoolSize(10); config.setJdbcUrl(\"jdbc:mysql://localhost:3306/test?useSSL=false&amp;characterEncoding=utf8\"); config.setUsername(\"root\"); config.setPassword(\"root\"); config.setDriverClassName(\"com.mysql.jdbc.Driver\"); DataSource dataSource = new HikariDataSource(config); Connection connection = dataSource.getConnection(); connection.setAutoCommit(false); PreparedStatement p = connection.prepareStatement(\"INSERT INTO t_user(id,username,birthday,create_time) VALUES (?,?,?,?)\"); p.setLong(1, 1L); p.setString(2, \"Throwable\"); p.setDate(3, Date.valueOf(LocalDate.of(1993, 3, 10))); p.setTimestamp(4, Timestamp.from(OffsetDateTime.now().toInstant())); //LocalDateTime -&gt; p.setTimestamp(4, Timestamp.from(LocalDateTime.now())); int updateCount = p.executeUpdate(); connection.commit(); System.out.println(String.format(\"更新数据%d条\", updateCount)); p = connection.prepareStatement(\"SELECT * FROM t_user WHERE id = ?\"); p.setLong(1, 1L); ResultSet resultSet = p.executeQuery(); User user = null; if (resultSet.next()) &#123; user = new User(); user.setId(resultSet.getLong(\"id\")); user.setName(resultSet.getString(\"username\")); user.setBirthday(resultSet.getDate(\"birthday\").toLocalDate()); user.setCreateTime(OffsetDateTime.ofInstant(resultSet.getTimestamp(\"create_time\").toInstant(), ZoneId.systemDefault())); //LocalDateTime -&gt; user.setCreateTime(resultSet.getTimestamp(\"create_time\").toLocalDateTime()); &#125; System.out.println(user); &#125;&#125;// 输出结果更新数据1条User(id=1, name=Throwable, birthday=1993-03-10, createTime=2019-01-06T23:09:01+08:00) 除了需要做少量类型转换，没有其他的兼容性问题。 Mybatis中使用JSR-310日期时间类库 既然JDBC已经可以使用JSR-310的日期时间类库，那么基于JDBC封装的ORM框架必定也可以支持。除了需要引入Mybatis本身的依赖，还需要引入mybatis-typehandlers-jsr310依赖： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-typehandlers-jsr310&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt;&lt;/dependency&gt; 新建一个Mapper接口类UserMapper： 12345678public interface UserMapper &#123; @Insert(\"INSERT INTO t_user(id,username,birthday,create_time) VALUES (#&#123;id&#125;,#&#123;name&#125;,#&#123;birthday&#125;,#&#123;createTime&#125;)\") int insert(User user); @Select(\"SELECT id,username as name,birthday,create_time as createTime FROM t_user WHERE id = #&#123;id&#125;\") User selectById(Long id);&#125; 核心代码如下： 123456789101112131415161718192021222324252627282930313233public class MybatisSample &#123; public static void main(String[] args) throws Exception &#123; HikariConfig config = new HikariConfig(); config.setMaximumPoolSize(10); config.setJdbcUrl(\"jdbc:mysql://localhost:3306/test?useSSL=false&amp;characterEncoding=utf8\"); config.setUsername(\"root\"); config.setPassword(\"root\"); config.setDriverClassName(\"com.mysql.jdbc.Driver\"); DataSource dataSource = new HikariDataSource(config); TransactionFactory transactionFactory = new JdbcTransactionFactory(); Environment environment = new Environment(\"development\", transactionFactory, dataSource); Configuration configuration = new Configuration(environment); configuration.addMapper(UserMapper.class); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(configuration); SqlSession sqlSession = sqlSessionFactory.openSession(); UserMapper userMapper = sqlSession.getMapper(UserMapper.class); User user = new User(); user.setId(1L); user.setCreateTime(OffsetDateTime.now()); user.setBirthday(LocalDate.of(1993, 3, 10)); user.setName(\"Throwable\"); int updateCount = userMapper.insert(user); System.out.println(String.format(\"更新数据%d条\", updateCount)); sqlSession.commit(); User result = userMapper.selectById(1L); System.out.println(result); sqlSession.close(); &#125;&#125;// 输出结果更新数据1条User(id=1, name=Throwable, birthday=1993-03-10, createTime=2019-01-06T23:30:09+08:00) 虽然多引入了一个依赖，但是使用起来十分简单，甚至可以做到开发态无感知，Mybatis这一点做得比较完善。 Jackson中使用JSR-310日期时间类库 Jackson从2.x某个版本中，官方就基于JDK8的新特性开发了第三方类库jackson-modules-java8，这个第三方类库包括三个模块jackson-module-parameter-names、jackson-datatype-jdk8和jackson-datatype-jsr310，这三个模块是独立打包的，可以按需引入。这里做的实例需要引入下面的依赖： 12345678910&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt; &lt;artifactId&gt;jackson-datatype-jsr310&lt;/artifactId&gt; &lt;version&gt;2.9.8&lt;/version&gt;&lt;/dependency&gt; 在官方文档中已经很详细给出具体的使用例子，这里也简单做一个例子： 12345678910111213141516171819202122232425262728public class JacksonMain &#123; private static final DateTimeFormatter DATE_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM-dd\"); private static final DateTimeFormatter DATE_TIME_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"); public static void main(String[] args) throws Exception &#123; ObjectMapper objectMapper = new ObjectMapper(); JavaTimeModule javaTimeModule = new JavaTimeModule(); javaTimeModule.addSerializer(LocalDate.class, new LocalDateSerializer(DATE_FORMATTER)); javaTimeModule.addDeserializer(LocalDate.class, new LocalDateDeserializer(DATE_FORMATTER)); javaTimeModule.addSerializer(LocalDateTime.class, new LocalDateTimeSerializer(DATE_TIME_FORMATTER)); javaTimeModule.addDeserializer(LocalDateTime.class, new LocalDateTimeDeserializer(DATE_TIME_FORMATTER)); objectMapper.registerModule(javaTimeModule); Sample sample = new Sample(); sample.setLocalDate(LocalDate.now()); sample.setLocalDateTime(LocalDateTime.now()); System.out.println(objectMapper.writeValueAsString(sample)); &#125; @Data public static class Sample &#123; private LocalDate localDate; private LocalDateTime localDateTime; &#125;&#125;// 某个时刻输出如下&#123;\"localDate\":\"2019-01-07\",\"localDateTime\":\"2019-01-07 23:40:12\"&#125; ObjectMapper实例中可以注册自定义的JavaTimeModule模块，JavaTimeModule模块中已经存在了不少默认的日期时间类的序列化和反序列化器，必要时可以像上面的例子一样重写对应的日期时间类型的序列化和反序列化器并且覆盖已经配置的默认实现，这样子就能实现我们想要的格式化输出。JavaTimeModule默认的序列化和反序列化器配置如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public JavaTimeModule() &#123; super(PackageVersion.VERSION); this.addDeserializer(Instant.class, InstantDeserializer.INSTANT); this.addDeserializer(OffsetDateTime.class, InstantDeserializer.OFFSET_DATE_TIME); this.addDeserializer(ZonedDateTime.class, InstantDeserializer.ZONED_DATE_TIME); this.addDeserializer(Duration.class, DurationDeserializer.INSTANCE); this.addDeserializer(LocalDateTime.class, LocalDateTimeDeserializer.INSTANCE); this.addDeserializer(LocalDate.class, LocalDateDeserializer.INSTANCE); this.addDeserializer(LocalTime.class, LocalTimeDeserializer.INSTANCE); this.addDeserializer(MonthDay.class, MonthDayDeserializer.INSTANCE); this.addDeserializer(OffsetTime.class, OffsetTimeDeserializer.INSTANCE); this.addDeserializer(Period.class, JSR310StringParsableDeserializer.PERIOD); this.addDeserializer(Year.class, YearDeserializer.INSTANCE); this.addDeserializer(YearMonth.class, YearMonthDeserializer.INSTANCE); this.addDeserializer(ZoneId.class, JSR310StringParsableDeserializer.ZONE_ID); this.addDeserializer(ZoneOffset.class, JSR310StringParsableDeserializer.ZONE_OFFSET); this.addSerializer(Duration.class, DurationSerializer.INSTANCE); this.addSerializer(Instant.class, InstantSerializer.INSTANCE); this.addSerializer(LocalDateTime.class, LocalDateTimeSerializer.INSTANCE); this.addSerializer(LocalDate.class, LocalDateSerializer.INSTANCE); this.addSerializer(LocalTime.class, LocalTimeSerializer.INSTANCE); this.addSerializer(MonthDay.class, MonthDaySerializer.INSTANCE); this.addSerializer(OffsetDateTime.class, OffsetDateTimeSerializer.INSTANCE); this.addSerializer(OffsetTime.class, OffsetTimeSerializer.INSTANCE); this.addSerializer(Period.class, new ToStringSerializer(Period.class)); this.addSerializer(Year.class, YearSerializer.INSTANCE); this.addSerializer(YearMonth.class, YearMonthSerializer.INSTANCE); this.addSerializer(ZonedDateTime.class, ZonedDateTimeSerializer.INSTANCE); this.addSerializer(ZoneId.class, new ToStringSerializer(ZoneId.class)); this.addSerializer(ZoneOffset.class, new ToStringSerializer(ZoneOffset.class)); this.addKeySerializer(ZonedDateTime.class, ZonedDateTimeKeySerializer.INSTANCE); this.addKeyDeserializer(Duration.class, DurationKeyDeserializer.INSTANCE); this.addKeyDeserializer(Instant.class, InstantKeyDeserializer.INSTANCE); this.addKeyDeserializer(LocalDateTime.class, LocalDateTimeKeyDeserializer.INSTANCE); this.addKeyDeserializer(LocalDate.class, LocalDateKeyDeserializer.INSTANCE); this.addKeyDeserializer(LocalTime.class, LocalTimeKeyDeserializer.INSTANCE); this.addKeyDeserializer(MonthDay.class, MonthDayKeyDeserializer.INSTANCE); this.addKeyDeserializer(OffsetDateTime.class, OffsetDateTimeKeyDeserializer.INSTANCE); this.addKeyDeserializer(OffsetTime.class, OffsetTimeKeyDeserializer.INSTANCE); this.addKeyDeserializer(Period.class, PeriodKeyDeserializer.INSTANCE); this.addKeyDeserializer(Year.class, YearKeyDeserializer.INSTANCE); this.addKeyDeserializer(YearMonth.class, YearMothKeyDeserializer.INSTANCE); this.addKeyDeserializer(ZonedDateTime.class, ZonedDateTimeKeyDeserializer.INSTANCE); this.addKeyDeserializer(ZoneId.class, ZoneIdKeyDeserializer.INSTANCE); this.addKeyDeserializer(ZoneOffset.class, ZoneOffsetKeyDeserializer.INSTANCE);&#125; 如果熟练掌握Jackson的解析原理和源码，可以尝试继承JSR310FormattedSerializerBase或者JSR310DateTimeDeserializerBase实现自定义序列化或反序列化器，从更底层控制日期时间类的序列化和反序列化。 SpringMVC中使用JSR-310日期时间类库 SpringMVC中默认的HTTP消息转换器就是使用Jackson实现的，前面已经提到了Jackson可以完美支持JSR-310，那么SpringMVC也必定可以支持，只需要对ObjectMapper做一些额外的配置即可。这里简单以SpringBoot应用做示例，引入依赖： 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt; &lt;artifactId&gt;jackson-datatype-jsr310&lt;/artifactId&gt; &lt;version&gt;2.9.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 由于org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration中会通过Jackson2ObjectMapperBuilder去构造内部使用的ObjectMapper，我们只需要提供一个自定义的Jackson2ObjectMapperBuilder类型的Bean即可。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 配置类@Configurationpublic class JacksonBuilderAutoConfiguration &#123; private static final DateTimeFormatter DATE_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM-dd\"); private static final DateTimeFormatter DATE_TIME_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"); @Bean public Jackson2ObjectMapperBuilder jackson2ObjectMapperBuilder() &#123; Jackson2ObjectMapperBuilder builder = new Jackson2ObjectMapperBuilder(); JavaTimeModule javaTimeModule = new JavaTimeModule(); javaTimeModule.addSerializer(LocalDate.class, new LocalDateSerializer(DATE_FORMATTER)); javaTimeModule.addDeserializer(LocalDate.class, new LocalDateDeserializer(DATE_FORMATTER)); javaTimeModule.addSerializer(LocalDateTime.class, new LocalDateTimeSerializer(DATE_TIME_FORMATTER)); javaTimeModule.addDeserializer(LocalDateTime.class, new LocalDateTimeDeserializer(DATE_TIME_FORMATTER)); builder.modules(javaTimeModule); return builder; &#125;&#125;// 启动类@SpringBootApplicationpublic class Application implements CommandLineRunner &#123; @Autowired private ObjectMapper objectMapper; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; @Override public void run(String... args) throws Exception &#123; Sample sample = new Sample(); sample.setLocalDate(LocalDate.now()); sample.setLocalDateTime(LocalDateTime.now()); System.out.println(objectMapper.writeValueAsString(sample)); &#125; @Data public static class Sample &#123; private LocalDate localDate; private LocalDateTime localDateTime; &#125;&#125;// 运行启动类，某个时刻输出如下&#123;\"localDate\":\"2019-01-07\",\"localDateTime\":\"2019-01-07 23:58:08\"&#125; 这里只要保证SpringMVC内部使用的ObjectMapper类型的Bean对JSR-310日期时间类型的序列化和反序列化生效即可，因为默认配置的MappingJackson2HttpMessageConverterHTTP消息转换器就是使用内置的ObjectMapper类型的Bean做JSON的序列化和反序列化。 小结 实战层面来看，使用的框架都是基于JDK类库的实现，只要JDK类库的功能可以实现，那么在应用的时候要有信心主流的框架一定会支持对应的特性。 参考资料： Mybatis官方文档 JDK11相关源码和注释 (本文完 e-a-201818 c-2-d)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"JSR-310","slug":"JSR-310","permalink":"http://throwable.club/blog/tags/JSR-310/"}]},{"title":"JSR310新日期API(四)-日期时间常用计算工具","slug":"java-jsr310-date-time-calculate","date":"2019-01-06T08:20:22.000Z","updated":"2019-01-06T08:25:10.417Z","comments":true,"path":"2019/01/06/java-jsr310-date-time-calculate/","link":"","permalink":"http://throwable.club/2019/01/06/java-jsr310-date-time-calculate/","excerpt":"","text":"JSR310新日期API(四)-日期时间常用计算工具 前提 这篇文章主要介绍JSR-310中日期时间类的常用计算工具，包括常规的两个日期时间实例之间的前后比较、间隔的时间量等等。 日期时间的基准类 日期时间类库中提供了几个常用的计算或者度量基准类，分别是： 表示取值范围的ValueRange：内部持有四个主要的成员变量minSmallest、minLargest、maxSmallest和maxLargest，可以表示的值范围是[minSmallest/maxSmallest,minLargest/maxLargest]。 表示秒和纳秒级别的时间量Duration：TemporalAmount的实现类，内部持有一个长整型的成员seconds代表秒和一个整型的成员nanos代表纳秒，由秒和纳秒组成时间量。 表示年月日级别的时间量Period：TemporalAmount的实现类，内部持有三个整型的成员years、months和days分别代表年、月、日，由年月日组成时间量。 日期时间的基本单位TemporalUnit：主要实现类是枚举类型ChronoUnit，一个ChronoUnit成员会维护一个字符串名字属性name和一个Duration类型的实例。 日期时间的属性(field)表示TemporalField：主要实现是枚举类型ChronoField，一个ChronoField成员会维护一个字符串名字属性name、一个TemporalUnit的基础单位baseUnit、一个TemporalUnit的表示范围的单位rangeUnit和一个ValueRange类型的range用于表示当前属性的范围。 举一些简单的使用例子： 123456789101112public class ValueRangeMain &#123; public static void main(String[] args) throws Exception &#123; ValueRange valueRange = ValueRange.of(1L, 10000L); System.out.println(valueRange); valueRange = ValueRange.of(1L, 5L, 10000L, 50000L); System.out.println(valueRange); &#125;&#125;// 输出结果1 - 100001/5 - 10000/50000 123456789101112131415public class DurationMain &#123; public static void main(String[] args) throws Exception &#123; Duration duration = Duration.of(1L, ChronoUnit.HOURS); System.out.println(duration); duration = Duration.from(duration); System.out.println(duration); duration = Duration.ofSeconds(1L, 999_999_999); System.out.println(duration.get(ChronoUnit.SECONDS)); &#125;&#125;//输出结果 - toString方法重写了，有特定的格式PT1HPT1H1 123456789101112public class PeriodMain &#123; public static void main(String[] args) throws Exception &#123; Period period = Period.of(10, 10, 10); System.out.println(period); period = Period.from(period); System.out.println(period.getYears()); &#125;&#125;//输出结果P10Y10M10D10 常用计算工具 判断是否闰年 判断是否闰年这个功能是由年表Chronology提供的，因为不同的年表中的闰年规则可能不一致。一般情况下，我们都是使用ISO规范下的年表，对应的是IsoChronology，可以看一下IsoChronology判断闰年方法的实现： 123public boolean isLeapYear(long prolepticYear) &#123; return ((prolepticYear &amp; 3) == 0) &amp;&amp; ((prolepticYear % 100) != 0 || (prolepticYear % 400) == 0);&#125; 这个也是最常见的Java基础面试题之一，可以记下来怎么实现。静态方法java.time.Year#isLeap()也是同样的实现。举个简单的使用例子： 123456789101112131415161718public class IsLeapYearMain &#123; public static void main(String[] args) throws Exception &#123; int year = 2016; System.out.println(Year.isLeap(year)); System.out.println(IsoChronology.INSTANCE.isLeapYear(year)); // 2018年 LocalDate localDate = LocalDate.now(); LocalDateTime localDateTime = LocalDateTime.now(); System.out.println(localDate.isLeapYear()); System.out.println(localDateTime.toLocalDate().isLeapYear()); &#125;&#125;// 输出结果truetruefalsefalse 比较日期时间的先后 所有的日期时间、日期、时间类都具备三个比较方法：isBefore()、isAfter()和isEqual()或者equals()，对于ChronoLocalDateTime或者ChronoZonedDateTime，底层总是先转化为新纪元天数再基于天数进行比较。举个简单的使用例子： 123456789101112public class DateTimeCompareMain &#123; public static void main(String[] args) throws Exception &#123; System.out.println(LocalDateTime.now().isBefore(LocalDateTime.now().plus(1, ChronoUnit.SECONDS))); System.out.println(LocalDate.now().isBefore(LocalDate.now().plus(1, ChronoUnit.DAYS))); System.out.println(LocalTime.now().equals(LocalTime.now().plus(1, ChronoUnit.SECONDS))); &#125;&#125;// 输出truetruefalse 计算日期时间的间隔 计算日期时间的间隔主要通过Duration或者Period的静态方法，主要是通过两个类的between()方法： 12345678910111213// Duration中public class Duration&#123; public static Duration between(Temporal startInclusive, Temporal endExclusive)&#125;// Period中public class Period&#123; public static ChronoPeriod between(ChronoLocalDate startDateInclusive, ChronoLocalDate endDateExclusive) public static Period between(LocalDate startDateInclusive, LocalDate endDateExclusive)&#125; 对于日期时间类来说，计算时间间隔底层是基于TemporalUnit#between()方法，入口方法一般是long until(Temporal endExclusive, TemporalUnit unit)方法。 举个简单的使用例子： 123456789101112131415161718192021222324252627282930public class DurationPeriodMain &#123; public static void main(String[] args) throws Exception &#123; LocalTime start = LocalTime.of(1, 1, 1); LocalTime end = LocalTime.of(2, 2, 2); Duration duration = Duration.between(start, end); long until = start.until(end, ChronoUnit.SECONDS); System.out.println(duration.getSeconds()); System.out.println(until); LocalDateTime startDt = LocalDateTime.of(2017, 9, 6, 1, 2, 3); LocalDateTime endDt = LocalDateTime.of(2018, 1, 6, 12, 12, 12); duration = Duration.between(startDt, endDt); until = startDt.until(endDt, ChronoUnit.SECONDS); System.out.println(duration.getSeconds()); System.out.println(until); LocalDate startD = LocalDate.of(2018, 2, 1); LocalDate endD = LocalDate.of(2019, 1, 6); Period period = Period.between(startD, endD); Period untilPeriod = startD.until(endD); System.out.println(period); System.out.println(untilPeriod); &#125;&#125;// 输出结果366136611058100910581009P11M5DP11M5D 只要通过计算得到Duration或者Period实例，那么可以通过get(TemporalUnit unit)方法转换为对应单位的时间量，但是要注意的是对于此方法Duration只支持ChronoUnit.SECONDS和ChronoUnit.NANOS，而Period只支持ChronoUnit.YEARS、ChronoUnit.MONTHS和ChronoUnit.DAYS。一般情况下，我们更希望得知两个日期时间之间相差多少年，多少个月等，这个时候，可以使用Duration或者Period提供的实例方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// Period中public class Period&#123; // 相差的总月数 public long toTotalMonths()&#125;// Period中public class Period&#123; // 转换为天数 public long toDays() // 转换为小时数 public long toHours() // 转换为分钟数 public long toMinutes() // 转换为秒钟数 public long toSeconds() // 转换为毫秒数 public long toMillis() // 转换为纳秒数 public long toNanos() // 转换为准确天数 public long toDaysPart() // 转换为准确小时数 public int toHoursPart() // 转换为准确分钟数 public int toMinutesPart() // 转换为准确秒钟数 public int toSecondsPart() // 转换为准确毫秒数 public int toMillisPart() // 转换为准确纳秒数 public int toNanosPart()&#125; 以上的实例方法都是基于整数的除法，也就是说会截断尾数。举个简单使用例子： 123456789LocalDateTime start = LocalDateTime.of(2017, 9, 6, 1, 2, 3);LocalDateTime end = LocalDateTime.of(2018, 1, 6, 12, 12, 12);Duration duration = Duration.between(start, end);Period period = Period.between(start.toLocalDate(), end.toLocalDate());System.out.println(duration.toDays());System.out.println(period.toTotalMonths());// 输出结果1224 如果不使用Duration或者Period，可以直接使用日期时间类的util()方法，本质是一致的，以LocalDateTime为例： 123456789LocalDateTime start = LocalDateTime.of(2017, 9, 6, 1, 2, 3);LocalDateTime end = LocalDateTime.of(2018, 1, 6, 12, 12, 12);long months = start.until(end, ChronoUnit.MONTHS);long days = start.until(end, ChronoUnit.DAYS);System.out.println(days);System.out.println(months);// 输出结果1224 (本文完 c-1-d e-a-201816)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"JSR-310","slug":"JSR-310","permalink":"http://throwable.club/blog/tags/JSR-310/"}]},{"title":"JSR310新日期API(三)-日期时间格式化与解析","slug":"java-jsr310-date-time-format-parse","date":"2019-01-05T13:43:51.000Z","updated":"2019-01-05T13:45:27.222Z","comments":true,"path":"2019/01/05/java-jsr310-date-time-format-parse/","link":"","permalink":"http://throwable.club/2019/01/05/java-jsr310-date-time-format-parse/","excerpt":"","text":"JSR310新日期API(三)-日期时间格式化与解析 前提 前一篇文章已经比较详细地介绍了JSR-310中新增的常用的日期时间类，在实际应用中，我们也十分关注这些日期时间类的格式化操作，更加通俗来说就是字符串和日期时间类的相互转换问题。下面先回顾一下Java旧有的日期时间类和字符串之间的转换方案，然后重点分析JSR-310中新增的常用的日期时间类和字符串之间的转换方案。 SimpleDateFormat Java旧有的日期时间类格式化为字符串或者字符串基于模式(pattern)解析为日期时间类完全依赖于java.text.DateFormat的实现类java.text.SimpleDateFormat。SimpleDateFormat的基本功能是完备的，但是存在两个问题： 解析和格式化的效率比较低，原因是依赖了本来就效率不高的Calendar，内部有大量的字符串或者字符(char)的判断和转换代码，因此使用了大量循环、switch块等，这些因素都导致了SimpleDateFormat的效率比较低。 非线程安全，这个是因为SimpleDateFormat在做转换操作的时候共享了DateFormat的一个内部Calendar的成员calendar。 效率低是可以忍受的，但是非线程安全这一点可能会导致严重的问题。对于非线程安全这个问题也有解决方案： 方案一：把SimpleDateFormat实例封闭在方法中，也就是调用的时候才创建，这样虽然导致了资源浪费，但是可以避免并发问题。 方案二：使用ThreadLocal装载SimpleDateFormat实例，对于同一个线程来说，共享一个SimpleDateFormat实例。 举个简单的使用例子： 123456789101112131415161718public class SimpleDateFormatMain &#123; public static void main(String[] args) throws Exception &#123; java.util.Date date = new Date(); SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); String dateString = simpleDateFormat.format(date); System.out.println(dateString); date = simpleDateFormat.parse(dateString); System.out.println(date); simpleDateFormat.applyPattern(\"yyyy-MM-dd\"); dateString = simpleDateFormat.format(date); System.out.println(dateString); &#125;&#125;// 某个时刻的输出如下2019-01-03 23:32:05Thu Jan 03 23:32:05 CST 20192019-01-03 对于Java旧有的日期时间类，SimpleDateFormat是基本能够满足的，再加上有第三方库apache-common-lang3、joda-time等的补足，格式化和解析的效率也会有所提高。 JSR-310日期时间类的格式化和解析 JSR-310日期时间类的格式化依赖于日期时间格式化器java.time.format.DateTimeFormatter，它有一个建造器类java.time.format.DateTimeFormatterBuilder。 DateTimeFormatterBuilder java.time.format.DateTimeFormatterBuilder用于构建日期时间类格式化器，它在设计的时候使用了链式结构，内部持有一个DateTimeFormatterBuilder类型的parent成员指向父DateTimeFormatterBuilder实例和一个DateTimeFormatterBuilder类型的active成员指向当前的DateTimeFormatterBuilder实例。还有一点比较重要的是：DateTimeFormatterBuilder实例内部维护了一个DateTimePrinterParser列表printerParsers，真正的解析工作是委托给对应的DateTimePrinterParser实例完成的，如果没有可用或者没有添加DateTimePrinterParser，那么解析或者格式化方法相当于空跑。接着看下DateTimeFormatterBuilder提供构建DateTimeFormatter时允许添加特性的方法。 解析风格配置： 12345678// 大小写敏感 - 默认public DateTimeFormatterBuilder parseCaseSensitive()// 大小写不敏感public DateTimeFormatterBuilder parseCaseInsensitive()// 严格 - 默认public DateTimeFormatterBuilder parseStrict()// 宽松public DateTimeFormatterBuilder parseLenient() 默认值配置： 12// 基于TemporalField实例配置解析时候写入默认值，支持的TemporalField主要在ChronoFieldpublic DateTimeFormatterBuilder parseDefaulting(TemporalField field, long value) 追加日期时间属性格式化符号控制配置： 123456789101112131415161718/** * 对于每个日期时间字段格式化的控制，实际作用是添加一个DateTimePrinterParser的实现NumberPrinterParser * TemporalField：日期时间字段类型实例，主要实现类为在ChronoField的枚举属性 * minWidth：打印最小长度限制，范围是[1,19] * maxWidth：打印最大长度限制，范围是[1,19] * SignStyle：符号风格，有NORMAL、ALWAYS、NEVER、NOT_NEGATIVE、EXCEEDS_PAD五种选择 * - NORMAL：严格模式下只接收负值，宽松模式下接收所有符号 * - ALWAYS：0会替换为'+'，严格模式下不接收缺失的符号，宽松模式下缺失的符号会替换为一个正数 * - NEVER：只输出绝对的固定值，严格模式下不接收任何符号，宽松模式下只接收固定长度的符号 * - NOT_NEGATIVE：以异常的方式阻止负值，严格模式下不接收任何符号，宽松模式下只接收固定长度的符号 * - EXCEEDS_PAD：只输出超出宽度限制的符号，负数替换为'-'，严格模式下只输出超出宽度限制的符号，宽松模式下缺失的符号会替换为一个正数 */public DateTimeFormatterBuilder appendValue(TemporalField field, int minWidth, int maxWidth, SignStyle signStyle)// 下面2个是重载方法// minWidth = 1,maxWidth = 19,signStyle = SignStyle.NORMALpublic DateTimeFormatterBuilder appendValue(TemporalField field)// minWidth = maxWidth = width,signStyle = SignStyle.NOT_NEGATIVEpublic DateTimeFormatterBuilder appendValue(TemporalField field, int width) 追加基于基础值进行减少配置： 1234// 例如field=YEAR，width=2，baseValue=2018，那么当前格式化的实例的有效值为[2018,2117]，2019-&gt;1，2117-&gt;99// width范围是[1,10]，maxWidth范围是[1,10]public DateTimeFormatterBuilder appendValueReduced(TemporalField field, int width, int maxWidth, int baseValue)public DateTimeFormatterBuilder appendValueReduced(TemporalField field, int width, int maxWidth, ChronoLocalDate baseDate) 追加小数(点)配置： 12// decimalPoint = true则输出小数，minWidth范围是[0,9]，maxWidth范围是[1,9]public DateTimeFormatterBuilder appendFraction(TemporalField field, int minWidth, int maxWidth, boolean decimalPoint) 追加文本格式配置： 123public DateTimeFormatterBuilder appendText(TemporalField field)public DateTimeFormatterBuilder appendText(TemporalField field, TextStyle textStyle)public DateTimeFormatterBuilder appendText(TemporalField field, Map&lt;Long, String&gt; textLookup) 追加瞬时时间配置： 12public DateTimeFormatterBuilder appendInstant()public DateTimeFormatterBuilder appendInstant(int fractionalDigits) 追加时区相关的配置： 1234567891011121314151617// 时间偏移量如+01:00public DateTimeFormatterBuilder appendOffsetId()// 指定格式的时间偏移量public DateTimeFormatterBuilder appendOffset(String pattern, String noOffsetText)// 指定文本风格的本地时间偏移量public DateTimeFormatterBuilder appendLocalizedOffset(TextStyle style)public DateTimeFormatterBuilder appendZoneId()public DateTimeFormatterBuilder appendZoneRegionId()public DateTimeFormatterBuilder appendZoneOrOffsetId()public DateTimeFormatterBuilder appendZoneText(TextStyle textStyle)public DateTimeFormatterBuilder appendZoneText(TextStyle textStyle, Set&lt;ZoneId&gt; preferredZones)// 太平洋时间时区偏移量public DateTimeFormatterBuilder appendGenericZoneText(TextStyle textStyle)public DateTimeFormatterBuilder appendGenericZoneText(TextStyle textStyle, Set&lt;ZoneId&gt; preferredZones) // 日历配置public DateTimeFormatterBuilder appendChronologyId()public DateTimeFormatterBuilder appendChronologyText(TextStyle textStyle) 追加本地日期时间配置： 1public DateTimeFormatterBuilder appendLocalized(FormatStyle dateStyle, FormatStyle timeStyle) 追加常量文字(字符串)配置： 12public DateTimeFormatterBuilder appendLiteral(char literal)public DateTimeFormatterBuilder appendLiteral(String literal) 追加其他格式化器的属性到当期建造器： 123public DateTimeFormatterBuilder append(DateTimeFormatter formatter)// 配置候选格式化器public DateTimeFormatterBuilder appendOptional(DateTimeFormatter formatter) 追加通用格式配置： 12// pattern的解析基本包含了上面提到的其他种类的配置public DateTimeFormatterBuilder appendPattern(String pattern) 上面只是分析完毕，实际上理解这些配置方法的成本还是挺高的，可以参考DateTimeFormatter中已经存在的一些静态变量ISO_LOCAL_TIME、ISO_OFFSET_TIME、ISO_LOCAL_DATE_TIME等学习怎么使用DateTimeFormatterBuilder： 12345678910111213public static final DateTimeFormatter ISO_LOCAL_TIME;static &#123; ISO_LOCAL_TIME = new DateTimeFormatterBuilder() .appendValue(HOUR_OF_DAY, 2) .appendLiteral(':') .appendValue(MINUTE_OF_HOUR, 2) .optionalStart() .appendLiteral(':') .appendValue(SECOND_OF_MINUTE, 2) .optionalStart() .appendFraction(NANO_OF_SECOND, 0, 9, true) .toFormatter(ResolverStyle.STRICT, null);&#125; 模仿上面的代码，我们做一个简单的例子：格式化用LocalDateTime存储的日期时间2018-1-5 15:30:30为&quot;当前时间是：2018年1月5日 15时30分30秒，祝你生活愉快！&quot;。 12345678910111213141516171819202122232425262728public class DateTimeFormatterBuilderMain &#123; public static void main(String[] args) throws Exception &#123; DateTimeFormatterBuilder builder = new DateTimeFormatterBuilder(); builder.appendLiteral(\"当前时间是：\"); builder.appendValue(ChronoField.YEAR, 4); builder.appendLiteral(\"年\"); builder.appendValue(ChronoField.MONTH_OF_YEAR, 1, 2, SignStyle.NORMAL); builder.appendLiteral(\"月\"); builder.appendValue(ChronoField.DAY_OF_MONTH, 1, 2, SignStyle.NORMAL); builder.appendLiteral(\"日\"); builder.appendLiteral(\" \"); builder.appendValue(ChronoField.HOUR_OF_DAY, 2); builder.appendLiteral(\"时\"); builder.appendLiteral(\":\"); builder.appendValue(ChronoField.MINUTE_OF_HOUR, 2); builder.appendLiteral(\"分\"); builder.appendLiteral(\":\"); builder.appendValue(ChronoField.SECOND_OF_MINUTE, 2); builder.appendLiteral(\"秒\"); builder.appendLiteral(\"，祝你生活愉快！\"); DateTimeFormatter formatter = builder.toFormatter(); System.out.println(formatter.format(LocalDateTime.now())); &#125;&#125;// 某个时刻执行后输出结果当前时间是：2019年1月5日 15时:50分:50秒，祝你生活愉快！ 从理论上来看，如果能够熟练使用上面分析过的规则，那么可以格式化或者反向解析任意格式的日期时间或者字符串。 DateTimeFormatter java.time.format.DateTimeFormatter在设计上是一个不可变类，也就是它是线程安全的，DateTimeFormatter的静态方法和实例方法只要返回DateTimeFormatter类型，那么必定是一个新的实例。它主要职责是格式化日期时间。一般情况下，构造DateTimeFormatter实例可以使用它提供的静态工厂方法，这些静态方法如果不能满足需求，可以考虑使用DateTimeFormatterBuilder定制化建造DateTimeFormatter实例。常用的2个静态工厂方法是： 12public static DateTimeFormatter ofPattern(String pattern)public static DateTimeFormatter ofPattern(String pattern, Locale locale) 字符串pattern基本可以填写任意合法的日期时间格式，因为底层使用DateTimeFormatterBuilder#appendPattern()进行解析，例如： 123DateTimeFormatter.ofPattern(\"yyyy-MM-dd\")DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\")DateTimeFormatter.ofPattern(\"yyyy年MM月dd日 HH时mm分ss秒\") 至于日期时间实例的格式化，主要通过下面的两个方法： 12public String format(TemporalAccessor temporal)public void formatTo(TemporalAccessor temporal, Appendable appendable) 举个简单的例子： 123456789101112131415public class DateTimeFormatterMain &#123; public static void main(String[] args) throws Exception &#123; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"yyyy年MM月dd日 HH时mm分ss秒\"); LocalDateTime localDateTime = LocalDateTime.now(); String value = formatter.format(localDateTime); StringBuilder builder = new StringBuilder(); formatter.formatTo(localDateTime, builder); System.out.println(value); System.out.println(builder.toString()); &#125;&#125;// 某个时刻的输出2019年01月05日 16时28分01秒2019年01月05日 16时28分01秒 字符串反解析为日期时间类型的(parse)方法并不存在于DateTimeFormatter类中，parse方法存在于日期时间类自身之中，这样的设计才是合理的，思想和领域驱动的方向是一致的，这里用LocalDateTime为例： 1234// 使用DateTimeFormatter.ISO_LOCAL_DATE_TIME进行解析public static LocalDateTime parse(CharSequence text)// 使用传入的自定义DateTimeFormatter进行解析public static LocalDateTime parse(CharSequence text, DateTimeFormatter formatter) 举个简单的例子： 1234567891011public class DateTimeFormatterMain &#123; public static void main(String[] args) throws Exception &#123; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"yyyy年MM月dd日 HH时mm分ss秒\"); String dateTime = \"2019年01月05日 16时28分01秒\"; LocalDateTime parseResult = LocalDateTime.parse(dateTime, formatter); System.out.println(parseResult); &#125;&#125;// 某个时刻的输出2019-01-05T16:28:01 由于DateTimeFormatter实例创建的时候相对耗时，因此需要考虑避免多次创建DateTimeFormatter实例，可以考虑编写一个工具类，用哈希表缓存pattern -&gt; DateTimeFormatter： 12345678910111213141516171819202122232425262728// 这里只列举LocalDateTime和LocalDate的例子，其他的日期时间类可以以此类推public enum DateTimeFormatUtils &#123; // 单例 SINGLETON; private static final ConcurrentMap&lt;String, DateTimeFormatter&gt; FORMATTERS = new ConcurrentHashMap&lt;&gt;(); public String formatLocalDateTime(LocalDateTime value, String pattern) &#123; return getOrCreateDateTimeFormatter(pattern).format(value); &#125; public LocalDateTime parseLocalDateTime(String value, String pattern) &#123; return LocalDateTime.parse(value, getOrCreateDateTimeFormatter(pattern)); &#125; public String formatLocalDate(LocalDate value, String pattern) &#123; return getOrCreateDateTimeFormatter(pattern).format(value); &#125; public LocalDate parseLocalDate(String value, String pattern) &#123; return LocalDate.parse(value, getOrCreateDateTimeFormatter(pattern)); &#125; private DateTimeFormatter getOrCreateDateTimeFormatter(String pattern) &#123; return FORMATTERS.computeIfAbsent(pattern, DateTimeFormatter::ofPattern); &#125;&#125; 最后还要注意一点：格式化或者解析的时候使用的模式pattern必须是合法日期时间表示格式(例如年份用yyyy表示)，并且严格区分日期时间、只有日期属性和只有时间属性三种不同的情况，如果使用yyyy-MM-dd HH:mm:ss模式创建的DateTimeFormatter去格式化LocalTime或者LocalDate，会抛出异常，异常的类型是DateTimeException或者其子类，属于运行时异常。 小结 在JavaEE开发中，特别在系统交互中，日期时间字段的转换是比较重要的。其实JSR-310中的日期时间API的格式化和解析和旧有的日期时间API的格式化和解析从本质上是没有区别的，都是字符串解析和转换的游戏，但是个人是推荐使用JSR-310中的日期时间API的格式化和解析，原因是： 性能上有很大提升(直观上推测，没有做严格测试)。 类库设计上更加合理。 线程安全。 (本文完 e-a-2019-1-5 c-2-d)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"JSR-310","slug":"JSR-310","permalink":"http://throwable.club/blog/tags/JSR-310/"}]},{"title":"JSR310新日期API(二)-日期时间API","slug":"java-jsr310-time-api","date":"2019-01-01T14:03:36.000Z","updated":"2019-01-01T14:04:22.587Z","comments":true,"path":"2019/01/01/java-jsr310-time-api/","link":"","permalink":"http://throwable.club/2019/01/01/java-jsr310-time-api/","excerpt":"","text":"JSR310新日期API(二)-日期时间API 前提 这篇文章主要介绍一下日期时间API中最常用的类库，分别是： java.time.Clock：时钟。 java.time.Instant：瞬时时间，时间戳java.sql.Timestamp的替代类。 java.time.LocalDate：本地日期，ISO-8601日历系统下的日期表示，不包含时区的概念，只能表示年月日。 java.time.LocalDateTime：本地日期时间，ISO-8601日历系统下的日期时间表示，不包含时区的概念，只能表示年月日时分秒。 java.time.LocalTime：本地时间，ISO-8601日历系统下的时间表示，不包含时区的概念，只能表示时分秒。 java.time.OffsetTime：带有时间偏移量的时间，ISO-8601日历系统下的带有UTC/GMT时间偏移量的时间表示。 java.time.OffsetDateTime：带有时间偏移量的日期时间，ISO-8601日历系统下的带有UTC/GMT时间偏移量(不包含基于ZoneRegion的时间偏移量)的日期时间表示。 java.time.ZonedDateTime：带有时间偏移量的日期时间，ISO-8601日历系统下的带有UTC/GMT时间偏移量(包含基于ZoneRegion的时间偏移量)的日期时间表示。 其他的类库还有Year、Month、DayOfWeek、MonthDay、YearMonth等。值得注意的是：JSR-310增加的日期API是严格区分年月日-时分秒格式的日期表示类，例如XXXDateTime一定表示为年月日时分秒，XXXTime只能表示时分秒，XXXDate只能表示年月日。 值得注意的是：这些新增的日期时间类都是不可变类，每次通过其方法更变或者修改都是返回一个全新的对象，因此它们都是线程安全的。 Clock java.time.Clock是一个抽象类，它表示时钟，一般情况下，它需要结合时区使用，提供获取当前时刻的功能。Clock主要提供下面四个方法，其他方法都是静态工厂方法： 1234567891011// 获取用于创建时钟的时区。public abstract ZoneId getZone()// 获取时钟的当前瞬时对象。public abstract Instant instant()// 获取时钟的当前毫秒数值public long millis()// 返回当前时钟实例的一个新的拷贝时钟实例，并且使用入参作为新时钟实例的时区public abstract Clock withZone(ZoneId zone) 静态工厂方法如下： 方法 功能 public static Clock systemUTC() 获取可以返回当前时刻的系统时钟，使用UTC(零)时区进行进行时间转换[SystemClock] public static Clock systemDefaultZone() 获取可以返回当前时刻的系统时钟，使用默认时区进行时间转换[SystemClock] public static Clock system(ZoneId zone) 获取可以返回当前时刻的系统时钟，使用指定时区ID进行时间转换[SystemClock] public static Clock tickMillis(ZoneId zone) 获取以整数毫秒返回当前时刻的时钟，使用指定时区ID进行时间转换[TickClock] public static Clock tickSeconds(ZoneId zone) 获取以整数秒返回当前时刻的时钟，使用指定时区ID进行时间转换[TickClock] public static Clock tickMinutes(ZoneId zone) 获取以整数分钟返回当前时刻的时钟，使用指定时区ID进行时间转换[TickClock] public static Clock tick(Clock baseClock, Duration tickDuration) 返回一个以基础时钟和时钟记录基础单位为构造的时钟[TickClock] public static Clock fixed(Instant fixedInstant, ZoneId zone) 获得一个始终返回同一时刻的时钟，使用指定时区ID进行时间转换[FixedClock] offset​(Clock baseClock, Duration offsetDuration) 返回一个以基础时钟和固定时间偏移量为构造的时钟[OffsetClock] java.time.Clock主要有四个实现，它们都是java.time.Clock的内部类，上面的工厂方法创建的实例一定是这四个实现之一： SystemClock：总是基于System#currentTimeMillis()返回最新的时间SystemClock.UTC是典型的实现。 FixedClock：总是返回相同的瞬时时间，可以认为是一个固定时刻的时钟，通常使用于测试。 OffsetClock：基于一个确定的Clock实现，为它添加一个时间偏移量，时间偏移量的单位是Duration。 TickClock：基于一个确定的Clock实现，为它添加一个时间偏移量，时间偏移量的单位是纳秒。 上面比较难理解的是TickClock，这里举个简单的例子： 12345678910111213public class TickClockMain &#123; public static void main(String[] args) throws Exception&#123; Clock tickMillis = Clock.tickMillis(ZoneId.systemDefault()); Clock tickSeconds = Clock.tickSeconds(ZoneId.systemDefault()); System.out.println(tickMillis.millis()); System.out.println(tickSeconds.millis()); &#125;&#125;//输出结果15460109455751546010945000 简单来说，Clock#tickMillis()构造的时钟的计时单位是毫秒，而Clock#tickSeconds()构造的时钟的计时单位是秒(毫秒部分会被截断)，以此类推。 FixedClock是一个固定时刻的时钟，一般用于测试： 1234567891011121314public class FixedClockMain &#123; public static void main(String[] args) throws Exception &#123; Clock fixed = Clock.fixed(Instant.now(), ZoneId.systemDefault()); System.out.println(fixed.millis()); System.out.println(fixed.millis()); System.out.println(fixed.millis()); &#125;&#125;//输出结果154601149259015460114925901546011492590 最常用的是默认ZoneId下的系统时钟SystemClock和UTC系统时钟： 123456789101112131415public class SystemClockMain &#123; public static void main(String[] args) throws Exception &#123; Clock clock = Clock.systemDefaultZone(); System.out.println(clock.millis()); Clock utc = Clock.systemUTC(); System.out.println(utc.millis()); System.out.println(System.currentTimeMillis()); &#125;&#125;//某个时刻的输出结果154601168641315460116864131546011686413 Instant java.time.Instant字面意思是瞬时时间，它是java.sql.Timestamp的对应类，代表时间线(time-line)上的一个瞬时时间点，准确来说，它内部持有一个long类型的纪元秒属性(seconds)和一个int类型的纳秒属性(nanos，nanos的取值范围是[0,999_999_999])，纪元秒如果为正数，表示该瞬时时间点位于格林威治新纪元1970-01-01T00:00:00Z之后，而纪元秒如果为负数，则表示该瞬时时间点位于格林威治新纪元之前。因此Instant能表示的时间点其实是有上下界的，逻辑上的界限就是1970-01-01T00:00:00Z - 31557014167219200秒到1970-01-01T00:00:00Z + 31556889864403199秒 + 999_999_999纳秒或者表示为Instant#MIN到Instant#MAX，这个范围很大，因此暂时不需要考虑超限的问题。Instant中已经提供了一个公有静态实例用于表示格林威治新纪元，它就是Instant#EPOCH，代表1970-01-01T00:00:00Z这个瞬时时间点。先看一下Instant的常用静态工厂方法(Instant没有公有构造器，必须通过工厂方法构造实例)： 1234567891011121314151617181920// 当前时刻的瞬时时间点public static Instant now()// 基于时钟实例获取瞬时时间点public static Instant now(Clock clock)// 基于距离新纪元的秒数创建瞬时时间点public static Instant ofEpochSecond(long epochSecond)// 基于距离新纪元的秒数和纳秒创建瞬时时间点public static Instant ofEpochSecond(long epochSecond, long nanoAdjustment)// 基于毫秒数创建瞬时时间点public static Instant ofEpochMilli(long epochMilli)// 基于其他日期时间API创建瞬时时间点public static Instant from(TemporalAccessor temporal)// 基于特定格式字符串创建瞬时时间点，如2007-12-03T10:15:30.00Zpublic static Instant parse(final CharSequence text) 当然还有其他常用的方法： 1234567891011121314151617181920212223242526// 获取当前Instant实例对于不同计时单位的值，见ChronoFieldpublic long getLong(TemporalField field)// 获取当前Instant实例的纪元秒属性public long getEpochSecond()// 获取当前Instant实例的纳秒属性public int getNano()// 获取当前Instant实例的毫秒值public long toEpochMilli() // 基于TemporalField实例(TemporalField)和新的值调整并且创建一个新的Instantpublic Instant with(TemporalField field, long newValue)// 当前Instant实例基于TemporalUnit(ChronoUnit)截断并且返回一个新的Instantpublic Instant truncatedTo(TemporalUnit unit)// 顾名思义，基于一个时间基准单位进行时间量增加，返回一个新的Instantpublic Instant plus(long amountToAdd, TemporalUnit unit)// 顾名思义，基于一个时间基准单位进行时间量减少，返回一个新的Instantpublic Instant minus(long amountToSubtract, TemporalUnit unit)// 计算当前Instant实例和入参endExclusive基于时间基准单位unit之间的时间量public long until(Temporal endExclusive, TemporalUnit unit) 举个使用例子： 123456789101112131415161718192021222324public class InstantMain &#123; public static void main(String[] args) throws Exception &#123; Instant instant = Instant.now(); System.out.println(String.format(\"Second:%d,Nano:%d\", instant.getEpochSecond(), instant.getNano())); instant = Instant.now(Clock.systemDefaultZone()); System.out.println(String.format(\"Second:%d,Nano:%d\", instant.getEpochSecond(), instant.getNano())); instant = Instant.ofEpochSecond(new Date().toInstant().getEpochSecond()); System.out.println(String.format(\"Second:%d,Nano:%d\", instant.getEpochSecond(), instant.getNano())); instant = Instant.ofEpochMilli(System.currentTimeMillis()); System.out.println(String.format(\"Second:%d,Nano:%d\", instant.getEpochSecond(), instant.getNano())); instant = Instant.from(Instant.now()); System.out.println(String.format(\"Second:%d,Nano:%d\", instant.getEpochSecond(), instant.getNano())); instant = Instant.parse(\"2018-12-31T10:15:30.00Z\"); System.out.println(String.format(\"Second:%d,Nano:%d\", instant.getEpochSecond(), instant.getNano())); &#125;&#125;// 某个时刻的输出Second:1546187685,Nano:261861900Second:1546187685,Nano:291941900Second:1546187685,Nano:0Second:1546187685,Nano:292000000Second:1546187685,Nano:292946400Second:1546251330,Nano:0 LocalDate java.time.LocalDate代表ISO-8601日历系统中不包含时区的日期(当然也不包含具体的时间)表示，例如2007-12-03。LocalDate是一个不可变的日期对象，也就是只能表示日期，通常的表示格式为年-月-日，同时提供其他日期字段的访问，例如一年中的第几日(day-of-year)、星期几(day-of-week)和一年中的第几周(week-of-year)等。不同的LocalDate之间的比较只能通过LocalDate#equals()方法，其他比较操作如==或者hash()方法会产生无法预知的结果。LocalDate提供的常量： 12345678// -999999999-01-01public static final LocalDate MIN = LocalDate.of(Year.MIN_VALUE, 1, 1)// 999999999-12-31public static final LocalDate MAX = LocalDate.of(Year.MAX_VALUE, 12, 31)// 1970-01-01public static final LocalDate EPOCH = LocalDate.of(1970, 1, 1) LocalDate的工厂方法比较多，这里只列举部分常用的： 1234567891011121314151617181920// 基于当前日期获取LocalDate实例public static LocalDate now()// 基于当前日期和时区获取LocalDate实例public static LocalDate now(ZoneId zone)// 基于当前日期和时钟获取LocalDate实例public static LocalDate now(Clock clock)// 基于年月(枚举)日获取LocalDate实例public static LocalDate of(int year, Month month, int dayOfMonth)// 基于年月日获取LocalDate实例public static LocalDate of(int year, int month, int dayOfMonth)// 基于年和具体该年中的某一日获取LocalDate实例public static LocalDate ofYearDay(int year, int dayOfYear)// 基于新纪元1970-01-01的偏移天数获取LocalDate实例public static LocalDate ofEpochDay(long epochDay) LocalDate的实例方法也比较多，这里也列举部分常用的： 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 获取年份值public int getYear()// 获取月份值，范围是1-12public int getMonthValue()// 获取月份枚举public Month getMonth()// 返回当前LocalDate实例的该年中具体的第几天public int getDayOfYear()// 返回当前LocalDate实例的具体是星期几public DayOfWeek getDayOfWeek()// 是否闰年public boolean isLeapYear()// 返回当前LocalDate实例月份长度public int lengthOfMonth()// 返回当前LocalDate实例年份长度public int lengthOfYear()// 基于一个日期属性修改对应的值返回一个新的LocalDate实例public LocalDate with(TemporalField field, long newValue)// 基于一个日期时间基准单位增加对应的值返回一个新的LocalDate实例public LocalDate plus(long amountToAdd, TemporalUnit unit)// 基于一个日期时间基准单位减去对应的值返回一个新的LocalDate实例public LocalDate minus(long amountToSubtract, TemporalUnit unit)// 基于一个日期时间基准单位计算以入参为endExclusive计算日期或者时间的间隔public long until(Temporal endExclusive, TemporalUnit unit)// 返回基于新纪元年1970-1-1的偏移天数public long toEpochDay()// 如果入参为LocalDate类型功能和equals一致，否则通过基于纪元年的偏移天数比较public boolean isEqual(ChronoLocalDate other)// 只有年月日三个成员同时相等此方法才返回truepublic boolean equals(Object obj) 举个简单的使用例子： 12345678910111213141516171819public class LocalDateMain &#123; public static void main(String[] args) throws Exception &#123; LocalDate localDate = LocalDate.now(); System.out.println(localDate); localDate = LocalDate.of(2018, 12, 31); System.out.println(localDate); localDate = localDate.plus(1, ChronoUnit.DAYS); System.out.println(localDate); System.out.println(localDate.equals(LocalDate.of(2019,1,1))); System.out.println(localDate.toEpochDay()); &#125;&#125;// 某天执行的输出结果2018-12-312018-12-312019-01-01true17897 LocalTime java.time.LocalTime代表ISO-8601日历系统中不包含时区的时间(当然也不包含具体的日期)表示，例如10:15:30。LocalTime是一个不可变的时间对象，也就是只能表示时间，通常的表示格式为时:分:秒，也可以包含一个纳秒属性(nano取值范围[0,999999999])，通俗来说，它表示的就是挂钟上所见的时间的描述。同样，不同的LocalTime实例必须通过LocalTime#equals()方法比较。LocalTime提供的静态实例如下： 1234567891011// 一天的起始时间 - 00:00public static final LocalTime MIN// 一天的结束时间 - 23:59:59.999999999public static final LocalTime MAX// 午夜 - 00:00 其实和MIN是一样的public static final LocalTime MIDNIGHT// 中午 - 12:00public static final LocalTime NOON LocalTime常用的工厂方法： 12345678910111213141516171819202122// 基于当前时间构造LocalTime实例public static LocalTime now()// 基于当前时间和时区ID构造LocalTime实例public static LocalTime now(ZoneId zone)// 基于当前时间和时钟实例构造LocalTime实例public static LocalTime now(Clock clock)// 基于小时、分钟(、秒和纳秒)构造LocalTime实例public static LocalTime of(int hour, int minute)public static LocalTime of(int hour, int minute, int second)public static LocalTime of(int hour, int minute, int second, int nanoOfSecond)// 基于瞬时时间实例和时区ID构造LocalTime实例public static LocalTime ofInstant(Instant instant, ZoneId zone)// 基于一天当中的具体秒数构造LocalTime实例,secondOfDay范围是[0,24 * 60 * 60 - 1]public static LocalTime ofSecondOfDay(long secondOfDay)// 基于一天当中的具体纳秒数构造LocalTime实例,nanoOfDay[0,24 * 60 * 60 * 1,000,000,000 - 1]public static LocalTime ofNanoOfDay(long nanoOfDay) LocalTime常用的实例方法有很多，套路和上面章节提到过的方法类似，这里不啰嗦分析： 1234567891011// 返回小时值，范围[0,23]public int getHour()// 返回分钟值，范围[0,59]public int getMinute()// 返回秒数值，范围[0,59]public int getSecond()// 返回纳秒数值，范围[0,999_999_999]public int getNano() 举个简单的例子： 12345678910111213141516public class LocalTimeMain &#123; public static void main(String[] args) throws Exception &#123; LocalTime localTime = LocalTime.now(); System.out.println(localTime); localTime = LocalTime.of(23, 59); System.out.println(localTime); localTime = LocalTime.MAX; System.out.println(String.format(\"Hour:%d,minute:%d,second:%d,nano:%d\", localTime.getHour(), localTime.getMinute(), localTime.getSecond(), localTime.getNano())); &#125;&#125;// 某个时刻下的输出结果00:46:08.84584880023:59Hour:23,minute:59,second:59,nano:999999999 LocalDateTime java.time.LocalDateTime实际上就是LocalDate和LocalTime的结合版本，代表ISO-8601日历系统中不包含时区(LocalDateTime不存储时区信息，但是可以使用时区ID构造LocalDateTime实例)的日期时间表示，例如2007-12-03T10:15:30。LocalDateTime是一个不可变的时间对象，也就是只能表示日期时间，通常的表示格式为年-月日 时:分:秒，也可以包含一个纳秒属性(nano取值范围[0,999999999])。不同的LocalDateTime实例必须通过LocalDateTime#equals()方法比较。LocalDateTime内部持有一个LocalDate实例和一个LocalTime实例。它定义了两个公有的静态常量： 12345// LocalDateTime能够表示的最小日期时间，即-999999999-01-01T00:00:00public static final LocalDateTime MIN = LocalDateTime.of(LocalDate.MIN, LocalTime.MIN)// LocalDateTime能够表示的最大日期时间，即999999999-12-31T23:59:59.999999999public static final LocalDateTime MAX = LocalDateTime.of(LocalDate.MAX, LocalTime.MAX) LocalDateTime常用的静态工厂方法如下： 123456789101112131415161718192021// 基于当前日期时间、时区ID、时钟创建LocalDateTime实例public static LocalDateTime now()public static LocalDateTime now(ZoneId zone)public static LocalDateTime now(Clock clock)// 基于年月(枚举)日时分秒纳秒创建LocalDateTime实例public static LocalDateTime of(int year, Month month, int dayOfMonth, int hour, int minute)public static LocalDateTime of(int year, Month month, int dayOfMonth, int hour, int minute, int second)public static LocalDateTime of(int year, Month month, int dayOfMonth, int hour, int minute, int second, int nanoOfSecond)public static LocalDateTime of(int year, int month, int dayOfMonth, int hour, int minute)public static LocalDateTime of(int year, int month, int dayOfMonth, int hour, int minute, int second)public static LocalDateTime of(int year, int month, int dayOfMonth, int hour, int minute, int second, int nanoOfSecond)// 基于LocalDate和LocalTime实例创建LocalDateTime实例public static LocalDateTime of(LocalDate date, LocalTime time)// 基于Instant实例和时区ID实例创建LocalDateTime实例public static LocalDateTime ofInstant(Instant instant, ZoneId zone)// 基于新纪元偏移秒数、纳秒数和时间偏移量创建LocalDateTime实例public static LocalDateTime ofEpochSecond(long epochSecond, int nanoOfSecond, ZoneOffset offset) LocalDateTime的实例方法和前面介绍过的类差不多，这里不做详细展开，举个简单的使用例子： 123456789101112131415public class LocalDateTimeMain &#123; public static void main(String[] args) throws Exception &#123; LocalDateTime localDateTime = LocalDateTime.now(ZoneId.systemDefault()); System.out.println(localDateTime); localDateTime = LocalDateTime.ofInstant(Instant.now(), ZoneId.systemDefault()); System.out.println(localDateTime); localDateTime = localDateTime.plus(1, ChronoUnit.YEARS); System.out.println(localDateTime); &#125;&#125;// 某个时刻的输出如下2019-01-01T17:43:48.2605174002019-01-01T17:43:48.2605174002020-01-01T17:43:48.260517400 OffsetTime java.time.OffsetTime表示ISO-8601日历系统中带有基于UTC/Greenwich时间偏移量的时间，例如10:15:30+01:00。OffsetTime也是一个不可变的时间对象，通常表示格式为时:分:秒-时间偏移量，当然它也可以包含一个纳秒属性(nano取值范围[0,999999999])。相比LocalTime，它多存储了一个时区时间偏移量(zone offset)属性。OffsetTime的公有静态实例如下： 12345// 代表00:00:00+18:00public static final OffsetTime MIN = LocalTime.MIN.atOffset(ZoneOffset.MAX)// 代表23:59:59.999999999-18:00public static final OffsetTime MAX = LocalTime.MAX.atOffset(ZoneOffset.MIN) OffsetTime的常用工厂方法如下： 12345678910111213// 基于当前时间、时区ID、时钟创建OffsetTime实例public static OffsetTime now()public static OffsetTime now(ZoneId zone)public static OffsetTime now(Clock clock)// 基于LocalTime实例和时间偏移量创建OffsetTime实例public static OffsetTime of(LocalTime time, ZoneOffset offset)// 基于时分秒纳秒和时间偏移量创建OffsetTime实例public static OffsetTime of(int hour, int minute, int second, int nanoOfSecond, ZoneOffset offset)// 基于Instant实例和时区ID实例创建OffsetTime实例public static OffsetTime ofInstant(Instant instant, ZoneId zone) 举个简单的使用例子： 123456789101112131415public class OffsetTimeMain &#123; public static void main(String[] args) throws Exception &#123; OffsetTime offsetTime = OffsetTime.now(); System.out.println(offsetTime); offsetTime = OffsetTime.ofInstant(Instant.now(), ZoneId.systemDefault()); System.out.println(offsetTime); offsetTime = OffsetTime.of(LocalTime.now(), ZoneOffset.UTC); System.out.println(offsetTime); &#125;&#125;//某个时刻下的输出结果如下18:08:26.263710800+08:0018:08:26.264713600+08:0018:08:26.264713600Z OffsetDateTime java.time.OffsetDateTime表示ISO-8601日历系统中带有基于UTC/Greenwich时间偏移量的日期时间，例如2007-12-03T10:15:30+01:00。OffsetDateTime也是一个不可变的日期时间对象，通常表示格式为年-月-日 时:分:秒-时间偏移量，当然它也可以包含一个纳秒属性(nano取值范围[0,999999999])。相比LocalDateTime，它多存储了一个时区时间偏移量(zone offset)属性。OffsetDateTime提供的公有静态实例常量如下： 12345// OffsetDateTime能表示的最小的日期时间-999999999-01-01T00:00:00+18:00public static final OffsetDateTime MIN = LocalDateTime.MIN.atOffset(ZoneOffset.MAX)// OffsetDateTime能表示的最大的日期时间999999999-12-31T23:59:59.999999999-18:00public static final OffsetDateTime MAX = LocalDateTime.MAX.atOffset(ZoneOffset.MIN) OffsetDateTime的常用静态工厂方法如下： 123456789101112131415161718// 基于当前的日期时间、时区ID、时钟创建OffsetDateTime实例public static OffsetDateTime now()public static OffsetDateTime now(ZoneId zone)public static OffsetDateTime now(Clock clock)// 基于LocalDate实例、LocalTime实例和时间偏移量创建OffsetDateTime实例public static OffsetDateTime of(LocalDate date, LocalTime time, ZoneOffset offset)// 基于LocalDateTime实例和时间偏移量创建OffsetDateTime实例public static OffsetDateTime of(LocalDateTime dateTime, ZoneOffset offset)// 基于年月日时分秒纳秒和时间偏移量创建OffsetDateTime实例public static OffsetDateTime of( int year, int month, int dayOfMonth, int hour, int minute, int second, int nanoOfSecond, ZoneOffset offset)// 基于Instant实例和时区ID实例创建OffsetDateTime实例public static OffsetDateTime ofInstant(Instant instant, ZoneId zone) 举个简单的使用例子： 123456789101112131415public class OffsetDateTimeMain &#123; public static void main(String[] args) throws Exception &#123; OffsetDateTime offsetDateTime = OffsetDateTime.now(); System.out.println(offsetDateTime); offsetDateTime = OffsetDateTime.ofInstant(Instant.now(), ZoneId.systemDefault()); System.out.println(offsetDateTime); offsetDateTime = OffsetDateTime.of(LocalDateTime.now(), ZoneOffset.ofHours(8)); System.out.println(offsetDateTime); &#125;&#125;// 某个时刻的输出如下2019-01-01T20:38:03.388846400+08:002019-01-01T20:38:03.388846400+08:002019-01-01T20:38:03.388846400+08:00 ZonedDateTime java.time.ZonedDateTime应该是JSR-310中最复杂但是最全面的日期时间类(它的API文档中注释也是最多的，从这点也可以看出它的复杂性)。ZonedDateTime可以简单理解为LocalDateTime，时区ID和一个可处理的ZoneOffset三者的共同实现，或者更简单理解为日期时间、时间偏移量、区域时区等时区规则的多重实现。ZonedDateTime也是一个不可变的日期时间对象，常用的格式为：年-月-日 时:分:秒-时区偏移量-区域，例如2007-12-03T10:15:30+01:00 Europe/Paris。除了包含所有的日期时间属性之外，ZonedDateTime还包含一个纳秒属性(nano取值范围[0,999999999])。ZonedDateTime的常用静态工厂方法如下： 123456789101112131415161718// 根据当前的日期时间、时区ID和时钟创建ZonedDateTime实例public static ZonedDateTime now()public static ZonedDateTime now(ZoneId zone)public static ZonedDateTime now(Clock clock)// 基于LocalDate实例、LocalTime实例和时区ID创建ZonedDateTime实例public static ZonedDateTime of(LocalDate date, LocalTime time, ZoneId zone)// 基于LocalDateTime实例和时区ID创建ZonedDateTime实例public static ZonedDateTime of(LocalDateTime localDateTime, ZoneId zone)// 基于年月日时分秒纳秒和时区ID创建ZonedDateTime实例public static ZonedDateTime of( int year, int month, int dayOfMonth, int hour, int minute, int second, int nanoOfSecond, ZoneId zone)// 基于LocalDateTime实例、时区ID和候选偏好的时间偏移量创建ZonedDateTime实例public static ZonedDateTime ofLocal(LocalDateTime localDateTime, ZoneId zone, ZoneOffset preferredOffset) 举个简单的使用例子： 123456789101112131415public class ZonedDateTimeMain &#123; public static void main(String[] args) throws Exception &#123; ZonedDateTime zonedDateTime = ZonedDateTime.now(); System.out.println(zonedDateTime); zonedDateTime = ZonedDateTime.of(LocalDateTime.now(), ZoneId.systemDefault()); System.out.println(zonedDateTime); zonedDateTime = ZonedDateTime.ofInstant(Instant.now(), ZoneId.systemDefault()); System.out.println(zonedDateTime); &#125;&#125;// 某个时刻的执行结果2019-01-01T21:00:03.193242200+08:00[Asia/Shanghai]2019-01-01T21:00:03.193242200+08:00[Asia/Shanghai]2019-01-01T21:00:03.193242200+08:00[Asia/Shanghai] 其他 Year java.time.Year基于ISO-8601日期系统下表示年份，支持的范围是[-999_999_999,999_999_999]。举个简单的例子： 12345678910111213141516public class YearMain &#123; public static void main(String[] args) throws Exception&#123; Year year = Year.now(); System.out.println(year); System.out.println(year.isLeap()); year = Year.of(2016); System.out.println(year); System.out.println(year.isLeap()); &#125;&#125;// 输出结果2019false2016true Month java.time.Month是一个枚举，代表ISO-8601日期系统中的月份。枚举的成员一共有12个，就是JANUARY到DECEMBER一共12个月份的英文大写表示。举个简单的使用例子： 123456789101112public class MonthMain &#123; public static void main(String[] args) throws Exception &#123; Month month = Month.of(12); System.out.println(month); month = Month.JANUARY; System.out.println(month); &#125;&#125;// 输出结果DECEMBERJANUARY DayOfWeek java.time.DayOfWeek是一个枚举，表示一个星期中具体是星期几。枚举成员一共有7个，就是从MONDAY到SUNDAY一共7个指代具体星期几的英文大写表示。举个简单的使用例子： 123456789101112public class DayOfWeekMain &#123; public static void main(String[] args) throws Exception&#123; DayOfWeek dayOfWeek = DayOfWeek.of(1); System.out.println(dayOfWeek); dayOfWeek = DayOfWeek.SUNDAY; System.out.println(dayOfWeek); &#125;&#125;// 输出结果MONDAYSUNDAY MonthDay java.time.MonthDay代表月份和对应月份一共存在的天数，内部维护着整型的属性month和整型的属性day。举个例子： 123456789101112public class MonthDayMain &#123; public static void main(String[] args) throws Exception &#123; MonthDay monthDay = MonthDay.now(); System.out.println(monthDay); monthDay = MonthDay.of(2, 29); System.out.println(monthDay); &#125;&#125;//某个时刻的输出结果--01-01--02-29 MonthDay通过静态工厂方法构建实例的时候会判断月份或者天数是否超过实际的限制，如果超限会抛异常。 YearMonth java.time.YearMonth代表年份和月份，内部维护着整型的属性month和整型的属性month。举个例子： 123456789101112public class YearMonthMain &#123; public static void main(String[] args) throws Exception&#123; YearMonth yearMonth = YearMonth.now(); System.out.println(yearMonth); yearMonth = YearMonth.of(2019, 12); System.out.println(yearMonth); &#125;&#125;// 某个时刻的输出2019-012019-12 类型转换 这里主要总结一下JSR-310的日期时间类之间的转换以及JSR-310的日期时间类和已经存在的旧Java日期时间类之间的转换关系。 Instant和其他日期时间类互转 如果有注意到上面介绍日期时间类的时候会发现每个类的工厂方法都包含ofInstant()方法，也就是Instant实例可以转化为其他日期时间类实例，这里总结一下： 12345678910111213public class InstantConvertTo &#123; public static void main(String[] args) throws Exception &#123; Instant instant = Instant.now(); ZoneId zoneId = ZoneId.systemDefault(); LocalDateTime localDateTime = LocalDateTime.ofInstant(instant, zoneId); LocalDate localDate = LocalDate.ofInstant(instant, zoneId); LocalTime localTime = LocalTime.ofInstant(instant, zoneId); OffsetTime offsetTime = OffsetTime.ofInstant(instant, zoneId); OffsetDateTime offsetDateTime = OffsetDateTime.ofInstant(instant,zoneId); ZonedDateTime zonedDateTime = ZonedDateTime.ofInstant(instant, zoneId); &#125;&#125; 其实很好理解，即使在旧的Java日期时间API中，长整型的时间戳毫秒也可以通过各种日期时间类的构造或者静态工厂方法创建对应的实例。值得注意的是，只有同时包含日期和时间的类才能转换为Instant实例，这一点也很好理解，只包含时间或者只包含日期的类转换成瞬时时间会丢失部分时间值。这里举个简单例子： 12345678910public class InstantConvertFrom &#123; public static void main(String[] args) throws Exception &#123; // 这里只以LocalDateTime为例,其他类似 LocalDateTime localDateTime = LocalDateTime.now(); Instant instant = localDateTime.toInstant(ZoneOffset.UTC); // 或者 instant = Instant.ofEpochMilli(localDateTime.toEpochSecond(ZoneOffset.UTC) * 1000); &#125;&#125; JSR-310日期时间类之间互相转换 日期时间类本身就包含日期和时间的维度，一般它们直接保存时间类实例作为成员属性，所以转换也十分方便： 12345678public class DateTimeToTime &#123; public static void main(String[] args) throws Exception&#123; LocalDateTime localDateTime = LocalDateTime.now(); LocalDate localDate = localDateTime.toLocalDate(); LocalTime localTime = localDateTime.toLocalTime(); &#125;&#125; 日期类不包含时间部分，所以日期类转换为日期时间类的时候，时间部分会取最小，例如： 123456789101112131415public class DateToDateTime &#123; public static void main(String[] args) throws Exception&#123; LocalDate localDate = LocalDate.now(); System.out.println(localDate); LocalDateTime localDateTime = localDate.atStartOfDay(); System.out.println(localDateTime); ZonedDateTime zonedDateTime = localDate.atStartOfDay(ZoneId.systemDefault()); System.out.println(zonedDateTime); &#125;&#125;// 某个时刻的输出如下2019-01-012019-01-01T00:002019-01-01T00:00+08:00[Asia/Shanghai] 带有时区ID(时间偏移量或者地区)的类型可以轻易转变为不带有时区ID的类型，如果要反过来，则需要添加对应的时区ID属性，例如： 1234567891011121314151617public class ZoneIdDateTimeMain &#123; public static void main(String[] args) throws Exception &#123; ZonedDateTime zonedDateTime = ZonedDateTime.of(LocalDateTime.now(), ZoneId.systemDefault()); System.out.println(zonedDateTime); LocalDateTime localDateTime = zonedDateTime.toLocalDateTime(); LocalDate localDate = zonedDateTime.toLocalDate(); LocalTime localTime = zonedDateTime.toLocalTime(); zonedDateTime = ZonedDateTime.of(localDateTime, ZoneId.systemDefault()); OffsetDateTime offsetDateTime = OffsetDateTime.of(LocalDateTime.now(), ZoneOffset.UTC); localDateTime = offsetDateTime.toLocalDateTime(); localDate = offsetDateTime.toLocalDate(); localTime = offsetDateTime.toLocalTime(); offsetDateTime = OffsetDateTime.of(localDateTime, ZoneOffset.UTC); &#125;&#125; JSR-310中的类和旧的日期时间相关类之间的转换 java.sql.Timestamp和java.time.LocalDateTime之间的转换： 12345678public class TimestampLocalDateTime &#123; public static void main(String[] args) throws Exception &#123; LocalDateTime localDateTime = LocalDateTime.now(); Timestamp timestamp = Timestamp.valueOf(localDateTime); LocalDateTime ldt = timestamp.toLocalDateTime(); &#125;&#125; java.sql.Date和java.time.LocalDate之间的转换： 12345678public class DateLocalDate &#123; public static void main(String[] args) throws Exception &#123; Date date = new Date(2018, 1, 1); LocalDate localDate = date.toLocalDate(); date = new Date(localDate.getYear(), localDate.getMonthValue(), localDate.getDayOfMonth()); &#125;&#125; 只要是能使用毫秒表示的旧的日期时间类，都可以和java.time.Instant相互转换，例如： 1234567891011public class ToInstant &#123; public static void main(String[] args) throws Exception&#123; Timestamp timestamp = new Timestamp(System.currentTimeMillis()); Instant instant = timestamp.toInstant(); java.util.Date date = new Date(System.currentTimeMillis()); instant = date.toInstant(); timestamp = new Timestamp(instant.toEpochMilli()); date = new Date(instant.toEpochMilli()); &#125;&#125; 小结 JSR-310的新时间日期类库的设计相比已经存在的旧的日期时间类库来说，个人认为有以下的优点： 线程安全。 类的职责更加分明，时间、日期、日期时间需要使用明确的类去表示。 API封装更加合理，使得易用性提高。 不过会存在一些问题，最明显的是已有的旧类库存在兼容性问题，例如JDBC模块里面处理日期时间需要进行新的日期时间类和java.sql.Timestamp进行转换的问题，不过转换成本并不高。 (本文完 c-3-d e-a-20181230)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"JSR-310","slug":"JSR-310","permalink":"http://throwable.club/blog/tags/JSR-310/"}]},{"title":"JSR310新日期API(一)-时区与时间偏移量","slug":"java-jsr310-zone-id","date":"2018-12-23T15:05:42.000Z","updated":"2019-01-01T14:04:05.225Z","comments":true,"path":"2018/12/23/java-jsr310-zone-id/","link":"","permalink":"http://throwable.club/2018/12/23/java-jsr310-zone-id/","excerpt":"","text":"JSR310新日期API(一)-时区与时间偏移量 前提 最近刚好有新项目使用到JSR-310(JDK8)中引入的新日期API，打算做一下总结。本文编写基于JDK11，部分API可能是JDK9之后新增的。 地理知识补充 主要补充一下一些地理知识：时区、UTC、GMT、CST、DST和ISO-8601的相关概念。 时区 时区(Time Zone)是地球上的区域使用同一个时间定义。1884年在华盛顿召开国际经度会议时，为了克服时间上的混乱，规定将全球划分为24个时区。造成时间上的混乱是由于世界各个国家位于地球不同位置上，因此不同国家，特别是东西跨度大的国家日出、日落时间必定有所偏差(这个偏差我们通常叫做时差)。 前边提到全球共分为24个时区(东、西各12个时区)，也就是每个时区的经度宽度为15度，其中本初子午线(0度经线)为0时区的中心线，而东、西12时区合并为一个时区，这些时区的经度分布如下： 时区 时区经度范围 时区中心线 UTC(0时区) 7.5°W~7.5°E 0° UTC+1(东1区) 7.5°E~22.5°E 15°E UTC+2(东2区) 22.5°E~37.5°E 30°E UTC+3(东3区) 37.5°E~52.5°E 45°E UTC+4(东4区) 52.5°E~67.5°E 60°E UTC+5(东5区) 67.5°E~82.5°E 75°E UTC+6(东6区) 82.5°E~97.5°E 90°E UTC+7(东7区) 97.5°E~112.5°E 105°E UTC+8(东8区) 112.5°E~127.5°E 120°E UTC+9(东9区) 127.5°E~142.5°E 135°E UTC+10(东10区) 142.5°E~157.5°E 150°E UTC+11(东11区) 157.5°E~172.5°E 165°E UTC12(东、西12区) 172.5°E~172.5°W 180° UTC-11(西11区) 172.5°W~157.5°W 165°W UTC-10(西10区) 157.5°W~142.5°W 150°W UTC-9(西9区) 142.5°W~127.5°W 135°W UTC-8(西8区) 127.5°W~112.5°W 120°W UTC-7(西7区) 112.5°W~97.5°W 105°W UTC-6(西6区) 97.5°W~82.5°W 90°W UTC-5(西5区) 82.5°W~67.5°W 75°W UTC-4(西4区) 67.5°W~52.5°W 60°W UTC-3(西3区) 52.5°W~37.5°W 45°W UTC-2(西2区) 37.5°W~22.5°W 30°W UTC-1(西1区) 22.5°W~7.5°W 15°W 但是实际上，通常1个国家或1个省份同时跨着多个时区，是因为为了照顾到行政上的方便，常将1个国家或1个省份划在同一个时区。例如，中国跨5个时区，但为了使用方便简单并且全国统一使用一个区时，实际上在中国使用东8区的区时一般称为北京时间作为标准时间。全球的标准时区划分如下： UTC、GMT、CST、DST与ISO-8601 GMT，Greenwich Mean Time，格林尼治(或者有时候翻译为格林威治)标准时间，是指位于伦敦郊区的皇家格林尼治天文台的标准时间。格林尼治所在地的标准时间也叫世界时UT。以地球自转为基础的时间计量系统。地球自转的角度可用地方子午线相对于地球上的基本参考点的运动来度量。为了测量地球自转，人们在地球上选取了两个基本参考点：春分点(见分至点)和平太阳，由此确定的时间分别称为恒星时和平太阳时。对于世界上发生的重大事件，都以格林尼治的地方时间记录下来。一旦知道了格林尼治时间，人们就很容易推算出相对应的本地时间。指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义在通过那里的经线。 自1924年2月5日开始，格林尼治天文台每隔一小时会向全世界发放调时信息。 格林威治子午线上的地方时，或零时区（中时区）的区时叫做格林威治时间(又译为&quot;格林尼治时间&quot;)，也叫&quot;世界时&quot;。原是采用格林威治的平正午作为一个平太阳日的开始，但在使用中有些不便。因此，国际天文学联合会于1928年决定，将由格林威治平子夜起算的平太阳时作为世界时，也就是通常所说的格林威治时间。格林威治时间所在时区为0时区，可以推算出使用GMT+8表示中国的时间，是因为中国位于东八区，时间上比格林威治时间快8个小时。 UTC，Coordinated Universal Time，也就是协调世界时，由于英文(CUT)和法文(TUC)的缩写不同，作为妥协，简称UTC。协调世界时是以原子时秒长为基础，在时刻上尽量接近于世界时的一种时间计量系统(由实验室用足够精确的铯原子钟导出的时间作为原子时，原子时的精确度极高，精度可以达到每2000万年才误差1秒)。国际原子时的准确度为每日数纳秒，而世界时的准确度为每日数毫秒。许多应用部门要求时间系统接近世界时UT，对于这种情况，一种称为协调世界时的折衷时标于1972年面世。为确保协调世界时与世界时相差不会超过0.9秒，在有需要的情况下会在协调世界时内加上正或负闰秒。因此协调世界时与国际原子时之间会出现若干整数秒的差别，两者之差逐年积累，便采用跳秒(闰秒)的方法使协调时与世界时的时刻相接近，其差不超过1s。通常将GMT和UTC视作等同，但UTC更加科学更加精确，它是以原子时为基础，在时刻上尽量接近世界时的一种时间计量系统。类似的，可以使用UTC+8表示中国的时间。 CST，China Standard Time，也就是中国标准时间，当格林威治时间为凌晨0:00时，中国标准时间正好为上午8:00，也就是CST实际上是参照于UTC，通用公式为：CST = UTC/GMT +8。 DST，Daylight Saving Time，阳光节约时，在我国称为夏时制，又称夏令时，是一种为节约能源而人为调整地方时间的制度。有些国家DST的使用时间较长，(如美国长达7个月)跨越了春夏秋等三个季节，因此简单地用夏时制的概念已经不能完全表达DST的确切含义了，所以有人也称其为节能时。所谓的DST，就是利用夏季天亮得早这一自然现象，人为地将时间提前一小时。这样就可以使人们早起早睡，以充分利用光照资源，减少照明时间，从而节约照明用电。目前中国已经弃用DST。 ISO-8601，是国际标准化组织的日期和时间的表示方法，全称为《数据存储和交换形式·信息交换·日期和时间的表示方法》。目前是2004年12月1日发行的第三版&quot;ISO8601:2004&quot;以替代1998年的第一版&quot;ISO8601:1988&quot;与2000年的第二版&quot;ISO8601:2000&quot;。该表示方法规定：年由4位数字组成YYYY，或者带正负号的四或五位数字表示±YYYYY，月、日用两位数字表示：MM、DD。只使用数字为基本格式。使用短横线&quot;-“间隔开年、月、日为扩展格式。时间只使用数字为基本格式。使用冒号”:&quot;间隔开小时、分、秒的为扩展格式。小时、分和秒都用2位数表示。合并表示时，要在时间前面加一大写字母T，如要表示北京时间2004年5月3日下午5点30分8秒，可以写成2004-05-03T17:30:08+08:00或20040503T173008+08。如果时间在零时区，并恰好与协调世界时相同，那么(不加空格地)在时间最后加一个大写字母Z。Z是相对协调世界时时间0偏移的代号。如下午2点30分5秒表示为14:30:05Z或143005Z；只表示小时和分，为1430Z或14:30Z；只表示小时，则为14Z或14Z。其他时区用实际时间加时差表示，当时的UTC+8时间表示为22:30:05+08:00或223005+0800，也可以简化成223005+08。Java中已存在的类java.util.Date默认就是使用ISO-8601表示的。 ZoneId JSR-310中引入了抽象类java.time.ZoneId表示时区ID，它是旧APIjava.util.TimeZone的替代。ZoneRulesProvider用于加载Zone Rule(时区规则，ZoneRules)，自定义实现是可以通过系统变量设置java.time.zone.DefaultZoneRulesProvider=全类名为ZoneRulesProvider自定义的提供类，或者通过SPI加载，默认的实现类是TzdbZoneRulesProvider，TzdbZoneRulesProvider会加载${JAVA_HONE}/lib/tzdb.dat文件(可以打开这个文件看下里面是怎么定义和描述时区的相应规则，这里不做详细分析，实际上如果深入了解这个规则文件的定义可以自行编写规则文件和实现加载类加载自定义的规则)，这个DAT文件中存放着时区的规则映射。ZoneId就是时区ID主要用于定制Instant和LocalDateTime之间的转换规则的。时区ID一共有两种不同的类型： 固定时间偏移量(Fixed Offset) - 实际上对应ZoneOffset。 地理区域(Geographical Region) - 实际上对应ZoneRegion。 静态方法ZoneId#of(String zoneId)会根据入参自动适配最终的时区ID到底表示固定时间偏移量还是地理区域，此方法支持如下的参数： 地理区域参数，形式是：洲(州、国家)/城市，如ZoneId.of(&quot;Asia/Shanghia&quot;)，值得注意的是默认加载的规则里面没有北京。 固定时间偏移量格式(offset-style)，支持的格式比较多： UTC或者GMT。 Z(相当于UTC)。 +h或者-h。 +hh或者-hh。 +hh:mm或者-hh:mm。 +hh:mm:ss或者-hh:mm:ss。 +hhmmss或者-hhmmss。 基于固定时间偏移量格式举几个例子： 123456789101112ZoneId z;z = ZoneId.of(\"Z\"); //for UTCz = ZoneId.of(\"+02:00\");z = ZoneId.of(\"-02:00\");ZoneId.of(\"GMT+2\");ZoneId.of(\"UTC\");ZoneId.of(\"UT+01:00\");ZoneId.of(\"Asia/Aden\");ZoneId.of(\"Etc/GMT+9\");ZoneId.of(\"Asia/Aqtau\"); 固定时间偏移量-ZoneOffset java.time.ZoneOffset是java.time.ZoneId实现类，表示固定时间偏移量，这个偏移量是以格林尼治(GMT)/协调世界时(UTC)为基准的偏移时间量。举个例子： 123456789public class ZoneOffsetMain &#123; public static void main(String[] args) throws Exception &#123; ZoneOffset zoneOffset = ZoneOffset.of(\"+02:00\"); System.out.println(zoneOffset); zoneOffset = ZoneOffset.of(\"-02:00\"); System.out.println(zoneOffset); &#125;&#125; 其中，ZoneOffset.of(&quot;+02:00&quot;)表示UTC下2小时的时间偏移(简单理解为东2区)，ZoneOffset.of(&quot;-02:00&quot;)表示UTC下-2小时的时间偏移(简单理解为西2区)。 地理区域-ZoneRegion java.time.ZoneRegion是java.time.ZoneId实现类(不过其修饰符为default，因此无法直接访问，只能通过ZoneId操作)，表示地理区域，格式是：洲(州、国家)/城市。注释中提到：最常见的区域分类是时区数据库(TZDB)，TZDB使用Europe/Paris’和’Asia/Tokyo’等形式区分地区。举个简单的例子： 12345678910111213public class ZoneRegionMain &#123; public static void main(String[] args) throws Exception &#123; ZoneId zoneId = ZoneId.systemDefault(); System.out.println(zoneId); Set&lt;String&gt; availableZoneIds = ZoneId.getAvailableZoneIds(); for (String z : availableZoneIds) &#123; if (z.contains(\"Beijing\") || z.contains(\"BeiJing\")) &#123; System.out.println(z); &#125; &#125; &#125;&#125; 执行后控制台输出： 1Asia/Shanghai 实际上，执行这个方法的时候，笔者在广州，得到的系统默认zoneId是Asia/Shanghai，并且默认加载的地理区域中没有北京相关的zoneId。 小结 JSR-310中引入的时间API类ZoneId表示时区ID，具体有两种类型：固定时间偏移量-ZoneOffset和地理区域-ZoneRegion，这两种类型可以再细分为三种表示方式： 地理区域表示，如：ZoneId.of(&quot;Asia/Aden&quot;)。 GMT/UTC偏移量详细表示，如：ZoneId.of(&quot;UTC&quot;)、ZoneId.of(&quot;GMT+2&quot;)。 GMT/UTC偏移量简单表示，如：ZoneId.of(&quot;Z&quot;)、ZoneId.of(&quot;+2:00&quot;)。 参考资料： 维基百科-Time zone 维基百科-ISO 8601 Bing互动百科相关资料 Java 8: how to derive a ZoneId from ZoneOffset JDK11相关源码 (本文完 c-1-d e-a-20181223)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"JSR-310","slug":"JSR-310","permalink":"http://throwable.club/blog/tags/JSR-310/"}]},{"title":"RabbitMQ扩展之交换器间的绑定","slug":"rabbitmq-extension-exchange-binding","date":"2018-12-18T15:37:34.000Z","updated":"2018-12-18T15:40:44.922Z","comments":true,"path":"2018/12/18/rabbitmq-extension-exchange-binding/","link":"","permalink":"http://throwable.club/2018/12/18/rabbitmq-extension-exchange-binding/","excerpt":"","text":"RabbitMQ扩展之交换器间的绑定 概要 AMQP-0-9-1中提供了queue.bind方法用于绑定一个队列到一个交换器，然后发送消息的时候，数据流总是先通过交换器(source)最终到达目标队列中(destination)。RabbitMQ实现了扩展，为交换器提供了一个exchange.bind方法用于绑定一个交换器到另一个交换器。交换器之间的绑定和队列与交换器的绑定在语义上是相同的：单向的、使用路由键和多种交换器类型。这一点允许使用者创建更丰富的路由拓扑。exchange.bind方法中的source和destination反映了消息的流向：从源(source)交换器到目标(destination)交换器。 像queue.bind方法一样，可以在相同的绑定端点上创建多个不同的交换器绑定，例如： exchange-source -&gt; exchange-destination-1 -&gt; queue-1。 exchange-source -&gt; exchange-destination-2 -&gt; queue-2。 exchange-source -&gt; exchange-destination-3 -&gt; queue-3。 RabbitMQ在消息传递期间检测并消除循环，并确保在任何路由拓扑上传递给定路由的每个队列，每个队列将只接收该消息的一个副本。 使用了auto-delete参数声明的交换器只有它关联的所有绑定关系都移除(不管是交换器之间的绑定还是交换器和队列的绑定)，它自身才会被删除。举个例子： exchange-source -&gt; exchange-destination -&gt; queue-1。 如果exchange-source被删除或者解除与exchange-destination的绑定关系同时exchange-destination和queue-1解除绑定，而exchange-destination使用了auto-delete参数声明，那么exchange-destination就会被删除。 RabbitMQ中还提供了一个exchange.unbind方法进行交换器之间绑定关系的解除。 编码实现 12345678910111213141516public class ExchangeBindingMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; channel.exchangeDeclare(\"exchange.source\", BuiltinExchangeType.DIRECT, true, false, null); channel.exchangeDeclare(\"exchange.destination\", BuiltinExchangeType.DIRECT, true, true, null); channel.queueDeclare(\"exchange.binding.queue\", true, false, false, null); channel.exchangeBind(\"exchange.destination\", \"exchange.source\", \"exchange.routingKey\"); channel.queueBind(\"exchange.binding.queue\", \"exchange.destination\", \"exchange.routingKey\"); channel.basicPublish(\"exchange.source\", \"exchange.routingKey\", MessageProperties.BASIC, \"message\".getBytes(StandardCharsets.UTF_8)); channel.exchangeUnbind(\"exchange.destination\", \"exchange.source\", \"exchange.routingKey\");// channel.exchangeDelete(\"exchange.source\"); channel.queueUnbind(\"exchange.binding.queue\", \"exchange.destination\", \"exchange.routingKey\"); &#125;); &#125;&#125; 在解除exchange.source和exchange.destination、exchange.binding.queue和exchange.destination之间的绑定后，exchange.destination会自动删除。 (本文完 e-a-20181218 c-1-d)","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"RabbitMQ","slug":"Middleware/RabbitMQ","permalink":"http://throwable.club/blog/categories/Middleware/RabbitMQ/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://throwable.club/blog/tags/RabbitMQ/"}]},{"title":"基于SpringBoot的Environment源码理解实现分散配置","slug":"spring-boot-environment-configuration-spread","date":"2018-12-16T14:41:46.000Z","updated":"2020-01-02T03:22:02.427Z","comments":true,"path":"2018/12/16/spring-boot-environment-configuration-spread/","link":"","permalink":"http://throwable.club/2018/12/16/spring-boot-environment-configuration-spread/","excerpt":"前提 org.springframework.core.env.Environment是当前应用运行环境的公开接口，主要包括应用程序运行环境的两个关键方面：配置文件(profiles)和属性。Environment继承自接口PropertyResolver，而PropertyResolver提供了属性访问的相关方法。这篇文章从源码的角度分析Environment的存储容器和加载流程，然后基于源码的理解给出一个生产级别的扩展。 本文较长，请用一个舒服的姿势阅读。","text":"前提 org.springframework.core.env.Environment是当前应用运行环境的公开接口，主要包括应用程序运行环境的两个关键方面：配置文件(profiles)和属性。Environment继承自接口PropertyResolver，而PropertyResolver提供了属性访问的相关方法。这篇文章从源码的角度分析Environment的存储容器和加载流程，然后基于源码的理解给出一个生产级别的扩展。 本文较长，请用一个舒服的姿势阅读。 Environment类体系 PropertyResolver：提供属性访问功能。 ConfigurablePropertyResolver：继承自PropertyResolver，额外主要提供属性类型转换(基于org.springframework.core.convert.ConversionService)功能。 Environment：继承自PropertyResolver，额外提供访问和判断profiles的功能。 ConfigurableEnvironment：继承自ConfigurablePropertyResolver和Environment，并且提供设置激活的profile和默认的profile的功能。 ConfigurableWebEnvironment：继承自ConfigurableEnvironment，并且提供配置Servlet上下文和Servlet参数的功能。 AbstractEnvironment：实现了ConfigurableEnvironment接口，默认属性和存储容器的定义，并且实现了ConfigurableEnvironment种的方法，并且为子类预留可覆盖了扩展方法。 StandardEnvironment：继承自AbstractEnvironment，非Servlet(Web)环境下的标准Environment实现。 StandardServletEnvironment：继承自StandardEnvironment，Servlet(Web)环境下的标准Environment实现。 reactive相关的暂时不研究。 Environment提供的方法 一般情况下，我们在SpringMVC项目中启用到的是StandardServletEnvironment，它的父接口问ConfigurableWebEnvironment，我们可以查看此接口提供的方法： Environment的存储容器 Environment的静态属性和存储容器都是在AbstractEnvironment中定义的，ConfigurableWebEnvironment接口提供的getPropertySources()方法可以获取到返回的MutablePropertySources实例，然后添加额外的PropertySource。实际上，Environment的存储容器就是org.springframework.core.env.PropertySource的子类集合，AbstractEnvironment中使用的实例是org.springframework.core.env.MutablePropertySources，下面看下PropertySource的源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public abstract class PropertySource&lt;T&gt; &#123; protected final Log logger = LogFactory.getLog(getClass()); protected final String name; protected final T source; public PropertySource(String name, T source) &#123; Assert.hasText(name, \"Property source name must contain at least one character\"); Assert.notNull(source, \"Property source must not be null\"); this.name = name; this.source = source; &#125; @SuppressWarnings(\"unchecked\") public PropertySource(String name) &#123; this(name, (T) new Object()); &#125; public String getName() &#123; return this.name; &#125; public T getSource() &#123; return this.source; &#125; public boolean containsProperty(String name) &#123; return (getProperty(name) != null); &#125; @Nullable public abstract Object getProperty(String name); @Override public boolean equals(Object obj) &#123; return (this == obj || (obj instanceof PropertySource &amp;&amp; ObjectUtils.nullSafeEquals(this.name, ((PropertySource&lt;?&gt;) obj).name))); &#125; @Override public int hashCode() &#123; return ObjectUtils.nullSafeHashCode(this.name); &#125; //省略其他方法和内部类的源码 &#125; 源码相对简单，预留了一个getProperty抽象方法给子类实现，重点需要关注的是覆写了的equals和hashCode方法，实际上只和name属性相关，这一点很重要，说明一个PropertySource实例绑定到一个唯一的name，这个name有点像HashMap里面的key，部分移除、判断方法都是基于name属性。PropertySource的最常用子类是MapPropertySource、PropertiesPropertySource、ResourcePropertySource、StubPropertySource、ComparisonPropertySource： MapPropertySource：source指定为Map实例的PropertySource实现。 PropertiesPropertySource：source指定为Map实例的PropertySource实现，内部的Map实例由Properties实例转换而来。 ResourcePropertySource：继承自PropertiesPropertySource，source指定为通过Resource实例转化为Properties再转换为Map实例。 StubPropertySource：PropertySource的一个内部类，source设置为null，实际上就是空实现。 ComparisonPropertySource：继承自ComparisonPropertySource，所有属性访问方法强制抛出异常，作用就是一个不可访问属性的空实现。 AbstractEnvironment中的属性定义： 123456789101112public static final String IGNORE_GETENV_PROPERTY_NAME = \"spring.getenv.ignore\";public static final String ACTIVE_PROFILES_PROPERTY_NAME = \"spring.profiles.active\";public static final String DEFAULT_PROFILES_PROPERTY_NAME = \"spring.profiles.default\";protected static final String RESERVED_DEFAULT_PROFILE_NAME = \"default\";private final Set&lt;String&gt; activeProfiles = new LinkedHashSet&lt;&gt;();private final Set&lt;String&gt; defaultProfiles = new LinkedHashSet&lt;&gt;(getReservedDefaultProfiles());private final MutablePropertySources propertySources = new MutablePropertySources(this.logger);private final ConfigurablePropertyResolver propertyResolver = new PropertySourcesPropertyResolver(this.propertySources); 上面的propertySources(MutablePropertySources类型)属性就是用来存放PropertySource列表的，PropertySourcesPropertyResolver是ConfigurablePropertyResolver的实现，默认的profile就是字符串default。MutablePropertySources的内部属性如下： 1private final List&lt;PropertySource&lt;?&gt;&gt; propertySourceList = new CopyOnWriteArrayList&lt;&gt;(); 没错，这个就是最底层的存储容器，也就是环境属性都是存放在一个CopyOnWriteArrayList&lt;PropertySource&lt;?&gt;&gt;实例中。MutablePropertySources是PropertySources的子类，它提供了get(String name)、addFirst、addLast、addBefore、addAfter、remove、replace等便捷方法，方便操作propertySourceList集合的元素，这里挑选addBefore的源码分析： 12345678910111213141516171819202122232425262728293031323334353637383940public void addBefore(String relativePropertySourceName, PropertySource&lt;?&gt; propertySource) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Adding PropertySource '\" + propertySource.getName() + \"' with search precedence immediately higher than '\" + relativePropertySourceName + \"'\"); &#125; //前一个PropertySource的name指定为relativePropertySourceName时候必须和添加的PropertySource的name属性不相同 assertLegalRelativeAddition(relativePropertySourceName, propertySource); //尝试移除同名的PropertySource removeIfPresent(propertySource); //获取前一个PropertySource在CopyOnWriteArrayList中的索引 int index = assertPresentAndGetIndex(relativePropertySourceName); //添加当前传入的PropertySource到指定前一个PropertySource的索引，相当于relativePropertySourceName对应的PropertySource后移到原来索引值+1的位置 addAtIndex(index, propertySource);&#125;protected void assertLegalRelativeAddition(String relativePropertySourceName, PropertySource&lt;?&gt; propertySource) &#123; String newPropertySourceName = propertySource.getName(); if (relativePropertySourceName.equals(newPropertySourceName)) &#123; throw new IllegalArgumentException( \"PropertySource named '\" + newPropertySourceName + \"' cannot be added relative to itself\"); &#125;&#125;protected void removeIfPresent(PropertySource&lt;?&gt; propertySource) &#123; this.propertySourceList.remove(propertySource);&#125;private int assertPresentAndGetIndex(String name) &#123; int index = this.propertySourceList.indexOf(PropertySource.named(name)); if (index == -1) &#123; throw new IllegalArgumentException(\"PropertySource named '\" + name + \"' does not exist\"); &#125; return index;&#125;private void addAtIndex(int index, PropertySource&lt;?&gt; propertySource) &#123; //注意，这里会再次尝试移除同名的PropertySource removeIfPresent(propertySource); this.propertySourceList.add(index, propertySource);&#125; 大多数PropertySource子类的修饰符都是public，可以直接使用，这里写个小demo： 123456789101112MutablePropertySources mutablePropertySources = new MutablePropertySources();Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(8);map.put(\"name\", \"throwable\");map.put(\"age\", 25);MapPropertySource mapPropertySource = new MapPropertySource(\"map\", map);mutablePropertySources.addLast(mapPropertySource);Properties properties = new Properties();PropertiesPropertySource propertiesPropertySource = new PropertiesPropertySource(\"prop\", properties);properties.put(\"name\", \"doge\");properties.put(\"gourp\", \"group-a\");mutablePropertySources.addBefore(\"map\", propertiesPropertySource);System.out.println(mutablePropertySources); Environment加载过程源码分析 Environment加载的源码位于SpringApplication#prepareEnvironment： 123456789101112131415161718192021private ConfigurableEnvironment prepareEnvironment( SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123; // Create and configure the environment //创建ConfigurableEnvironment实例 ConfigurableEnvironment environment = getOrCreateEnvironment(); //启动参数绑定到ConfigurableEnvironment中 configureEnvironment(environment, applicationArguments.getSourceArgs()); //发布ConfigurableEnvironment准备完毕事件 listeners.environmentPrepared(environment); //绑定ConfigurableEnvironment到当前的SpringApplication实例中 bindToSpringApplication(environment); //这一步是非SpringMVC项目的处理，暂时忽略 if (this.webApplicationType == WebApplicationType.NONE) &#123; environment = new EnvironmentConverter(getClassLoader()) .convertToStandardEnvironmentIfNecessary(environment); &#125; //绑定ConfigurationPropertySourcesPropertySource到ConfigurableEnvironment中，name为configurationProperties，实例是SpringConfigurationPropertySources，属性实际是ConfigurableEnvironment中的MutablePropertySources ConfigurationPropertySources.attach(environment); return environment;&#125; 这里重点看下getOrCreateEnvironment方法： 1234567891011121314151617181920212223242526private ConfigurableEnvironment getOrCreateEnvironment() &#123; if (this.environment != null) &#123; return this.environment; &#125; //在SpringMVC项目，ConfigurableEnvironment接口的实例就是新建的StandardServletEnvironment实例 if (this.webApplicationType == WebApplicationType.SERVLET) &#123; return new StandardServletEnvironment(); &#125; return new StandardEnvironment();&#125;//REACTIVE_WEB_ENVIRONMENT_CLASS=org.springframework.web.reactive.DispatcherHandler//MVC_WEB_ENVIRONMENT_CLASS=org.springframework.web.servlet.DispatcherServlet//MVC_WEB_ENVIRONMENT_CLASS=&#123;\"javax.servlet.Servlet\",\"org.springframework.web.context.ConfigurableWebApplicationContext\"&#125;//这里，默认就是WebApplicationType.SERVLETprivate WebApplicationType deduceWebApplicationType() &#123; if (ClassUtils.isPresent(REACTIVE_WEB_ENVIRONMENT_CLASS, null) &amp;&amp; !ClassUtils.isPresent(MVC_WEB_ENVIRONMENT_CLASS, null)) &#123; return WebApplicationType.REACTIVE; &#125; for (String className : WEB_ENVIRONMENT_CLASSES) &#123; if (!ClassUtils.isPresent(className, null)) &#123; return WebApplicationType.NONE; &#125; &#125; return WebApplicationType.SERVLET;&#125; 还有一个地方要重点关注：发布ConfigurableEnvironment准备完毕事件listeners.environmentPrepared(environment)，实际上这里用到了同步的EventBus，事件的监听者是ConfigFileApplicationListener，具体处理逻辑是onApplicationEnvironmentPreparedEvent方法： 123456789101112131415161718192021private void onApplicationEnvironmentPreparedEvent( ApplicationEnvironmentPreparedEvent event) &#123; List&lt;EnvironmentPostProcessor&gt; postProcessors = loadPostProcessors(); postProcessors.add(this); AnnotationAwareOrderComparator.sort(postProcessors); //遍历所有的EnvironmentPostProcessor对Environment实例进行处理 for (EnvironmentPostProcessor postProcessor : postProcessors) &#123; postProcessor.postProcessEnvironment(event.getEnvironment(), event.getSpringApplication()); &#125;&#125;//从spring.factories文件中加载，一共有四个实例//ConfigFileApplicationListener//CloudFoundryVcapEnvironmentPostProcessor//SpringApplicationJsonEnvironmentPostProcessor//SystemEnvironmentPropertySourceEnvironmentPostProcessorList&lt;EnvironmentPostProcessor&gt; loadPostProcessors() &#123; return SpringFactoriesLoader.loadFactories(EnvironmentPostProcessor.class, getClass().getClassLoader());&#125; 实际上，处理工作大部分都在ConfigFileApplicationListener中，见它的postProcessEnvironment方法： 12345678910public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application) &#123; addPropertySources(environment, application.getResourceLoader());&#125;protected void addPropertySources(ConfigurableEnvironment environment, ResourceLoader resourceLoader) &#123; RandomValuePropertySource.addToEnvironment(environment); new Loader(environment, resourceLoader).load();&#125; 主要的配置环境加载逻辑在内部类Loader，Loader会匹配多个路径下的文件把属性加载到ConfigurableEnvironment中，加载器主要是PropertySourceLoader的实例，例如我们用到application-${profile}.yaml文件做应用主配置文件，使用的是YamlPropertySourceLoader，这个时候activeProfiles也会被设置到ConfigurableEnvironment中。加载完毕之后，ConfigurableEnvironment中基本包含了所有需要加载的属性(activeProfiles是这个时候被写入ConfigurableEnvironment)。值得注意的是，几乎所有属性都是key-value形式存储，如xxx.yyyy.zzzzz=value、xxx.yyyy[0].zzzzz=value-1、xxx.yyyy[1].zzzzz=value-2。Loader中的逻辑相对复杂，有比较多的遍历和过滤条件，这里不做展开。 Environment属性访问源码分析 上文提到过，都是委托到PropertySourcesPropertyResolver，先看它的构造函数： 123456@Nullableprivate final PropertySources propertySources;public PropertySourcesPropertyResolver(@Nullable PropertySources propertySources) &#123; this.propertySources = propertySources;&#125; 只依赖于一个PropertySources实例，在SpringBoot项目中就是MutablePropertySources的实例。重点分析一下最复杂的一个方法： 1234567891011121314151617181920212223242526protected &lt;T&gt; T getProperty(String key, Class&lt;T&gt; targetValueType, boolean resolveNestedPlaceholders) &#123; if (this.propertySources != null) &#123; //遍历所有的PropertySource for (PropertySource&lt;?&gt; propertySource : this.propertySources) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Searching for key '\" + key + \"' in PropertySource '\" + propertySource.getName() + \"'\"); &#125; Object value = propertySource.getProperty(key); //选用第一个不为null的匹配key的属性值 if (value != null) &#123; if (resolveNestedPlaceholders &amp;&amp; value instanceof String) &#123; //处理属性占位符，如$&#123;server.port&#125;，底层委托到PropertyPlaceholderHelper完成 value = resolveNestedPlaceholders((String) value); &#125; logKeyFound(key, propertySource, value); //如果需要的话，进行一次类型转换，底层委托到DefaultConversionService完成 return convertValueIfNecessary(value, targetValueType); &#125; &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Could not find key '\" + key + \"' in any property source\"); &#125; return null;&#125; 这里的源码告诉我们，如果出现多个PropertySource中存在同名的key，返回的是第一个PropertySource对应key的属性值的处理结果，因此我们如果需要自定义一些环境属性，需要十分清楚各个PropertySource的顺序。 扩展-实现分散配置 在不使用SpringCloud配置中心的情况下，一般的SpringBoot项目的配置文件如下： 123456- src - main - resources - application-prod.yaml - application-dev.yaml - application-test.yaml 随着项目发展，配置项越来越多，导致了application-${profile}.yaml迅速膨胀，大的配置文件甚至超过一千行，为了简化和划分不同功能的配置，可以考虑把配置文件拆分如下： 12345678910111213141516171819- src - main - resources - profiles - dev - business.yaml - mq.json - datasource.properties - prod - business.yaml - mq.json - datasource.properties - test - business.yaml - mq.json - datasource.properties - application-prod.yaml - application-dev.yaml - application-test.yaml 外层的application-${profile}.yaml只留下项目的核心配置如server.port等，其他配置打散放在/profiles/${profile}/各自的配置文件中。实现方式是：依据当前配置的spring.profiles.active属性，读取类路径中指定文件夹下的配置文件中，加载到Environment中，需要注意这一个加载步骤必须在Spring刷新上下文方法最后一步finishRefresh()之前完成，否则有可能会影响到占位符属性的自动装配(例如使用了@Value(&quot;${filed}&quot;))。 先定义一个属性探索者接口： 12345678910111213141516171819public interface PropertySourceDetector &#123; /** * 获取支持的文件后缀数组 * * @return String[] */ String[] getFileExtensions(); /** * 加载目标文件属性到环境中 * * @param environment environment * @param name name * @param resource resource * @throws IOException IOException */ void load(ConfigurableEnvironment environment, String name, Resource resource) throws IOException;&#125; 然后需要一个抽象属性探索者把Resource转换为字符串，额外提供Map的缩进、添加PropertySource到Environment等方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public abstract class AbstractPropertySourceDetector implements PropertySourceDetector &#123; private static final String SERVLET_ENVIRONMENT_CLASS = \"org.springframework.web.\" + \"context.support.StandardServletEnvironment\"; public boolean support(String fileExtension) &#123; String[] fileExtensions = getFileExtensions(); return null != fileExtensions &amp;&amp; Arrays.stream(fileExtensions).anyMatch(extension -&gt; extension.equals(fileExtension)); &#125; private String findPropertySource(MutablePropertySources sources) &#123; if (ClassUtils.isPresent(SERVLET_ENVIRONMENT_CLASS, null) &amp;&amp; sources .contains(StandardServletEnvironment.JNDI_PROPERTY_SOURCE_NAME)) &#123; return StandardServletEnvironment.JNDI_PROPERTY_SOURCE_NAME; &#125; return StandardEnvironment.SYSTEM_PROPERTIES_PROPERTY_SOURCE_NAME; &#125; protected void addPropertySource(ConfigurableEnvironment environment, PropertySource&lt;?&gt; source) &#123; MutablePropertySources sources = environment.getPropertySources(); String name = findPropertySource(sources); if (sources.contains(name)) &#123; sources.addBefore(name, source); &#125; else &#123; sources.addFirst(source); &#125; &#125; protected Map&lt;String, Object&gt; flatten(Map&lt;String, Object&gt; map) &#123; Map&lt;String, Object&gt; result = new LinkedHashMap&lt;&gt;(); flatten(null, result, map); return result; &#125; private void flatten(String prefix, Map&lt;String, Object&gt; result, Map&lt;String, Object&gt; map) &#123; String namePrefix = (prefix != null ? prefix + \".\" : \"\"); map.forEach((key, value) -&gt; extract(namePrefix + key, result, value)); &#125; @SuppressWarnings(\"unchecked\") private void extract(String name, Map&lt;String, Object&gt; result, Object value) &#123; if (value instanceof Map) &#123; flatten(name, result, (Map&lt;String, Object&gt;) value); &#125; else if (value instanceof Collection) &#123; int index = 0; for (Object object : (Collection&lt;Object&gt;) value) &#123; extract(name + \"[\" + index + \"]\", result, object); index++; &#125; &#125; else &#123; result.put(name, value); &#125; &#125; protected String getContentStringFromResource(Resource resource) throws IOException &#123; return StreamUtils.copyToString(resource.getInputStream(), Charset.forName(\"UTF-8\")); &#125;&#125; 上面的方法参考SpringApplicationJsonEnvironmentPostProcessor，然后编写各种类型配置属性探索者的实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859//Json@Slf4jpublic class JsonPropertySourceDetector extends AbstractPropertySourceDetector &#123; private static final JsonParser JSON_PARSER = JsonParserFactory.getJsonParser(); @Override public String[] getFileExtensions() &#123; return new String[]&#123;\"json\"&#125;; &#125; @Override public void load(ConfigurableEnvironment environment, String name, Resource resource) throws IOException &#123; try &#123; Map&lt;String, Object&gt; map = JSON_PARSER.parseMap(getContentStringFromResource(resource)); Map&lt;String, Object&gt; target = flatten(map); addPropertySource(environment, new MapPropertySource(name, target)); &#125; catch (Exception e) &#123; log.warn(\"加载Json文件属性到环境变量失败,name = &#123;&#125;,resource = &#123;&#125;\", name, resource); &#125; &#125;&#125;//Propertiespublic class PropertiesPropertySourceDetector extends AbstractPropertySourceDetector &#123; @Override public String[] getFileExtensions() &#123; return new String[]&#123;\"properties\", \"conf\"&#125;; &#125; @SuppressWarnings(\"unchecked\") @Override public void load(ConfigurableEnvironment environment, String name, Resource resource) throws IOException &#123; Map map = PropertiesLoaderUtils.loadProperties(resource); addPropertySource(environment, new MapPropertySource(name, map)); &#125;&#125;//Yaml@Slf4jpublic class YamlPropertySourceDetector extends AbstractPropertySourceDetector &#123; private static final JsonParser YAML_PARSER = new YamlJsonParser(); @Override public String[] getFileExtensions() &#123; return new String[]&#123;\"yaml\", \"yml\"&#125;; &#125; @Override public void load(ConfigurableEnvironment environment, String name, Resource resource) throws IOException &#123; try &#123; Map&lt;String, Object&gt; map = YAML_PARSER.parseMap(getContentStringFromResource(resource)); Map&lt;String, Object&gt; target = flatten(map); addPropertySource(environment, new MapPropertySource(name, target)); &#125; catch (Exception e) &#123; log.warn(\"加载Yaml文件属性到环境变量失败,name = &#123;&#125;,resource = &#123;&#125;\", name, resource); &#125; &#125;&#125; 子类的全部PropertySource都是MapPropertySource，name为文件的名称，所有PropertySource都用addBefore()方法插入到systemProperties的前面，主要是为了提高匹配属性的优先级。接着需要定义一个属性探索者的合成类用来装载所有的子类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class PropertySourceDetectorComposite implements PropertySourceDetector &#123; private static final String DEFAULT_SUFFIX = \"properties\"; private final List&lt;AbstractPropertySourceDetector&gt; propertySourceDetectors = new ArrayList&lt;&gt;(); public void addPropertySourceDetector(AbstractPropertySourceDetector sourceDetector) &#123; propertySourceDetectors.add(sourceDetector); &#125; public void addPropertySourceDetectors(List&lt;AbstractPropertySourceDetector&gt; sourceDetectors) &#123; propertySourceDetectors.addAll(sourceDetectors); &#125; public List&lt;AbstractPropertySourceDetector&gt; getPropertySourceDetectors() &#123; return Collections.unmodifiableList(propertySourceDetectors); &#125; @Override public String[] getFileExtensions() &#123; List&lt;String&gt; fileExtensions = new ArrayList&lt;&gt;(8); for (AbstractPropertySourceDetector propertySourceDetector : propertySourceDetectors) &#123; fileExtensions.addAll(Arrays.asList(propertySourceDetector.getFileExtensions())); &#125; return fileExtensions.toArray(new String[0]); &#125; @Override public void load(ConfigurableEnvironment environment, String name, Resource resource) throws IOException &#123; if (resource.isFile()) &#123; String fileName = resource.getFile().getName(); int index = fileName.lastIndexOf(\".\"); String suffix; if (-1 == index) &#123; //如果文件没有后缀,当作properties处理 suffix = DEFAULT_SUFFIX; &#125; else &#123; suffix = fileName.substring(index + 1); &#125; for (AbstractPropertySourceDetector propertySourceDetector : propertySourceDetectors) &#123; if (propertySourceDetector.support(suffix)) &#123; propertySourceDetector.load(environment, name, resource); return; &#125; &#125; &#125; &#125;&#125; 最后添加一个配置类作为入口： 1234567891011121314151617181920212223242526272829303132333435363738public class PropertySourceDetectorConfiguration implements ImportBeanDefinitionRegistrar &#123; private static final String PATH_PREFIX = \"profiles\"; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; DefaultListableBeanFactory beanFactory = (DefaultListableBeanFactory) registry; ConfigurableEnvironment environment = beanFactory.getBean(ConfigurableEnvironment.class); List&lt;AbstractPropertySourceDetector&gt; propertySourceDetectors = new ArrayList&lt;&gt;(); configurePropertySourceDetectors(propertySourceDetectors, beanFactory); PropertySourceDetectorComposite propertySourceDetectorComposite = new PropertySourceDetectorComposite(); propertySourceDetectorComposite.addPropertySourceDetectors(propertySourceDetectors); String[] activeProfiles = environment.getActiveProfiles(); ResourcePatternResolver resourcePatternResolver = new PathMatchingResourcePatternResolver(); try &#123; for (String profile : activeProfiles) &#123; String location = PATH_PREFIX + File.separator + profile + File.separator + \"*\"; Resource[] resources = resourcePatternResolver.getResources(location); for (Resource resource : resources) &#123; propertySourceDetectorComposite.load(environment, resource.getFilename(), resource); &#125; &#125; &#125; catch (IOException e) &#123; throw new IllegalStateException(e); &#125; &#125; private void configurePropertySourceDetectors(List&lt;AbstractPropertySourceDetector&gt; propertySourceDetectors, DefaultListableBeanFactory beanFactory) &#123; Map&lt;String, AbstractPropertySourceDetector&gt; beansOfType = beanFactory.getBeansOfType(AbstractPropertySourceDetector.class); for (Map.Entry&lt;String, AbstractPropertySourceDetector&gt; entry : beansOfType.entrySet()) &#123; propertySourceDetectors.add(entry.getValue()); &#125; propertySourceDetectors.add(new JsonPropertySourceDetector()); propertySourceDetectors.add(new YamlPropertySourceDetector()); propertySourceDetectors.add(new PropertiesPropertySourceDetector()); &#125;&#125; 准备就绪，在示例项目的/resources/profiles/dev目录下面添加两个文件app.json和conf： 123456789//app.json文件内容&#123; \"app\": &#123; \"name\": \"throwable\", \"age\": 25 &#125;&#125;//conf文件内容name=doge 项目的application.yaml添加属性spring.profiles.active: dev，最后添加一个CommandLineRunner的实现用来观察数据： 12345678910111213141516@Slf4j@Componentpublic class CustomCommandLineRunner implements CommandLineRunner &#123; @Value(\"$&#123;app.name&#125;\") String name; @Value(\"$&#123;app.age&#125;\") Integer age; @Autowired ConfigurableEnvironment configurableEnvironment; @Override public void run(String... args) throws Exception &#123; log.info(\"name = &#123;&#125;,age = &#123;&#125;\", name, age); &#125;&#125; 自动装配的属性值和Environment实例中的属性和预期一样，改造是成功的。 小结 Spring中的环境属性管理的源码个人认为是最清晰和简单的：从文件中读取数据转化为key-value结构，key-value结构存放在一个PropertySource实例中，然后得到的多个PropertySource实例存放在一个CopyOnWriteArrayList中，属性访问的时候总是遍历CopyOnWriteArrayList中的PropertySource进行匹配。可能相对复杂的就是占位符的解析和参数类型的转换，后者牵连到Converter体系，这些不在本文的讨论范围内。最后附上一张Environment存储容器的示例图： 参考资料： spring-boot-starter-web:2.0.3.RELEASE源码。 (本文完 r-a-20181216)","categories":[{"name":"Spring","slug":"Spring","permalink":"http://throwable.club/blog/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"http://throwable.club/blog/categories/Spring/SpringBoot/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://throwable.club/blog/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://throwable.club/blog/tags/SpringBoot/"}]},{"title":"CGLIB动态代理原理分析","slug":"cglib-dynamic-proxy-analyze","date":"2018-12-16T09:10:39.000Z","updated":"2018-12-16T09:13:03.952Z","comments":true,"path":"2018/12/16/cglib-dynamic-proxy-analyze/","link":"","permalink":"http://throwable.club/2018/12/16/cglib-dynamic-proxy-analyze/","excerpt":"","text":"CGLIB动态代理原理分析 前提 前一篇文章介绍了CGLIB中常用的API，实际上使用了Enhancer和MethodInterceptor之后会生成代理子类，这篇文章就是分析一下CGLIB动态代理的原理。 CGLIB动态代理原理分析 我们经常说CGLIB的动态代理的底层通过被代理类生成代理子类实现的，那么下面我们就分析一下生成的子类到底是什么样的。开启CGLIB的debug模式，输出它生成的类到指定的目录： 12345678910111213141516171819202122232425262728public class DebuggingCglibDemo &#123; private static final String METHOD_NAME = \"sayHello\"; public static void main(String[] args) throws Exception &#123; String location = DebuggingCglibDemo.class.getResource(\"\").getPath() + \"debugging/\"; System.out.println(\"location -&gt; \" + location); System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, location); Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(SampleClass.class); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object obj, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; Object result; if (METHOD_NAME.equals(method.getName())) &#123; System.out.println(\"Before invoking sayHello...\"); result = methodProxy.invokeSuper(obj, objects); System.out.println(\"After invoking sayHello...\"); &#125; else &#123; result = methodProxy.invokeSuper(obj, objects); &#125; return result; &#125; &#125;); SampleClass sampleClass = (SampleClass) enhancer.create(); System.out.println(sampleClass.sayHello(\"throwable\")); &#125;&#125; 输出结果： 12345location -&gt; /D:/Projects/cglib-seed/target/classes/club/throwable/cglib/debugging/CGLIB debugging enabled, writing to '/D:/Projects/cglib-seed/target/classes/club/throwable/cglib/debugging/'Before invoking sayHello...After invoking sayHello...throwable say hello! 这个时候，看下target下面生成的类如下： 一共有五个类： ../net.sf.cglib包下： MethodWrapper$MethodWrapperKey$$KeyFactoryByCGLIB$$d45e49f7.class Enhancer$EnhancerKey$$KeyFactoryByCGLIB$$7fb24d72.class 这两个类主要很缓存的Key相关，这里不做详细展开。 用户自定义包../club/throwable/cglib包下： SampleClass$$EnhancerByCGLIB$$53c7afed$$FastClassByCGLIB$$da5c8621.class SampleClass$$EnhancerByCGLIB$$53c7afed.class SampleClass$$FastClassByCGLIB$$cf1a549b.class 这三个就是实际使用到的子类，其中有一个是被代理类的直接子类SampleClass$$EnhancerByCGLIB$$53c7afed，其他的两个是FastClass。 接着我们先看一下SampleClass$$EnhancerByCGLIB$$53c7afed这个类的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243与Java原生代理类似，仍然以静态变量保存了指向代理方法的引用 private boolean CGLIB$BOUND; public static Object CGLIB$FACTORY_DATA; private static final ThreadLocal CGLIB$THREAD_CALLBACKS; private static final Callback[] CGLIB$STATIC_CALLBACKS; private MethodInterceptor CGLIB$CALLBACK_0; private static Object CGLIB$CALLBACK_FILTER; //每个函数有两个反射方法，一个是通过原生反射获得的，另外一个是通过Cglib构建的。 private static final Method CGLIB$sayHello$0$Method; private static final MethodProxy CGLIB$sayHello$0$Proxy; private static final Object[] CGLIB$emptyArgs; private static final Method CGLIB$equals$1$Method; private static final MethodProxy CGLIB$equals$1$Proxy; private static final Method CGLIB$toString$2$Method; private static final MethodProxy CGLIB$toString$2$Proxy; private static final Method CGLIB$hashCode$3$Method; private static final MethodProxy CGLIB$hashCode$3$Proxy; private static final Method CGLIB$clone$4$Method; private static final MethodProxy CGLIB$clone$4$Proxy; //这里通过静态代码块初始化上面用到的静态变量，主要使用到反射 static void CGLIB$STATICHOOK1() &#123; CGLIB$THREAD_CALLBACKS = new ThreadLocal(); CGLIB$emptyArgs = new Object[0]; Class var0 = Class.forName(\"club.throwable.cglib.SampleClass$$EnhancerByCGLIB$$53c7afed\"); Class var1; Method[] var10000 = ReflectUtils.findMethods(new String[]&#123;\"equals\", \"(Ljava/lang/Object;)Z\", \"toString\", \"()Ljava/lang/String;\", \"hashCode\", \"()I\", \"clone\", \"()Ljava/lang/Object;\"&#125;, (var1 = Class.forName(\"java.lang.Object\")).getDeclaredMethods()); CGLIB$equals$1$Method = var10000[0]; CGLIB$equals$1$Proxy = MethodProxy.create(var1, var0, \"(Ljava/lang/Object;)Z\", \"equals\", \"CGLIB$equals$1\"); CGLIB$toString$2$Method = var10000[1]; CGLIB$toString$2$Proxy = MethodProxy.create(var1, var0, \"()Ljava/lang/String;\", \"toString\", \"CGLIB$toString$2\"); CGLIB$hashCode$3$Method = var10000[2]; CGLIB$hashCode$3$Proxy = MethodProxy.create(var1, var0, \"()I\", \"hashCode\", \"CGLIB$hashCode$3\"); CGLIB$clone$4$Method = var10000[3]; CGLIB$clone$4$Proxy = MethodProxy.create(var1, var0, \"()Ljava/lang/Object;\", \"clone\", \"CGLIB$clone$4\"); CGLIB$sayHello$0$Method = ReflectUtils.findMethods(new String[]&#123;\"sayHello\", \"(Ljava/lang/String;)Ljava/lang/String;\"&#125;, (var1 = Class.forName(\"club.throwable.cglib.SampleClass\")).getDeclaredMethods())[0]; CGLIB$sayHello$0$Proxy = MethodProxy.create(var1, var0, \"(Ljava/lang/String;)Ljava/lang/String;\", \"sayHello\", \"CGLIB$sayHello$0\"); &#125; //这个方法就是直接调用原来的被代理类(父类)的方法 final String CGLIB$sayHello$0(String var1) &#123; return super.sayHello(var1); &#125; //这个方法就是通过方法代理进行回调，里面用到了Callback实例 public final String sayHello(String var1) &#123; MethodInterceptor var10000 = this.CGLIB$CALLBACK_0; if (this.CGLIB$CALLBACK_0 == null) &#123; CGLIB$BIND_CALLBACKS(this); var10000 = this.CGLIB$CALLBACK_0; &#125; return var10000 != null ? (String)var10000.intercept(this, CGLIB$sayHello$0$Method, new Object[]&#123;var1&#125;, CGLIB$sayHello$0$Proxy) : super.sayHello(var1); &#125; final boolean CGLIB$equals$1(Object var1) &#123; return super.equals(var1); &#125; public final boolean equals(Object var1) &#123; MethodInterceptor var10000 = this.CGLIB$CALLBACK_0; if (this.CGLIB$CALLBACK_0 == null) &#123; CGLIB$BIND_CALLBACKS(this); var10000 = this.CGLIB$CALLBACK_0; &#125; if (var10000 != null) &#123; Object var2 = var10000.intercept(this, CGLIB$equals$1$Method, new Object[]&#123;var1&#125;, CGLIB$equals$1$Proxy); return var2 == null ? false : (Boolean)var2; &#125; else &#123; return super.equals(var1); &#125; &#125; final String CGLIB$toString$2() &#123; return super.toString(); &#125; public final String toString() &#123; MethodInterceptor var10000 = this.CGLIB$CALLBACK_0; if (this.CGLIB$CALLBACK_0 == null) &#123; CGLIB$BIND_CALLBACKS(this); var10000 = this.CGLIB$CALLBACK_0; &#125; return var10000 != null ? (String)var10000.intercept(this, CGLIB$toString$2$Method, CGLIB$emptyArgs, CGLIB$toString$2$Proxy) : super.toString(); &#125; final int CGLIB$hashCode$3() &#123; return super.hashCode(); &#125; public final int hashCode() &#123; MethodInterceptor var10000 = this.CGLIB$CALLBACK_0; if (this.CGLIB$CALLBACK_0 == null) &#123; CGLIB$BIND_CALLBACKS(this); var10000 = this.CGLIB$CALLBACK_0; &#125; if (var10000 != null) &#123; Object var1 = var10000.intercept(this, CGLIB$hashCode$3$Method, CGLIB$emptyArgs, CGLIB$hashCode$3$Proxy); return var1 == null ? 0 : ((Number)var1).intValue(); &#125; else &#123; return super.hashCode(); &#125; &#125; final Object CGLIB$clone$4() throws CloneNotSupportedException &#123; return super.clone(); &#125; protected final Object clone() throws CloneNotSupportedException &#123; MethodInterceptor var10000 = this.CGLIB$CALLBACK_0; if (this.CGLIB$CALLBACK_0 == null) &#123; CGLIB$BIND_CALLBACKS(this); var10000 = this.CGLIB$CALLBACK_0; &#125; return var10000 != null ? var10000.intercept(this, CGLIB$clone$4$Method, CGLIB$emptyArgs, CGLIB$clone$4$Proxy) : super.clone(); &#125; public static MethodProxy CGLIB$findMethodProxy(Signature var0) &#123; String var10000 = var0.toString(); switch(var10000.hashCode()) &#123; case -1816210712: if (var10000.equals(\"sayHello(Ljava/lang/String;)Ljava/lang/String;\")) &#123; return CGLIB$sayHello$0$Proxy; &#125; break; case -508378822: if (var10000.equals(\"clone()Ljava/lang/Object;\")) &#123; return CGLIB$clone$4$Proxy; &#125; break; case 1826985398: if (var10000.equals(\"equals(Ljava/lang/Object;)Z\")) &#123; return CGLIB$equals$1$Proxy; &#125; break; case 1913648695: if (var10000.equals(\"toString()Ljava/lang/String;\")) &#123; return CGLIB$toString$2$Proxy; &#125; break; case 1984935277: if (var10000.equals(\"hashCode()I\")) &#123; return CGLIB$hashCode$3$Proxy; &#125; &#125; return null; &#125; public SampleClass$$EnhancerByCGLIB$$53c7afed() &#123; CGLIB$BIND_CALLBACKS(this); &#125; public static void CGLIB$SET_THREAD_CALLBACKS(Callback[] var0) &#123; CGLIB$THREAD_CALLBACKS.set(var0); &#125; public static void CGLIB$SET_STATIC_CALLBACKS(Callback[] var0) &#123; CGLIB$STATIC_CALLBACKS = var0; &#125; private static final void CGLIB$BIND_CALLBACKS(Object var0) &#123; SampleClass$$EnhancerByCGLIB$$53c7afed var1 = (SampleClass$$EnhancerByCGLIB$$53c7afed)var0; if (!var1.CGLIB$BOUND) &#123; var1.CGLIB$BOUND = true; Object var10000 = CGLIB$THREAD_CALLBACKS.get(); if (var10000 == null) &#123; var10000 = CGLIB$STATIC_CALLBACKS; if (CGLIB$STATIC_CALLBACKS == null) &#123; return; &#125; &#125; var1.CGLIB$CALLBACK_0 = (MethodInterceptor)((Callback[])var10000)[0]; &#125; &#125; public Object newInstance(Callback[] var1) &#123; CGLIB$SET_THREAD_CALLBACKS(var1); SampleClass$$EnhancerByCGLIB$$53c7afed var10000 = new SampleClass$$EnhancerByCGLIB$$53c7afed(); CGLIB$SET_THREAD_CALLBACKS((Callback[])null); return var10000; &#125; public Object newInstance(Callback var1) &#123; CGLIB$SET_THREAD_CALLBACKS(new Callback[]&#123;var1&#125;); SampleClass$$EnhancerByCGLIB$$53c7afed var10000 = new SampleClass$$EnhancerByCGLIB$$53c7afed(); CGLIB$SET_THREAD_CALLBACKS((Callback[])null); return var10000; &#125; public Object newInstance(Class[] var1, Object[] var2, Callback[] var3) &#123; CGLIB$SET_THREAD_CALLBACKS(var3); SampleClass$$EnhancerByCGLIB$$53c7afed var10000 = new SampleClass$$EnhancerByCGLIB$$53c7afed; switch(var1.length) &#123; case 0: var10000.&lt;init&gt;(); CGLIB$SET_THREAD_CALLBACKS((Callback[])null); return var10000; default: throw new IllegalArgumentException(\"Constructor not found\"); &#125; &#125; public Callback getCallback(int var1) &#123; CGLIB$BIND_CALLBACKS(this); MethodInterceptor var10000; switch(var1) &#123; case 0: var10000 = this.CGLIB$CALLBACK_0; break; default: var10000 = null; &#125; return var10000; &#125; public void setCallback(int var1, Callback var2) &#123; switch(var1) &#123; case 0: this.CGLIB$CALLBACK_0 = (MethodInterceptor)var2; default: &#125; &#125; public Callback[] getCallbacks() &#123; CGLIB$BIND_CALLBACKS(this); return new Callback[]&#123;this.CGLIB$CALLBACK_0&#125;; &#125; public void setCallbacks(Callback[] var1) &#123; this.CGLIB$CALLBACK_0 = (MethodInterceptor)var1[0]; &#125; static &#123; CGLIB$STATICHOOK1(); &#125;&#125; 这个类十分长，因为里面有很多的变量，它们都通过了静态代码块使用反射初始化。类的代码比JDK动态代理的子类多，因此生成效率会比较低。相关比较重要的注释已经写在类中，我们最主要关注两点： 第一点： 12private static final Method CGLIB$sayHello$0$Method;private static final MethodProxy CGLIB$sayHello$0$Proxy; 这两个静态变量都是指向sayHello这个方法，CGLIB$sayHello$0$Method直接指向父类方法，CGLIB$sayHello$0$Proxy是CGLIB生成的方法代理。 第二点： 1234567891011121314//这个方法就是直接调用原来的被代理类(父类)的方法final String CGLIB$sayHello$0(String var1) &#123; return super.sayHello(var1);&#125;//这个方法就是通过方法代理进行回调，里面用到了Callback实例public final String sayHello(String var1) &#123; MethodInterceptor var10000 = this.CGLIB$CALLBACK_0; if (this.CGLIB$CALLBACK_0 == null) &#123; CGLIB$BIND_CALLBACKS(this); var10000 = this.CGLIB$CALLBACK_0; &#125; //如果找不到Callback会直接调用父类的原方法 return var10000 != null ? (String)var10000.intercept(this, CGLIB$sayHello$0$Method, new Object[]&#123;var1&#125;, CGLIB$sayHello$0$Proxy) : super.sayHello(var1);&#125; 也就是如果想要启用CGLIB的回调，我们主观上应该是这样操作的： 12SampleClass$$EnhancerByCGLIB$$53c7afed sample = new SampleClass$$EnhancerByCGLIB$$53c7afed();sample.sayHello(\"doge\"); 但是由于这个代理类是动态生成的，只能通过反射调用。 那么，剩下的两个FastClass的作用是什么？我们先看一下MethodProxy的invoke()和invokeSuper()方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344 //初始化FastClass中的index索引 private void init() &#123; if (this.fastClassInfo == null) &#123; Object var1 = this.initLock; synchronized(this.initLock) &#123; if (this.fastClassInfo == null) &#123; MethodProxy.CreateInfo ci = this.createInfo; MethodProxy.FastClassInfo fci = new MethodProxy.FastClassInfo(); fci.f1 = helper(ci, ci.c1); fci.f2 = helper(ci, ci.c2); fci.i1 = fci.f1.getIndex(this.sig1); fci.i2 = fci.f2.getIndex(this.sig2); this.fastClassInfo = fci; this.createInfo = null; &#125; &#125; &#125; &#125;public Object invoke(Object obj, Object[] args) throws Throwable &#123; try &#123; this.init(); MethodProxy.FastClassInfo fci = this.fastClassInfo; return fci.f1.invoke(fci.i1, obj, args); &#125; catch (InvocationTargetException var4) &#123; throw var4.getTargetException(); &#125; catch (IllegalArgumentException var5) &#123; if (this.fastClassInfo.i1 &lt; 0) &#123; throw new IllegalArgumentException(\"Protected method: \" + this.sig1); &#125; else &#123; throw var5; &#125; &#125; &#125; public Object invokeSuper(Object obj, Object[] args) throws Throwable &#123; try &#123; this.init(); MethodProxy.FastClassInfo fci = this.fastClassInfo; return fci.f2.invoke(fci.i2, obj, args); &#125; catch (InvocationTargetException var4) &#123; throw var4.getTargetException(); &#125; &#125; 这里，两个方法各自使用了不同的FastClassInfo实例fci.f2和fci.f2。其中，SampleClass$$FastClassByCGLIB$$cf1a549b.class是对应于父类，而SampleClass$$EnhancerByCGLIB$$53c7afed$$FastClassByCGLIB$$da5c8621是对应于CGLIB生成的被代理类的子类。下面展开SampleClass$$EnhancerByCGLIB$$53c7afed$$FastClassByCGLIB$$da5c8621的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405public class SampleClass$$EnhancerByCGLIB$$53c7afed$$FastClassByCGLIB$$da5c8621 extends FastClass &#123; public SampleClass$$EnhancerByCGLIB$$53c7afed$$FastClassByCGLIB$$da5c8621(Class var1) &#123; super(var1); &#125; public int getIndex(Signature var1) &#123; String var10000 = var1.toString(); switch(var10000.hashCode()) &#123; case -2055565910: if (var10000.equals(\"CGLIB$SET_THREAD_CALLBACKS([Lnet/sf/cglib/proxy/Callback;)V\")) &#123; return 10; &#125; break; case -1882565338: if (var10000.equals(\"CGLIB$equals$1(Ljava/lang/Object;)Z\")) &#123; return 18; &#125; break; case -1816210712: if (var10000.equals(\"sayHello(Ljava/lang/String;)Ljava/lang/String;\")) &#123; return 7; &#125; break; case -1457535688: if (var10000.equals(\"CGLIB$STATICHOOK1()V\")) &#123; return 15; &#125; break; case -1411842725: if (var10000.equals(\"CGLIB$hashCode$3()I\")) &#123; return 19; &#125; break; case -894172689: if (var10000.equals(\"newInstance(Lnet/sf/cglib/proxy/Callback;)Ljava/lang/Object;\")) &#123; return 5; &#125; break; case -623122092: if (var10000.equals(\"CGLIB$findMethodProxy(Lnet/sf/cglib/core/Signature;)Lnet/sf/cglib/proxy/MethodProxy;\")) &#123; return 14; &#125; break; case -508378822: if (var10000.equals(\"clone()Ljava/lang/Object;\")) &#123; return 3; &#125; break; case -419626537: if (var10000.equals(\"setCallbacks([Lnet/sf/cglib/proxy/Callback;)V\")) &#123; return 13; &#125; break; case 560567118: if (var10000.equals(\"setCallback(ILnet/sf/cglib/proxy/Callback;)V\")) &#123; return 8; &#125; break; case 811063227: if (var10000.equals(\"newInstance([Ljava/lang/Class;[Ljava/lang/Object;[Lnet/sf/cglib/proxy/Callback;)Ljava/lang/Object;\")) &#123; return 6; &#125; break; case 973717575: if (var10000.equals(\"getCallbacks()[Lnet/sf/cglib/proxy/Callback;\")) &#123; return 11; &#125; break; case 1221173700: if (var10000.equals(\"newInstance([Lnet/sf/cglib/proxy/Callback;)Ljava/lang/Object;\")) &#123; return 4; &#125; break; case 1230699260: if (var10000.equals(\"getCallback(I)Lnet/sf/cglib/proxy/Callback;\")) &#123; return 12; &#125; break; case 1298742135: if (var10000.equals(\"CGLIB$sayHello$0(Ljava/lang/String;)Ljava/lang/String;\")) &#123; return 16; &#125; break; case 1306468936: if (var10000.equals(\"CGLIB$toString$2()Ljava/lang/String;\")) &#123; return 20; &#125; break; case 1584330438: if (var10000.equals(\"CGLIB$SET_STATIC_CALLBACKS([Lnet/sf/cglib/proxy/Callback;)V\")) &#123; return 9; &#125; break; case 1800494055: if (var10000.equals(\"CGLIB$clone$4()Ljava/lang/Object;\")) &#123; return 17; &#125; break; case 1826985398: if (var10000.equals(\"equals(Ljava/lang/Object;)Z\")) &#123; return 0; &#125; break; case 1913648695: if (var10000.equals(\"toString()Ljava/lang/String;\")) &#123; return 1; &#125; break; case 1984935277: if (var10000.equals(\"hashCode()I\")) &#123; return 2; &#125; &#125; return -1; &#125; public int getIndex(String var1, Class[] var2) &#123; switch(var1.hashCode()) &#123; case -2012993625: if (var1.equals(\"sayHello\")) &#123; switch(var2.length) &#123; case 1: if (var2[0].getName().equals(\"java.lang.String\")) &#123; return 7; &#125; &#125; &#125; break; case -1983192202: if (var1.equals(\"CGLIB$sayHello$0\")) &#123; switch(var2.length) &#123; case 1: if (var2[0].getName().equals(\"java.lang.String\")) &#123; return 16; &#125; &#125; &#125; break; case -1776922004: if (var1.equals(\"toString\")) &#123; switch(var2.length) &#123; case 0: return 1; &#125; &#125; break; case -1295482945: if (var1.equals(\"equals\")) &#123; switch(var2.length) &#123; case 1: if (var2[0].getName().equals(\"java.lang.Object\")) &#123; return 0; &#125; &#125; &#125; break; case -1053468136: if (var1.equals(\"getCallbacks\")) &#123; switch(var2.length) &#123; case 0: return 11; &#125; &#125; break; case -124978609: if (var1.equals(\"CGLIB$equals$1\")) &#123; switch(var2.length) &#123; case 1: if (var2[0].getName().equals(\"java.lang.Object\")) &#123; return 18; &#125; &#125; &#125; break; case -60403779: if (var1.equals(\"CGLIB$SET_STATIC_CALLBACKS\")) &#123; switch(var2.length) &#123; case 1: if (var2[0].getName().equals(\"[Lnet.sf.cglib.proxy.Callback;\")) &#123; return 9; &#125; &#125; &#125; break; case -29025555: if (var1.equals(\"CGLIB$hashCode$3\")) &#123; switch(var2.length) &#123; case 0: return 19; &#125; &#125; break; case 85179481: if (var1.equals(\"CGLIB$SET_THREAD_CALLBACKS\")) &#123; switch(var2.length) &#123; case 1: if (var2[0].getName().equals(\"[Lnet.sf.cglib.proxy.Callback;\")) &#123; return 10; &#125; &#125; &#125; break; case 94756189: if (var1.equals(\"clone\")) &#123; switch(var2.length) &#123; case 0: return 3; &#125; &#125; break; case 147696667: if (var1.equals(\"hashCode\")) &#123; switch(var2.length) &#123; case 0: return 2; &#125; &#125; break; case 161998109: if (var1.equals(\"CGLIB$STATICHOOK1\")) &#123; switch(var2.length) &#123; case 0: return 15; &#125; &#125; break; case 495524492: if (var1.equals(\"setCallbacks\")) &#123; switch(var2.length) &#123; case 1: if (var2[0].getName().equals(\"[Lnet.sf.cglib.proxy.Callback;\")) &#123; return 13; &#125; &#125; &#125; break; case 1154623345: if (var1.equals(\"CGLIB$findMethodProxy\")) &#123; switch(var2.length) &#123; case 1: if (var2[0].getName().equals(\"net.sf.cglib.core.Signature\")) &#123; return 14; &#125; &#125; &#125; break; case 1543336189: if (var1.equals(\"CGLIB$toString$2\")) &#123; switch(var2.length) &#123; case 0: return 20; &#125; &#125; break; case 1811874389: if (var1.equals(\"newInstance\")) &#123; switch(var2.length) &#123; case 1: String var10001 = var2[0].getName(); switch(var10001.hashCode()) &#123; case -845341380: if (var10001.equals(\"net.sf.cglib.proxy.Callback\")) &#123; return 5; &#125; break; case 1730110032: if (var10001.equals(\"[Lnet.sf.cglib.proxy.Callback;\")) &#123; return 4; &#125; &#125; case 2: default: break; case 3: if (var2[0].getName().equals(\"[Ljava.lang.Class;\") &amp;&amp; var2[1].getName().equals(\"[Ljava.lang.Object;\") &amp;&amp; var2[2].getName().equals(\"[Lnet.sf.cglib.proxy.Callback;\")) &#123; return 6; &#125; &#125; &#125; break; case 1817099975: if (var1.equals(\"setCallback\")) &#123; switch(var2.length) &#123; case 2: if (var2[0].getName().equals(\"int\") &amp;&amp; var2[1].getName().equals(\"net.sf.cglib.proxy.Callback\")) &#123; return 8; &#125; &#125; &#125; break; case 1905679803: if (var1.equals(\"getCallback\")) &#123; switch(var2.length) &#123; case 1: if (var2[0].getName().equals(\"int\")) &#123; return 12; &#125; &#125; &#125; break; case 1951977610: if (var1.equals(\"CGLIB$clone$4\")) &#123; switch(var2.length) &#123; case 0: return 17; &#125; &#125; &#125; return -1; &#125; public int getIndex(Class[] var1) &#123; switch(var1.length) &#123; case 0: return 0; default: return -1; &#125; &#125; public Object invoke(int var1, Object var2, Object[] var3) throws InvocationTargetException &#123; 53c7afed var10000 = (53c7afed)var2; int var10001 = var1; try &#123; switch(var10001) &#123; case 0: return new Boolean(var10000.equals(var3[0])); case 1: return var10000.toString(); case 2: return new Integer(var10000.hashCode()); case 3: return var10000.clone(); case 4: return var10000.newInstance((Callback[])var3[0]); case 5: return var10000.newInstance((Callback)var3[0]); case 6: return var10000.newInstance((Class[])var3[0], (Object[])var3[1], (Callback[])var3[2]); case 7: return var10000.sayHello((String)var3[0]); case 8: var10000.setCallback(((Number)var3[0]).intValue(), (Callback)var3[1]); return null; case 9: 53c7afed.CGLIB$SET_STATIC_CALLBACKS((Callback[])var3[0]); return null; case 10: 53c7afed.CGLIB$SET_THREAD_CALLBACKS((Callback[])var3[0]); return null; case 11: return var10000.getCallbacks(); case 12: return var10000.getCallback(((Number)var3[0]).intValue()); case 13: var10000.setCallbacks((Callback[])var3[0]); return null; case 14: return 53c7afed.CGLIB$findMethodProxy((Signature)var3[0]); case 15: 53c7afed.CGLIB$STATICHOOK1(); return null; case 16: return var10000.CGLIB$sayHello$0((String)var3[0]); case 17: return var10000.CGLIB$clone$4(); case 18: return new Boolean(var10000.CGLIB$equals$1(var3[0])); case 19: return new Integer(var10000.CGLIB$hashCode$3()); case 20: return var10000.CGLIB$toString$2(); &#125; &#125; catch (Throwable var4) &#123; throw new InvocationTargetException(var4); &#125; throw new IllegalArgumentException(\"Cannot find matching method/constructor\"); &#125; public Object newInstance(int var1, Object[] var2) throws InvocationTargetException &#123; 53c7afed var10000 = new 53c7afed; 53c7afed var10001 = var10000; int var10002 = var1; try &#123; switch(var10002) &#123; case 0: var10001.&lt;init&gt;(); return var10000; &#125; &#125; catch (Throwable var3) &#123; throw new InvocationTargetException(var3); &#125; throw new IllegalArgumentException(\"Cannot find matching method/constructor\"); &#125; public int getMaxIndex() &#123; return 20; &#125;&#125; 这个类更加长，但是其实大部分都是switch-case的代码块，它的功能就是为方法的调用添加基于整型数字的索引，主要目的是为了减少反射调用的时间，将反射调用转化为直接调用。简单来说，invokeSuper的流程就是这样的： 通过MethodProxy的init方法，用当前方法的Signature(签名)构建两个FastClass实例(当然，这里会做缓存)和当前方法对应的index，存放在FastClassInfo实例中。 通过FastClassInfo中的FastClass实例和index，在FastClass中找到对应的方法(在switch-case块中基于整数索引index进行查找)直接调用。 直观来看，CGLIB在类生成期间的操作会相对耗时，而且生成的类数目比较多，会占据大量永久代或者元空间的内存。子类一旦生成，后面的方法调用就会变成搜索方法索引和直接调用，这样的操作在特定的条件下效率会比JDK的反射高。这里特定的场景是指CGLIB子类中的switch-case块不大并且当前调用的方法的index在switch-case块的前部而不是中后部(简单来说就是子类中的方法要尽量少从而提高switch-case中的搜寻效率)。详细可以参考这篇性能对比的文章：cglib和jdk动态代理调用性能测 小结 CGLIB提供了许多基于代码生成的高级功能的API，可以在通过上面的例子熟悉它的使用，并且在合适的场景用于实战中。可能最常用到的是基于Enhancer的动态代理，这里总结一下CGLIB和JDK动态代理的区别(老生常谈)： JDK动态代理只能够对接口进行代理，不能对普通的类进行代理（因为所有生成的代理类的父类为Proxy，Java类继承机制不允许多重继承）；CGLIB能够代理普通类，但是该普通类必须能够被继承(不能用final修饰符)。 JDK动态代理使用Java原生的反射API进行操作，在生成类上比较高效；CGLIB使用ASM框架直接对字节码进行修改，使用了FastClass的特性，在某些情况下类的方法执行会比较高效。 (本文完 e-a-20181216 c-1-d)","categories":[{"name":"Framework","slug":"Framework","permalink":"http://throwable.club/blog/categories/Framework/"},{"name":"Cglib","slug":"Framework/Cglib","permalink":"http://throwable.club/blog/categories/Framework/Cglib/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Cglib","slug":"Cglib","permalink":"http://throwable.club/blog/tags/Cglib/"}]},{"title":"简述CGLIB常用API","slug":"cglib-api","date":"2018-12-16T08:52:35.000Z","updated":"2018-12-16T08:55:12.514Z","comments":true,"path":"2018/12/16/cglib-api/","link":"","permalink":"http://throwable.club/2018/12/16/cglib-api/","excerpt":"","text":"简述CGLIB常用API CGLIB简介 CGLIB，即Code Generation Library，是一个强大的、高性能的代码生成库。其被广泛应用于AOP框架（例如Spring）中，用以提供方法拦截操作。Hibernate作为一个比较受欢迎的ORM框架，同样使用CGLIB来代理单端（多对一和一对一）关联（延迟提取集合使用的另一种机制）。CGLIB作为一个开源项目，其代码托管在github，地址为：https://github.com/cglib/cglib。 CGLIB的github简介：CGLIB - 字节码生成库，是用于生成和转换Java字节码的高级API。它被AOP、测试、数据访问框架用于生成动态代理对象和拦截字段访问。(原文：cglib - Byte Code Generation Library is high level API to generate and transform Java byte code. It is used by AOP, testing, data access frameworks to generate dynamic proxy objects and intercept field access.) CGLIB提供两种类型的JAR包： cglib-nodep-x.x.x.jar：使用nodep包不需要关联ASM的jar包，也就是jar包内部包含ASM的类库。 cglib-x.x.x.jar：使用此jar包需要另外提供ASM的jar包，否则运行时报错，建议选用不包含ASM类库的jar包，可以方便控制ASM的。 本文中使用的CGLIB依赖为： 12345678910&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib-nodep&lt;/artifactId&gt; &lt;version&gt;3.2.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.22&lt;/version&gt;&lt;/dependency&gt; CGLIB基本原理 基本原理：动态生成一个要代理类的子类(被代理的类作为继承的父类)，子类重写要代理的类的所有不是final的方法。在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑。它比使用Java反射的JDK动态代理要快，因为它采用了整形变量建立了方法索引。 底层实现：使用字节码处理框架ASM，用于转换字节码并生成新的类。不鼓励直接使用ASM，因为它要求必须对JVM内部结构包括class文件的格式和JVM指令集都很熟悉，否则一旦出现错误将会是JVM崩溃级别的异常。 劣势：对于final方法或者final的类，无法进行代理。 CGLIB的包结构 net.sf.cglib.core：底层字节码处理类，它们大部分与ASM有关系，在使用者角度来看不需要过多关注此包。 net.sf.cglib.transform：编译期或运行期类和类文件的转换。 net.sf.cglib.proxy：实现创建代理和方法拦截器的类。 net.sf.cglib.reflect：反射相关工具类。 net.sf.cglib.util：集合排序等工具类。 net.sf.cglib.beans：JavaBean相关的工具类。 CGLIB常用API介绍 下面介绍一下CGLIB中常用的API，先建立一个模特接口类和普通模特类： 1234567891011public class SampleClass &#123; public String sayHello(String name) &#123; return String.format(\"%s say hello!\", name); &#125;&#125;public interface SampleInterface &#123; String sayHello(String name);&#125; Enhancer Enhancer，即(字节码)增强器。它是CGLIB库中最常用的一个类，功能JDK动态代理中引入的Proxy类差不多，但是Enhancer既能够代理普通的Java类，也能够代理接口。Enhancer创建一个被代理对象的子类并且拦截所有的方法调用（包括从Object中继承的toString和hashCode方法）。Enhancer不能够拦截final方法，例如Object.getClass()方法，这是由于final关键字的语义决定的。基于同样的道理，Enhancer也不能对fianl类进行代理操作。这也是Hibernate为什么不能持久化final关键字修饰的类的原因。 123456789101112131415public class EnhancerClassDemo &#123; public static void main(String[] args) throws Exception &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(SampleClass.class); //使用FixedValue，拦截返回值，每次返回固定值\"Doge say hello!\" enhancer.setCallback((FixedValue) () -&gt; \"Doge say hello!\"); SampleClass sampleClass = (SampleClass) enhancer.create(); System.out.println(sampleClass.sayHello(\"throwable-10086\")); System.out.println(sampleClass.sayHello(\"throwable-doge\")); System.out.println(sampleClass.toString()); System.out.println(sampleClass.getClass()); System.out.println(sampleClass.hashCode()); &#125;&#125; 输出结果： 123456Doge say hello!Doge say hello!Doge say hello!class club.throwable.cglib.SampleClass$$EnhancerByCGLIB$$6f6e7a68Exception in thread \"main\" java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Number...... 上述代码中，FixedValue用来对所有拦截的方法返回相同的值，从输出我们可以看出来，Enhancer对非final方法test()、toString()、hashCode()进行了拦截，没有对getClass进行拦截。由于hashCode()方法需要返回一个Number，但是我们返回的是一个String，这解释了上面的程序中为什么会抛出异常。 Enhancer3setSuperclass()用来设置父类型，从toString()方法可以看出，使用CGLIB生成的类为被代理类的一个子类，类简写名称为SampleClass$$EnhancerByCGLIB$$e3ea9b7。 Enhancer#create(Class[] argumentTypes, Object[] arguments)方法是用来创建增强对象的，其提供了很多不同参数的方法用来匹配被增强类的不同构造方法。我们也可以先使用Enhancer#createClass()来创建字节码(.class)，然后用字节码加载完成后的类动态生成增强后的对象。Enhancer中还有其他几个方法名为create的方法，提供不同的参数选择，具体可以自行查阅。 下面再举个例子说明一下使用Enhancer代理接口： 1234567891011121314public class EnhancerInterfaceDemo &#123; public static void main(String[] args) throws Exception &#123; Enhancer enhancer = new Enhancer(); enhancer.setInterfaces(new Class[]&#123;SampleInterface.class&#125;); enhancer.setCallback((FixedValue) () -&gt; \"Doge say hello!\"); SampleInterface sampleInterface = (SampleInterface) enhancer.create(); System.out.println(sampleInterface.sayHello(\"throwable-10086\")); System.out.println(sampleInterface.sayHello(\"throwable-doge\")); System.out.println(sampleInterface.toString()); System.out.println(sampleInterface.getClass()); System.out.println(sampleInterface.hashCode()); &#125;&#125; 输出结果和上一个例子一致。 Callback Callback，即回调。值得注意的是，它是一个标识接口(空接口，没有任何方法)，它的回调时机是生成的代理类的方法被调用的时候。也就是说，生成的代理类的方法被调用的时候，Callback的实现逻辑就会被调用。Enhancer通过setCallback()和setCallbacks()设置Callback，设置了多个Callback实例将会按照设置的顺序进行回调。CGLIB中提供的Callback的子类有以下几种： NoOp FixedValue InvocationHandler MethodInterceptor Dispatcher LazyLoader NoOp NoOp，No Operation，也就是不做任何操作。这个回调实现只是简单地把方法调用委托给了被代理类的原方法(也就是调用原始类的原始方法)，不做任何其它的操作，所以不能使用在接口代理。 12345678910public class NoOpDemo &#123; public static void main(String[] args) throws Exception&#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(SampleClass.class); enhancer.setCallback(NoOp.INSTANCE); SampleClass sampleClass = (SampleClass) enhancer.create(); System.out.println(sampleClass.sayHello(\"throwable\")); &#125;&#125; 输出结果： 1throwable say hello! FixedValue FixedValue，Fixed Value，即固定值。它提供了一个loadObject()方法，不过这个方法返回的不是代理对象，而是原方法调用想要的结果。也就是说，在这个Callback里面，看不到任何原方法的信息，也就没有调用原方法的逻辑，不管原方法是什么都只会调用loadObject()并返回一个固定结果。需要注意的是，如果loadObject()方法的返回值并不能转换成原方法的返回值类型，那么会抛出类型转换异常(ClassCastException)。 最前面的Enhancer两个例子就是用FixedValue做分析的，这里不再举例。 InvocationHandler InvocationHandler全类名为net.sf.cglib.proxy.InvocationHandler，它的功能和JDK动态代理中的java.lang.reflect.InvocationHandler类似，提供了一个Object invoke(Object proxy, Method method, Object[] objects)方法。需要注意的是：所有对invoke方法的参数proxy对象的方法调用都会被委托给同一个InvocationHandler，所以可能会导致无限循环(因为invoke中调用的任何原代理类方法，均会重新代理到invoke方法中)。举个简单的例子： 123456789101112131415public class InvocationHandlerDeadLoopDemo &#123; public static void main(String[] args) throws Exception&#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(SampleClass.class); enhancer.setCallback(new InvocationHandler() &#123; @Override public Object invoke(Object o, Method method, Object[] objects) throws Throwable &#123; return method.invoke(o, objects); &#125; &#125;); SampleClass sampleClass = (SampleClass) enhancer.create(); System.out.println(sampleClass.sayHello(\"throwable\")); &#125;&#125; 上面的main方法执行后会直接爆栈，因为method#invoke()方法会重新调用InvocationHandler的invoke方法，形成死循环。正确的使用例子如下： 123456789101112131415161718public class InvocationHandlerDemo &#123; public static void main(String[] args) throws Exception &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(SampleClass.class); enhancer.setCallback(new InvocationHandler() &#123; @Override public Object invoke(Object o, Method method, Object[] objects) throws Throwable &#123; if (!Objects.equals(method.getDeclaringClass(), Object.class) &amp;&amp; Objects.equals(String.class, method.getReturnType())) &#123; return String.format(\"%s say hello!\", objects); &#125; return \"No one say hello!\"; &#125; &#125;); SampleClass sampleClass = (SampleClass) enhancer.create(); System.out.println(sampleClass.sayHello(\"throwable\")); &#125;&#125; 输出结果： 1throwable say hello! MethodInterceptor MethodInterceptor，即方法拦截器，这是一个功能很强大的接口，它可以实现类似于AOP编程中的环绕增强（Around Advice）。它只有一个方法public Object intercept(Object obj,java.lang.reflect.Method method,Object[] args,MethodProxy methodProxy) throws Throwable。设置了MethodInterceptor后，代理类的所有方法调用都会转而执行这个接口中的intercept方法而不是原方法。如果需要在intercept方法中执行原方法可以使用参数method基于代理实例obj进行反射调用，但是使用方法代理methodProxy效率会更高（反射调用比正常的方法调用的速度慢很多）。MethodInterceptor的生成效率不高，它的优势在于调用效率，它需要产生不同类型的字节码，并且需要生成一些运行时对象(InvocationHandler就不需要)。注意，在使用MethodProxy调用invokeSuper方法相当于通过方法代理直接调用原类的对应方法，如果调用MethodProxy的invoke会进入死循环导致爆栈，原因跟InvocationHandler差不多。 123456789101112131415161718public class MethodInterceptorDemo &#123; public static void main(String[] args) throws Exception &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(SampleClass.class); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object obj, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(\"Before invoking sayHello...\"); Object result = methodProxy.invokeSuper(obj, objects); System.out.println(\"After invoking sayHello...\"); return result; &#125; &#125;); SampleClass sampleClass = (SampleClass) enhancer.create(); System.out.println(sampleClass.sayHello(\"throwable\")); &#125;&#125; 输出结果： 123Before invoking sayHello...After invoking sayHello...throwable say hello! 这个例子就是Spring的AOP中的环绕增强(Around Advice)的简化版，这里没有改变原来的方法的行为，只是在方法调用前和调用后织入额外的逻辑。 Dispatcher Dispatcher，即分发器，提供一个方法Object loadObject() throws Exception;，同样地返回一个代理对象，这个对象同样可以代理原方法的调用。Dispatcher的loadObject()方法在每次发生对原方法的调用时都会被调用并返回一个代理对象来调用原方法。Dispatcher可以类比为Spring中的Prototype类型。 123456789101112131415161718192021222324252627282930313233public class DispatcherDemo &#123; private static final AtomicInteger COUNTER = new AtomicInteger(0); public static void main(String[] args) throws Exception &#123; Enhancer enhancer = new Enhancer(); SampleInterfaceImpl impl = new SampleInterfaceImpl(); enhancer.setInterfaces(new Class[]&#123;SampleInterface.class&#125;); enhancer.setCallback(new Dispatcher() &#123; @Override public Object loadObject() throws Exception &#123; COUNTER.incrementAndGet(); return impl; &#125; &#125;); SampleInterface sampleInterface = (SampleInterface) enhancer.create(); System.out.println(sampleInterface.sayHello(\"throwable-1\")); System.out.println(sampleInterface.sayHello(\"throwable-2\")); System.out.println(COUNTER.get()); &#125; private static class SampleInterfaceImpl implements SampleInterface&#123; public SampleInterfaceImpl()&#123; System.out.println(\"SampleInterfaceImpl init...\"); &#125; @Override public String sayHello(String name) &#123; return \"Hello i am SampleInterfaceImpl!\"; &#125; &#125;&#125; 输出结果： 1234SampleInterfaceImpl init...Hello i am SampleInterfaceImpl!Hello i am SampleInterfaceImpl!2 计数器输出为2，印证了每次调用方法都会回调Dispatcher中的实例进行调用。 LazyLoader LazyLoader，即懒加载器，它只提供了一个方法Object loadObject() throws Exception;，loadObject()方法会在第一次被代理类的方法调用时触发，它返回一个代理类的对象，这个对象会被存储起来然后负责所有被代理类方法的调用，就像它的名字说的那样，一种lazy加载模式。如果被代理类或者代理类的对象的创建比较麻烦，而且不确定它是否会被使用，那么可以选择使用这种lazy模式来延迟生成代理。LazyLoader可以类比为Spring中的Lazy模式的Singleton。 123456789101112131415161718192021222324252627282930313233public class LazyLoaderDemo &#123; private static final AtomicInteger COUNTER = new AtomicInteger(0); public static void main(String[] args) throws Exception &#123; Enhancer enhancer = new Enhancer(); SampleInterfaceImpl impl = new SampleInterfaceImpl(); enhancer.setInterfaces(new Class[]&#123;SampleInterface.class&#125;); enhancer.setCallback(new LazyLoader() &#123; @Override public Object loadObject() throws Exception &#123; COUNTER.incrementAndGet(); return impl; &#125; &#125;); SampleInterface sampleInterface = (SampleInterface) enhancer.create(); System.out.println(sampleInterface.sayHello(\"throwable-1\")); System.out.println(sampleInterface.sayHello(\"throwable-2\")); System.out.println(COUNTER.get()); &#125; private static class SampleInterfaceImpl implements SampleInterface&#123; public SampleInterfaceImpl()&#123; System.out.println(\"SampleInterfaceImpl init...\"); &#125; @Override public String sayHello(String name) &#123; return \"Hello i am SampleInterfaceImpl!\"; &#125; &#125;&#125; 输出结果： 1234SampleInterfaceImpl init...Hello i am SampleInterfaceImpl!Hello i am SampleInterfaceImpl!1 计数器输出为1，印证了LazyLoader中的实例只回调了1次，这就是懒加载。 BeanCopier JavaBean属性拷贝器，提供从一个JavaBean实例中拷贝属性到另一个JavaBean实例中，注意类型必须完全匹配属性才能拷贝成功(原始类型和其包装类不属于相同类型)。它还提供了一个net.sf.cglib.core.Converter转换器回调接口让使用者控制拷贝的过程。注意，BeanCopier内部使用了缓存和基于ASM动态生成BeanCopier的子类实现的转换方法中直接使用实例的Getter和Setter方法，拷贝速度极快(BeanCopier属性拷贝比直接的Setter、Getter稍慢，稍慢的原因在于首次需要动态生成BeanCopier的子类，一旦子类生成完成之后就和直接的Setter、Getter效率一致，但是效率远远高于其他使用反射的工具类库)。 123456789101112131415161718192021222324252627282930313233343536public class BeanCopierDemo &#123; private static final Map&lt;String, BeanCopier&gt; CACHE = new ConcurrentHashMap&lt;&gt;(); public static void main(String[] args) throws Exception &#123; //这里useConverter设置为false,调用copy方法的时候不能传入转换器实例 BeanCopier beanCopier; String key = generateCacheKey(Person.class, Person.class); if (CACHE.containsKey(key)) &#123; beanCopier = CACHE.get(key); &#125; else &#123; beanCopier = BeanCopier.create(Person.class, Person.class, false); CACHE.put(key, beanCopier); &#125; Person person = new Person(); person.setId(10086L); person.setName(\"throwable\"); person.setAge(25); Person newPerson = new Person(); beanCopier.copy(person, newPerson, null); //这里转换器实例要传null System.out.println(newPerson); &#125; private static String generateCacheKey(Class&lt;?&gt; source, Class&lt;?&gt; target) &#123; return String.format(\"%s-%s\", source.getName(), target.getName()); &#125; @ToString @Data private static class Person &#123; private Long id; private String name; private Integer age; &#125;&#125; 输出结果： 1BeanCopierDemo.Person(id=10086, name=throwable, age=25) 在使用BeanCopier时候最好缓存BeanCopier实例，因为构造BeanCopier实例是一个耗时的操作。 ImmutableBean ImmutableBean，即不可变的Bean。ImmutableBean允许创建一个原来对象的包装类，这个包装类是不可变的，任何改变底层对象的包装类操作都会抛出IllegalStateException。但是我们可以通过直接操作底层对象来改变包装类对象。这有点类似于Guava中的不可变视图或者JDK中的不可变集合。 12345678910111213141516171819public class ImmutableBeanDemo &#123; public static void main(String[] args) throws Exception &#123; Person person = new Person(); person.setName(\"throwable\"); Person immutablePerson = (Person) ImmutableBean.create(person); System.out.println(immutablePerson.getName()); person.setName(\"doge\"); System.out.println(immutablePerson.getName()); immutablePerson.setName(\"throwable-doge\"); System.out.println(immutablePerson.getName()); &#125; @Data private static class Person &#123; private String name; &#125;&#125; 输出结果: 1234throwabledogeException in thread \"main\" java.lang.IllegalStateException: Bean is immutable... BeanGenerator BeanGenerator，即Bean生成器，使用它能够在运行时动态的创建一个JavaBean。可以直接设置父类，生成的JavaBean就是父类类型的实例。 123456789101112public class BeanGeneratorDemo &#123; public static void main(String[] args) throws Exception &#123; BeanGenerator beanGenerator = new BeanGenerator(); beanGenerator.addProperty(\"name\", String.class); Object target = beanGenerator.create(); Method setter = target.getClass().getDeclaredMethod(\"setName\", String.class); Method getter = target.getClass().getDeclaredMethod(\"getName\"); setter.invoke(target, \"throwable\"); System.out.println(getter.invoke(target)); &#125;&#125; 输出结果： 1throwable BulkBean 相比于BeanCopier，BulkBean创建时候依赖于确定的目标类型，Setter和Getter方法名称列表以及参数类型，它将copy的动作拆分为getPropertyValues()和setPropertyValues()两个方法，允许自定义处理属性。 12345678910111213141516171819202122public class BulkBeanDemo &#123; public static void main(String[] args) throws Exception &#123; BulkBean bulkBean = BulkBean.create( Person.class, new String[]&#123;\"getName\"&#125;, new String[]&#123;\"setName\"&#125;, new Class[]&#123;String.class&#125;); Person person = new Person(); person.setName(\"throwable\"); Object[] propertyValues = bulkBean.getPropertyValues(person); System.out.println(Arrays.toString(propertyValues)); bulkBean.setPropertyValues(person, new Object[]&#123;\"doge\"&#125;); System.out.println(person.getName()); &#125; @Data private static class Person &#123; private String name; &#125;&#125; 输出结果： 12[throwable]doge BeanMap BeanMap类实现了JDK的java.util.Map接口，将一个JavaBean对象中的所有属性转换为一个String-To-Obejct的Map实例。 12345678910111213141516public class BeanMapDemo &#123; public static void main(String[] args) throws Exception&#123; Person person = new Person(); person.setName(\"throwable\"); BeanMap beanMap = BeanMap.create(person); System.out.println(beanMap); System.out.println(beanMap.get(\"name\")); &#125; @Data private static class Person &#123; private String name; &#125;&#125; 输出结果： 12&#123;name=throwable&#125;throwable KeyFactory KeyFactory源码中的注释是：Generates classes to handle multi-valued keys, for use in things such as Maps and Sets. Code for equals and hashCode methods follow the the rules laid out in Effective Java by Joshua Bloch.(翻译一下：通过生成类来处理多值键，以便在诸如Map和集合之类的东西中使用。equals和hashCode方法的代码遵循Joshua Bloch在《Effective Java》中列出的规则)。 什么叫multi-valued keys? 就是有多个键的组合，一起作为一个Key。 比如[a b c]是一个组合，一起作为一个key，[2 3]也可以是作为一个key。 KeyFactory就是用来生成这样一组Key的，通过两组的equals，hashCode等方法判断是否为同一组key的场景。为了描述Key的组合，需要定义一个接口，仅提供一个方法，叫做newInstance()，且返回值为Object，这个是使用KeyFactory的要求。 12345678910111213141516171819public class KeyFactoryDemo &#123; public static void main(String[] args) throws Exception &#123; KeyFactoryInterface keyFactoryInterface1 = (KeyFactoryInterface) KeyFactory.create(KeyFactoryInterface.class); KeyFactoryInterface keyFactoryInterface2 = (KeyFactoryInterface) KeyFactory.create(KeyFactoryInterface.class); System.out.println(keyFactoryInterface1 == keyFactoryInterface2); System.out.println(keyFactoryInterface1.equals(keyFactoryInterface2)); Object key1 = keyFactoryInterface1.newInstance(1, \"doge\"); Object key2 = keyFactoryInterface1.newInstance(1, \"doge\"); System.out.println(key1.equals(key2)); key2 = keyFactoryInterface1.newInstance(1, \"doge10086\"); System.out.println(key1.equals(key2)); &#125; interface KeyFactoryInterface &#123; Object newInstance(Integer a, String b); &#125;&#125; 输出结果： 1234falsetruetruefalse Mixin Mixin能够让我们将多个接口的多个实现合并到同一个接口的单个实现。 12345678910111213141516171819202122232425262728293031323334353637383940public class MixinDemo &#123; interface InterfaceFirst &#123; String first(); &#125; interface InterfaceSecond &#123; String second(); &#125; static class ImplFirst implements InterfaceFirst &#123; @Override public String first() &#123; return \"I am first\"; &#125; &#125; static class ImplSecond implements InterfaceSecond &#123; @Override public String second() &#123; return \"I am second\"; &#125; &#125; interface MixinImpl extends InterfaceFirst, InterfaceSecond &#123; &#125; public static void main(String[] args) throws Exception &#123; Mixin mixin = Mixin.create(new Class[]&#123;InterfaceFirst.class, InterfaceSecond.class, MixinImpl.class&#125;, new Object[]&#123;new ImplFirst(), new ImplSecond()&#125;); MixinImpl mixinImpl = (MixinImpl) mixin; System.out.println(mixinImpl.first()); System.out.println(mixinImpl.second()); &#125;&#125; 输出结果： 12I am firstI am second StringSwitcher 用来模拟一个String到int类型的Map类型。如果在Java7以后的版本中，类似一个switch块的逻辑。 12345678public class StringSwitcherDemo &#123; public static void main(String[] args) throws Exception &#123; StringSwitcher stringSwitcher = StringSwitcher.create(new String[]&#123;\"one\", \"two\"&#125;, new int[]&#123;1, 2&#125;, true); System.out.println(stringSwitcher.intValue(\"one\")); System.out.println(stringSwitcher.intValue(\"two\")); &#125;&#125; 输出结果： 1212 InterfaceMaker 接口生成器，底层依赖ASM的相关API。 1234567891011121314public class InterfaceMakerDemo &#123; public static void main(String[] args) throws Exception &#123; Signature signature = new Signature(\"foo\", Type.DOUBLE_TYPE, new Type[]&#123;Type.INT_TYPE&#125;); InterfaceMaker interfaceMaker = new InterfaceMaker(); interfaceMaker.add(signature, new Type[0]); Class&lt;?&gt; clazz = interfaceMaker.create(); Method[] methods = clazz.getMethods(); System.out.println(methods.length); Method foo = methods[0]; System.out.println(foo.getReturnType()); System.out.println(Arrays.toString(foo.getParameterTypes())); &#125;&#125; 输出结果： 1231double[int] 上述的InterfaceMaker创建的接口中只含有一个方法，签名为double foo(int)。InterfaceMaker与上面介绍的其他类不同，它依赖ASM中的Type类型。由于接口仅仅只用做在编译时期进行类型检查，因此在一个运行的应用中动态的创建接口没有什么作用。但是InterfaceMaker可以用来自动生成接口代码，为以后的开发做准备。 MethodDelegate 方法代理，个人认为作用不太大，这里仅举例。 1234567891011121314151617181920212223242526272829public class MethodDelegateDemo &#123; interface MethodDelegateInterface &#123; String getValueFromDelegate(); &#125; static class Delegate &#123; private String value; public String getValue() &#123; return value; &#125; public Delegate setValue(String value) &#123; this.value = value; return this; &#125; &#125; public static void main(String[] args) throws Exception &#123; Delegate delegate = new Delegate(); delegate.setValue(\"throwable\"); MethodDelegate methodDelegate = MethodDelegate.create(delegate, \"getValue\", MethodDelegateInterface.class); MethodDelegateInterface delegateInterface = (MethodDelegateInterface) methodDelegate; System.out.println(delegateInterface.getValueFromDelegate()); &#125;&#125; 输出结果： 1throwable MulticastDelegate 多重代理，个人认为作用不太大，这里仅举例。 123456789101112131415161718192021222324252627282930313233public class MulticastDelegateDemo &#123; public interface DelegateProvider &#123; void setValue(String value); &#125; static class MulticastBean implements DelegateProvider &#123; private String value; @Override public void setValue(String value) &#123; this.value = value; &#125; public String getValue() &#123; return value; &#125; &#125; public static void main(String[] args) throws Exception &#123; MulticastDelegate multicastDelegate = MulticastDelegate.create(DelegateProvider.class); MulticastBean first = new MulticastBean(); MulticastBean second = new MulticastBean(); multicastDelegate = multicastDelegate.add(first); multicastDelegate = multicastDelegate.add(second); DelegateProvider provider = (DelegateProvider) multicastDelegate; provider.setValue(\"throwable\"); System.out.println(first.getValue()); System.out.println(second.getValue()); &#125;&#125; 输出结果： 12throwablethrowable ConstructorDelegate 构造器代理，个人认为作用不太大，这里仅举例。 123456789101112131415161718192021222324252627282930313233public class ConstructorDelegateDemo &#123; public interface ConstructorInterface &#123; Object newInstance(String value); &#125; static class ConstructorImpl &#123; private String value; public ConstructorImpl(String value) &#123; this.value = value; &#125; public String getValue() &#123; return value; &#125; public ConstructorImpl setValue(String value) &#123; this.value = value; return this; &#125; &#125; public static void main(String[] args) throws Exception &#123; ConstructorInterface constructorInterface = (ConstructorInterface) ConstructorDelegate.create(ConstructorImpl.class, ConstructorInterface.class); ConstructorImpl constructorImpl = (ConstructorImpl) constructorInterface.newInstance(\"throwable\"); System.out.println(ConstructorImpl.class.isAssignableFrom(constructorImpl.getClass())); System.out.println(constructorImpl.getValue()); &#125;&#125; 输出结果： 12truethrowable ParallelSorter 并行排序器，能够对多个数组同时进行排序，目前实现的算法有归并排序(mergeSort)和快速排序(quickSort)，查看源码的时候发现Float和Double类的比较直接用大于或者小于，有可能造成这两个类型的数据排序不准确(应该使用Float或Double的compare方法进行比较)。 12345678910111213public class ParallelSorterDemo &#123; public static void main(String[] args) throws Exception &#123; Integer[][] array = new Integer[][]&#123; &#123;4, 3, 9, 0&#125;, &#123;2, 1, 6, 0&#125; &#125;; ParallelSorter.create(array).quickSort(0); for (Integer[] row : array) &#123; System.out.println(Arrays.toString(row)); &#125; &#125;&#125; 输出结果： 12[0, 3, 4, 9][0, 1, 2, 6] FastClass FastClass就是对Class对象进行特定的处理，认知上可以理解为索引类，比如通过数组保存method引用，因此FastClass引出了一个index下标的新概念，比如getIndex(String name, Class[] parameterTypes)就是以前的获取method的方法。通过数组存储method，constructor等class信息，从而将原先的反射调用，转化为class.index的直接调用以提高效率，从而体现所谓的FastClass。 12345678910public class FastClassDemo &#123; public static void main(String[] args) throws Exception &#123; FastClass fastClass = FastClass.create(SampleClass.class); FastMethod fastMethod = fastClass.getMethod(\"sayHello\", new Class[]&#123;String.class&#125;); SampleClass sampleClass = new SampleClass(); System.out.println(fastMethod.invoke(sampleClass, new Object[]&#123;\"throwable\"&#125;)); System.out.println(fastMethod.getIndex()); &#125;&#125; 输出结果： 12throwable say hello!0 实际上，在接口或者代理类的方法比较少的时候，使用FastClass进行方法调用有可能比原生反射方法调用Method#invoke()高，但是实际还是需要进行测试和分析，不能盲目一概而论。 小结 本文简单分析了一下CGLIB中的常用API，其实在实现AOP、动态代理和反射调用的时候，最常用的是字节码增强器Enhancer、回调(Callback)以及快类(FastClass)，掌握它们的使用方式有利于进行AOP编程以及反射性能创新性提升。 (本文完 r-a-20181216 c-1-d)","categories":[{"name":"Framework","slug":"Framework","permalink":"http://throwable.club/blog/categories/Framework/"},{"name":"Cglib","slug":"Framework/Cglib","permalink":"http://throwable.club/blog/categories/Framework/Cglib/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Cglib","slug":"Cglib","permalink":"http://throwable.club/blog/tags/Cglib/"}]},{"title":"Zookeeper客户端Curator使用详解","slug":"zookeeper-curator-usage","date":"2018-12-16T07:31:56.000Z","updated":"2018-12-16T07:39:39.330Z","comments":true,"path":"2018/12/16/zookeeper-curator-usage/","link":"","permalink":"http://throwable.club/2018/12/16/zookeeper-curator-usage/","excerpt":"","text":"Zookeeper客户端Curator使用详解 前提 因为最近项目需要使用Zookeeper这个中间件，提前了解一下它的客户端Curator的使用。 简介 Curator是Netflix公司开源的一套zookeeper客户端框架，解决了很多Zookeeper客户端非常底层的细节开发工作，包括连接重连、反复注册Watcher和NodeExistsException异常等等。Patrixck Hunt（Zookeeper）以一句“Guava is to Java that Curator to Zookeeper”给Curator予高度评价。 引子和趣闻： Zookeeper名字的由来是比较有趣的，下面的片段摘抄自《从PAXOS到ZOOKEEPER分布式一致性原理与实践》一书： Zookeeper最早起源于雅虎的研究院的一个研究小组。在当时，研究人员发现，在雅虎内部很多大型的系统需要依赖一个类似的系统进行分布式协调，但是这些系统往往存在分布式单点问题。所以雅虎的开发人员就试图开发一个通用的无单点问题的分布式协调框架。在立项初期，考虑到很多项目都是用动物的名字来命名的(例如著名的Pig项目)，雅虎的工程师希望给这个项目也取一个动物的名字。时任研究院的首席科学家Raghu Ramakrishnan开玩笑说：再这样下去，我们这儿就变成动物园了。此话一出，大家纷纷表示就叫动物园管理员吧——因为各个以动物命名的分布式组件放在一起，雅虎的整个分布式系统看上去就像一个大型的动物园了，而Zookeeper正好用来进行分布式环境的协调——于是，Zookeeper的名字由此诞生了。 Curator无疑是Zookeeper客户端中的瑞士军刀，它译作&quot;馆长&quot;或者’‘管理者’’，不知道是不是开发小组有意而为之，笔者猜测有可能这样命名的原因是说明Curator就是Zookeeper的馆长(脑洞有点大：Curator就是动物园的园长)。 Curator包含了几个包： curator-framework：对zookeeper的底层api的一些封装。 curator-client：提供一些客户端的操作，例如重试策略等。 curator-recipes：封装了一些高级特性，如：Cache事件监听、选举、分布式锁、分布式计数器、分布式Barrier等。 Maven依赖(使用curator的版本：2.12.0，对应Zookeeper的版本为：3.4.x，如果跨版本会有兼容性问题，很有可能导致节点操作失败)： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt;&lt;/dependency&gt; Curator的基本Api 创建会话 1.使用静态工程方法创建客户端 一个例子如下： 1234567RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);CuratorFramework client =CuratorFrameworkFactory.newClient( connectionInfo, 5000, 3000, retryPolicy); newClient静态工厂方法包含四个主要参数： 参数名 说明 connectionString 服务器列表，格式host1:port1,host2:port2,… retryPolicy 重试策略,内建有四种重试策略,也可以自行实现RetryPolicy接口 sessionTimeoutMs 会话超时时间，单位毫秒，默认60000ms connectionTimeoutMs 连接创建超时时间，单位毫秒，默认60000ms 2.使用Fluent风格的Api创建会话 核心参数变为流式设置，一个列子如下： 12345678 RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);CuratorFramework client =CuratorFrameworkFactory.builder() .connectString(connectionInfo) .sessionTimeoutMs(5000) .connectionTimeoutMs(5000) .retryPolicy(retryPolicy) .build(); 3.创建包含隔离命名空间的会话 为了实现不同的Zookeeper业务之间的隔离，需要为每个业务分配一个独立的命名空间（NameSpace），即指定一个Zookeeper的根路径（官方术语：为Zookeeper添加“Chroot”特性）。例如（下面的例子）当客户端指定了独立命名空间为“/base”，那么该客户端对Zookeeper上的数据节点的操作都是基于该目录进行的。通过设置Chroot可以将客户端应用与Zookeeper服务端的一课子树相对应，在多个应用共用一个Zookeeper集群的场景下，这对于实现不同应用之间的相互隔离十分有意义。 123456789RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3); CuratorFramework client = CuratorFrameworkFactory.builder() .connectString(connectionInfo) .sessionTimeoutMs(5000) .connectionTimeoutMs(5000) .retryPolicy(retryPolicy) .namespace(\"base\") .build(); 启动客户端 当创建会话成功，得到client的实例然后可以直接调用其start( )方法： 1client.start(); 数据节点操作 创建数据节点 Zookeeper的节点创建模式： PERSISTENT：持久化 PERSISTENT_SEQUENTIAL：持久化并且带序列号 EPHEMERAL：临时 EPHEMERAL_SEQUENTIAL：临时并且带序列号 创建一个节点，初始内容为空 1client.create().forPath(&quot;path&quot;); 注意：如果没有设置节点属性，节点创建模式默认为持久化节点，内容默认为空 创建一个节点，附带初始化内容 1client.create().forPath(&quot;path&quot;,&quot;init&quot;.getBytes()); 创建一个节点，指定创建模式（临时节点），内容为空 1client.create().withMode(CreateMode.EPHEMERAL).forPath(&quot;path&quot;); 创建一个节点，指定创建模式（临时节点），附带初始化内容 1client.create().withMode(CreateMode.EPHEMERAL).forPath(&quot;path&quot;,&quot;init&quot;.getBytes()); 创建一个节点，指定创建模式（临时节点），附带初始化内容，并且自动递归创建父节点 1234client.create() .creatingParentContainersIfNeeded() .withMode(CreateMode.EPHEMERAL) .forPath(\"path\",\"init\".getBytes()); 这个creatingParentContainersIfNeeded()接口非常有用，因为一般情况开发人员在创建一个子节点必须判断它的父节点是否存在，如果不存在直接创建会抛出NoNodeException，使用creatingParentContainersIfNeeded()之后Curator能够自动递归创建所有所需的父节点。 删除数据节点 删除一个节点 1client.delete().forPath(&quot;path&quot;); 注意，此方法只能删除叶子节点，否则会抛出异常。 删除一个节点，并且递归删除其所有的子节点 1client.delete().deletingChildrenIfNeeded().forPath(&quot;path&quot;); 删除一个节点，强制指定版本进行删除 1client.delete().withVersion(10086).forPath(&quot;path&quot;); 删除一个节点，强制保证删除 1client.delete().guaranteed().forPath(&quot;path&quot;); guaranteed()接口是一个保障措施，只要客户端会话有效，那么Curator会在后台持续进行删除操作，直到删除节点成功。 **注意：**上面的多个流式接口是可以自由组合的，例如： 1client.delete().guaranteed().deletingChildrenIfNeeded().withVersion(10086).forPath(&quot;path&quot;); 读取数据节点数据 读取一个节点的数据内容 1client.getData().forPath(&quot;path&quot;); 注意，此方法返的返回值是byte[ ]; 读取一个节点的数据内容，同时获取到该节点的stat 12Stat stat &#x3D; new Stat();client.getData().storingStatIn(stat).forPath(&quot;path&quot;); 更新数据节点数据 更新一个节点的数据内容 1client.setData().forPath(&quot;path&quot;,&quot;data&quot;.getBytes()); 注意：该接口会返回一个Stat实例 更新一个节点的数据内容，强制指定版本进行更新 1client.setData().withVersion(10086).forPath(&quot;path&quot;,&quot;data&quot;.getBytes()); 检查节点是否存在 1client.checkExists().forPath(&quot;path&quot;); 注意：该方法返回一个Stat实例，用于检查ZNode是否存在的操作. 可以调用额外的方法(监控或者后台处理)并在最后调用forPath()指定要操作的ZNode 获取某个节点的所有子节点路径 1client.getChildren().forPath(&quot;path&quot;); 注意：该方法的返回值为List,获得ZNode的子节点Path列表。 可以调用额外的方法(监控、后台处理或者获取状态watch, background or get stat) 并在最后调用forPath()指定要操作的父ZNode 事务 CuratorFramework的实例包含inTransaction( )接口方法，调用此方法开启一个ZooKeeper事务. 可以复合create, setData, check, and/or delete 等操作然后调用commit()作为一个原子操作提交。一个例子如下： 1234567client.inTransaction().check().forPath(\"path\") .and() .create().withMode(CreateMode.EPHEMERAL).forPath(\"path\",\"data\".getBytes()) .and() .setData().withVersion(10086).forPath(\"path\",\"data2\".getBytes()) .and() .commit(); 异步接口 上面提到的创建、删除、更新、读取等方法都是同步的，Curator提供异步接口，引入了BackgroundCallback接口用于处理异步接口调用之后服务端返回的结果信息。BackgroundCallback接口中一个重要的回调值为CuratorEvent，里面包含事件类型、响应吗和节点的详细信息。 CuratorEventType 事件类型 对应CuratorFramework实例的方法 CREATE #create() DELETE #delete() EXISTS #checkExists() GET_DATA #getData() SET_DATA #setData() CHILDREN #getChildren() SYNC #sync(String,Object) GET_ACL #getACL() SET_ACL #setACL() WATCHED #Watcher(Watcher) CLOSING #close() 响应码(#getResultCode()) 响应码 意义 0 OK，即调用成功 -4 ConnectionLoss，即客户端与服务端断开连接 -110 NodeExists，即节点已经存在 -112 SessionExpired，即会话过期 一个异步创建节点的例子如下： 1234567Executor executor = Executors.newFixedThreadPool(2);client.create() .creatingParentsIfNeeded() .withMode(CreateMode.EPHEMERAL) .inBackground((curatorFramework, curatorEvent) -&gt; &#123; System.out.println(String.format(\"eventType:%s,resultCode:%s\",curatorEvent.getType(),curatorEvent.getResultCode())); &#125;,executor) .forPath(\"path\"); 注意：如果#inBackground()方法不指定executor，那么会默认使用Curator的EventThread去进行异步处理。 Curator食谱(高级特性) 提醒：首先你必须添加curator-recipes依赖，下文仅仅对recipes一些特性的使用进行解释和举例，不打算进行源码级别的探讨 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt;&lt;/dependency&gt; 重要提醒：强烈推荐使用ConnectionStateListener监控连接的状态，当连接状态为LOST，curator-recipes下的所有Api将会失效或者过期，尽管后面所有的例子都没有使用到ConnectionStateListener。 缓存 Zookeeper原生支持通过注册Watcher来进行事件监听，但是开发者需要反复注册(Watcher只能单次注册单次使用)。Cache是Curator中对事件监听的包装，可以看作是对事件监听的本地缓存视图，能够自动为开发者处理反复注册监听。Curator提供了三种Watcher(Cache)来监听结点的变化。 Path Cache Path Cache用来监控一个ZNode的子节点. 当一个子节点增加， 更新，删除时， Path Cache会改变它的状态， 会包含最新的子节点， 子节点的数据和状态，而状态的更变将通过PathChildrenCacheListener通知。 实际使用时会涉及到四个类： PathChildrenCache PathChildrenCacheEvent PathChildrenCacheListener ChildData 通过下面的构造函数创建Path Cache: 1public PathChildrenCache(CuratorFramework client, String path, boolean cacheData) 想使用cache，必须调用它的start方法，使用完后调用close方法。 可以设置StartMode来实现启动的模式， StartMode有下面几种： NORMAL：正常初始化。 BUILD_INITIAL_CACHE：在调用start()之前会调用rebuild()。 POST_INITIALIZED_EVENT： 当Cache初始化数据后发送一个PathChildrenCacheEvent.Type#INITIALIZED事件 public void addListener(PathChildrenCacheListener listener)可以增加listener监听缓存的变化。 getCurrentData()方法返回一个List&lt;ChildData&gt;对象，可以遍历所有的子节点。 设置/更新、移除其实是使用client (CuratorFramework)来操作, 不通过PathChildrenCache操作： 1234567891011121314151617181920212223242526272829303132333435public class PathCacheDemo &#123; private static final String PATH = \"/example/pathCache\"; public static void main(String[] args) throws Exception &#123; TestingServer server = new TestingServer(); CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); client.start(); PathChildrenCache cache = new PathChildrenCache(client, PATH, true); cache.start(); PathChildrenCacheListener cacheListener = (client1, event) -&gt; &#123; System.out.println(\"事件类型：\" + event.getType()); if (null != event.getData()) &#123; System.out.println(\"节点数据：\" + event.getData().getPath() + \" = \" + new String(event.getData().getData())); &#125; &#125;; cache.getListenable().addListener(cacheListener); client.create().creatingParentsIfNeeded().forPath(\"/example/pathCache/test01\", \"01\".getBytes()); Thread.sleep(10); client.create().creatingParentsIfNeeded().forPath(\"/example/pathCache/test02\", \"02\".getBytes()); Thread.sleep(10); client.setData().forPath(\"/example/pathCache/test01\", \"01_V2\".getBytes()); Thread.sleep(10); for (ChildData data : cache.getCurrentData()) &#123; System.out.println(\"getCurrentData:\" + data.getPath() + \" = \" + new String(data.getData())); &#125; client.delete().forPath(\"/example/pathCache/test01\"); Thread.sleep(10); client.delete().forPath(\"/example/pathCache/test02\"); Thread.sleep(1000 * 5); cache.close(); client.close(); System.out.println(\"OK!\"); &#125;&#125; **注意：**如果new PathChildrenCache(client, PATH, true)中的参数cacheData值设置为false，则示例中的event.getData().getData()、data.getData()将返回null，cache将不会缓存节点数据。 **注意：**示例中的Thread.sleep(10)可以注释掉，但是注释后事件监听的触发次数会不全，这可能与PathCache的实现原理有关，不能太过频繁的触发事件！ Node Cache Node Cache与Path Cache类似，Node Cache只是监听某一个特定的节点。它涉及到下面的三个类： NodeCache - Node Cache实现类 NodeCacheListener - 节点监听器 ChildData - 节点数据 **注意：**使用cache，依然要调用它的start()方法，使用完后调用close()方法。 getCurrentData()将得到节点当前的状态，通过它的状态可以得到当前的值。 12345678910111213141516171819202122232425262728293031public class NodeCacheDemo &#123; private static final String PATH = \"/example/cache\"; public static void main(String[] args) throws Exception &#123; TestingServer server = new TestingServer(); CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); client.start(); client.create().creatingParentsIfNeeded().forPath(PATH); final NodeCache cache = new NodeCache(client, PATH); NodeCacheListener listener = () -&gt; &#123; ChildData data = cache.getCurrentData(); if (null != data) &#123; System.out.println(\"节点数据：\" + new String(cache.getCurrentData().getData())); &#125; else &#123; System.out.println(\"节点被删除!\"); &#125; &#125;; cache.getListenable().addListener(listener); cache.start(); client.setData().forPath(PATH, \"01\".getBytes()); Thread.sleep(100); client.setData().forPath(PATH, \"02\".getBytes()); Thread.sleep(100); client.delete().deletingChildrenIfNeeded().forPath(PATH); Thread.sleep(1000 * 2); cache.close(); client.close(); System.out.println(\"OK!\"); &#125;&#125; **注意：**示例中的Thread.sleep(10)可以注释，但是注释后事件监听的触发次数会不全，这可能与NodeCache的实现原理有关，不能太过频繁的触发事件！ **注意：**NodeCache只能监听一个节点的状态变化。 Tree Cache Tree Cache可以监控整个树上的所有节点，类似于PathCache和NodeCache的组合，主要涉及到下面四个类： TreeCache - Tree Cache实现类 TreeCacheListener - 监听器类 TreeCacheEvent - 触发的事件类 ChildData - 节点数据 1234567891011121314151617181920212223242526public class TreeCacheDemo &#123; private static final String PATH = \"/example/cache\"; public static void main(String[] args) throws Exception &#123; TestingServer server = new TestingServer(); CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); client.start(); client.create().creatingParentsIfNeeded().forPath(PATH); TreeCache cache = new TreeCache(client, PATH); TreeCacheListener listener = (client1, event) -&gt; System.out.println(\"事件类型：\" + event.getType() + \" | 路径：\" + (null != event.getData() ? event.getData().getPath() : null)); cache.getListenable().addListener(listener); cache.start(); client.setData().forPath(PATH, \"01\".getBytes()); Thread.sleep(100); client.setData().forPath(PATH, \"02\".getBytes()); Thread.sleep(100); client.delete().deletingChildrenIfNeeded().forPath(PATH); Thread.sleep(1000 * 2); cache.close(); client.close(); System.out.println(\"OK!\"); &#125;&#125; **注意：**在此示例中没有使用Thread.sleep(10)，但是事件触发次数也是正常的。 **注意：**TreeCache在初始化(调用start()方法)的时候会回调TreeCacheListener实例一个事TreeCacheEvent，而回调的TreeCacheEvent对象的Type为INITIALIZED，ChildData为null，此时event.getData().getPath()很有可能导致空指针异常，这里应该主动处理并避免这种情况。 Leader选举 在分布式计算中， leader elections是很重要的一个功能， 这个选举过程是这样子的： 指派一个进程作为组织者，将任务分发给各节点。 在任务开始前， 哪个节点都不知道谁是leader(领导者)或者coordinator(协调者). 当选举算法开始执行后， 每个节点最终会得到一个唯一的节点作为任务leader. 除此之外， 选举还经常会发生在leader意外宕机的情况下，新的leader要被选举出来。 在zookeeper集群中，leader负责写操作，然后通过Zab协议实现follower的同步，leader或者follower都可以处理读操作。 Curator 有两种leader选举的recipe,分别是LeaderSelector和LeaderLatch。 前者是所有存活的客户端不间断的轮流做Leader，大同社会。后者是一旦选举出Leader，除非有客户端挂掉重新触发选举，否则不会交出领导权。某党? LeaderLatch LeaderLatch有两个构造函数： 12public LeaderLatch(CuratorFramework client, String latchPath)public LeaderLatch(CuratorFramework client, String latchPath, String id) LeaderLatch的启动： leaderLatch.start( ); 一旦启动，LeaderLatch会和其它使用相同latch path的其它LeaderLatch交涉，然后其中一个最终会被选举为leader，可以通过hasLeadership方法查看LeaderLatch实例是否leader： leaderLatch.hasLeadership( ); //返回true说明当前实例是leader 类似JDK的CountDownLatch， LeaderLatch在请求成为leadership会block(阻塞)，一旦不使用LeaderLatch了，必须调用close方法。 如果它是leader,会释放leadership， 其它的参与者将会选举一个leader。 1234public void await() throws InterruptedException,EOFException/*Causes the current thread to wait until this instance acquires leadershipunless the thread is interrupted or closed.*/public boolean await(long timeout,TimeUnit unit)throws InterruptedException 异常处理： LeaderLatch实例可以增加ConnectionStateListener来监听网络连接问题。 当 SUSPENDED 或 LOST 时, leader不再认为自己还是leader。当LOST后连接重连后RECONNECTED,LeaderLatch会删除先前的ZNode然后重新创建一个。LeaderLatch用户必须考虑导致leadership丢失的连接问题。 强烈推荐你使用ConnectionStateListener。 一个LeaderLatch的使用例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class LeaderLatchDemo extends BaseConnectionInfo &#123; protected static String PATH = \"/francis/leader\"; private static final int CLIENT_QTY = 10; public static void main(String[] args) throws Exception &#123; List&lt;CuratorFramework&gt; clients = Lists.newArrayList(); List&lt;LeaderLatch&gt; examples = Lists.newArrayList(); TestingServer server=new TestingServer(); try &#123; for (int i = 0; i &lt; CLIENT_QTY; i++) &#123; CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(20000, 3)); clients.add(client); LeaderLatch latch = new LeaderLatch(client, PATH, \"Client #\" + i); latch.addListener(new LeaderLatchListener() &#123; @Override public void isLeader() &#123; // TODO Auto-generated method stub System.out.println(\"I am Leader\"); &#125; @Override public void notLeader() &#123; // TODO Auto-generated method stub System.out.println(\"I am not Leader\"); &#125; &#125;); examples.add(latch); client.start(); latch.start(); &#125; Thread.sleep(10000); LeaderLatch currentLeader = null; for (LeaderLatch latch : examples) &#123; if (latch.hasLeadership()) &#123; currentLeader = latch; &#125; &#125; System.out.println(\"current leader is \" + currentLeader.getId()); System.out.println(\"release the leader \" + currentLeader.getId()); currentLeader.close(); Thread.sleep(5000); for (LeaderLatch latch : examples) &#123; if (latch.hasLeadership()) &#123; currentLeader = latch; &#125; &#125; System.out.println(\"current leader is \" + currentLeader.getId()); System.out.println(\"release the leader \" + currentLeader.getId()); &#125; finally &#123; for (LeaderLatch latch : examples) &#123; if (null != latch.getState()) CloseableUtils.closeQuietly(latch); &#125; for (CuratorFramework client : clients) &#123; CloseableUtils.closeQuietly(client); &#125; &#125; &#125;&#125; 可以添加test module的依赖方便进行测试，不需要启动真实的zookeeper服务端： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-test&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt;&lt;/dependency&gt; 首先我们创建了10个LeaderLatch，启动后它们中的一个会被选举为leader。 因为选举会花费一些时间，start后并不能马上就得到leader。 通过hasLeadership查看自己是否是leader， 如果是的话返回true。 可以通过.getLeader().getId()可以得到当前的leader的ID。 只能通过close释放当前的领导权。 await是一个阻塞方法， 尝试获取leader地位，但是未必能上位。 LeaderSelector LeaderSelector使用的时候主要涉及下面几个类： LeaderSelector LeaderSelectorListener LeaderSelectorListenerAdapter CancelLeadershipException 核心类是LeaderSelector，它的构造函数如下： 12public LeaderSelector(CuratorFramework client, String mutexPath,LeaderSelectorListener listener)public LeaderSelector(CuratorFramework client, String mutexPath, ThreadFactory threadFactory, Executor executor, LeaderSelectorListener listener) 类似LeaderLatch,LeaderSelector必须start: leaderSelector.start(); 一旦启动，当实例取得领导权时你的listener的takeLeadership()方法被调用。而takeLeadership()方法只有领导权被释放时才返回。 当你不再使用LeaderSelector实例时，应该调用它的close方法。 异常处理 LeaderSelectorListener类继承ConnectionStateListener。LeaderSelector必须小心连接状态的改变。如果实例成为leader, 它应该响应SUSPENDED 或 LOST。 当 SUSPENDED 状态出现时， 实例必须假定在重新连接成功之前它可能不再是leader了。 如果LOST状态出现， 实例不再是leader， takeLeadership方法返回。 重要: 推荐处理方式是当收到SUSPENDED 或 LOST时抛出CancelLeadershipException异常.。这会导致LeaderSelector实例中断并取消执行takeLeadership方法的异常.。这非常重要， 你必须考虑扩展LeaderSelectorListenerAdapter. LeaderSelectorListenerAdapter提供了推荐的处理逻辑。 下面的一个例子摘抄自官方： 1234567891011121314151617181920212223242526272829303132333435public class LeaderSelectorAdapter extends LeaderSelectorListenerAdapter implements Closeable &#123; private final String name; private final LeaderSelector leaderSelector; private final AtomicInteger leaderCount = new AtomicInteger(); public LeaderSelectorAdapter(CuratorFramework client, String path, String name) &#123; this.name = name; leaderSelector = new LeaderSelector(client, path, this); leaderSelector.autoRequeue(); &#125; public void start() throws IOException &#123; leaderSelector.start(); &#125; @Override public void close() throws IOException &#123; leaderSelector.close(); &#125; @Override public void takeLeadership(CuratorFramework client) throws Exception &#123; final int waitSeconds = (int) (5 * Math.random()) + 1; System.out.println(name + \" is now the leader. Waiting \" + waitSeconds + \" seconds...\"); System.out.println(name + \" has been leader \" + leaderCount.getAndIncrement() + \" time(s) before.\"); try &#123; Thread.sleep(TimeUnit.SECONDS.toMillis(waitSeconds)); &#125; catch (InterruptedException e) &#123; System.err.println(name + \" was interrupted.\"); Thread.currentThread().interrupt(); &#125; finally &#123; System.out.println(name + \" relinquishing leadership.\\n\"); &#125; &#125;&#125; 你可以在takeLeadership进行任务的分配等等，并且不要返回，如果你想要要此实例一直是leader的话可以加一个死循环。调用 leaderSelector.autoRequeue();保证在此实例释放领导权之后还可能获得领导权。 在这里我们使用AtomicInteger来记录此client获得领导权的次数， 它是”fair”， 每个client有平等的机会获得领导权。 12345678910111213141516171819202122232425262728293031323334public class LeaderSelectorDemo &#123; protected static String PATH = \"/francis/leader\"; private static final int CLIENT_QTY = 10; public static void main(String[] args) throws Exception &#123; List&lt;CuratorFramework&gt; clients = Lists.newArrayList(); List&lt;LeaderSelectorAdapter&gt; examples = Lists.newArrayList(); TestingServer server = new TestingServer(); try &#123; for (int i = 0; i &lt; CLIENT_QTY; i++) &#123; CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(20000, 3)); clients.add(client); LeaderSelectorAdapter selectorAdapter = new LeaderSelectorAdapter(client, PATH, \"Client #\" + i); examples.add(selectorAdapter); client.start(); selectorAdapter.start(); &#125; System.out.println(\"Press enter/return to quit\\n\"); new BufferedReader(new InputStreamReader(System.in)).readLine(); &#125; finally &#123; System.out.println(\"Shutting down...\"); for (LeaderSelectorAdapter exampleClient : examples) &#123; CloseableUtils.closeQuietly(exampleClient); &#125; for (CuratorFramework client : clients) &#123; CloseableUtils.closeQuietly(client); &#125; CloseableUtils.closeQuietly(server); &#125; &#125;&#125; 对比可知，LeaderLatch必须调用close()方法才会释放领导权，而对于LeaderSelector，通过LeaderSelectorListener可以对领导权进行控制， 在适当的时候释放领导权，这样每个节点都有可能获得领导权。从而，LeaderSelector具有更好的灵活性和可控性，建议有LeaderElection应用场景下优先使用LeaderSelector。 分布式锁 提醒： 1.推荐使用ConnectionStateListener监控连接的状态，因为当连接LOST时你不再拥有锁 2.分布式的锁全局同步， 这意味着任何一个时间点不会有两个客户端都拥有相同的锁。 可重入共享锁—Shared Reentrant Lock Shared意味着锁是全局可见的， 客户端都可以请求锁。 Reentrant和JDK的ReentrantLock类似，即可重入， 意味着同一个客户端在拥有锁的同时，可以多次获取，不会被阻塞。 它是由类InterProcessMutex来实现。 它的构造函数为： 1public InterProcessMutex(CuratorFramework client, String path) 通过acquire()获得锁，并提供超时机制： 123456789101112public void acquire()Acquire the mutex - blocking until it's available. Note: the same thread can call acquirere-entrantly. Each call to acquire must be balanced by a call to release()public boolean acquire(long time,TimeUnit unit)Acquire the mutex - blocks until it's available or the given time expires. Note: the same thread can call acquire re-entrantly. Each call to acquire that returns true must be balanced by a call to release()Parameters:time - time to waitunit - time unitReturns:true if the mutex was acquired, false if not 通过release()方法释放锁。 InterProcessMutex 实例可以重用。 Revoking ZooKeeper recipes wiki定义了可协商的撤销机制。 为了撤销mutex, 调用下面的方法： 1234public void makeRevocable(RevocationListener&lt;T&gt; listener)将锁设为可撤销的. 当别的进程或线程想让你释放锁时Listener会被调用。Parameters:listener - the listener 如果你请求撤销当前的锁， 调用attemptRevoke()方法,注意锁释放时RevocationListener将会回调。 1234567public static void attemptRevoke(CuratorFramework client,String path) throws ExceptionUtility to mark a lock for revocation. Assuming that the lock has been registeredwith a RevocationListener, it will get called and the lock should be released. Note,however, that revocation is cooperative.Parameters:client - the clientpath - the path of the lock - usually from something like InterProcessMutex.getParticipantNodes() 二次提醒：错误处理 还是强烈推荐你使用ConnectionStateListener处理连接状态的改变。 当连接LOST时你不再拥有锁。 首先让我们创建一个模拟的共享资源， 这个资源期望只能单线程的访问，否则会有并发问题。 1234567891011121314151617public class FakeLimitedResource &#123; private final AtomicBoolean inUse = new AtomicBoolean(false); public void use() throws InterruptedException &#123; // 真实环境中我们会在这里访问/维护一个共享的资源 //这个例子在使用锁的情况下不会非法并发异常IllegalStateException //但是在无锁的情况由于sleep了一段时间，很容易抛出异常 if (!inUse.compareAndSet(false, true)) &#123; throw new IllegalStateException(\"Needs to be used by one client at a time\"); &#125; try &#123; Thread.sleep((long) (3 * Math.random())); &#125; finally &#123; inUse.set(false); &#125; &#125;&#125; 然后创建一个InterProcessMutexDemo类， 它负责请求锁， 使用资源，释放锁这样一个完整的访问过程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class InterProcessMutexDemo &#123; private InterProcessMutex lock; private final FakeLimitedResource resource; private final String clientName; public InterProcessMutexDemo(CuratorFramework client, String lockPath, FakeLimitedResource resource, String clientName) &#123; this.resource = resource; this.clientName = clientName; this.lock = new InterProcessMutex(client, lockPath); &#125; public void doWork(long time, TimeUnit unit) throws Exception &#123; if (!lock.acquire(time, unit)) &#123; throw new IllegalStateException(clientName + \" could not acquire the lock\"); &#125; try &#123; System.out.println(clientName + \" get the lock\"); resource.use(); //access resource exclusively &#125; finally &#123; System.out.println(clientName + \" releasing the lock\"); lock.release(); // always release the lock in a finally block &#125; &#125; private static final int QTY = 5; private static final int REPETITIONS = QTY * 10; private static final String PATH = \"/examples/locks\"; public static void main(String[] args) throws Exception &#123; final FakeLimitedResource resource = new FakeLimitedResource(); ExecutorService service = Executors.newFixedThreadPool(QTY); final TestingServer server = new TestingServer(); try &#123; for (int i = 0; i &lt; QTY; ++i) &#123; final int index = i; Callable&lt;Void&gt; task = new Callable&lt;Void&gt;() &#123; @Override public Void call() throws Exception &#123; CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); try &#123; client.start(); final InterProcessMutexDemo example = new InterProcessMutexDemo(client, PATH, resource, \"Client \" + index); for (int j = 0; j &lt; REPETITIONS; ++j) &#123; example.doWork(10, TimeUnit.SECONDS); &#125; &#125; catch (Throwable e) &#123; e.printStackTrace(); &#125; finally &#123; CloseableUtils.closeQuietly(client); &#125; return null; &#125; &#125;; service.submit(task); &#125; service.shutdown(); service.awaitTermination(10, TimeUnit.MINUTES); &#125; finally &#123; CloseableUtils.closeQuietly(server); &#125; &#125;&#125; 代码也很简单，生成10个client， 每个client重复执行10次 请求锁–访问资源–释放锁的过程。每个client都在独立的线程中。 结果可以看到，锁是随机的被每个实例排他性的使用。 既然是可重用的，你可以在一个线程中多次调用acquire(),在线程拥有锁时它总是返回true。 你不应该在多个线程中用同一个InterProcessMutex， 你可以在每个线程中都生成一个新的InterProcessMutex实例，它们的path都一样，这样它们可以共享同一个锁。 不可重入共享锁—Shared Lock 这个锁和上面的InterProcessMutex相比，就是少了Reentrant的功能，也就意味着它不能在同一个线程中重入。这个类是InterProcessSemaphoreMutex,使用方法和InterProcessMutex类似 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class InterProcessSemaphoreMutexDemo &#123; private InterProcessSemaphoreMutex lock; private final FakeLimitedResource resource; private final String clientName; public InterProcessSemaphoreMutexDemo(CuratorFramework client, String lockPath, FakeLimitedResource resource, String clientName) &#123; this.resource = resource; this.clientName = clientName; this.lock = new InterProcessSemaphoreMutex(client, lockPath); &#125; public void doWork(long time, TimeUnit unit) throws Exception &#123; if (!lock.acquire(time, unit)) &#123; throw new IllegalStateException(clientName + \" 不能得到互斥锁\"); &#125; System.out.println(clientName + \" 已获取到互斥锁\"); if (!lock.acquire(time, unit)) &#123; throw new IllegalStateException(clientName + \" 不能得到互斥锁\"); &#125; System.out.println(clientName + \" 再次获取到互斥锁\"); try &#123; System.out.println(clientName + \" get the lock\"); resource.use(); //access resource exclusively &#125; finally &#123; System.out.println(clientName + \" releasing the lock\"); lock.release(); // always release the lock in a finally block lock.release(); // 获取锁几次 释放锁也要几次 &#125; &#125; private static final int QTY = 5; private static final int REPETITIONS = QTY * 10; private static final String PATH = \"/examples/locks\"; public static void main(String[] args) throws Exception &#123; final FakeLimitedResource resource = new FakeLimitedResource(); ExecutorService service = Executors.newFixedThreadPool(QTY); final TestingServer server = new TestingServer(); try &#123; for (int i = 0; i &lt; QTY; ++i) &#123; final int index = i; Callable&lt;Void&gt; task = new Callable&lt;Void&gt;() &#123; @Override public Void call() throws Exception &#123; CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); try &#123; client.start(); final InterProcessSemaphoreMutexDemo example = new InterProcessSemaphoreMutexDemo(client, PATH, resource, \"Client \" + index); for (int j = 0; j &lt; REPETITIONS; ++j) &#123; example.doWork(10, TimeUnit.SECONDS); &#125; &#125; catch (Throwable e) &#123; e.printStackTrace(); &#125; finally &#123; CloseableUtils.closeQuietly(client); &#125; return null; &#125; &#125;; service.submit(task); &#125; service.shutdown(); service.awaitTermination(10, TimeUnit.MINUTES); &#125; finally &#123; CloseableUtils.closeQuietly(server); &#125; Thread.sleep(Integer.MAX_VALUE); &#125;&#125; 运行后发现，有且只有一个client成功获取第一个锁(第一个acquire()方法返回true)，然后它自己阻塞在第二个acquire()方法，获取第二个锁超时；其他所有的客户端都阻塞在第一个acquire()方法超时并且抛出异常。 这样也就验证了InterProcessSemaphoreMutex实现的锁是不可重入的。 可重入读写锁—Shared Reentrant Read Write Lock 类似JDK的ReentrantReadWriteLock。一个读写锁管理一对相关的锁。一个负责读操作，另外一个负责写操作。读操作在写锁没被使用时可同时由多个进程使用，而写锁在使用时不允许读(阻塞)。 此锁是可重入的。一个拥有写锁的线程可重入读锁，但是读锁却不能进入写锁。这也意味着写锁可以降级成读锁， 比如请求写锁 —&gt;请求读锁—&gt;释放读锁 ----&gt;释放写锁。从读锁升级成写锁是不行的。 可重入读写锁主要由两个类实现：InterProcessReadWriteLock、InterProcessMutex。使用时首先创建一个InterProcessReadWriteLock实例，然后再根据你的需求得到读锁或者写锁，读写锁的类型是InterProcessMutex。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class ReentrantReadWriteLockDemo &#123; private final InterProcessReadWriteLock lock; private final InterProcessMutex readLock; private final InterProcessMutex writeLock; private final FakeLimitedResource resource; private final String clientName; public ReentrantReadWriteLockDemo(CuratorFramework client, String lockPath, FakeLimitedResource resource, String clientName) &#123; this.resource = resource; this.clientName = clientName; lock = new InterProcessReadWriteLock(client, lockPath); readLock = lock.readLock(); writeLock = lock.writeLock(); &#125; public void doWork(long time, TimeUnit unit) throws Exception &#123; // 注意只能先得到写锁再得到读锁，不能反过来！！！ if (!writeLock.acquire(time, unit)) &#123; throw new IllegalStateException(clientName + \" 不能得到写锁\"); &#125; System.out.println(clientName + \" 已得到写锁\"); if (!readLock.acquire(time, unit)) &#123; throw new IllegalStateException(clientName + \" 不能得到读锁\"); &#125; System.out.println(clientName + \" 已得到读锁\"); try &#123; resource.use(); // 使用资源 Thread.sleep(1000); &#125; finally &#123; System.out.println(clientName + \" 释放读写锁\"); readLock.release(); writeLock.release(); &#125; &#125; private static final int QTY = 5; private static final int REPETITIONS = QTY ; private static final String PATH = \"/examples/locks\"; public static void main(String[] args) throws Exception &#123; final FakeLimitedResource resource = new FakeLimitedResource(); ExecutorService service = Executors.newFixedThreadPool(QTY); final TestingServer server = new TestingServer(); try &#123; for (int i = 0; i &lt; QTY; ++i) &#123; final int index = i; Callable&lt;Void&gt; task = new Callable&lt;Void&gt;() &#123; @Override public Void call() throws Exception &#123; CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); try &#123; client.start(); final ReentrantReadWriteLockDemo example = new ReentrantReadWriteLockDemo(client, PATH, resource, \"Client \" + index); for (int j = 0; j &lt; REPETITIONS; ++j) &#123; example.doWork(10, TimeUnit.SECONDS); &#125; &#125; catch (Throwable e) &#123; e.printStackTrace(); &#125; finally &#123; CloseableUtils.closeQuietly(client); &#125; return null; &#125; &#125;; service.submit(task); &#125; service.shutdown(); service.awaitTermination(10, TimeUnit.MINUTES); &#125; finally &#123; CloseableUtils.closeQuietly(server); &#125; &#125;&#125; 信号量—Shared Semaphore 一个计数的信号量类似JDK的Semaphore。 JDK中Semaphore维护的一组许可(permits)，而Curator中称之为租约(Lease)。 有两种方式可以决定semaphore的最大租约数。第一种方式是用户给定path并且指定最大LeaseSize。第二种方式用户给定path并且使用SharedCountReader类。如果不使用SharedCountReader, 必须保证所有实例在多进程中使用相同的(最大)租约数量,否则有可能出现A进程中的实例持有最大租约数量为10，但是在B进程中持有的最大租约数量为20，此时租约的意义就失效了。 这次调用acquire()会返回一个租约对象。 客户端必须在finally中close这些租约对象，否则这些租约会丢失掉。 但是， 但是，如果客户端session由于某种原因比如crash丢掉， 那么这些客户端持有的租约会自动close， 这样其它客户端可以继续使用这些租约。 租约还可以通过下面的方式返还： 12public void returnAll(Collection&lt;Lease&gt; leases)public void returnLease(Lease lease) 注意你可以一次性请求多个租约，如果Semaphore当前的租约不够，则请求线程会被阻塞。 同时还提供了超时的重载方法。 1234public Lease acquire()public Collection&lt;Lease&gt; acquire(int qty)public Lease acquire(long time, TimeUnit unit)public Collection&lt;Lease&gt; acquire(int qty, long time, TimeUnit unit) Shared Semaphore使用的主要类包括下面几个： InterProcessSemaphoreV2 Lease SharedCountReader 123456789101112131415161718192021222324252627282930public class InterProcessSemaphoreDemo &#123; private static final int MAX_LEASE = 10; private static final String PATH = \"/examples/locks\"; public static void main(String[] args) throws Exception &#123; FakeLimitedResource resource = new FakeLimitedResource(); try (TestingServer server = new TestingServer()) &#123; CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); client.start(); InterProcessSemaphoreV2 semaphore = new InterProcessSemaphoreV2(client, PATH, MAX_LEASE); Collection&lt;Lease&gt; leases = semaphore.acquire(5); System.out.println(\"get \" + leases.size() + \" leases\"); Lease lease = semaphore.acquire(); System.out.println(\"get another lease\"); resource.use(); Collection&lt;Lease&gt; leases2 = semaphore.acquire(5, 10, TimeUnit.SECONDS); System.out.println(\"Should timeout and acquire return \" + leases2); System.out.println(\"return one lease\"); semaphore.returnLease(lease); System.out.println(\"return another 5 leases\"); semaphore.returnAll(leases); &#125; &#125;&#125; 首先我们先获得了5个租约， 最后我们把它还给了semaphore。 接着请求了一个租约，因为semaphore还有5个租约，所以请求可以满足，返回一个租约，还剩4个租约。 然后再请求一个租约，因为租约不够，阻塞到超时，还是没能满足，返回结果为null(租约不足会阻塞到超时，然后返回null，不会主动抛出异常；如果不设置超时时间，会一致阻塞)。 上面说讲的锁都是公平锁(fair)。 总ZooKeeper的角度看， 每个客户端都按照请求的顺序获得锁，不存在非公平的抢占的情况。 多共享锁对象 —Multi Shared Lock Multi Shared Lock是一个锁的容器。 当调用acquire()， 所有的锁都会被acquire()，如果请求失败，所有的锁都会被release。 同样调用release时所有的锁都被release(失败被忽略)。 基本上，它就是组锁的代表，在它上面的请求释放操作都会传递给它包含的所有的锁。 主要涉及两个类： InterProcessMultiLock InterProcessLock 它的构造函数需要包含的锁的集合，或者一组ZooKeeper的path。 12public InterProcessMultiLock(List&lt;InterProcessLock&gt; locks)public InterProcessMultiLock(CuratorFramework client, List&lt;String&gt; paths) 用法和Shared Lock相同。 1234567891011121314151617181920212223242526272829303132333435public class MultiSharedLockDemo &#123; private static final String PATH1 = \"/examples/locks1\"; private static final String PATH2 = \"/examples/locks2\"; public static void main(String[] args) throws Exception &#123; FakeLimitedResource resource = new FakeLimitedResource(); try (TestingServer server = new TestingServer()) &#123; CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); client.start(); InterProcessLock lock1 = new InterProcessMutex(client, PATH1); InterProcessLock lock2 = new InterProcessSemaphoreMutex(client, PATH2); InterProcessMultiLock lock = new InterProcessMultiLock(Arrays.asList(lock1, lock2)); if (!lock.acquire(10, TimeUnit.SECONDS)) &#123; throw new IllegalStateException(\"could not acquire the lock\"); &#125; System.out.println(\"has got all lock\"); System.out.println(\"has got lock1: \" + lock1.isAcquiredInThisProcess()); System.out.println(\"has got lock2: \" + lock2.isAcquiredInThisProcess()); try &#123; resource.use(); //access resource exclusively &#125; finally &#123; System.out.println(\"releasing the lock\"); lock.release(); // always release the lock in a finally block &#125; System.out.println(\"has got lock1: \" + lock1.isAcquiredInThisProcess()); System.out.println(\"has got lock2: \" + lock2.isAcquiredInThisProcess()); &#125; &#125;&#125; 新建一个InterProcessMultiLock， 包含一个重入锁和一个非重入锁。 调用acquire()后可以看到线程同时拥有了这两个锁。 调用release()看到这两个锁都被释放了。 最后再重申一次， 强烈推荐使用ConnectionStateListener监控连接的状态，当连接状态为LOST，锁将会丢失。 分布式计数器 顾名思义，计数器是用来计数的, 利用ZooKeeper可以实现一个集群共享的计数器。 只要使用相同的path就可以得到最新的计数器值， 这是由ZooKeeper的一致性保证的。Curator有两个计数器， 一个是用int来计数(SharedCount)，一个用long来计数(DistributedAtomicLong)。 分布式int计数器—SharedCount 这个类使用int类型来计数。 主要涉及三个类。 SharedCount SharedCountReader SharedCountListener SharedCount代表计数器， 可以为它增加一个SharedCountListener，当计数器改变时此Listener可以监听到改变的事件，而SharedCountReader可以读取到最新的值， 包括字面值和带版本信息的值VersionedValue。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class SharedCounterDemo implements SharedCountListener &#123; private static final int QTY = 5; private static final String PATH = \"/examples/counter\"; public static void main(String[] args) throws IOException, Exception &#123; final Random rand = new Random(); SharedCounterDemo example = new SharedCounterDemo(); try (TestingServer server = new TestingServer()) &#123; CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); client.start(); SharedCount baseCount = new SharedCount(client, PATH, 0); baseCount.addListener(example); baseCount.start(); List&lt;SharedCount&gt; examples = Lists.newArrayList(); ExecutorService service = Executors.newFixedThreadPool(QTY); for (int i = 0; i &lt; QTY; ++i) &#123; final SharedCount count = new SharedCount(client, PATH, 0); examples.add(count); Callable&lt;Void&gt; task = () -&gt; &#123; count.start(); Thread.sleep(rand.nextInt(10000)); System.out.println(\"Increment:\" + count.trySetCount(count.getVersionedValue(), count.getCount() + rand.nextInt(10))); return null; &#125;; service.submit(task); &#125; service.shutdown(); service.awaitTermination(10, TimeUnit.MINUTES); for (int i = 0; i &lt; QTY; ++i) &#123; examples.get(i).close(); &#125; baseCount.close(); &#125; Thread.sleep(Integer.MAX_VALUE); &#125; @Override public void stateChanged(CuratorFramework arg0, ConnectionState arg1) &#123; System.out.println(\"State changed: \" + arg1.toString()); &#125; @Override public void countHasChanged(SharedCountReader sharedCount, int newCount) throws Exception &#123; System.out.println(\"Counter's value is changed to \" + newCount); &#125;&#125; 在这个例子中，我们使用baseCount来监听计数值(addListener方法来添加SharedCountListener )。 任意的SharedCount， 只要使用相同的path，都可以得到这个计数值。 然后我们使用5个线程为计数值增加一个10以内的随机数。相同的path的SharedCount对计数值进行更改，将会回调给baseCount的SharedCountListener。 1count.trySetCount(count.getVersionedValue(), count.getCount() + rand.nextInt(10)) 这里我们使用trySetCount去设置计数器。 第一个参数提供当前的VersionedValue,如果期间其它client更新了此计数值， 你的更新可能不成功， 但是这时你的client更新了最新的值，所以失败了你可以尝试再更新一次。 而setCount是强制更新计数器的值。 注意计数器必须start,使用完之后必须调用close关闭它。 强烈推荐使用ConnectionStateListener。 在本例中SharedCountListener扩展ConnectionStateListener。 分布式long计数器—DistributedAtomicLong 再看一个Long类型的计数器。 除了计数的范围比SharedCount大了之外， 它首先尝试使用乐观锁的方式设置计数器， 如果不成功(比如期间计数器已经被其它client更新了)， 它使用InterProcessMutex方式来更新计数值。 可以从它的内部实现DistributedAtomicValue.trySet()中看出： 123456789101112AtomicValue&lt;byte[]&gt; trySet(MakeValue makeValue) throws Exception &#123; MutableAtomicValue&lt;byte[]&gt; result = new MutableAtomicValue&lt;byte[]&gt;(null, null, false); tryOptimistic(result, makeValue); if ( !result.succeeded() &amp;&amp; (mutex != null) ) &#123; tryWithMutex(result, makeValue); &#125; return result; &#125; 此计数器有一系列的操作： get(): 获取当前值 increment()： 加一 decrement(): 减一 add()： 增加特定的值 subtract(): 减去特定的值 trySet(): 尝试设置计数值 forceSet(): 强制设置计数值 你必须检查返回结果的succeeded()， 它代表此操作是否成功。 如果操作成功， preValue()代表操作前的值， postValue()代表操作后的值。 1234567891011121314151617181920212223242526272829303132333435public class DistributedAtomicLongDemo &#123; private static final int QTY = 5; private static final String PATH = \"/examples/counter\"; public static void main(String[] args) throws IOException, Exception &#123; List&lt;DistributedAtomicLong&gt; examples = Lists.newArrayList(); try (TestingServer server = new TestingServer()) &#123; CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); client.start(); ExecutorService service = Executors.newFixedThreadPool(QTY); for (int i = 0; i &lt; QTY; ++i) &#123; final DistributedAtomicLong count = new DistributedAtomicLong(client, PATH, new RetryNTimes(10, 10)); examples.add(count); Callable&lt;Void&gt; task = () -&gt; &#123; try &#123; AtomicValue&lt;Long&gt; value = count.increment(); System.out.println(\"succeed: \" + value.succeeded()); if (value.succeeded()) System.out.println(\"Increment: from \" + value.preValue() + \" to \" + value.postValue()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;; service.submit(task); &#125; service.shutdown(); service.awaitTermination(10, TimeUnit.MINUTES); Thread.sleep(Integer.MAX_VALUE); &#125; &#125;&#125; 分布式队列 使用Curator也可以简化Ephemeral Node (临时节点)的操作。Curator也提供ZK Recipe的分布式队列实现。 利用ZK的 PERSISTENTS_EQUENTIAL节点， 可以保证放入到队列中的项目是按照顺序排队的。 如果单一的消费者从队列中取数据， 那么它是先入先出的，这也是队列的特点。 如果你严格要求顺序，你就的使用单一的消费者，可以使用Leader选举只让Leader作为唯一的消费者。 但是， 根据Netflix的Curator作者所说， ZooKeeper真心不适合做Queue，或者说ZK没有实现一个好的Queue，详细内容可以看 Tech Note 4， 原因有五： ZK有1MB 的传输限制。 实践中ZNode必须相对较小，而队列包含成千上万的消息，非常的大。 如果有很多节点，ZK启动时相当的慢。 而使用queue会导致好多ZNode. 你需要显著增大 initLimit 和 syncLimit. ZNode很大的时候很难清理。Netflix不得不创建了一个专门的程序做这事。 当很大量的包含成千上万的子节点的ZNode时， ZK的性能变得不好 ZK的数据库完全放在内存中。 大量的Queue意味着会占用很多的内存空间。 尽管如此， Curator还是创建了各种Queue的实现。 如果Queue的数据量不太多，数据量不太大的情况下，酌情考虑，还是可以使用的。 分布式队列—DistributedQueue DistributedQueue是最普通的一种队列。 它设计以下四个类： QueueBuilder - 创建队列使用QueueBuilder,它也是其它队列的创建类 QueueConsumer - 队列中的消息消费者接口 QueueSerializer - 队列消息序列化和反序列化接口，提供了对队列中的对象的序列化和反序列化 DistributedQueue - 队列实现类 QueueConsumer是消费者，它可以接收队列的数据。处理队列中的数据的代码逻辑可以放在QueueConsumer.consumeMessage()中。 正常情况下先将消息从队列中移除，再交给消费者消费。但这是两个步骤，不是原子的。可以调用Builder的lockPath()消费者加锁，当消费者消费数据时持有锁，这样其它消费者不能消费此消息。如果消费失败或者进程死掉，消息可以交给其它进程。这会带来一点性能的损失。最好还是单消费者模式使用队列。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class DistributedQueueDemo &#123; private static final String PATH = \"/example/queue\"; public static void main(String[] args) throws Exception &#123; TestingServer server = new TestingServer(); CuratorFramework clientA = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); clientA.start(); CuratorFramework clientB = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); clientB.start(); DistributedQueue&lt;String&gt; queueA; QueueBuilder&lt;String&gt; builderA = QueueBuilder.builder(clientA, createQueueConsumer(\"A\"), createQueueSerializer(), PATH); queueA = builderA.buildQueue(); queueA.start(); DistributedQueue&lt;String&gt; queueB; QueueBuilder&lt;String&gt; builderB = QueueBuilder.builder(clientB, createQueueConsumer(\"B\"), createQueueSerializer(), PATH); queueB = builderB.buildQueue(); queueB.start(); for (int i = 0; i &lt; 100; i++) &#123; queueA.put(\" test-A-\" + i); Thread.sleep(10); queueB.put(\" test-B-\" + i); &#125; Thread.sleep(1000 * 10);// 等待消息消费完成 queueB.close(); queueA.close(); clientB.close(); clientA.close(); System.out.println(\"OK!\"); &#125; /** * 队列消息序列化实现类 */ private static QueueSerializer&lt;String&gt; createQueueSerializer() &#123; return new QueueSerializer&lt;String&gt;() &#123; @Override public byte[] serialize(String item) &#123; return item.getBytes(); &#125; @Override public String deserialize(byte[] bytes) &#123; return new String(bytes); &#125; &#125;; &#125; /** * 定义队列消费者 */ private static QueueConsumer&lt;String&gt; createQueueConsumer(final String name) &#123; return new QueueConsumer&lt;String&gt;() &#123; @Override public void stateChanged(CuratorFramework client, ConnectionState newState) &#123; System.out.println(\"连接状态改变: \" + newState.name()); &#125; @Override public void consumeMessage(String message) throws Exception &#123; System.out.println(\"消费消息(\" + name + \"): \" + message); &#125; &#125;; &#125;&#125; 例子中定义了两个分布式队列和两个消费者，因为PATH是相同的，会存在消费者抢占消费消息的情况。 带Id的分布式队列—DistributedIdQueue DistributedIdQueue和上面的队列类似，但是可以为队列中的每一个元素设置一个ID。 可以通过ID把队列中任意的元素移除。 它涉及几个类： QueueBuilder QueueConsumer QueueSerializer DistributedQueue 通过下面方法创建： 1builder.buildIdQueue() 放入元素时： 1queue.put(aMessage, messageId); 移除元素时： 1int numberRemoved &#x3D; queue.remove(messageId); 在这个例子中， 有些元素还没有被消费者消费前就移除了，这样消费者不会收到删除的消息。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class DistributedIdQueueDemo &#123; private static final String PATH = \"/example/queue\"; public static void main(String[] args) throws Exception &#123; TestingServer server = new TestingServer(); CuratorFramework client = null; DistributedIdQueue&lt;String&gt; queue = null; try &#123; client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); client.getCuratorListenable().addListener((client1, event) -&gt; System.out.println(\"CuratorEvent: \" + event.getType().name())); client.start(); QueueConsumer&lt;String&gt; consumer = createQueueConsumer(); QueueBuilder&lt;String&gt; builder = QueueBuilder.builder(client, consumer, createQueueSerializer(), PATH); queue = builder.buildIdQueue(); queue.start(); for (int i = 0; i &lt; 10; i++) &#123; queue.put(\" test-\" + i, \"Id\" + i); Thread.sleep((long) (15 * Math.random())); queue.remove(\"Id\" + i); &#125; Thread.sleep(20000); &#125; catch (Exception ex) &#123; &#125; finally &#123; CloseableUtils.closeQuietly(queue); CloseableUtils.closeQuietly(client); CloseableUtils.closeQuietly(server); &#125; &#125; private static QueueSerializer&lt;String&gt; createQueueSerializer() &#123; return new QueueSerializer&lt;String&gt;() &#123; @Override public byte[] serialize(String item) &#123; return item.getBytes(); &#125; @Override public String deserialize(byte[] bytes) &#123; return new String(bytes); &#125; &#125;; &#125; private static QueueConsumer&lt;String&gt; createQueueConsumer() &#123; return new QueueConsumer&lt;String&gt;() &#123; @Override public void stateChanged(CuratorFramework client, ConnectionState newState) &#123; System.out.println(\"connection new state: \" + newState.name()); &#125; @Override public void consumeMessage(String message) throws Exception &#123; System.out.println(\"consume one message: \" + message); &#125; &#125;; &#125;&#125; 优先级分布式队列—DistributedPriorityQueue 优先级队列对队列中的元素按照优先级进行排序。 Priority越小， 元素越靠前， 越先被消费掉。 它涉及下面几个类： QueueBuilder QueueConsumer QueueSerializer DistributedPriorityQueue 通过builder.buildPriorityQueue(minItemsBeforeRefresh)方法创建。 当优先级队列得到元素增删消息时，它会暂停处理当前的元素队列，然后刷新队列。minItemsBeforeRefresh指定刷新前当前活动的队列的最小数量。 主要设置你的程序可以容忍的不排序的最小值。 放入队列时需要指定优先级： 1queue.put(aMessage, priority); 例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class DistributedPriorityQueueDemo &#123; private static final String PATH = \"/example/queue\"; public static void main(String[] args) throws Exception &#123; TestingServer server = new TestingServer(); CuratorFramework client = null; DistributedPriorityQueue&lt;String&gt; queue = null; try &#123; client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); client.getCuratorListenable().addListener((client1, event) -&gt; System.out.println(\"CuratorEvent: \" + event.getType().name())); client.start(); QueueConsumer&lt;String&gt; consumer = createQueueConsumer(); QueueBuilder&lt;String&gt; builder = QueueBuilder.builder(client, consumer, createQueueSerializer(), PATH); queue = builder.buildPriorityQueue(0); queue.start(); for (int i = 0; i &lt; 10; i++) &#123; int priority = (int) (Math.random() * 100); System.out.println(\"test-\" + i + \" priority:\" + priority); queue.put(\"test-\" + i, priority); Thread.sleep((long) (50 * Math.random())); &#125; Thread.sleep(20000); &#125; catch (Exception ex) &#123; &#125; finally &#123; CloseableUtils.closeQuietly(queue); CloseableUtils.closeQuietly(client); CloseableUtils.closeQuietly(server); &#125; &#125; private static QueueSerializer&lt;String&gt; createQueueSerializer() &#123; return new QueueSerializer&lt;String&gt;() &#123; @Override public byte[] serialize(String item) &#123; return item.getBytes(); &#125; @Override public String deserialize(byte[] bytes) &#123; return new String(bytes); &#125; &#125;; &#125; private static QueueConsumer&lt;String&gt; createQueueConsumer() &#123; return new QueueConsumer&lt;String&gt;() &#123; @Override public void stateChanged(CuratorFramework client, ConnectionState newState) &#123; System.out.println(\"connection new state: \" + newState.name()); &#125; @Override public void consumeMessage(String message) throws Exception &#123; Thread.sleep(1000); System.out.println(\"consume one message: \" + message); &#125; &#125;; &#125;&#125; 有时候你可能会有错觉，优先级设置并没有起效。那是因为优先级是对于队列积压的元素而言，如果消费速度过快有可能出现在后一个元素入队操作之前前一个元素已经被消费，这种情况下DistributedPriorityQueue会退化为DistributedQueue。 分布式延迟队列—DistributedDelayQueue JDK中也有DelayQueue，不知道你是否熟悉。 DistributedDelayQueue也提供了类似的功能， 元素有个delay值， 消费者隔一段时间才能收到元素。 涉及到下面四个类。 QueueBuilder QueueConsumer QueueSerializer DistributedDelayQueue 通过下面的语句创建： 123QueueBuilder&lt;MessageType&gt; builder &#x3D; QueueBuilder.builder(client, consumer, serializer, path);... more builder method calls as needed ...DistributedDelayQueue&lt;MessageType&gt; queue &#x3D; builder.buildDelayQueue(); 放入元素时可以指定delayUntilEpoch： 1queue.put(aMessage, delayUntilEpoch); 注意delayUntilEpoch不是离现在的一个时间间隔， 比如20毫秒，而是未来的一个时间戳，如 System.currentTimeMillis() + 10秒。 如果delayUntilEpoch的时间已经过去，消息会立刻被消费者接收。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class DistributedDelayQueueDemo &#123; private static final String PATH = \"/example/queue\"; public static void main(String[] args) throws Exception &#123; TestingServer server = new TestingServer(); CuratorFramework client = null; DistributedDelayQueue&lt;String&gt; queue = null; try &#123; client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); client.getCuratorListenable().addListener((client1, event) -&gt; System.out.println(\"CuratorEvent: \" + event.getType().name())); client.start(); QueueConsumer&lt;String&gt; consumer = createQueueConsumer(); QueueBuilder&lt;String&gt; builder = QueueBuilder.builder(client, consumer, createQueueSerializer(), PATH); queue = builder.buildDelayQueue(); queue.start(); for (int i = 0; i &lt; 10; i++) &#123; queue.put(\"test-\" + i, System.currentTimeMillis() + 10000); &#125; System.out.println(new Date().getTime() + \": already put all items\"); Thread.sleep(20000); &#125; catch (Exception ex) &#123; &#125; finally &#123; CloseableUtils.closeQuietly(queue); CloseableUtils.closeQuietly(client); CloseableUtils.closeQuietly(server); &#125; &#125; private static QueueSerializer&lt;String&gt; createQueueSerializer() &#123; return new QueueSerializer&lt;String&gt;() &#123; @Override public byte[] serialize(String item) &#123; return item.getBytes(); &#125; @Override public String deserialize(byte[] bytes) &#123; return new String(bytes); &#125; &#125;; &#125; private static QueueConsumer&lt;String&gt; createQueueConsumer() &#123; return new QueueConsumer&lt;String&gt;() &#123; @Override public void stateChanged(CuratorFramework client, ConnectionState newState) &#123; System.out.println(\"connection new state: \" + newState.name()); &#125; @Override public void consumeMessage(String message) throws Exception &#123; System.out.println(new Date().getTime() + \": consume one message: \" + message); &#125; &#125;; &#125;&#125; SimpleDistributedQueue 前面虽然实现了各种队列，但是你注意到没有，这些队列并没有实现类似JDK一样的接口。 SimpleDistributedQueue提供了和JDK基本一致的接口(但是没有实现Queue接口)。 创建很简单： 1public SimpleDistributedQueue(CuratorFramework client,String path) 增加元素： 1public boolean offer(byte[] data) throws Exception 删除元素： 1public byte[] take() throws Exception 另外还提供了其它方法： 12345public byte[] peek() throws Exceptionpublic byte[] poll(long timeout, TimeUnit unit) throws Exceptionpublic byte[] poll() throws Exceptionpublic byte[] remove() throws Exceptionpublic byte[] element() throws Exception 没有add方法， 多了take方法。 take方法在成功返回之前会被阻塞。 而poll方法在队列为空时直接返回null。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class SimpleDistributedQueueDemo &#123; private static final String PATH = \"/example/queue\"; public static void main(String[] args) throws Exception &#123; TestingServer server = new TestingServer(); CuratorFramework client = null; SimpleDistributedQueue queue; try &#123; client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); client.getCuratorListenable().addListener((client1, event) -&gt; System.out.println(\"CuratorEvent: \" + event.getType().name())); client.start(); queue = new SimpleDistributedQueue(client, PATH); Producer producer = new Producer(queue); Consumer consumer = new Consumer(queue); new Thread(producer, \"producer\").start(); new Thread(consumer, \"consumer\").start(); Thread.sleep(20000); &#125; catch (Exception ex) &#123; &#125; finally &#123; CloseableUtils.closeQuietly(client); CloseableUtils.closeQuietly(server); &#125; &#125; public static class Producer implements Runnable &#123; private SimpleDistributedQueue queue; public Producer(SimpleDistributedQueue queue) &#123; this.queue = queue; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; try &#123; boolean flag = queue.offer((\"zjc-\" + i).getBytes()); if (flag) &#123; System.out.println(\"发送一条消息成功：\" + \"zjc-\" + i); &#125; else &#123; System.out.println(\"发送一条消息失败：\" + \"zjc-\" + i); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public static class Consumer implements Runnable &#123; private SimpleDistributedQueue queue; public Consumer(SimpleDistributedQueue queue) &#123; this.queue = queue; &#125; @Override public void run() &#123; try &#123; byte[] datas = queue.take(); System.out.println(\"消费一条消息成功：\" + new String(datas, \"UTF-8\")); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 但是实际上发送了100条消息，消费完第一条之后，后面的消息无法消费，目前没找到原因。查看一下官方文档推荐的demo使用下面几个Api： 123456789101112131415161718192021222324Creating a SimpleDistributedQueuepublic SimpleDistributedQueue(CuratorFramework client, String path)Parameters:client - the clientpath - path to store queue nodesAdd to the queuepublic boolean offer(byte[] data) throws ExceptionInserts data into queue.Parameters:data - the dataReturns:true if data was successfully addedTake from the queuepublic byte[] take() throws ExceptionRemoves the head of the queue and returns it, blocks until it succeeds.Returns:The former head of the queueNOTE: see the Javadoc for additional methods 但是实际使用发现还是存在消费阻塞问题。 分布式屏障—Barrier 分布式Barrier是这样一个类： 它会阻塞所有节点上的等待进程，直到某一个被满足， 然后所有的节点继续进行。 比如赛马比赛中， 等赛马陆续来到起跑线前。 一声令下，所有的赛马都飞奔而出。 DistributedBarrier DistributedBarrier类实现了栅栏的功能。 它的构造函数如下： 1234public DistributedBarrier(CuratorFramework client, String barrierPath)Parameters:client - clientbarrierPath - path to use as the barrier 首先你需要设置栅栏，它将阻塞在它上面等待的线程: 1setBarrier(); 然后需要阻塞的线程调用方法等待放行条件: 1public void waitOnBarrier() 当条件满足时，移除栅栏，所有等待的线程将继续执行： 1removeBarrier(); 异常处理 DistributedBarrier 会监控连接状态，当连接断掉时waitOnBarrier()方法会抛出异常。 1234567891011121314151617181920212223242526272829303132333435public class DistributedBarrierDemo &#123; private static final int QTY = 5; private static final String PATH = \"/examples/barrier\"; public static void main(String[] args) throws Exception &#123; try (TestingServer server = new TestingServer()) &#123; CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); client.start(); ExecutorService service = Executors.newFixedThreadPool(QTY); DistributedBarrier controlBarrier = new DistributedBarrier(client, PATH); controlBarrier.setBarrier(); for (int i = 0; i &lt; QTY; ++i) &#123; final DistributedBarrier barrier = new DistributedBarrier(client, PATH); final int index = i; Callable&lt;Void&gt; task = () -&gt; &#123; Thread.sleep((long) (3 * Math.random())); System.out.println(\"Client #\" + index + \" waits on Barrier\"); barrier.waitOnBarrier(); System.out.println(\"Client #\" + index + \" begins\"); return null; &#125;; service.submit(task); &#125; Thread.sleep(10000); System.out.println(\"all Barrier instances should wait the condition\"); controlBarrier.removeBarrier(); service.shutdown(); service.awaitTermination(10, TimeUnit.MINUTES); Thread.sleep(20000); &#125; &#125;&#125; 这个例子创建了controlBarrier来设置栅栏和移除栅栏。 我们创建了5个线程，在此Barrier上等待。 最后移除栅栏后所有的线程才继续执行。 如果你开始不设置栅栏，所有的线程就不会阻塞住。 双栅栏—DistributedDoubleBarrier 双栅栏允许客户端在计算的开始和结束时同步。当足够的进程加入到双栅栏时，进程开始计算， 当计算完成时，离开栅栏。 双栅栏类是DistributedDoubleBarrier。 构造函数为: 12345678910public DistributedDoubleBarrier(CuratorFramework client, String barrierPath, int memberQty)Creates the barrier abstraction. memberQty is the number of members in the barrier. When enter() is called, it blocks untilall members have entered. When leave() is called, it blocks until all members have left.Parameters:client - the clientbarrierPath - path to usememberQty - the number of members in the barrier memberQty是成员数量，当enter()方法被调用时，成员被阻塞，直到所有的成员都调用了enter()。 当leave()方法被调用时，它也阻塞调用线程，直到所有的成员都调用了leave()。 就像百米赛跑比赛， 发令枪响， 所有的运动员开始跑，等所有的运动员跑过终点线，比赛才结束。 DistributedDoubleBarrier会监控连接状态，当连接断掉时enter()和leave()方法会抛出异常。 12345678910111213141516171819202122232425262728293031323334public class DistributedDoubleBarrierDemo &#123; private static final int QTY = 5; private static final String PATH = \"/examples/barrier\"; public static void main(String[] args) throws Exception &#123; try (TestingServer server = new TestingServer()) &#123; CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), new ExponentialBackoffRetry(1000, 3)); client.start(); ExecutorService service = Executors.newFixedThreadPool(QTY); for (int i = 0; i &lt; QTY; ++i) &#123; final DistributedDoubleBarrier barrier = new DistributedDoubleBarrier(client, PATH, QTY); final int index = i; Callable&lt;Void&gt; task = () -&gt; &#123; Thread.sleep((long) (3 * Math.random())); System.out.println(\"Client #\" + index + \" enters\"); barrier.enter(); System.out.println(\"Client #\" + index + \" begins\"); Thread.sleep((long) (3000 * Math.random())); barrier.leave(); System.out.println(\"Client #\" + index + \" left\"); return null; &#125;; service.submit(task); &#125; service.shutdown(); service.awaitTermination(10, TimeUnit.MINUTES); Thread.sleep(Integer.MAX_VALUE); &#125; &#125;&#125; 参考资料： 《从PAXOS到ZOOKEEPER分布式一致性原理与实践》 《跟着实例学习ZooKeeper的用法》博客系列 项目仓库： https://github.com/zjcscut/curator-seed (e-a-2017-5-13 13:10 c-14-d r-a-20181216)","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"Zookeeper","slug":"Middleware/Zookeeper","permalink":"http://throwable.club/blog/categories/Middleware/Zookeeper/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://throwable.club/blog/tags/Zookeeper/"}]},{"title":"深入分析Java反射(八)-优化反射调用性能","slug":"java-reflection-optimal-performance","date":"2018-12-16T04:00:50.000Z","updated":"2018-12-16T04:01:22.795Z","comments":true,"path":"2018/12/16/java-reflection-optimal-performance/","link":"","permalink":"http://throwable.club/2018/12/16/java-reflection-optimal-performance/","excerpt":"","text":"深入分析Java反射(八)-优化反射调用性能 Java反射的API在JavaSE1.7的时候已经基本完善，但是本文编写的时候使用的是Oracle JDK11，因为JDK11对于sun包下的源码也上传了，可以直接通过IDE查看对应的源码和进行Debug。 前一篇文章已经介绍了反射调用的底层原理，其实在实际中对大多数Java使用者来说更关系的是如何提升反射调用的性能，本文主要提供几个可行的方案。另外，由于方法调用时频率最高的反射操作，会着重介绍方法的反射调用优化。 方法一：选择合适的API 选择合适的API主要是在获取反射相关元数据的时候尽量避免使用遍历的方法，例如： 获取Field实例：尽量避免频繁使用Class#getDeclaredFields()或者Class#getFields()，应该根据Field的名称直接调用Class#getDeclaredField()或者Class#getField()。 获取Method实例：尽量避免频繁使用Class#getDeclaredMethods()或者Class#getMethods()，应该根据Method的名称和参数类型数组调用Class#getDeclaredMethod()或者Class#getMethod()。 获取Constructor实例：尽量避免频繁使用Class#getDeclaredConstructors()或者Class#getConstructors()，应该根据Constructor参数类型数组调用Class#getDeclaredConstructor()或者Class#getConstructor()。 其实思路很简单，除非我们想要获取Class的所有Field、Method或者Constructor，否则应该避免使用返回一个集合或者数组的API，这样子能减少遍历或者判断带来的性能损耗。 方法二：缓存反射操作相关元数据 使用缓存机制缓存反射操作相关元数据的原因是因为反射操作相关元数据的实时获取是比较耗时的，这里列举几个相对耗时的场景： 获取Class实例：Class#forName()，此方法可以查看源码，耗时相对其他方法高得多。 获取Field实例：Class#getDeclaredField()、Class#getDeclaredFields()、Class#getField()、Class#getFields()。 获取Method实例：Class#getDeclaredMethod()、Class#getDeclaredMethods()、Class#getMethod()、Class#getMethods()。 获取Constructor实例：Class#getDeclaredConstructor()、Class#getDeclaredConstructors()、Class#getConstructor()、Class#getConstructors()。 这里举个简单的例子，需要反射调用一个普通JavaBean的Setter和Getter方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697// JavaBean@Datapublic class JavaBean &#123; private String name;&#125;public class Main &#123; private static final Map&lt;Class&lt;?&gt;, List&lt;ReflectionMetadata&gt;&gt; METADATA = new HashMap&lt;&gt;(); private static final Map&lt;String, Class&lt;?&gt;&gt; CLASSES = new HashMap&lt;&gt;(); // 解析的时候尽量放在&lt;cinit&gt;里面 static &#123; Class&lt;?&gt; clazz = JavaBean.class; CLASSES.put(clazz.getName(), clazz); List&lt;ReflectionMetadata&gt; metadataList = new ArrayList&lt;&gt;(); METADATA.put(clazz, metadataList); try &#123; for (Field f : clazz.getDeclaredFields()) &#123; ReflectionMetadata metadata = new ReflectionMetadata(); metadataList.add(metadata); metadata.setTargetClass(clazz); metadata.setField(f); String name = f.getName(); Class&lt;?&gt; type = f.getType(); metadata.setReadMethod(clazz.getDeclaredMethod(String.format(\"get%s%s\", Character.toUpperCase(name.charAt(0)), name.substring(1)))); metadata.setWriteMethod(clazz.getDeclaredMethod(String.format(\"set%s%s\", Character.toUpperCase(name.charAt(0)), name.substring(1)), type)); &#125; &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; public static void main(String[] args) throws Exception &#123; String fieldName = \"name\"; Class&lt;JavaBean&gt; javaBeanClass = JavaBean.class; JavaBean javaBean = new JavaBean(); invokeSetter(javaBeanClass, javaBean, fieldName , \"Doge\"); System.out.println(invokeGetter(javaBeanClass,javaBean, fieldName)); invokeSetter(javaBeanClass.getName(), javaBean, fieldName , \"Throwable\"); System.out.println(invokeGetter(javaBeanClass.getName(),javaBean, fieldName)); &#125; private static void invokeSetter(String className, Object target, String fieldName, Object value) throws Exception &#123; METADATA.get(CLASSES.get(className)).forEach(each -&gt; &#123; Field field = each.getField(); if (field.getName().equals(fieldName)) &#123; try &#123; each.getWriteMethod().invoke(target, value); &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; &#125;); &#125; private static void invokeSetter(Class&lt;?&gt; clazz, Object target, String fieldName, Object value) throws Exception &#123; METADATA.get(clazz).forEach(each -&gt; &#123; Field field = each.getField(); if (field.getName().equals(fieldName)) &#123; try &#123; each.getWriteMethod().invoke(target, value); &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; &#125;); &#125; private static Object invokeGetter(String className, Object target, String fieldName) throws Exception &#123; for (ReflectionMetadata metadata : METADATA.get(CLASSES.get(className))) &#123; if (metadata.getField().getName().equals(fieldName)) &#123; return metadata.getReadMethod().invoke(target); &#125; &#125; throw new IllegalStateException(); &#125; private static Object invokeGetter(Class&lt;?&gt; clazz, Object target, String fieldName) throws Exception &#123; for (ReflectionMetadata metadata : METADATA.get(clazz)) &#123; if (metadata.getField().getName().equals(fieldName)) &#123; return metadata.getReadMethod().invoke(target); &#125; &#125; throw new IllegalStateException(); &#125; @Data private static class ReflectionMetadata &#123; private Class&lt;?&gt; targetClass; private Field field; private Method readMethod; private Method writeMethod; &#125;&#125; 简单来说，解析反射元数据进行缓存的操作最好放在静态代码块或者首次调用的时候(也就是懒加载)，这样能够避免真正调用的时候总是需要重新加载一次反射相关元数据。 方法三：反射操作转变为直接调用 &quot;反射操作转变为直接调用&quot;并不是完全不依赖于反射的类库，这里的做法是把反射操作相关元数据直接放置在类的成员变量中，这样就能省去从缓存中读取反射相关元数据的消耗，而所谓&quot;直接调用&quot;一般是通过继承或者实现接口实现。有一些高性能的反射类库也会使用一些创新的方法：例如使用成员属性缓存反射相关元数据，并且把方法调用通过数字建立索引[Number-&gt;Method]或者建立索引类(像CGLIB的FastClass)，这种做法在父类或者接口方法比较少的时候会有一定的性能提升，但是实际上性能评估需要从具体的场景通过测试分析结果而不能盲目使用，使用这个思想的类库有CGLIB、ReflectASM等。&quot;反射操作转变为直接调用&quot;的最典型的实现就是JDK的动态代理，这里翻出之前动态代理那篇文章的例子来说： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596// 接口public interface Simple &#123; void sayHello(String name);&#125;// 接口实现public class DefaultSimple implements Simple &#123; @Override public void sayHello(String name) &#123; System.out.println(String.format(\"%s say hello!\", name)); &#125;&#125;// 场景类public class Main &#123; public static void main(String[] args) throws Exception &#123; Simple simple = new DefaultSimple(); Object target = Proxy.newProxyInstance(Main.class.getClassLoader(), new Class[]&#123;Simple.class&#125;, new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"Before say hello...\"); method.invoke(simple, args); System.out.println(\"After say hello...\"); return null; &#125; &#125;); Simple proxy = (Simple) target; proxy.sayHello(\"throwable\"); &#125;&#125;// 代理类public final class $Proxy0 extends Proxy implements Simple &#123; private static Method m1; private static Method m3; private static Method m2; private static Method m0; public $Proxy0(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final void sayHello(String var1) throws &#123; try &#123; super.h.invoke(this, m3, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final int hashCode() throws &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m3 = Class.forName(\"club.throwable.jdk.sample.reflection.proxy.Simple\").getMethod(\"sayHello\", Class.forName(\"java.lang.String\")); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125; 这样做的话Simple接口实例虽然最终是通过反射调用sayHello(String var1)方法，但是相关元数据在静态代码块中创建并且已经缓存在类成员属性中，那么反射调用方法的性能已经优化到极致，剩下的都只是Native方法的耗时，这一点使用者在编码层面已经没有办法优化，只能通过升级JVM(JDK)、使用JIT编译器等非编码层面的手段提升反射性能。 小结 本文主要从编码层面分析反射操作一些性能优化的可行经验或者方案，或许有其他更好的优化方案，具体还是需要看使用场景。 (本文完 e-a-20181216 c-2-d)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Reflection","slug":"Java/Reflection","permalink":"http://throwable.club/blog/categories/Java/Reflection/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Reflection","slug":"Reflection","permalink":"http://throwable.club/blog/tags/Reflection/"}]},{"title":"深入分析Java反射(七)-简述反射调用的底层实现","slug":"java-reflection-implementance","date":"2018-12-15T17:07:58.000Z","updated":"2018-12-15T17:09:52.958Z","comments":true,"path":"2018/12/16/java-reflection-implementance/","link":"","permalink":"http://throwable.club/2018/12/16/java-reflection-implementance/","excerpt":"","text":"深入分析Java反射(七)-简述反射调用的底层实现 前提 Java反射的API在JavaSE1.7的时候已经基本完善，但是本文编写的时候使用的是Oracle JDK11，因为JDK11对于sun包下的源码也上传了，可以直接通过IDE查看对应的源码和进行Debug。 本文主要介绍反射调用的底层实现，当然还没有能力分析JVM的实现，这里只分析到最终Native方法的调用点。底层会依赖到Unsafe类，可以的话可以看下笔者之前写的一篇文章《神奇的魔法类和双刃剑-Unsafe》。 反射调用的底层实现探究 主要考虑下面的情况： 属性操作：java.lang.reflect.Field#set(Object obj, Object value)和java.lang.reflect.Field#get(Object obj)。 构造器调用：java.lang.reflect.Constructor#newInstance(Object ... initargs)。 方法调用：java.lang.reflect.Method#invoke(Object obj, Object... args)。 处理属性操作的底层实现 属性操作方法Field#set(Object obj, Object value)和Field#get(Object obj)底层都是委托到jdk.internal.reflect.FieldAccessor实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public interface FieldAccessor &#123; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public Object get(Object obj) throws IllegalArgumentException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public boolean getBoolean(Object obj) throws IllegalArgumentException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public byte getByte(Object obj) throws IllegalArgumentException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public char getChar(Object obj) throws IllegalArgumentException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public short getShort(Object obj) throws IllegalArgumentException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public int getInt(Object obj) throws IllegalArgumentException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public long getLong(Object obj) throws IllegalArgumentException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public float getFloat(Object obj) throws IllegalArgumentException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public double getDouble(Object obj) throws IllegalArgumentException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public void set(Object obj, Object value) throws IllegalArgumentException, IllegalAccessException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public void setBoolean(Object obj, boolean z) throws IllegalArgumentException, IllegalAccessException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public void setByte(Object obj, byte b) throws IllegalArgumentException, IllegalAccessException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public void setChar(Object obj, char c) throws IllegalArgumentException, IllegalAccessException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public void setShort(Object obj, short s) throws IllegalArgumentException, IllegalAccessException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public void setInt(Object obj, int i) throws IllegalArgumentException, IllegalAccessException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public void setLong(Object obj, long l) throws IllegalArgumentException, IllegalAccessException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public void setFloat(Object obj, float f) throws IllegalArgumentException, IllegalAccessException; /** Matches specification in &#123;@link java.lang.reflect.Field&#125; */ public void setDouble(Object obj, double d) throws IllegalArgumentException, IllegalAccessException;&#125; FieldAccessor接口有很多的实现，FieldAccessor接口实例是通过jdk.internal.reflect.ReflectionFactory这个工厂构造的： 12345678910111213public FieldAccessor newFieldAccessor(Field field, boolean override) &#123; checkInitted(); Field root = langReflectAccess.getRoot(field); if (root != null) &#123; // FieldAccessor will use the root unless the modifiers have // been overrridden if (root.getModifiers() == field.getModifiers() || !override) &#123; field = root; &#125; &#125; return UnsafeFieldAccessorFactory.newFieldAccessor(field, override);&#125; 最终委托到UnsafeFieldAccessorFactory#newFieldAccessor()： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100class UnsafeFieldAccessorFactory &#123; static FieldAccessor newFieldAccessor(Field field, boolean override) &#123; Class&lt;?&gt; type = field.getType(); boolean isStatic = Modifier.isStatic(field.getModifiers()); boolean isFinal = Modifier.isFinal(field.getModifiers()); boolean isVolatile = Modifier.isVolatile(field.getModifiers()); boolean isQualified = isFinal || isVolatile; boolean isReadOnly = isFinal &amp;&amp; (isStatic || !override); if (isStatic) &#123; // This code path does not guarantee that the field's // declaring class has been initialized, but it must be // before performing reflective operations. UnsafeFieldAccessorImpl.unsafe.ensureClassInitialized(field.getDeclaringClass()); if (!isQualified) &#123; if (type == Boolean.TYPE) &#123; return new UnsafeStaticBooleanFieldAccessorImpl(field); &#125; else if (type == Byte.TYPE) &#123; return new UnsafeStaticByteFieldAccessorImpl(field); &#125; else if (type == Short.TYPE) &#123; return new UnsafeStaticShortFieldAccessorImpl(field); &#125; else if (type == Character.TYPE) &#123; return new UnsafeStaticCharacterFieldAccessorImpl(field); &#125; else if (type == Integer.TYPE) &#123; return new UnsafeStaticIntegerFieldAccessorImpl(field); &#125; else if (type == Long.TYPE) &#123; return new UnsafeStaticLongFieldAccessorImpl(field); &#125; else if (type == Float.TYPE) &#123; return new UnsafeStaticFloatFieldAccessorImpl(field); &#125; else if (type == Double.TYPE) &#123; return new UnsafeStaticDoubleFieldAccessorImpl(field); &#125; else &#123; return new UnsafeStaticObjectFieldAccessorImpl(field); &#125; &#125; else &#123; if (type == Boolean.TYPE) &#123; return new UnsafeQualifiedStaticBooleanFieldAccessorImpl(field, isReadOnly); &#125; else if (type == Byte.TYPE) &#123; return new UnsafeQualifiedStaticByteFieldAccessorImpl(field, isReadOnly); &#125; else if (type == Short.TYPE) &#123; return new UnsafeQualifiedStaticShortFieldAccessorImpl(field, isReadOnly); &#125; else if (type == Character.TYPE) &#123; return new UnsafeQualifiedStaticCharacterFieldAccessorImpl(field, isReadOnly); &#125; else if (type == Integer.TYPE) &#123; return new UnsafeQualifiedStaticIntegerFieldAccessorImpl(field, isReadOnly); &#125; else if (type == Long.TYPE) &#123; return new UnsafeQualifiedStaticLongFieldAccessorImpl(field, isReadOnly); &#125; else if (type == Float.TYPE) &#123; return new UnsafeQualifiedStaticFloatFieldAccessorImpl(field, isReadOnly); &#125; else if (type == Double.TYPE) &#123; return new UnsafeQualifiedStaticDoubleFieldAccessorImpl(field, isReadOnly); &#125; else &#123; return new UnsafeQualifiedStaticObjectFieldAccessorImpl(field, isReadOnly); &#125; &#125; &#125; else &#123; if (!isQualified) &#123; if (type == Boolean.TYPE) &#123; return new UnsafeBooleanFieldAccessorImpl(field); &#125; else if (type == Byte.TYPE) &#123; return new UnsafeByteFieldAccessorImpl(field); &#125; else if (type == Short.TYPE) &#123; return new UnsafeShortFieldAccessorImpl(field); &#125; else if (type == Character.TYPE) &#123; return new UnsafeCharacterFieldAccessorImpl(field); &#125; else if (type == Integer.TYPE) &#123; return new UnsafeIntegerFieldAccessorImpl(field); &#125; else if (type == Long.TYPE) &#123; return new UnsafeLongFieldAccessorImpl(field); &#125; else if (type == Float.TYPE) &#123; return new UnsafeFloatFieldAccessorImpl(field); &#125; else if (type == Double.TYPE) &#123; return new UnsafeDoubleFieldAccessorImpl(field); &#125; else &#123; return new UnsafeObjectFieldAccessorImpl(field); &#125; &#125; else &#123; if (type == Boolean.TYPE) &#123; return new UnsafeQualifiedBooleanFieldAccessorImpl(field, isReadOnly); &#125; else if (type == Byte.TYPE) &#123; return new UnsafeQualifiedByteFieldAccessorImpl(field, isReadOnly); &#125; else if (type == Short.TYPE) &#123; return new UnsafeQualifiedShortFieldAccessorImpl(field, isReadOnly); &#125; else if (type == Character.TYPE) &#123; return new UnsafeQualifiedCharacterFieldAccessorImpl(field, isReadOnly); &#125; else if (type == Integer.TYPE) &#123; return new UnsafeQualifiedIntegerFieldAccessorImpl(field, isReadOnly); &#125; else if (type == Long.TYPE) &#123; return new UnsafeQualifiedLongFieldAccessorImpl(field, isReadOnly); &#125; else if (type == Float.TYPE) &#123; return new UnsafeQualifiedFloatFieldAccessorImpl(field, isReadOnly); &#125; else if (type == Double.TYPE) &#123; return new UnsafeQualifiedDoubleFieldAccessorImpl(field, isReadOnly); &#125; else &#123; return new UnsafeQualifiedObjectFieldAccessorImpl(field, isReadOnly); &#125; &#125; &#125; &#125;&#125; 这里注意一下属性修饰符的判断： isStatic：静态属性，也就是static关键字修饰的属性。 isFinal：final关键字修饰的属性。 isVolatile：valatile关键字修饰的属性。 isQualified：valatile关键字或者final关键字修饰的属性。 isReadOnly：是否只读属性，final关键字修饰的属性或者static关键字修饰并且不能覆盖(override = false)的属性。 通过上面修饰符做判断，得到最终的FieldAccessor实现。这里挑一个例子进行分析，例如一个普通非静态没有volatile和final关键字修饰属性最终就会得到UnsafeObjectFieldAccessorImpl的实例： 12345678910111213141516171819202122232425262728293031323334class UnsafeObjectFieldAccessorImpl extends UnsafeFieldAccessorImpl &#123; UnsafeObjectFieldAccessorImpl(Field field) &#123; super(field); &#125; public Object get(Object obj) throws IllegalArgumentException &#123; ensureObj(obj); return unsafe.getObject(obj, fieldOffset); &#125; public void set(Object obj, Object value) throws IllegalArgumentException, IllegalAccessException&#123; ensureObj(obj); if (isFinal) &#123; throwFinalFieldIllegalAccessException(value); &#125; if (value != null) &#123; if (!field.getType().isAssignableFrom(value.getClass())) &#123; throwSetIllegalArgumentException(value); &#125; &#125; unsafe.putObject(obj, fieldOffset, value); &#125; public boolean getBoolean(Object obj) throws IllegalArgumentException &#123; throw newGetBooleanIllegalArgumentException(); &#125; public byte getByte(Object obj) throws IllegalArgumentException &#123; throw newGetByteIllegalArgumentException(); &#125; // 省略其他直接抛出异常的方法 &#125; 可见UnsafeObjectFieldAccessorImpl中除了get(Object obj)和set(Object obj, Object value)方法，其他方法都是直接抛出IllegalArgumentException。而get(Object obj)和set(Object obj, Object value)底层分别依赖于jdk.internal.misc.Unsafe的putObject(obj, fieldOffset, value)和getObject(obj, fieldOffset)方法。而属性的内存偏移地址是在UnsafeObjectFieldAccessorImpl的父类UnsafeFieldAccessorImpl的构造函数中计算出来的： 1234567891011121314151617abstract class UnsafeFieldAccessorImpl extends FieldAccessorImpl &#123; static final Unsafe unsafe = Unsafe.getUnsafe(); protected final Field field; protected final long fieldOffset; protected final boolean isFinal; UnsafeFieldAccessorImpl(Field field) &#123; this.field = field; if (Modifier.isStatic(field.getModifiers())) fieldOffset = unsafe.staticFieldOffset(field); else fieldOffset = unsafe.objectFieldOffset(field); isFinal = Modifier.isFinal(field.getModifiers()); &#125; // 省略其他方法 &#125; 这里可以做个小结，属性反射操作Field的setXX和getXX方法最终委托到jdk.internal.misc.Unsafe的putXX和getXX方法，而属性的内存偏移地址是通过jdk.internal.misc.Unsafe的staticFieldBase()、staticFieldOffset和objectFieldOffset几个方法计算的。 处理构造器调用的底层实现 Constructor#newInstance()方法调用依赖到ConstructorAccessor： 123456789101112131415161718192021222324252627 public T newInstance(Object ... initargs) throws InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException &#123; if (!override) &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, clazz, modifiers); &#125; if ((clazz.getModifiers() &amp; Modifier.ENUM) != 0) throw new IllegalArgumentException(\"Cannot reflectively create enum objects\"); ConstructorAccessor ca = constructorAccessor; // read volatile if (ca == null) &#123; ca = acquireConstructorAccessor(); &#125; @SuppressWarnings(\"unchecked\") T inst = (T) ca.newInstance(initargs); return inst; &#125;// ConstructorAccessor接口public interface ConstructorAccessor &#123; /** Matches specification in &#123;@link java.lang.reflect.Constructor&#125; */ public Object newInstance(Object[] args) throws InstantiationException, IllegalArgumentException, InvocationTargetException;&#125; 而获取ConstructorAccessor实例也是通过反射工厂类ReflectionFactory，具体是ReflectionFactory#newConstructorAccessor： 12345678910111213141516171819202122232425262728293031323334353637383940public ConstructorAccessor newConstructorAccessor(Constructor&lt;?&gt; c) &#123; checkInitted(); Class&lt;?&gt; declaringClass = c.getDeclaringClass(); // 抽象方法会进入此if分支 if (Modifier.isAbstract(declaringClass.getModifiers())) &#123; return new InstantiationExceptionConstructorAccessorImpl(null); &#125; // 宿主类直接是Class类型，则无法实例化 if (declaringClass == Class.class) &#123; return new InstantiationExceptionConstructorAccessorImpl (\"Can not instantiate java.lang.Class\"); &#125; // use the root Constructor that will not cache caller class Constructor&lt;?&gt; root = langReflectAccess.getRoot(c); if (root != null) &#123; c = root; &#125; // 当前声明构造的宿主类是ConstructorAccessorImpl的子类 if (Reflection.isSubclassOf(declaringClass, ConstructorAccessorImpl.class)) &#123; return new BootstrapConstructorAccessorImpl(c); &#125; // if (noInflation &amp;&amp; !ReflectUtil.isVMAnonymousClass(c.getDeclaringClass())) &#123; return new MethodAccessorGenerator(). generateConstructor(c.getDeclaringClass(), c.getParameterTypes(), c.getExceptionTypes(), c.getModifiers()); &#125; else &#123; NativeConstructorAccessorImpl acc = new NativeConstructorAccessorImpl(c); DelegatingConstructorAccessorImpl res = new DelegatingConstructorAccessorImpl(acc); acc.setParent(res); return res; &#125;&#125; 可见最终得到的ConstructorAccessor实例为DelegatingConstructorAccessorImpl，而DelegatingConstructorAccessorImpl只是一个委托实现，底层是调用NativeConstructorAccessorImpl： 12345678910111213141516171819202122232425262728293031323334353637383940class NativeConstructorAccessorImpl extends ConstructorAccessorImpl &#123; private final Constructor&lt;?&gt; c; private DelegatingConstructorAccessorImpl parent; private int numInvocations; NativeConstructorAccessorImpl(Constructor&lt;?&gt; c) &#123; this.c = c; &#125; public Object newInstance(Object[] args) throws InstantiationException, IllegalArgumentException, InvocationTargetException &#123; // We can't inflate a constructor belonging to a vm-anonymous class // because that kind of class can't be referred to by name, hence can't // be found from the generated bytecode. if (++numInvocations &gt; ReflectionFactory.inflationThreshold() &amp;&amp; !ReflectUtil.isVMAnonymousClass(c.getDeclaringClass())) &#123; ConstructorAccessorImpl acc = (ConstructorAccessorImpl) new MethodAccessorGenerator(). generateConstructor(c.getDeclaringClass(), c.getParameterTypes(), c.getExceptionTypes(), c.getModifiers()); parent.setDelegate(acc); &#125; return newInstance0(c, args); &#125; void setParent(DelegatingConstructorAccessorImpl parent) &#123; this.parent = parent; &#125; // 这个就是最终构造实例化对象的native方法 private static native Object newInstance0(Constructor&lt;?&gt; c, Object[] args) throws InstantiationException, IllegalArgumentException, InvocationTargetException;&#125; NativeConstructorAccessorImpl#newInstance0()就是最终构造实例化对象的Native方法。当然有例外的情况，例如非正常调用下，如果构造器的宿主类是一个抽象类，那么最终会返回一个InstantiationExceptionConstructorAccessorImpl实例，里面直接抛出InstantiationException异常。 处理方法调用的底层实现 Method#invoke()调用依赖于MethodAccessor： 12345678910111213141516171819202122// MethodAccessor接口public interface MethodAccessor &#123; /** Matches specification in &#123;@link java.lang.reflect.Method&#125; */ public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException;&#125; public Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException&#123; if (!override) &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, Modifier.isStatic(modifiers) ? null : obj.getClass(), modifiers); &#125; MethodAccessor ma = methodAccessor; // read volatile if (ma == null) &#123; ma = acquireMethodAccessor(); &#125; return ma.invoke(obj, args); &#125; 获取MethodAccessor实例的逻辑和前两节类似，是通过ReflectionFactory#newMethodAccessor()： 123456789101112131415161718192021222324252627282930313233public MethodAccessor newMethodAccessor(Method method) &#123; checkInitted(); if (Reflection.isCallerSensitive(method)) &#123; Method altMethod = findMethodForReflection(method); if (altMethod != null) &#123; method = altMethod; &#125; &#125; // use the root Method that will not cache caller class Method root = langReflectAccess.getRoot(method); if (root != null) &#123; method = root; &#125; if (noInflation &amp;&amp; !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) &#123; return new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); &#125; else &#123; NativeMethodAccessorImpl acc = new NativeMethodAccessorImpl(method); DelegatingMethodAccessorImpl res = new DelegatingMethodAccessorImpl(acc); acc.setParent(res); return res; &#125;&#125; 最终会委托到NativeMethodAccessorImpl#invoke(Object obj, Object[] args)： 12345678910111213141516171819202122232425262728293031323334353637class NativeMethodAccessorImpl extends MethodAccessorImpl &#123; private final Method method; private DelegatingMethodAccessorImpl parent; private int numInvocations; NativeMethodAccessorImpl(Method method) &#123; this.method = method; &#125; public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException &#123; // We can't inflate methods belonging to vm-anonymous classes because // that kind of class can't be referred to by name, hence can't be // found from the generated bytecode. if (++numInvocations &gt; ReflectionFactory.inflationThreshold() &amp;&amp; !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) &#123; MethodAccessorImpl acc = (MethodAccessorImpl) new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); parent.setDelegate(acc); &#125; return invoke0(method, obj, args); &#125; void setParent(DelegatingMethodAccessorImpl parent) &#123; this.parent = parent; &#125; private static native Object invoke0(Method m, Object obj, Object[] args);&#125; 而NativeMethodAccessorImpl#invoke0()就是方法调用的最终调用的Native方法。 小结 学习知识过程总是阶梯式上升的，JDK中的类库设计也类似这样，如果提前熟悉Unsafe类的相关方法，其实反射调用的底层实现也能够相对轻易地理解。属性、构造和方法反射调用底层的实现(只考虑正常调用的情况下)如下： 对于属性(Field)：Field#setXX()和Field#getXX()分别对应Unsafe的putXX()和getXX()方法，也就是说完全依赖Unsafe中的Native方法。 对于构造(Constructor)：Constructor#newInstance()底层调用NativeConstructorAccessorImpl#newInstance0()。 对于方法(Method)：Method#invoke()底层调用NativeMethodAccessorImpl#invoke0() (本文完 e-a-20181216 c-1-d)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Reflection","slug":"Java/Reflection","permalink":"http://throwable.club/blog/categories/Java/Reflection/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Reflection","slug":"Reflection","permalink":"http://throwable.club/blog/tags/Reflection/"}]},{"title":"深入分析Java反射(六)-反射调用异常处理","slug":"java-reflection-handle-exception","date":"2018-12-15T15:07:23.000Z","updated":"2019-01-07T16:04:20.014Z","comments":true,"path":"2018/12/15/java-reflection-handle-exception/","link":"","permalink":"http://throwable.club/2018/12/15/java-reflection-handle-exception/","excerpt":"","text":"深入分析Java反射(六)-反射调用异常处理 前提 Java反射的API在JavaSE1.7的时候已经基本完善，但是本文编写的时候使用的是Oracle JDK11，因为JDK11对于sun包下的源码也上传了，可以直接通过IDE查看对应的源码和进行Debug。 本文主要介绍一个使用反射一定会遇到的问题-反射调用异常处理。 反射调用异常处理 反射调用出现异常的方法主要考虑下面的情况： 属性操作：java.lang.reflect.Field#set(Object obj, Object value)和java.lang.reflect.Field#get(Object obj)。 构造器调用：java.lang.reflect.Constructor#newInstance(Object ... initargs)。 方法调用：java.lang.reflect.Method#invoke(Object obj, Object... args)。 处理属性操作异常 先看设置属性的方法： 1public void set(Object obj, Object value) throws IllegalArgumentException, IllegalAccessException 实际上，通过方法注释可以得知会抛出四种异常： IllegalAccessException：非法访问异常，注意它是检查(checked)异常，也就是需要显示捕获，此异常会在修饰符禁用访问的时候抛出，可以通过setAccessible(true)抑制修饰符检查来避免抛出此异常。 IllegalArgumentException：非法参数异常，它是运行时异常，当入参实例obj不是当前Field所在类(包括父类、子类和接口)的时候会抛出此异常。 NullPointerException：空指针异常，当入参实例obj为null的时候会抛出此异常。 ExceptionInInitializerError：初始化器调用异常导致的错误，如果由于set(Object obj, Object value)方法引发的初始化失败会包装成ExceptionInInitializerError，此异常的父类为Error，常见的发生情况就是静态成员或者静态代码块依赖到反射属性设置。 前面三种异常都很好理解，最后一个ExceptionInInitializerError可能有点陌生，它的抛出条件是：在静态代码块初始化解析过程总抛出异常或者静态变量初始化的时候抛出异常。笔者尝试了很多例子都没办法造出案例，从Stackoverflow找到一个例子： 123456789101112131415public class Example &#123; public static void main(String[] args) throws Exception &#123; Field field = Fail.class.getDeclaredField(\"number\"); field.set(null, 42); // Fail class isn't initialized at this point &#125;&#125;class Fail &#123; static int number; static &#123; boolean val = true; if (val) throw new RuntimeException(); // causes initialization to end with an exception &#125;&#125; 简单来说就是：静态代码块和静态变量的初始化顺序和它们在类文件编写的顺序是一致的，如果一个类未初始化直接使用它的静态代码块和静态变量通过Field#set(Object obj, Object value)调用就会出现ExceptionInInitializerError异常。 属性的获取方法抛出的异常和设置值方法是一致的，这里不做详细展开： 1public Object get(Object obj) throws IllegalArgumentException, IllegalAccessException 处理构造器调用异常 构造器调用主要是用于对象的实例化，先看newInstance方法的签名： 1public T newInstance(Object ... initargs) throws InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException InstantiationException：实例化异常，抛出此异常的一般情况是：当前构造所在类型为一个抽象类型。 IllegalAccessException：非法访问异常。 IllegalArgumentException：非法参数异常，下面的情况会抛出此异常：参数数量或者类型不匹配，参数列表为原始类型但是实际使用了包装类型、参数列表为原始类型但是实际使用了包装类型、构造所在的类是枚举类型等。 InvocationTargetException：目标调用异常，这个是需要处理的重点异常，在下一节&quot;处理方法调用异常&quot;详细探讨。 这里只举个例子说明一下InstantiationException出现的场景： 12345678910public abstract class AbstractSample &#123; public AbstractSample() &#123; &#125; public static void main(String[] args) throws Exception&#123; Constructor&lt;AbstractSample&gt; declaredConstructor = AbstractSample.class.getDeclaredConstructor(); declaredConstructor.newInstance(); &#125;&#125; 像上面的抽象类AbstractSample包含一个默认的公有构造，使用Constructor#newInstance()会抛出InstantiationException异常： 1234Exception in thread \"main\" java.lang.InstantiationException at java.base/jdk.internal.reflect.InstantiationExceptionConstructorAccessorImpl.newInstance(InstantiationExceptionConstructorAccessorImpl.java:48) at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490) at club.throwable.jdk.sample.reflection.reflect.AbstractSample.main(AbstractSample.java:18) 处理方法调用异常 方法调用是反射中使用频率最高的反射操作，主要是Method#invoke(Object obj, Object... args)方法： 1public Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException 主要包括以下几种异常： IllegalAccessException：非法访问异常。 IllegalArgumentException：非法参数异常，下面的情况会抛出此异常：入参obj并不是当前实例方法对应的实例对象、参数数量或者类型不匹配，参数列表为原始类型但是实际使用了包装类型、参数列表为原始类型但是实际使用了包装类型等等。 NullPointerException：空指针异常，入参obj为null时候会抛出此异常。 ExceptionInInitializerError：初始化器调用异常导致的错误。 InvocationTargetException：目标调用异常。 重点看InvocationTargetException(继承自ReflectiveOperationException，而ReflectiveOperationException继承自Exception，也就是它是checked异常，必须显式捕获)： 12345678910111213141516171819202122232425public class InvocationTargetException extends ReflectiveOperationException &#123; private static final long serialVersionUID = 4085088731926701167L; // 持有的目标异常实例 private Throwable target; public InvocationTargetException(Throwable target) &#123; super((Throwable)null); // Disallow initCause this.target = target; &#125; public InvocationTargetException(Throwable target) &#123; super((Throwable)null); // Disallow initCause this.target = target; &#125; public Throwable getTargetException() &#123; return target; &#125; public Throwable getCause() &#123; return target; &#125; &#125; 从注释中得知：方法(Method)或者构造(Constructor)调用异常会抛出此InvocationTargetException异常，用于包装源异常，源异常实例作为目标被InvocationTargetException通过成员target持有，可以通过InvocationTargetException#getTargetException()或者InvocationTargetException#getCause()获取原始的目标异常。这里注意到，InvocationTargetException在覆盖父类构造的时候使用了null，所以调用其getMessage()方法会得到null。 举个例子： 12345678910111213141516171819202122public class InvocationTargetExceptionMain &#123; public void method() &#123; throw new NullPointerException(\"Null\"); &#125; public static void main(String[] args) throws NoSuchMethodException, SecurityException &#123; InvocationTargetExceptionMain main = new InvocationTargetExceptionMain(); Method method = InvocationTargetExceptionMain.class.getDeclaredMethod(\"method\"); try &#123; method.invoke(main); &#125; catch (IllegalAccessException e) &#123; //no-op &#125; catch (InvocationTargetException e) &#123; System.out.println(\"InvocationTargetException#message:\" + e.getMessage()); if (e.getTargetException() instanceof NullPointerException) &#123; NullPointerException nullPointerException = (NullPointerException) e.getTargetException(); System.out.println(\"NullPointerException#message:\" + nullPointerException.getMessage()); &#125; &#125; &#125;&#125; 运行后输出： 12InvocationTargetException#message:nullNullPointerException#message:Null 构造器Constructor#newInstance()中抛出InvocationTargetException的场景是类似的。 小结 在反射操作中，方法调用的频次是最高的，其次是通过构造器实例化对象。需要重点关注这两个地方的异常处理，特别是异常类型InvocationTargetException，紧记需要获取原始目标异常类型再进行判断，否则很容易导致逻辑错误(最近笔者在做一个功能的时候刚好踩了这个坑)。 (本文完 e-a-20181215 c-2-d)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Reflection","slug":"Java/Reflection","permalink":"http://throwable.club/blog/categories/Java/Reflection/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Reflection","slug":"Reflection","permalink":"http://throwable.club/blog/tags/Reflection/"}]},{"title":"神奇的魔法类和双刃剑-Unsafe","slug":"java-magic-unsafe","date":"2018-12-13T15:46:58.000Z","updated":"2018-12-13T15:47:39.460Z","comments":true,"path":"2018/12/13/java-magic-unsafe/","link":"","permalink":"http://throwable.club/2018/12/13/java-magic-unsafe/","excerpt":"","text":"神奇的魔法类和双刃剑-Unsafe 前提 JDK9或者以后，sun.misc包的源码也可以上传到JDK类库中，可以直接导入IDE进行注释的阅读，这一点是比较好的改进。本文基于JDK11的源码阅读Unsafe类的注释，介绍一下这个类的使用方式。 Unsafe简介 在JDK9之后，sun.misc.Unsafe被移动到jdk.unsupported模块中，同时在java.base模块克隆了一个jdk.internal.misc.Unsafe类，代替了JDK8以前的sun.misc.Unsafe的功能，jdk.internal包不开放给开发者调用。 Unsafe是用于在实质上扩展Java语言表达能力、便于在更高层（Java层）代码里实现原本要在更低层（C层）实现的核心库功能用的。这些功能包括裸内存的申请/释放/访问，低层硬件的atomic/volatile支持，创建未初始化对象等。它原本的设计就只应该被标准库使用。 为了让开发者有机会过渡到尽量不使用sun.misc.Unsafe，默认不允许Java应用代码访问sun.misc.Unsafe类，同时在java.base模块克隆了一个不能被外部访问的jdk.internal.misc.Unsafe类用于JDK内部API演进。 获取Unsafe实例 sun.misc.Unsafe提供了一个静态方法来获取其实例： 1234567891011@CallerSensitivepublic static Unsafe getUnsafe() &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); if (!VM.isSystemDomainLoader(caller.getClassLoader())) throw new SecurityException(\"Unsafe\"); return theUnsafe;&#125;// VM类中的代码public static boolean isSystemDomainLoader(ClassLoader loader) &#123; return loader == null || loader == ClassLoader.getPlatformClassLoader();&#125; 这个静态方法getUnsafe()必须在当前调用的类对应的类加载器为null(类加载器为null也就是当前调用的类必须使用Bootstrap类加载器加载)或者为PlatformClassLoader才不会抛出SecurityException异常。由于对PlatformClassLoader理解不深入，所以我们可以用VM参数-Xbootclasspath:让当前的调用类被Bootstrap类加载器加载。 但是试验了一下(其实文档中已经提到此参数已经失效，不过这里还是试了下)，发现这个参数在JDK9之后已经不支持，使用的时候会导致JVM启动失败，异常信息是： 123Error: Could not create the Java Virtual Machine.-Xbootclasspath is no longer a supported option.Error: A fatal exception has occurred. Program will exit. 此特性暂时在JDK9以后找不到替代的VM参数，所以这里只能选择其他可行方法。查看sun.misc.Unsafe所在模块的信息： 12345678module jdk.unsupported &#123; exports com.sun.nio.file; exports sun.misc; exports sun.reflect; opens sun.misc; opens sun.reflect;&#125; 由于sun.misc是opens修饰的，可以使用反射直接调用。因此可以像下面这样获取sun.misc.Unsafe对象： 12345678public class UnsafeMain &#123; public static void main(String[] args) throws Exception &#123; Field f = Unsafe.class.getDeclaredField(\"theUnsafe\"); f.setAccessible(true); Unsafe unsafe = (Unsafe) f.get(null); &#125;&#125; 其实还有特殊的技巧可以直接暴露jdk.internal.misc.Unsafe所在的模块让它可以直接使用反射调用，只需要使用参数addExports:java.base/jdk.internal.misc=ALL-UNAMED，这样子就可以反射获取jdk.internal.misc.Unsafe的实例，不过推荐这种做法，毕竟jdk.internal.misc.Unsafe中提供更多底层的方法，能力越大越容易失去控制。 Unsafe的使用建议 使用Unsafe要注意以下几个问题： 1、Unsafe有可能在未来的JDK版本移除或者不允许Java应用代码使用，这一点可能导致使用了Unsafe的应用无法运行在高版本的JDK。 2、Unsafe的不少方法中必须提供原始地址(内存地址)和被替换对象的地址，偏移量要自己计算，一旦出现问题就是JVM崩溃级别的异常，会导致整个JVM实例崩溃，表现为应用程序直接crash掉(其实这个很好理解，JVM是C语言写出来的软件，如果操作一个不存在的内存地址，在C程序中就是引发程序崩溃的操作)。 3、Unsafe提供的直接内存访问的方法中使用的内存不受JVM管理(无法被GC)，需要手动管理，一旦出现疏忽很有可能成为内存泄漏的源头。 暂时总结出以上三点问题。Unsafe在JUC(java.util.concurrent)包中大量使用(主要是CAS)，在netty中方便使用直接内存，还有一些高并发的交易系统为了提高CAS的效率也有可能直接使用到Unsafe。总而言之，Unsafe类是魔法类，也可以说是一把双刃剑。 Unsafe的核心方法 sun.misc.Unsafe一共提供了89个public修饰的方法，下面针对核心方法按功能分组简单介绍一下。 类操作 类操作相关主要和类实例化、属性地址获取等等操作，原来存在一个defineClass方法，已经被移除，但是该方法在jdk.internal.misc.Unsafe中依然存在。 ensureClassInitialized public boolean shouldBeInitialized(Class&lt;?&gt; c) 检测给定的类是否已经初始化。通常需要使用在获取一个类的静态属性的时候(因为一个类如果没初始化，它的静态属性也不会初始化)。 shouldBeInitialized public boolean shouldBeInitialized(Class&lt;?&gt; c) 检测给定的类是否需要初始化。通常需要使用在获取一个类的静态属性的时候(因为一个类如果没初始化，它的静态属性也不会初始化)。 此方法当且仅当ensureClassInitialized方法不生效的时候才返回false。 defineAnonymousClass public Class&lt;?&gt; defineAnonymousClass(Class&lt;?&gt; hostClass, byte[] data, Object[] cpPatches) hostClass：宿主类。 data：字节码字节数组。 cpPatches：替换常量池(Constant Pool)中的字面量得到的引用数组。 这个方法的使用可以看R大的知乎回答：JVM crashes at libjvm.so，下面截取一点内容解释此方法。 1、VM Anonymous Class可以看作一种模板机制，如果程序要动态生成很多结构相同、只是若干变量不同的类的话，可以先创建出一个包含占位符常量的正常类作为模板，然后利用sun.misc.Unsafe#defineAnonymousClass()方法，传入该类(host class，宿主类或者模板类)以及一个作为&quot;constant pool path&quot;的数组来替换指定的常量为任意值，结果得到的就是一个替换了常量的VM Anonymous Class。 2、VM Anonymous Class从VM的角度看是真正的&quot;没有名字&quot;的，在构造出来之后只能通过Unsafe#defineAnonymousClass()返回出来一个Class实例来进行反射操作。 还有其他几点看以自行阅读。这个方法虽然翻译为&quot;定义匿名类&quot;，但是它所定义的类和实际的匿名类有点不相同，因此一般情况下我们不会用到此方法。在JDK中Lambda表达式的构造依赖到此方法，可以看InnerClassLambdaMetafactory这个类。方法的注释：定义一个不被类加载器系统或者系统字典感知的类型。 allocateInstance public native Object allocateInstance(Class&lt;?&gt; cls) 注意此方法是JVM本地接口方法，通过Class对象创建一个类的实例，不需要调用其构造函数、初始化代码、JVM安全检查等等。同时，它抑制修饰符检测，也就是即使构造器是private修饰的也能通过此方法实例化。 staticFieldBase public Object staticFieldBase(Field f) 返回给定的静态属性所在的位置(其实就是所在的对象的内存快照)，配合staticFieldOffset方法使用。实际上，这个方法返回值就是静态属性所在的Class对象的一个内存快照。注释中说到，此方法返回的Object有可能为null，它只是一个’cookie’而不是真实的对象，不要直接使用的它的实例中的获取属性和设置属性的方法，它的作用只是方便调用像getInt(Object,long)等等的任意方法。 staticFieldOffset public long staticFieldOffset(Field f) 返回给定的静态属性在它的类的内存分配中的位置(内存偏移地址)。不要在这个偏移量上执行任何类型的算术运算，它只是一个被传递给不安全的堆内存访问器的cookie。注意：这个方法仅仅针对静态属性，使用在非静态属性上会抛异常。 objectFieldOffset public long staticFieldOffset(Field f) 返回给定的非静态属性在它的类的内存分配中的位置(内存偏移地址)。不要在这个偏移量上执行任何类型的算术运算，它只是一个被传递给不安全的堆内存访问器的cookie。注意：这个方法仅仅针对非静态属性，使用在静态属性上会抛异常。 defineClass public Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len, ClassLoader loader, ProtectionDomain protectionDomain) 这个方法位于jdk.internal.misc.Unsafe，也就是开发者无法直接使用。作用是：绕过安全检查告知JVM定义一个类。默认情况下，ClassLoader(类加载器)和ProtectionDomain(保护域)实例应该来源于调用者。 基于内存地址直接存取属性 前一节中提供了一些方法可以直接获取静态或者非静态成员属性的内存地址，这一节介绍的API可以基于成员属性内存地址直接获取或者设置其值。 getObject public Object getObject(Object o, long offset) 通过给定的Java对象和属性内存地址获取引用值。这里实际上是获取一个Java对象o中，获取偏移地址为offset的属性的值，此方法可以突破修饰符的抑制，也就是无视private、protected和default修饰符。类似的方法有getInt、getDouble等等。 putObject public void putObject(Object o, long offset, Object x) o：当前操作的对象。 offset：成员属性的内存地址。 x：需要设置的目标属性值。 将引用值存储到给定的Java变量中。这里实际上是设置一个Java对象o中偏移地址为offset的属性的值为x，此方法可以突破修饰符的抑制，也就是无视private、protected和default修饰符。类似的方法有putInt、putDouble等等。 getObjectVolatile public Object getObjectVolatile(Object o, long offset) 此方法和上面的getObject功能类似，不过附加了volatile关键字加载语义，也就是强制从主存中获取属性值。类似的方法有getIntVolatile、getDoubleVolatile等等。这个方法要求被使用的属性被volatile修饰，否则功能和getObject方法相同。 putObjectVolatile public void putObjectVolatile(Object o, long offset, Object x) 此方法和上面的putObject功能类似，不过附加了volatile关键字加载语义，也就是设置值的时候强制(JMM会保证获得锁到释放锁之间所有对象的状态更新都会在锁被释放之后)更新到主存，从而保证这些变更对其他线程是可见的。类似的方法有putIntVolatile、putDoubleVolatile等等。这个方法要求被使用的属性被volatile修饰，否则功能和putObject方法相同。 putOrderedObject public void putOrderedObject(Object o, long offset, Object x) 设置o对象中offset偏移地址offset对应的Object型field的值为指定值x。这是一个有序或者有延迟的putObjectVolatile方法，并且不保证值的改变被其他线程立即看到。只有在属性被volatile修饰并且期望被修改的时候使用才会生效。类似的方法有putOrderedInt和putOrderedLong。方法注释中提到：相当于C11中的atomic_store_explicit(..., memory_order_release)。 数组操作 arrayBaseOffset public int arrayBaseOffset(Class&lt;?&gt; arrayClass) 返回数组类型的第一个元素的偏移地址(基础偏移地址)。如果arrayIndexScale方法返回的比例因子不为0，你可以通过结合基础偏移地址和比例因子访问数组的所有元素。Unsafe中已经初始化了很多类似的常量如ARRAY_BOOLEAN_BASE_OFFSET等。 arrayIndexScale public int arrayIndexScale(Class&lt;?&gt; arrayClass) 返回数组类型的比例因子(其实就是数据中元素偏移地址的增量，因为数组中的元素的地址是连续的)。此方法不适用于数组类型为&quot;narrow&quot;类型的数组，&quot;narrow&quot;类型的数组类型使用此方法会返回0(这里narrow应该是狭义的意思，但是具体指哪些类型暂时不明确，笔者查了很多资料也没找到结果)。Unsafe中已经初始化了很多类似的常量如ARRAY_BOOLEAN_INDEX_SCALE等。 低级同步原语 低级同步原语的相关方法在JDK8还能通过sun.misc.Unsafe使用，在JDK9以后sun.misc.Unsafe和jdk.internal.misc.Unsafe都移除了相关的方法。低级同步原语主要包括监视器锁定、解锁方法。 monitorEnter public native void monitorEnter(Object o) 锁定对象，必须通过monitorExit方法才能解锁。此方法经过实验是可以重入的，也就是可以多次调用，然后通过多次调用monitorExit进行解锁。 monitorExit public native void monitorExit(Object o) 解锁对象，前提是对象必须已经调用monitorEnter进行加锁，否则抛出IllegalMonitorStateException异常。 tryMonitorEnter public native boolean tryMonitorEnter(Object o) 尝试锁定对象，如果加锁成功返回true，否则返回false。必须通过monitorExit方法才能解锁。 线程挂起与恢复 JDK1.5引入了并发包java.util.concurrent中组件控制线程挂起和恢复就是依赖于java.util.concurrent.locks.LockSupport完成，而LockSupport底层依赖于sun.misc.Unsafe中下面提到线程的挂起和恢复方法完成的。相关方法主要是用于替代线程类Thread中过时并且不安全的suspend和resume方法。 park public void park(boolean isAbsolute, long time) time：时间长度，单位由isAbsolute控制，0表示永久阻塞。 isAbsolute：如果isAbsolute为true，time是相对于新纪元之后的毫秒，否则time表示纳秒。 注释：阻塞当前线程直到一个unpark方法出现(被调用)、一个用于unpark方法已经出现过(在此park方法调用之前已经调用过)、线程被中断或者time时间到期(也就是阻塞超时)。在time非零的情况下，如果isAbsolute为true，time是相对于新纪元之后的毫秒，否则time表示纳秒。这个方法执行时也可能不合理地返回(没有具体原因)。 unpark public void unpark(Object thread) 释放被park创建的在一个线程上的阻塞。这个方法也可以被使用来终止一个先前调用park导致的阻塞。这个操作是不安全的，因此必须保证线程是存活的(thread has not been destroyed)。从Java代码中判断一个线程是否存活的是显而易见的，所以解除阻塞的时候需要对线程的存活性做判断。 重点注意： unpark方法调用多次，实际上只有一次会生效，可以简单理解为它是一个只有0和1两个值的计数器，调用unpark多次，计数仍然为1。 park方法总是针对当前线程，如果预先已经调用过一次unpark方法后再调用park方法，那么将不会进入阻塞状态直接释放。 CAS操作 CAS，也就是Compare And Swap，也就是在一个原子操作中完成比较和交互。 compareAndSwapObject public final boolean compareAndSwapObject(Object o, long offset, Object expected, Object x) o：目标Java变量引用。 offset：目标Java变量中的目标属性的偏移地址。 expected：目标Java变量中的目标属性的期望的当前值。 x：目标Java变量中的目标属性的目标更新值。 针对Object对象进行CAS操作。即是对应Java变量引用o，原子性地更新o中偏移地址为offset的属性的值为x，当且仅的偏移地址为offset的属性的当前值为expected才会更新成功返回true，否则返回false。类似的方法有compareAndSwapInt和compareAndSwapLong，在Jdk8中基于CAS扩展出来的相关方法有getAndAddInt、getAndAddLong、getAndSetInt、getAndSetLong、getAndSetObject，它们的作用都是：通过CAS设置新的值，返回旧的值。 getAndSetObject public final Object getAndSetObject(Object o, long offset, Object newValue) 见compareAndSwapObject中的描述。 内存管理 addressSize public int addressSize(); 获取本地指针的大小(单位是byte)，通常值为4或者8。常量ADDRESS_SIZE就是调用此方法。 pageSize public int pageSize(); 获取本地内存的页数，此值为2的幂次方。 allocateMemory public long allocateMemory(long bytes); 分配一块新的本地内存，通过bytes指定内存块的大小(单位是byte)，返回新开辟的内存的地址。如果内存块的内容不被初始化，那么它们一般会变成内存垃圾。生成的本机指针永远不会为零，并将对所有值类型进行对齐。可以通过freeMemory方法释放内存块，或者通过reallocateMemory方法调整内存块大小。bytes值为负数或者过大会抛出IllegalArgumentException异常，如果系统拒绝分配内存会抛出OutOfMemoryError异常。 reallocateMemory public long reallocateMemory(long address, long bytes); 通过指定的内存地址address重新调整本地内存块的大小，调整后的内存块大小通过bytes指定(单位为byte)。可以通过freeMemory方法释放内存块，或者通过reallocateMemory方法调整内存块大小。bytes值为负数或者过大会抛出IllegalArgumentException异常，如果系统拒绝分配内存会抛出OutOfMemoryError异常。 setMemory public void setMemory(Object o, long offset, long bytes, byte value); 将给定内存块中的所有字节设置为固定值(通常是0)。内存块的地址由对象引用o和偏移地址共同决定，如果对象引用o为null，offset就是绝对地址。第三个参数就是内存块的大小，如果使用allocateMemory进行内存开辟的话，这里的值应该和allocateMemory的参数一致。value就是设置的固定值，一般为0(这里可以参考netty的DirectByteBuffer)。一般而言，o为null，所有有个重载方法是public void setMemory(long offset, long bytes, byte value);，等效于setMemory(null, long offset, long bytes, byte value);。 copyMemory public void copyMemory(Object srcBase, long srcOffset, Object destBase, long destOffset, long bytes) 拷贝给定内存地址的字节长度对应的字节到指定内存地址中。如果srcBase或者destBase为null，则srcOffset或者destOffset分别指代绝对地址。 内存屏障 内存屏障相关的方法是在Jdk8添加的。内存屏障相关的知识可以先自行查阅，笔者目前也没有深入了解相关知识。 loadFence public void loadFence(); 在该方法之前的所有读操作，一定在load屏障之前执行完成。 storeFence public void storeFence(); 在该方法之前的所有写操作，一定在store屏障之前执行完成 fullFence public void fullFence(); 在该方法之前的所有读写操作，一定在full屏障之前执行完成，这个内存屏障相当于上面两个(load屏障和store屏障)的合体功能。 其它 invokeCleaner public void invokeCleaner(java.nio.ByteBuffer directBuffer) 清空使用了堆外内存的ByteBuffer实例占据的内存，一般是DirectBuffer的子类。 throwException public void throwException(Throwable ee) 绕过检测机制直接抛出异常。 getLoadAverage public int getLoadAverage(double[] loadavg, int nelems); 获取系统的平均负载值，loadavg这个double数组将会存放负载值的结果，nelems决定样本数量，nelems只能取值为1到3，分别代表最近1、5、15分钟内系统的平均负载。如果无法获取系统的负载，此方法返回-1，否则返回获取到的样本数量(loadavg中有效的元素个数)。实验中这个方法一直返回-1，其实完全可以使用JMX中的相关方法替代此方法。 使用例子 先封装一下获取Unsafe实例的方法： 12345private static Unsafe getUnsafe() throws Exception &#123; Field f = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\"); f.setAccessible(true); return (Unsafe) f.get(null);&#125; 通过内存地址直接操作属性 通过staticFieldOffset和objectFieldOffset可以获取静态和非静态成员属性的偏移地址，然后直接进行存取值操作。 1234567891011121314151617181920212223242526272829303132public static class Simple &#123; static Integer STATIC_INT = 10086; Long longField = 1024L;&#125; public static void main(String[] args) throws Exception &#123; Unsafe unsafe = getUnsafe(); Field staticInt = Simple.class.getDeclaredField(\"STATIC_INT\"); staticInt.setAccessible(true); Object staticFieldBase = unsafe.staticFieldBase(staticInt); long staticFieldOffset = unsafe.staticFieldOffset(staticInt); // 注意这里一定要getObject,getInt是针对原始类型int,包装类型要自己强转 System.out.println(\"Sample初始化前,STATIC_INT = \" + unsafe.getObject(staticFieldBase, staticFieldOffset)); Simple simple = new Simple(); System.out.println(\"Sample初始化后,STATIC_INT = \" + unsafe.getObject(staticFieldBase, staticFieldOffset)); Field longField = Simple.class.getDeclaredField(\"longField\"); longField.setAccessible(true); long objectFieldOffset = unsafe.objectFieldOffset(longField); System.out.println(\"Sample初始化后,longField = \" + unsafe.getObject(simple, objectFieldOffset)); unsafe.putObject(simple,objectFieldOffset, 4201L); System.out.println(\"Sample属性被覆盖后,longField = \" + simple.longField); &#125;// 输出如下：Sample初始化前,STATIC_INT = nullSample初始化后,STATIC_INT = 10086Sample初始化后,longField = 1024Sample属性被覆盖后,longField = 4201 线程挂起和恢复 主要介绍一下park和unpark的用法： 123456789101112131415161718192021 public static void main(String[] args) throws Exception &#123; Unsafe unsafe = getUnsafe(); Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"线程park!\"); unsafe.park(false, 0); System.out.println(\"线程恢复运行!\"); &#125; &#125;); thread.start(); TimeUnit.SECONDS.sleep(2); System.out.println(\"主线程unpark阻塞着的线程!\"); unsafe.unpark(thread); TimeUnit.SECONDS.sleep(Integer.MAX_VALUE); &#125;// 运行后输出：线程park!主线程unpark阻塞着的线程!线程恢复运行! 小结 存在即合理，虽然不推荐使用Unsafe，但是如果有需要的还是要挥动这把双刃剑。 参考资料： 为什么JUC中大量使用了sun.misc.Unsafe 这个类，但官方却不建议开发者使用？ JDK11相关源码 Java Magic. Part 4: sun.misc.Unsafe (本文完 e-a-20181213 c-3-d)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"}]},{"title":"深入分析Java反射(五)-类实例化和类加载","slug":"java-reflection-class-load","date":"2018-12-09T07:58:40.000Z","updated":"2018-12-11T16:45:32.147Z","comments":true,"path":"2018/12/09/java-reflection-class-load/","link":"","permalink":"http://throwable.club/2018/12/09/java-reflection-class-load/","excerpt":"","text":"深入分析Java反射(五)-类实例化和类加载 前提 其实在前面写过的《深入分析Java反射(一)-核心类库和方法》已经介绍过通过类名或者java.lang.Class实例去实例化一个对象，在《浅析Java中的资源加载》中也比较详细地介绍过类加载过程中的双亲委派模型，这篇文章主要是加深一些对类实例化和类加载的认识。 类实例化 在反射类库中，用于实例化对象只有两个方法： T java.lang.Class#newInstance()：这个方法只需要提供java.lang.Class&lt;T&gt;的实例就可以实例化对象，如果提供的是无限定类型Class&lt;?&gt;则得到的是Object类型的返回值，可以进行强转。这个方法不支持任何入参，底层实际上也是依赖无参数的构造器Constructor进行实例化。 T java.lang.reflect.Constructor#newInstance(Object ... initargs)：这个方法需要提供java.lang.reflect.Constructor&lt;T&gt;实例和一个可变参数数组进行对象的实例化，上面提到的T java.lang.Class#newInstance()底层也是依赖此方法。这个方法除了可以传入构造参数之外，还有一个好处就是可以通过``抑制修饰符访问权限检查，也就是私有的构造器也可以用于实例化对象。 在编写反射类库的时候，优先选择T java.lang.reflect.Constructor#newInstance(Object ... initargs)进行对象实例化，目前参考很多优秀的框架(例如Spring)都是用这个方法进行对象实例化。 类加载 类加载实际上由类加载器(ClassLoader)完成，protected Class&lt;?&gt; java.lang.ClassLoader#loadClass(String name, boolean resolve)方法提现了类加载过程中遵循了双亲委派模型，实际上，我们可以覆写此方法完全不遵循双亲委派模型，实现同一个类(这里指的是全类名完全相同)重新加载。JDK中提供类加载相关的特性有两个方法： protected Class&lt;?&gt; java.lang.ClassLoader#loadClass(String name, boolean resolve)：通过类加载器实例去加载类，一般应用类路径下的类是由jdk.internal.loader.ClassLoaders$AppClassLoader加载，也可以自行继承java.lang.ClassLoader实现自己的类加载器。 public static Class&lt;?&gt; forName(String name, boolean initialize, ClassLoader loader)：通过全类名进行类加载，可以通过参数控制类初始化行为。 ClassLoader中的类加载 类加载过程其实是一个很复杂的过程，主要包括下面的步骤： 1、加载过程：使用(自定义)类加载器去获取类文件字节码字节类的过程，Class实例在这一步生成，作为方法区的各种数据类型的访问入口。 2、验证过程：JVM验证字节码的合法性。 3、准备过程：为类变量分配内存并且设置初始值。 4、解析过程：JVM把常量池中的符号替换为直接引用。 5、初始化过程：执行类构造器&lt;cinit&gt;()方法，&lt;cinit&gt;()方法是编译器自动收集所有类变量的赋值动作和静态代码块中的语句合并生成，收集顺序由语句在源文件中出现的顺序决定，JVM保证在子类&lt;cinit&gt;()方法调用前父类的&lt;cinit&gt;()方法已经执行完毕。 ClassLoader#loadClass()方法就是用于控制类加载过程的第一步-加载过程，也就是控制字节码字节数组和类名生成Class实例的过程。ClassLoader中还有一个protected final Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len)方法用于指定全类名和字节码字节数组去定义一个类，我们再次看下loadClass()的源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123; // 检查类是否已经加载过，如果已经加载过，则直接返回 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); // 委派父类加载器去加载类 try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; // 委派父类加载器如果加载失败则调用findClass方法进行加载动作 if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats PerfCounter.getParentDelegationTime().addTime(t1 - t0); PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125;// 扩展点-1protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; throw new ClassNotFoundException(name);&#125; // 扩展点-2protected final void resolveClass(Class&lt;?&gt; c) &#123; if (c == null) &#123; throw new NullPointerException(); &#125;&#125; 实际上，loadClass()方法留下了两个扩展点用于改变类加载的行为，而findClass()方法就是用于扩展父类加载器加载失败的情况下，子类加载器的行为。当然，实际上Class&lt;?&gt; loadClass(String name, boolean resolve)方法是非final的方法，可以整个方法覆写掉，这样子就有办法完全打破双亲委派机制。但是注意一点，即使打破双亲委派机制，子类加载器也不可能重新加载一些由Bootstrap类加载器加载的类库如java.lang.String，这些是由JVM验证和保证的。自定义类加载器的使用在下一节的&quot;类重新加载&quot;中详细展开。 最后还有两点十分重要： 1、对于任意一个类，都需要由加载它的类加载器和这个类本身一起确立其在Java虚拟机中的唯一性，也就是一个类在JVM中的签名是加载它的类加载器和它本身，对于每一个类加载器，都拥有一个独立的类命名空间。 2、比较两个类是否&quot;相等&quot;，只有这两个类是由同一个类加载器加载的前提下才有意义。即使这两个类的全类名一致、来源于同一个字节码文件、被同一个Java虚拟机加载，但是加载它们的类加载器不同，那么它们必定不相等。这里相等的范畴包括：Class对象的equals()方法、isAssignableForm()方法、isInstance()方法的返回结果以及使用instanceof关键字做对象所属关系时候的判定等情况。 Class中的类加载 java.lang.Class中的类加载主要由public static Class&lt;?&gt; forName(String name, boolean initialize, ClassLoader loader)方法完成，该方法可以指定全类名、是否初始化和类加载器实例。源码如下： 12345678910111213141516171819202122232425@CallerSensitivepublic static Class&lt;?&gt; forName(String name, boolean initialize, ClassLoader loader) throws ClassNotFoundException&#123; Class&lt;?&gt; caller = null; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; // Reflective call to get caller class is only needed if a security manager // is present. Avoid the overhead of making this call otherwise. caller = Reflection.getCallerClass(); if (loader == null) &#123; ClassLoader ccl = ClassLoader.getClassLoader(caller); if (ccl != null) &#123; sm.checkPermission( SecurityConstants.GET_CLASSLOADER_PERMISSION); &#125; &#125; &#125; return forName0(name, initialize, loader, caller);&#125;private static native Class&lt;?&gt; forName0(String name, boolean initialize, ClassLoader loader, Class&lt;?&gt; caller) throws ClassNotFoundException; 它最终调用的是JVM的本地接口方法，由于暂时没有能力分析JVM的源码，只能通过forName方法的注释理解方法的功能： 返回给定字符串全限定名称、指定类加载器的类或者接口的Class实例，此方法会尝试对类或者接口进行locate、load and link操作，如果loader参数为null，则使用bootstrap类加载器进行加载，如果initialize参数为true同时类或者接口在早期没有被初始化，则会进行初始化操作。 也就是说initialize参数对于已经初始化过的类或者接口来说是没有意义的。这个方法的特性还可以参考Java语言规范的12章中的内容，这里不做展开。 虽然暂时没法分析JVM本地接口方法native Class&lt;?&gt; forName0()的功能，但是它依赖一个类加载器实例入参，可以大胆猜测它也是依赖于类加载器的loadClass()进行类加载的。 类重新加载 先提出一个实验，如果定义一个类如下： 123456public class Sample &#123; public void say() &#123; System.out.println(\"Hello Doge!\"); &#125;&#125; 如果使用字节码工具修改say()方法的内容为System.out.println(&quot;Hello Throwable!&quot;);，并且使用自定义的ClassLoader重新加载一个同类名的Sample类，那么通过new关键字实例化出来的Sample对象调用say()到底打印&quot;Hello Doge!“还是&quot;Hello Throwable!”？ 先引入字节码工具javassist用于修改类的字节码： 12345&lt;dependency&gt; &lt;groupId&gt;org.javassist&lt;/groupId&gt; &lt;artifactId&gt;javassist&lt;/artifactId&gt; &lt;version&gt;3.24.0-GA&lt;/version&gt;&lt;/dependency&gt; 下面是测试代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 例子public class Demo &#123; public void say() &#123; System.out.println(\"Hello Doge!\"); &#125;&#125;// 一次性使用的自定义类加载器public class CustomClassLoader extends ClassLoader &#123; private final byte[] data; public CustomClassLoader(byte[] data) &#123; this.data = data; &#125; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; if (!Demo.class.getName().equals(name)) &#123; return super.loadClass(name); &#125; return defineClass(name, data, 0, data.length); &#125;&#125;public class Main &#123; public static void main(String[] args) throws Exception &#123; String name = Demo.class.getName(); CtClass ctClass = ClassPool.getDefault().getCtClass(name); CtMethod method = ctClass.getMethod(\"say\", \"()V\"); method.setBody(\"&#123;System.out.println(\\\"Hello Throwable!\\\");&#125;\"); byte[] bytes = ctClass.toBytecode(); CustomClassLoader classLoader = new CustomClassLoader(bytes); // 新的Demo类,只能反射调用,因为类路径中的Demo类已经被应用类加载器加载 Class&lt;?&gt; newDemoClass = classLoader.loadClass(name); // 类路径中的Demo类 Demo demo = new Demo(); demo.say(); // 新的Demo类 newDemoClass.getDeclaredMethod(\"say\").invoke(newDemoClass.newInstance()); // 比较 System.out.println(newDemoClass.equals(Demo.class)); &#125;&#125; 执行后输出： 123Hello Doge!Hello Throwable!false 这里得出的结论是： new关键字只能使用在当前类路径下的类的实例化，而这些类都是由应用类加载器加载，如果上面的例子中newDemoClass.newInstance()强制转换为Demo类型会报错。 通过自定义类加载器加载的和当前类路径相同名全类名的类只能通过反射去使用，而且即使全类名相同，由于类加载器隔离，它们其实是不相同的类。 如何避免类重新加载导致内存溢出 实际上，JDK没有提供方法去卸载一个已经加载的类，也就是类的生命周期是由JVM管理的，因此要解决类重新加载导致内存溢出的问题归根结底就是解决重新加载的类被回收的问题。由于创建出来是的java.lang.Class对象，如果需要回收它，则要考虑下面几点： 1、java.lang.Class对象反射创建的实例需要被回收。 2、java.lang.Class对象不能被任何地方强引用。 3、加载java.lang.Class对象的ClassLoder已经被回收。 基于这几点考虑可以做个试验验证一下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Demo &#123; // 这里故意建立一个数组占用大量内存 private int[] array = new int[1000]; public void say() &#123; System.out.println(\"Hello Doge!\"); &#125;&#125;public class Main &#123; private static final Map&lt;ClassLoader, List&lt;Class&lt;?&gt;&gt;&gt; CACHE = new HashMap&lt;&gt;(); public static void main(String[] args) throws Exception &#123; String name = Demo.class.getName(); CtClass ctClass = ClassPool.getDefault().getCtClass(name); CtMethod method = ctClass.getMethod(\"say\", \"()V\"); method.setBody(\"&#123;System.out.println(\\\"Hello Throwable!\\\");&#125;\"); for (int i = 0; i &lt; 100000; i++) &#123; byte[] bytes = ctClass.toBytecode(); CustomClassLoader classLoader = new CustomClassLoader(bytes); // 新的Demo类,只能反射调用,因为类路径中的Demo类已经被应用类加载器加载 Class&lt;?&gt; newDemoClass = classLoader.loadClass(name); add(classLoader, newDemoClass); &#125; // 清理类加载器和它加载过的类 clear(); System.gc(); Thread.sleep(Integer.MAX_VALUE); &#125; private static void add(ClassLoader classLoader, Class&lt;?&gt; clazz) &#123; if (CACHE.containsKey(classLoader)) &#123; CACHE.get(classLoader).add(clazz); &#125; else &#123; List&lt;Class&lt;?&gt;&gt; classes = new ArrayList&lt;&gt;(); CACHE.put(classLoader, classes); classes.add(clazz); &#125; &#125; private static void clear() &#123; CACHE.clear(); &#125;&#125; 使用VM参数-XX:+PrintGC -XX:+PrintGCDetails执行上面的方法，JDK11默认使用G1收集器，由于Z收集器还在实验阶段，不是很建议使用，执行main方法后输出： 123456789101112131415161718[11.374s][info ][gc,task ] GC(17) Using 8 workers of 8 for full compaction[11.374s][info ][gc,start ] GC(17) Pause Full (System.gc())[11.374s][info ][gc,phases,start] GC(17) Phase 1: Mark live objects[11.429s][info ][gc,stringtable ] GC(17) Cleaned string and symbol table, strings: 5637 processed, 0 removed, symbols: 135915 processed, 0 removed[11.429s][info ][gc,phases ] GC(17) Phase 1: Mark live objects 54.378ms[11.429s][info ][gc,phases,start] GC(17) Phase 2: Prepare for compaction[11.429s][info ][gc,phases ] GC(17) Phase 2: Prepare for compaction 0.422ms[11.429s][info ][gc,phases,start] GC(17) Phase 3: Adjust pointers[11.430s][info ][gc,phases ] GC(17) Phase 3: Adjust pointers 0.598ms[11.430s][info ][gc,phases,start] GC(17) Phase 4: Compact heap[11.430s][info ][gc,phases ] GC(17) Phase 4: Compact heap 0.362ms[11.648s][info ][gc,heap ] GC(17) Eden regions: 44-&gt;0(9)[11.648s][info ][gc,heap ] GC(17) Survivor regions: 12-&gt;0(12)[11.648s][info ][gc,heap ] GC(17) Old regions: 146-&gt;7[11.648s][info ][gc,heap ] GC(17) Humongous regions: 3-&gt;2[11.648s][info ][gc,metaspace ] GC(17) Metaspace: 141897K-&gt;9084K(1062912K)[11.648s][info ][gc ] GC(17) Pause Full (System.gc()) 205M-&gt;3M(30M) 273.440ms[11.648s][info ][gc,cpu ] GC(17) User=0.31s Sys=0.08s Real=0.27s 可见FullGC之后，元空间(Metaspace)回收了(141897-9084)KB，一共回收了202M的内存空间，初步可以认为元空间的内存被回收了，接下来注释掉main方法中调用的clear()方法，再调用一次main方法： 12345....[4.083s][info ][gc,heap ] GC(17) Humongous regions: 3-&gt;2[4.083s][info ][gc,metaspace ] GC(17) Metaspace: 141884K-&gt;141884K(1458176K)[4.083s][info ][gc ] GC(17) Pause Full (System.gc()) 201M-&gt;166M(564M) 115.504ms[4.083s][info ][gc,cpu ] GC(17) User=0.84s Sys=0.00s Real=0.12s 可见元空间在FullGC执行没有进行回收，而堆内存的回收率也比较低，由此可以得出一个经验性的结论：只需要通过ClassLoader对象做映射关系保存使用它加载出来的新的类，只需要确保这些类没有没强引用、类实例都已经销毁，那么只需要移除ClassLoader对象的引用，那么在JVM进行GC的时候会把ClassLoader对象以及使用它加载的类回收，这样做就可以避免元空间的内存泄漏。 小结 通过一些资料和实验，深化了类加载过程的一些认识。 参考资料： 《深入理解Java虚拟机-第二版》 JDK11部分源码 (本文完 e-2018129 c-2-d r-20181212)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Reflection","slug":"Java/Reflection","permalink":"http://throwable.club/blog/categories/Java/Reflection/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Reflection","slug":"Reflection","permalink":"http://throwable.club/blog/tags/Reflection/"}]},{"title":"深入分析Java反射(四)-动态代理","slug":"java-reflection-dynamic-proxy","date":"2018-12-08T12:25:06.000Z","updated":"2018-12-08T12:25:34.127Z","comments":true,"path":"2018/12/08/java-reflection-dynamic-proxy/","link":"","permalink":"http://throwable.club/2018/12/08/java-reflection-dynamic-proxy/","excerpt":"","text":"深入分析Java反射(四)-动态代理 动态代理的简介 Java动态代理机制的出现，使得Java开发人员不用手工编写代理类，只要简单地指定一组接口及委托类对象，便能动态地获得代理类。代理类会负责将所有的方法调用分派到委托对象上反射执行，在分派执行的过程中，开发人员还可以按需调整委托类对象及其功能，这是一套非常灵活有弹性的代理框架。Java动态代理实际上通过反射技术，把代理对象和被代理对象(真实对象)的代理关系建立延迟到程序运行之后，动态创建新的代理类去完成对真实对象的代理操作(可以改变原来真实对象的方法行为)，这一点成为了当前主流的AOP框架和延迟加载功能的基础。本文在查看和编写动态代理相关的代码使用的是JDK11，不过JDK动态代理相关的功能和接口已经相对稳定，不必担心JDK版本升级带来的兼容性问题，但是需要注意由于JDK9引入了模块概念，动态代理的源码也有不少的改动。下文先介绍设计模式中的代理模式，接着会分析JDK动态代理的核心类库、流程和机制，最后分析其底层源码级别实现。 设计模式中的代理模式 代理模式是一种常用的设计模式，其目的就是为其他对象提供一个代理以控制对某个对象的访问。代理类负责为委托类预处理消息，过滤消息并转发消息，以及进行消息被委托类执行后的后续处理。 代理模式主要包括三种角色： Subject抽象主题角色：一般定义为抽象类或者接口，是作为功能的定义，提供一系列抽象的功能方法。 RealSubject具体(真实)主题角色：一般称为被委托角色或者被代理角色，它是Subject的一个具体实现。 ProxySubject代理主题角色：一般称为委托角色或者代理角色，一般ProxySubject也实现(或者继承)Subject，接收一个具体的Subject实例RealSubject，在RealSubject处理前后做预定义或者后置操作，甚至可以直接忽略RealSubject原来的方法。 把上面的类图编写成代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940public interface Subject &#123; void doSomething();&#125;public class RealSubject implements Subject &#123; @Override public void doSomething() &#123; System.out.println(\"RealSubject doSomething...\"); &#125;&#125;public class ProxySubject implements Subject &#123; private final Subject subject; public ProxySubject(Subject subject) &#123; this.subject = subject; &#125; @Override public void doSomething() &#123; subject.doSomething(); doOtherThing(); &#125; private void doOtherThing() &#123; System.out.println(\"ProxySubject doOtherThing...\"); &#125;&#125;public class Client &#123; public static void main(String[] args) throws Exception &#123; Subject subject = new RealSubject(); ProxySubject proxySubject = new ProxySubject(subject); proxySubject.doSomething(); &#125;&#125; 运行Client#main()输出： 12RealSubject doSomething...ProxySubject doOtherThing... 代理模式在日常的场景中也经常碰到，比较常见的一个场景就是游戏代练，套进去上面的代码可以写个比较生动的例子： 123456789101112131415161718192021222324252627282930313233343536public interface Player &#123; void playGame();&#125;public class I implements Player &#123; @Override public void playGame() &#123; System.out.println(\"操作Throwable游戏角色打怪升级\"); &#125;&#125;public class ProxyPlayer implements Player &#123; private final Player player; public ProxyPlayer(Player player) &#123; this.player = player; &#125; @Override public void playGame() &#123; login(); this.player.playGame(); logout(); &#125; private void login() &#123; System.out.println(\"登录Throwable游戏角色\"); &#125; private void logout() &#123; System.out.println(\"退出Throwable游戏角色\"); &#125;&#125; 代理模式有几个比较大的优点： 职责清晰：也就是真实主题角色只需要实现具体的逻辑，不需关注代理类的职责，而代理类也只需要处理预处理和后置的逻辑，类的职责分明。 高扩展性：由于职责分明，也就是真实主题角色可以随时修改实现，这样就能通过更新或者替换真实主题的实现并且不改变代理主题角色的情况下改变具体功能。 高灵活性：主要体现在后面提到的动态代理。 JDK动态代理的核心API JDK动态代理提供外部使用的主要依赖两个类： java.lang.reflect.Proxy：可以理解为代理类的工厂类(其实也是父类，见下文)。 java.lang.reflect.InvocationHandler：代理实例需要实现的调用处理器接口。 Proxy java.lang.reflect.Proxy是JDK动态代理的核心类，它的核心功能是提供静态方法来为一组接口动态地生成代理类并且返回代理实例对象，类似于代理类实例的工厂类。java.lang.reflect.Proxy主要提供四个public静态方法： 1234567891011// 方法 1: 该方法用于获取指定代理对象所关联的调用处理器public static InvocationHandler getInvocationHandler(Object proxy) // 方法 2：该方法用于获取关联于指定类装载器和一组接口的动态代理类的类对象public static Class&lt;?&gt; getProxyClass(ClassLoader loader, Class&lt;?&gt;[] interfaces) // 方法 3：该方法用于判断指定类对象是否是一个动态代理类public static boolean isProxyClass(Class&lt;?&gt; cl) // 方法 4：该方法用于为指定类装载器、一组接口及调用处理器生成动态代理类实例public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) InvocationHandler getInvocationHandler(Object proxy)：通过制定的代理类实例查找它关联的调用处理器实例。 Class&lt;?&gt; getProxyClass(ClassLoader loader, Class&lt;?&gt;[] interfaces)：用于获取关联于指定类装载器和一组接口的动态代理类的类对象，也就是获取$ProxyXXX的类型，此方法在JDK9以后标记为过期，原因是：在命名模块中生成的代理类是封闭的，模块外的代码无法访问这些类(违反模块规则调用了会抛异常)。 boolean isProxyClass(Class&lt;?&gt; cl)：用于判断指定类是否是一个动态代理类。 Object newProxyInstance(ClassLoader loader, Class[] interfaces, InvocationHandler h)：这个是JDK动态代理最核心的方法，用于为指定类装载器、一组接口及调用处理器生成动态代理类实例，也就是生成$ProxyXXX的实例。此方法需要指定类加载器java.lang.ClassLoader，Proxy静态方法生成动态代理类同样需要通过类装载器来进行装载才能使用，它与普通类的唯一区别就是其字节码是在运行时动态生成的而非预存在于任何一个.class文件中。interfaces是Class数组，也就是需要使用InvocationHandler进行代理访问的接口类型数组，这里的h参数就是调用处理器的实例。 InvocationHandler java.lang.reflect.InvocationHandler是调用处理器接口，它自定义了一个invoke方法，用于集中处理在动态代理类对象上的方法调用，通常在该方法中实现对委托类的代理访问。 123public interface InvocationHandler &#123; Object invoke(Object proxy, Method method, Object[] args) throws Throwable;&#125; 参数说明： proxy：Object类型，此参数即是代理类实例，也就是$ProxyXXX的实例。 method：java.lang.reflect.Method类型，被调用的方法的实例。 args：Object[]类型，被调用方法的参数数组。 实现java.lang.reflect.InvocationHandler接口，通过实现invoke方法即可添加代理访问的逻辑，在这个逻辑代码块中除了可以调用委托类的方法，还可以织入额外的自定义逻辑，AOP就是这样实现的。 JDK动态代理的流程 JDK动态代理的使用流程如下： 1、通过实现java.lang.reflect.InvocationHandler接口创建自定义的调用处理器。 2、通过为java.lang.reflect.Proxy类指定ClassLoader对象和一组interface来创建动态代理类。 3、通过反射机制获得动态代理类的构造函数，其唯一参数类型是调用处理器接口类型。 4、通过构造函数创建动态代理类实例，构造时调用处理器对象作为参数被传入。 伪代码如下： 123456789101112// InvocationHandlerImpl 实现了 InvocationHandler 接口，并能实现方法调用从代理类到委托类的分派转发// 其内部通常包含指向委托类实例的引用，用于真正执行分派转发过来的方法调用InvocationHandler handler = new InvocationHandlerImpl(..); // 通过Proxy为包括Interface接口在内的一组接口动态创建代理类的类对象Class clazz = Proxy.getProxyClass(classLoader, new Class[] &#123; Interface.class, ... &#125;); // 通过反射从生成的类对象获得构造函数对象Constructor constructor = clazz.getConstructor(new Class[] &#123; InvocationHandler.class &#125;); // 通过构造函数对象创建动态代理类实例Interface Proxy = (Interface)constructor.newInstance(new Object[] &#123; handler &#125;); 上面的过程比较复杂，可以进行精简。简化后的伪代码如下： 12345// InvocationHandlerImpl实现了InvocationHandler 接口，并能实现方法调用从代理类到委托类的分派转发InvocationHandler handler = new InvocationHandlerImpl(..); // 通过Proxy直接创建动态代理类实例Interface proxy = (Interface) Proxy.newProxyInstance(classLoader, new Class[] &#123; Interface.class &#125;, handler); JDK动态代理的机制 首先是JDK动态代理生成的代理类本身的特点： 1、包(或者JDK9引入的模块)：如果所代理的接口都是public的，那么它将被定义在包com.sun.proxy；如果所代理的接口中有非public的接口(因为接口不能被定义为protect或private，所以除public之外就是默认的package访问级别，修饰符为default)，那么它将被定义在该接口所在包(假设代理了throwable.club包中的某非public接口A，那么新生成的代理类所在的包就是throwable.club)，值得注意的是，如果接口数组中存在非public的接口，那么它们必须在同一个包路径下，否则会抛异常。这样设计的目的是为了最大程度的保证动态代理类不会因为包管理的问题而无法被成功定义并访问。 2、类修饰符：该代理类具有final和public修饰符，意味着它可以被所有的类访问，但是不能被再度继承。 3、类名：代理类名称格式是$ProxyN，其中N是一个逐一递增的阿拉伯数字，代表java.lang.reflect.Proxy类第N次生成的动态代理类，值得注意的一点是，并不是每次调用Proxy的静态方法创建动态代理类都会使得N值增加，原因是如果对同一组接口(包括接口排列的顺序相同)试图重复创建动态代理类，它会从缓存中获取先前已经创建好的代理类的类对象，而不会再尝试去创建一个全新的代理类，这样可以节省不必要的代码重复生成，提高了代理类的创建效率。 4、类继承关系：代理类的继承关系图如下： 由图可知，java.lang.reflect.Proxy类是代理类的父类，这个规则适用于所有由java.lang.reflect.Proxy创建的动态代理类。而且该类还实现了其所代理的一组接口，这就是为什么它能够被安全地类型转换到其所代理的某接口的根本原因。 代理类实例的特点 每个代理类实例都会关联一个调用处理器对象，可以通过java.lang.reflect.Proxy提供的静态方法getInvocationHandler()去获得代理类实例的调用处理器对象。在代理类实例上调用其代理的接口中所声明的方法时，这些方法最终都会由调用处理器的 invoke 方法执行，此外，值得注意的是，代理类的根类java.lang.Object中有三个方法也同样会被分派到调用处理器的invoke方法执行，它们是hashCode、equals和toString，可能的原因有： 一、因为这些方法为public且非final类型，能够被代理类覆盖。 二、因为这些方法往往呈现出一个类的某种特征属性，具有一定的区分度，所以为了保证代理类与委托类对外的一致性，这三个方法也应该被分派到委托类执行。当代理的一组接口有重复声明的方法且该方法被调用时，代理类总是从排在最前面的接口中获取方法对象并分派给调用处理器，而无论代理类实例是否正在以该接口(或继承于该接口的某子接口)的形式被外部引用，因为在代理类内部无法区分其当前的被引用类型。 被代理的一组接口的特点 首先，要注意不能有重复的接口，以避免动态代理类代码生成时的编译错误。其次，这些接口对于类装载器必须可见，否则类装载器将无法链接它们，将会导致类定义失败。再次，需被代理的所有非public的接口必须在同一个包中，否则代理类生成也会失败。最后，接口的数目不能超过65535，这是JVM设定的限制，这一点在代理类生成的时候也做了判断。 异常处理 从调用处理器接口声明的方法中可以看到理论上它能够抛出任何类型的异常，因为所有的异常都继承于Throwable接口，但事实是否如此呢？答案是否定的，原因是我们必须遵守一个继承原则：即子类覆盖父类或实现父接口的方法时，抛出的异常必须在原方法支持的异常列表之内。所以虽然调用处理器理论上讲能够，但实际上往往受限制，除非父接口中的方法支持抛Throwable异常。那么如果在invoke方法中的确产生了接口方法声明中不支持的异常，那将如何呢？放心，Jdk动态代理类已经为我们设计好了解决方法：它将会抛出UndeclaredThrowableException 异常。这个异常是一个RuntimeException类型，所以不会引起编译错误。通过该异常的getCause方法，还可以获得原来那个不受支持的异常对象，以便于错误诊断。 JDK动态代理源码分析 因为JDK动态代理核心逻辑都在java.lang.reflect.Proxy类中，下面简单分析一下这个类的源码。先看Proxy类中的几个重要的静态变量： 12345678// 接口组中接口都为为public时候代理类创建的包路径：com.sun.proxyprivate static final String PROXY_PACKAGE_PREFIX = ReflectUtil.PROXY_PACKAGE;// 代理类的构造方法参数类型数组，可见代理类的构造参数只有InvocationHandler类型private static final Class&lt;?&gt;[] constructorParams = &#123; InvocationHandler.class &#125;;// 缓存了所有已经调用过setAccessible(true)的代理类的构造(Constructor)实例private static final ClassLoaderValue&lt;Constructor&lt;?&gt;&gt; proxyCache = new ClassLoaderValue&lt;&gt;(); 这里注意到ClassLoaderValue，下文会调用到它的一个很复杂的调用链： 12345678910//intf是Class&lt;?&gt;类型//loader是类加载器实例return proxyCache.sub(intf).computeIfAbsent( loader, (ld, clv) -&gt; new ProxyBuilder(ld, clv.key()).build());public V computeIfAbsent(ClassLoader cl, BiFunction&lt;? super ClassLoader,? super CLV,? extends V&gt; mappingFunction) throws IllegalStateException &#123; 上面的computeIfAbsent中使用了函数式接口和Lambda表达式，如果Lambda表达式玩的比较熟练看起来应该没问题，它的功能可以解读为：通过接口类型和类加载器实例计算通过接口类型和类加载器实例构建ProxyBuilder实例并且调用ProxyBuilder#build()得到的结果，如果结果已经存在则直接返回缓存。其实computeIfAbsent在Map接口中也定义了同样的方法，功能是相似的。 接着看Proxy的构造函数： 123456789protected InvocationHandler h;private Proxy() &#123;&#125;protected Proxy(InvocationHandler h) &#123; Objects.requireNonNull(h); this.h = h;&#125; 到此可以明确一点，既然所有动态代理类都是java.lang.reflect.Proxy的子类，那么它们一定具备一个包含InvocationHandler参数的构造器。接着查看``方法的源码： 1234567891011121314public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) &#123; // 空判断 Objects.requireNonNull(h); // 当前调用类获取 final Class&lt;?&gt; caller = System.getSecurityManager() == null ? null : Reflection.getCallerClass(); // 获取代理类的构造器实例 Constructor&lt;?&gt; cons = getProxyConstructor(caller, loader, interfaces); // 生成代理实例 return newProxyInstance(caller, cons, h);&#125; 先看getProxyConstructor方法： 123456789101112131415161718192021222324252627private static Constructor&lt;?&gt; getProxyConstructor(Class&lt;?&gt; caller, ClassLoader loader, Class&lt;?&gt;... interfaces)&#123; // 这里需要区分代理接口数组中只有单个接口和多个接口的逻辑 // 而基本的逻辑都是先校验当前调用类的权限，后续获取Constructor实例委托到ProxyBuilder if (interfaces.length == 1) &#123; Class&lt;?&gt; intf = interfaces[0]; if (caller != null) &#123; checkProxyAccess(caller, loader, intf); &#125; return proxyCache.sub(intf).computeIfAbsent( loader, (ld, clv) -&gt; new ProxyBuilder(ld, clv.key()).build() ); &#125; else &#123; // 接口克隆 final Class&lt;?&gt;[] intfsArray = interfaces.clone(); if (caller != null) &#123; checkProxyAccess(caller, loader, intfsArray); &#125; final List&lt;Class&lt;?&gt;&gt; intfs = Arrays.asList(intfsArray); return proxyCache.sub(intfs).computeIfAbsent( loader, (ld, clv) -&gt; new ProxyBuilder(ld, clv.key()).build() ); &#125;&#125; 可以明确，核心的逻辑都交给了Proxy的内部类ProxyBuilder完成，先看ProxyBuilder的静态成员变量： 1234567891011// Unsafe实例private static final Unsafe UNSAFE = Unsafe.getUnsafe();// 代理类的简单类名的前置字符串private static final String proxyClassNamePrefix = \"$Proxy\";// 用于生成下一个代理类的数字计数器，记住它是静态的private static final AtomicLong nextUniqueNumber = new AtomicLong();// 记录了已经生成的代理类-Boolean的映射，已经生成过对应代理类则记录为trueprivate static final ClassLoaderValue&lt;Boolean&gt; reverseProxyCache = new ClassLoaderValue&lt;&gt;(); 123456789101112131415161718192021222324252627282930// 单个代理接口的情况，其实也是把接口转换为ListProxyBuilder(ClassLoader loader, Class&lt;?&gt; intf) &#123; this(loader, Collections.singletonList(intf));&#125;// 多个代理接口的情况ProxyBuilder(ClassLoader loader, List&lt;Class&lt;?&gt;&gt; interfaces) &#123; // 通过JVM参数强制关闭动态代理功能则抛出异常 if (!VM.isModuleSystemInited()) &#123; throw new InternalError(\"Proxy is not supported until \" + \"module system is fully initialized\"); &#125; // 代理接口数量不能超过65535，也就是最多代理65535个接口 if (interfaces.size() &gt; 65535) &#123; throw new IllegalArgumentException(\"interface limit exceeded: \" + interfaces.size()); &#125; // 收集接口数组中所有接口的非静态方法的返回值类型、共享(shared)参数类型和共享(shared)异常类型，注释说是收集代理接口的方法签名 Set&lt;Class&lt;?&gt;&gt; refTypes = referencedTypes(loader, interfaces); // 确保上一步得到的代理接口方法签名的类型都是\"可见(其实就是类型都存在)\"的，通过遍历调用Class.forName(type.getName(), false, ld)去判断 validateProxyInterfaces(loader, interfaces, refTypes); this.interfaces = interfaces; // 获取代理类最终生成的模块，规则如下： // 1、所有代理接口的修饰符都为public，接口所在模块都能公开访问，则返回unnamed模块 // 2、如果有任意的代理接口是包私有，则返回该包所在的模块 、 // 3、所有代理接口的修饰符都为public，有任意至少一个接口所在模块不能公开访问，则返回该不能公开访问的模块， this.module = mapToModule(loader, interfaces, refTypes); assert getLoader(module) == loader;&#125; 一个构造器处理的逻辑也是相对复杂，主要是因为引入模块管理的概念，接着看ProxyBuilder#build()的源码： 123456789101112131415161718Constructor&lt;?&gt; build() &#123; // 定义代理类，实际上是动态生成代理类字节码和缓存它的类型的过程 Class&lt;?&gt; proxyClass = defineProxyClass(module, interfaces); final Constructor&lt;?&gt; cons; try &#123; // 返回代理类的构造 cons = proxyClass.getConstructor(constructorParams); &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); return cons;&#125; 最后到逻辑最复杂的代理类的生成过程ProxyBuilder#defineProxyClass()： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263private static Class&lt;?&gt; defineProxyClass(Module m, List&lt;Class&lt;?&gt;&gt; interfaces) &#123; String proxyPkg = null; // package to define proxy class in int accessFlags = Modifier.PUBLIC | Modifier.FINAL; // 这里就是定义代理类包路径的逻辑，规则如下： // 1、代理接口数组所有接口都是public修饰，则代理类包路径为com.sun.proxy // 2、代理接口数组有任意接口是包私有的，则代理类包路径为该私有包的路径 for (Class&lt;?&gt; intf : interfaces) &#123; int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) &#123; accessFlags = Modifier.FINAL; // non-public, final String pkg = intf.getPackageName(); if (proxyPkg == null) &#123; proxyPkg = pkg; &#125; else if (!pkg.equals(proxyPkg)) &#123; throw new IllegalArgumentException( \"non-public interfaces from different packages\"); &#125; &#125; &#125; // 下面几个if都是包路径的合法性判断 if (proxyPkg == null) &#123; // all proxy interfaces are public proxyPkg = m.isNamed() ? PROXY_PACKAGE_PREFIX + \".\" + m.getName() : PROXY_PACKAGE_PREFIX; &#125; else if (proxyPkg.isEmpty() &amp;&amp; m.isNamed()) &#123; throw new IllegalArgumentException( \"Unnamed package cannot be added to \" + m); &#125; if (m.isNamed()) &#123; if (!m.getDescriptor().packages().contains(proxyPkg)) &#123; throw new InternalError(proxyPkg + \" not exist in \" + m.getName()); &#125; &#125; // 计数器加1返回新的计数值 long num = nextUniqueNumber.getAndIncrement(); // 生成代理类全类名，一个常见的格式是：com.sun.proxy.$Proxy1 String proxyName = proxyPkg.isEmpty() ? proxyClassNamePrefix + num : proxyPkg + \".\" + proxyClassNamePrefix + num; ClassLoader loader = getLoader(m); trace(proxyName, m, loader, interfaces); // 动态生成代理类字节码字节数组 byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces.toArray(EMPTY_CLASS_ARRAY), accessFlags); try &#123; // 通过Unsafe定义代理类-这里是通过字节码定义新的类 Class&lt;?&gt; pc = UNSAFE.defineClass(proxyName, proxyClassFile, 0, proxyClassFile.length, loader, null); // 缓存代理类已经生成过的标记 reverseProxyCache.sub(pc).putIfAbsent(loader, Boolean.TRUE); return pc; &#125; catch (ClassFormatError e) &#123; /* * A ClassFormatError here means that (barring bugs in the * proxy class generation code) there was some other * invalid aspect of the arguments supplied to the proxy * class creation (such as virtual machine limitations * exceeded). */ throw new IllegalArgumentException(e.toString()); &#125;&#125; 到这一步为止，代理类的生成过程已经大致分析完毕，ProxyGenerator中涉及到大量字节码操作，这里就不深入分析了。那么回到最前面的方法，得到代理类和它的构造实例，接着就可以生成代理实例： 1234567891011121314151617181920private static Object newProxyInstance(Class&lt;?&gt; caller, // null if no SecurityManager Constructor&lt;?&gt; cons, InvocationHandler h) &#123; try &#123; if (caller != null) &#123; checkNewProxyPermission(caller, cons.getDeclaringClass()); &#125; // 这里简单反射调用Constructor#newInstance(h) return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException | InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125;&#125; 小结一下： 接口数组中所有接口元素的类修饰符最好一致为public。如果接口数组中存在非default修饰的接口元素，那么接口数组中的所有接口类都要放在同一个包下，并且都要使用default修饰。 很少情况下我们修改接口的修饰符，默认为public，那么所有代理类的包路径都是com.sun.proxy，全类名是:com.sun.proxy.$ProxyN。 代理接口数量不能超过65535。 JDK动态代理类的源代码 前面已经分析完了代理类的生成过程，这里举个简单的使用例子，并且观察生成的动态代理类的源代码。 使用例子： 12345678910111213141516171819202122232425262728293031// 接口public interface Simple &#123; void sayHello(String name);&#125;// 接口实现public class DefaultSimple implements Simple &#123; @Override public void sayHello(String name) &#123; System.out.println(String.format(\"%s say hello!\", name)); &#125;&#125;// 场景类public class Main &#123; public static void main(String[] args) throws Exception &#123; Simple simple = new DefaultSimple(); Object target = Proxy.newProxyInstance(Main.class.getClassLoader(), new Class[]&#123;Simple.class&#125;, new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"Before say hello...\"); method.invoke(simple, args); System.out.println(\"After say hello...\"); return null; &#125; &#125;); Simple proxy = (Simple) target; proxy.sayHello(\"throwable\"); &#125;&#125; 调用后输出： 123Before say hello...throwable say hello!After say hello... 可以看到，我们在被代理类DefaultSimple实例的方法调用前后织入了自定义的逻辑，这就是通过JDK动态代理实现AOP的底层原理。在JDK8中可以直接使用sun.misc.ProxyGenerator去输出代理类的class文件，但是JDK11中这个代理类生成器已经变成java.lang.reflect.ProxyGenerator，并且这个类是包私有的，我们无法使用，但是它提供了jdk.proxy.ProxyGenerator.saveGeneratedFiles这个VM参数让我们可以保存代理类的class文件： 12# JVM参数-Djdk.proxy.ProxyGenerator.saveGeneratedFiles=true 配置好VM参数后，再次调用mian方法就能看到在项目的顶层包路径下看到对应的类com.sun.proxy.$Proxy0，目前从java.lang.reflect.ProxyGenerator源码看无法控制代理类文件的输出路径，生成的代理类内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public final class $Proxy0 extends Proxy implements Simple &#123; private static Method m1; private static Method m3; private static Method m2; private static Method m0; public $Proxy0(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final void sayHello(String var1) throws &#123; try &#123; super.h.invoke(this, m3, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final int hashCode() throws &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m3 = Class.forName(\"club.throwable.jdk.sample.reflection.proxy.Simple\").getMethod(\"sayHello\", Class.forName(\"java.lang.String\")); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125; 代理类的代码比较简单，有如下几个特点： 1、代理类继承于java.lang.reflect.Proxy，实现了接口数组中的接口元素类，构造函数只有一个InvocationHandler类型的参数。 2、接口中的所有被代理方法包括equals、toString、hashCode都建立了一个对应的Method私有静态实例，在最后面的静态代码块中实例化。 3、所有代理方法都是用public final修饰，也就是代理类中的代理方法是不能覆盖的。 4、所有代理方法都是通过InvocationHandler实例的invoke方法进行调用的，记得第一个参数是代理类实例本身，如果用了在InvocationHandler#invoke()方法实现过程中使用了这个参数有可能造成死循环。 小结 诚然，Proxy已经设计得非常优美，但是还是有一点点小小的遗憾之处，那就是它始终无法摆脱仅支持interface代理的桎梏，因为它的设计注定了这个遗憾。回想一下那些动态生成的代理类的继承关系图，它们已经注定有一个共同的父类叫Proxy。Java的单继承机制注定了这些动态代理类们无法实现对class的动态代理(所以只能代理接口，实际上是基于反射对方法级别的逻辑进行编织)。有很多条理由，可以否定对class代理的必要性，但是同样有一些理由，相信支持class动态代理会更美好。但是，不完美并不等于不伟大，伟大是一种本质，JDK动态代理就是佐例。 参考资料： Java动态代理机制分析及扩展-第1部分 Java动态代理机制分析及扩展-第2部分 JDK11相关源码 (本文完 e-20181208 c-3-d)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Reflection","slug":"Java/Reflection","permalink":"http://throwable.club/blog/categories/Java/Reflection/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Reflection","slug":"Reflection","permalink":"http://throwable.club/blog/tags/Reflection/"}]},{"title":"深入分析Java反射(三)-泛型","slug":"java-reflection-generics","date":"2018-12-04T17:05:59.000Z","updated":"2018-12-05T15:20:21.522Z","comments":true,"path":"2018/12/05/java-reflection-generics/","link":"","permalink":"http://throwable.club/2018/12/05/java-reflection-generics/","excerpt":"","text":"深入分析Java反射(三)-泛型 前提 Java反射的API在JavaSE1.7的时候已经基本完善，但是本文编写的时候使用的是Oracle JDK11，因为JDK11对于sun包下的源码也上传了，可以直接通过IDE查看对应的源码和进行Debug。 本文主要介绍反射中一个比较难的问题-泛型。 泛型的简介 泛型是在2004年JavaSE 5.0(JDK1.5)版本中添加到Java编程语言中的泛型编程工具。泛型的设计是为了应用在Java的类型系统，提供&quot;用类型或者方法操作各种类型的对象从而提供编译期的类型安全功能(原文：a type or method to operate on objects of various types while providing compile-time type safety)&quot;。但是在2016年的一些研究表明，泛型并不是在所有的情况下都能保证编译期的类型安全，例如切面(Aspect)编程的编译期类型安全并没有完全实现。 泛型的一个最大的优点就是：提供编译期的类型安全。举个很简单的例子，在引入泛型之前，ArrayList内部只维护了一个Object数组引用，这种做法有两个问题： 从数组列表获取一个元素的时候必须进行类型的强转。 向数组列表中可以添加任何类型的对象，导致无法得知数组列表中存放了什么类型的元素。 引入泛型之后，我们可以通过类型参数明确定义ArrayList： 1234ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();// JavaSE 7以后的版本中构造函数可以省略类型，编译器可以推导出实际类型ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); 下面先列举出Java中泛型的一些事实： Java虚拟机中不存在泛型，只有普通的类和方法，但是字节码中存放着泛型相关的信息。 所有的类型参数都使用它们的限定类型替换。 桥方法(Bridge Method)由编译器合成，用于保持多态(Java虚拟机利用方法的参数类型、方法名称和方法返回值类型确定一个方法)。 为了保持类型的安全性，必要时需要进行类型的强制转换。 理解类型擦除 类型擦除是什么 类型擦除(或者更多时候喜欢称为&quot;泛型擦除&quot;)的具体表现是：无论何时定义一个泛型类型，都自动提供一个相应的原始类型(Raw Type，这里的原始类型并不是指int、boolean等基本数据类型)，原始类型的类名称就是带有泛型参数的类删去泛型参数后的类型名称，而原始类型会擦除(Erased)类型变量，并且把它们替换为限定类型(如果没有指定限定类型，则擦除为Object类型)，举个例子Pair&lt;T&gt;带有泛型参数的类型如下： 123456789101112131415161718public class Pair&lt;T&gt;&#123; private T first; private T second; public Pair(T first,T second)&#123; this.first = first; this.second = second; &#125; public T getFirst()&#123; return first; &#125; public T getSecond()&#123; return second; &#125;&#125; 擦除类型后的Pair&lt;T&gt;的原始类型为： 123456789101112131415161718public class Pair&#123; private Object first; private Object second; public Pair(Object first,Object second)&#123; this.first = first; this.second = second; &#125; public Object getFirst()&#123; return first; &#125; public Object getSecond()&#123; return second; &#125;&#125; 举个更复杂的例子，如果泛型参数类型是有上限的，变量会擦除为上限的类型： 123456789101112public class Interval&lt;T extends Comparable &amp; Serializable&gt; implements Serializable &#123; private T lower; private T upper; public Interval(T lower, T upper) &#123; this.lower = lower; this.upper = upper; &#125; //省略其他方法&#125; 类型擦除后的Interval&lt;T extends Comparable &amp; Serializable&gt;原始类型： 123456789101112public class Interval implements Serializable &#123; private Comparable lower; private Comparable upper; public Interval(Comparable lower, Comparable upper) &#123; this.lower = lower; this.upper = upper; &#125; //省略其他方法&#125; 像上面这种多个泛型上限的类型，应该尽量把标识接口上限类型放在边界列表的尾部，这样做可以提高效率。 为什么需要擦除类型 在JDK1.5之前，也就是在泛型出现之前，所有的类型包括基本数据类型(int、byte等)、包装类型、其他自定义的类型等等都可以使用类文件(.class)字节码对应的java.lang.Class描述，也就是java.lang.Class类的一个具体实例对象就可以代表任意一个指定类型的原始类型。这里把泛型出现之前的所有类型暂时称为&quot;历史原始类型&quot;。 在JDK1.5之后，数据类型得到了扩充，出历史原始类型扩充了四种泛型类型：参数化类型(ParameterizedType)、类型变量类型(TypeVariable)、限定符类型(WildcardType)、泛型数组类型(GenericArrayType)。历史原始类型和新扩充的泛型类型都应该统一成各自的字节码文件类型对象，也就应该把泛型类型归并进去java.lang.Class中。但是由于JDK已经迭代了很多版本，泛型并不属于当前Java中的基本成分，如果JVM中引入真正的泛型类型，那么必须涉及到JVM指令集和字节码文件的修改(这个修改肯定不是小的修改，因为JDK当时已经迭代了很多年，而类型是编程语言的十分基础的特性，引入泛型从项目功能迭代角度看可能需要整个JVM项目做回归测试)，这个功能的代价十分巨大，所以Java没有在Java虚拟机层面引入泛型。 Java为了使用泛型，于是使用了类型擦除的机制引入了&quot;泛型的使用&quot;，并没有真正意义上引入和实现泛型。Java中的泛型实现的是编译期的类型安全，也就是泛型的类型安全检查是在编译期由编译器(常见的是javac)实现的，这样就能够确保数据基于类型上的安全性并且避免了强制类型转换的麻烦(实际上，强制类型转换是由编译器完成了，只是不需要人为去完成而已)。一旦编译完成，所有的泛型类型都会被擦除，如果没有指定上限，就会擦除为Object类型，否则擦除为上限类型。 既然Java虚拟机中不存在泛型，那么为什么可以从JDK中的一些类库获取泛型信息？这是因为类文件(.class)或者说字节码文件本身存储了泛型的信息，相关类库(可以是JDK的类库，也可以是第三方的类库)读取泛型信息的时候可以从字节码文件中提取，例如比较常用的字节码操作类库ASM就可以读取字节码中的信息甚至改造字节码动态生成类。例如前面提到的Interval&lt;T extends Comparable &amp; Serializable&gt;类，使用javap -c -v命令查看其反编译得到的字节码信息，可以看到其签名如下： 1Signature: #22 // &lt;T::Ljava/lang/Comparable;:Ljava/io/Serializable;&gt;Ljava/lang/Object;Ljava/io/Serializable; 这里的签名信息实际上是保存在常量池中的，关于字节码文件的解析将来会出一个系列文章详细展开。 Type体系 前文提到了在JDK1.5中引入了四种新的泛型类型java.lang.reflect.ParameterizedType、java.lang.reflect.TypeVariable、java.lang.reflect.WildcardType、java.lang.reflect.GenericArrayType，包括原来存在的java.lang.Class，一共存在五种类型。为了程序的扩展性，引入了java.lang.reflect.Type类作为这五种类型的公共父接口，这样子就可以使用java.lang.reflect.Type类型参数去接收以上五种子类型的实参或者返回值，由此从逻辑上统一了泛型相关的类型和原始存在的java.lang.Class描述的类型。Type体系如下： 注意： ParameterizedType、TypeVariable、WildcardType、GenericArrayType都是接口，它们位于java.lang.reflect包中。 ParameterizedTypeImpl、TypeVariableImpl、WildcardTypeImpl、GenericArrayTypeImpl是四种泛型类型的实现，位于sun.reflect.generics.reflectiveObjects包中。 Type体系虽然看似很美好解决了泛型相关的类型和原始存在的java.lang.Class描述的类型的统一问题，但是引入了新的问题：如果一个方法返回值为java.lang.reflect.Type类型，或者一个方法的入参类型为java.lang.reflect.Type类型，这两种情况下，可能需要对java.lang.reflect.Type类型的对象做子类型判断，因为它的子类型有可能是上面提到的五种类型中的其中一种，这一点提高了编码的复杂性。 ParameterizedType ParameterizedType，parameterized type，也就是参数化类型，注释里面说到ParameterizedType表示一个参数化类型，例如Collection&lt;String&gt;，实际上只要带有参数化(泛型)标签&lt;ClassName&gt;的参数或者属性，都属于ParameterizedType。例如下面的类型都是ParameterizedType： 12345678Set&lt;String&gt; set;Class&lt;Integer&gt; clazz;MyClass&lt;String&gt; myClass;List&lt;String&gt; list;class MyClass&lt;V&gt;&#123;&#125; 而像下面的忽略泛型参数或者基本数据类型和基本数据类型的包装类都不是ParameterizedType： 12345678String name = \"throwbale\";int age = 25;Set set;List list;public String method(int age,String name)&#123;&#125; java.lang.reflect.ParameterizedType接口继承自java.lang.reflect.Type接口，实现类是sun.reflect.generics.reflectiveObjects.ParameterizedTypeImpl，其实，必要的时候，我们也可以自行实现ParameterizedType，像一些Json解析工具都是自行实现ParameterizedType的。ParameterizedType接口的方法如下： 12345678public interface ParameterizedType extends Type &#123; Type[] getActualTypeArguments(); Type getRawType(); Type getOwnerType();&#125; Type[] getActualTypeArguments()：返回这个ParameterizedType类型的参数的实际类型Type数组，Type数组里面的元素有可能是Class、ParameterizedType、TypeVariable、GenericArrayType或者WildcardType之一。值得注意的是，无论泛型符号&lt;&gt;中有几层&lt;&gt;嵌套，这个方法仅仅脱去最外层的&lt;&gt;，之后剩下的内容就作为这个方法的返回值。 Type getRawType()：返回的是当前这个ParameterizedType的原始类型，从ParameterizedTypeImpl的源码看来，原始类型rawType一定是一个Class&lt;?&gt;实例。举个例子，List&lt;Person&gt;通过getRawType()获取到的Type实例实际上是Class&lt;?&gt;实例，和List.class等价。 Type getOwnerType()：获取原始类型所属的类型，从ParameterizedTypeImpl的源码看来，就是调用了原始类型rawType的getDeclaringClass()方法，而像rawType为List&lt;T&gt;、Map&lt;T&gt;这些类型的getOwnerType()实际上就是调用List.class.getDeclaringClass()，Map.class.getDeclaringClass()，返回值都是null。 举个关于ParameterizedType的简单使用例子： 123456789101112131415161718192021222324252627282930public class Main13 &#123; public static void main(String[] args) throws Exception &#123; Class&lt;Sub&gt; subClass = Sub.class; Type genericSuperclass = subClass.getGenericSuperclass(); if (genericSuperclass instanceof ParameterizedType) &#123; ParameterizedType parameterizedType = (ParameterizedType) genericSuperclass; //获取父类泛型类型数组 Type[] actualTypeArguments = parameterizedType.getActualTypeArguments(); for (Type type : actualTypeArguments) &#123; System.out.println(type + \" is ParameterizedType -&gt; \" + (type instanceof ParameterizedType)); &#125; &#125; Field field = subClass.getDeclaredField(\"clazz\"); Type genericType = field.getGenericType(); System.out.println(genericType + \" is ParameterizedType -&gt; \" + (genericType instanceof ParameterizedType)); &#125; public static class Person &#123; &#125; public static abstract class Supper&lt;T, E&gt; &#123; &#125; public static class Sub extends Supper&lt;String, List&lt;Person&gt;&gt; &#123; &#125;&#125; 输出结果： 123class java.lang.String is ParameterizedType -&gt; falsejava.util.List&lt;org.throwable.inherited.Main13$Person&gt; is ParameterizedType -&gt; truejava.lang.Class&lt;?&gt; is ParameterizedType -&gt; true TypeVariable TypeVariable，type variable，也就是类型变量，它是各种类型变量的公共父接口，它主要用来表示带有上界的泛型参数的信息，它和ParameterizedType不同的地方是，ParameterizedType表示的参数的最外层一定是已知具体类型的(如List&lt;String&gt;)，而TypeVariable面向的是K、V、E等这些泛型参数字面量的表示。常见的TypeVariable的表示形式是&lt;T extends KnownType-1 &amp; KnownType-2&gt;。TypeVariable接口源码如下： 12345678910public interface TypeVariable&lt;D extends GenericDeclaration&gt; extends Type &#123; //获得泛型的上限，若未明确声明上边界则默认为Object Type[] getBounds(); //获取声明该类型变量实体(即获得类、方法或构造器名) D getGenericDeclaration(); //获得名称，即K、V、E之类名称 String getName(); //获得注解类型的上限，若未明确声明上边界则默认为长度为0的数组 AnnotatedType[] getAnnotatedBounds()&#125; Type[] getBounds()：获得该类型变量的上限(上边界)，若无显式定义(extends)，默认为Object，类型变量的上限可能不止一个，因为可以用&amp;符号限定多个（这其中有且只能有一个为类或抽象类，且必须放在extends后的第一个，即若有多个上边界，则第一个&amp;之后的必为接口）。 D getGenericDeclaration：获得声明(定义)这个类型变量的类型及名称，会使用泛型的参数字面量表示，如public void club.throwable.Main.query(java.util.List&lt;club.throwable.Person&gt;)。 String getName()：获取泛型参数的字面量名称，即K、V、E之类名称。 AnnotatedType[] getAnnotatedBounds()：Jdk1.8新增的方法，用于获得注解类型的上限，若未明确声明上边界则默认为长度为0的数组。 举个关于TypeVariable的简单使用例子： 123456789101112131415161718192021222324252627282930313233343536373839public class Main14 &#123; public static void main(String[] args) throws Exception &#123; Class&lt;Supper&gt; subClass = Supper.class; TypeVariable&lt;Class&lt;Supper&gt;&gt;[] typeParameters = subClass.getTypeParameters(); for (TypeVariable&lt;Class&lt;Supper&gt;&gt; typeVariable : typeParameters) &#123; System.out.println(\"getBounds --&gt; \" + Arrays.toString(typeVariable.getBounds())); System.out.println(\"getGenericDeclaration --&gt; \" + typeVariable.getGenericDeclaration()); System.out.println(\"getName --&gt; \" + typeVariable.getName()); AnnotatedType[] annotatedBounds = typeVariable.getAnnotatedBounds(); StringBuilder stringBuilder = new StringBuilder(\"getAnnotatedBounds --&gt; \"); for (AnnotatedType annotatedType : annotatedBounds) &#123; java.lang.annotation.Annotation[] annotations = annotatedType.getAnnotations(); for (java.lang.annotation.Annotation annotation : annotations) &#123; stringBuilder.append(annotation).append(\",\"); &#125; &#125; System.out.println(stringBuilder.toString()); System.out.println(\"===================\"); &#125; &#125; @Target(ElementType.TYPE) public @interface Annotation &#123; &#125; interface InterFace &#123; &#125; public static class Person &#123; &#125; public static abstract class Supper&lt;T extends Person &amp; InterFace, E extends Annotation&gt; &#123; &#125;&#125; 输出结果： 12345678910getBounds --&gt; [class org.throwable.inherited.Main14$Person, interface org.throwable.inherited.Main14$InterFace]getGenericDeclaration --&gt; class org.throwable.inherited.Main14$SuppergetName --&gt; TgetAnnotatedBounds --&gt;===================getBounds --&gt; [interface org.throwable.inherited.Main14$Annotation]getGenericDeclaration --&gt; class org.throwable.inherited.Main14$SuppergetName --&gt; EgetAnnotatedBounds --&gt;=================== WildcardType WildcardType用于表示通配符(?)类型的表达式的泛型参数，例如&lt;? extends Number&gt;等。根据WildcardType注释提示：现阶段通配符表达式仅仅接受一个上边界或者下边界，这个和定义类型变量时候可以指定多个上边界是不一样。但是为了保持扩展性，这里返回值类型写成了数组形式。实际上现在返回的数组的大小就是1。WildcardType接口源码如下： 123456public interface WildcardType extends Type &#123; Type[] getUpperBounds(); Type[] getLowerBounds();&#125; Type[] getUpperBounds()：获取泛型通配符的上限类型Type数组，实际上目前该数组只有一个元素，也就是说只能有一个上限类型。 Type[] getLowerBounds()：获取泛型通配符的下限类型Type数组，实际上目前该数组只有一个元素，也就是说只能有一个下限类型。 举个关于WildcardType的简单使用例子： 123456789101112131415161718192021222324252627282930313233343536public class Main16 &#123; public static void main(String[] args) &#123; Class&lt;Main16&gt; clazz = Main16.class; Method[] methods = clazz.getMethods(); for (Method method : methods) &#123; if (\"print\".equals(method.getName())) &#123; Type[] genericParameterTypes = method.getGenericParameterTypes(); for (Type type : genericParameterTypes) &#123; if (type instanceof ParameterizedType) &#123; ParameterizedType parameterizedType = (ParameterizedType) type; Type[] actualTypeArguments = parameterizedType.getActualTypeArguments(); for (Type actualType : actualTypeArguments) &#123; if (actualType instanceof WildcardType) &#123; WildcardType wildcardType = (WildcardType) actualType; System.out.println(\"WildcardType --&gt; \" + wildcardType + \" getUpperBounds--&gt; \" + Arrays.toString(wildcardType.getUpperBounds()) + \" getLowerBounds--&gt; \" + Arrays.toString(wildcardType.getLowerBounds())); &#125; else &#123; System.out.println(\"Not WildcardType --&gt; \" + actualType); &#125; &#125; &#125; &#125; &#125; &#125; &#125; interface Person &#123; &#125; public static void print(List&lt;? extends Number&gt; list, Set&lt;? super Person&gt; persons) &#123; &#125;&#125; 输出结果： 12WildcardType --&gt; ? extends java.lang.Number getUpperBounds--&gt; [class java.lang.Number] getLowerBounds--&gt; []WildcardType --&gt; ? super org.throwable.inherited.Main16$Person getUpperBounds--&gt; [class java.lang.Object] getLowerBounds--&gt; [interface org.throwable.inherited.Main16$Person] 这里注意的是List&lt;? extends Number&gt; list这个参数整体来看是ParameterizedType类型，剥掉第一次List之后的? extends Number是WildcardType类型。 GenericArrayType GenericArrayType，generic array type，也就是泛型数组，也就是元素类型为泛型类型的数组实现了该接口。它要求元素的类型是ParameterizedType或TypeVariable(实际中发现元素是GenericArrayType也是允许的)。举个例子： 12345List&lt;String&gt;[] listArray; //是GenericArrayType,元素是List&lt;String&gt;类型，也就是ParameterizedType类型T[] tArray; //是GenericArrayType,元素是T类型，也就是TypeVariable类型Person[] persons; //不是GenericArrayTypeList&lt;String&gt; strings; //不是GenericArrayType GenericArrayType接口的源码如下： 1234public interface GenericArrayType extends Type &#123; Type getGenericComponentType();&#125; Type getGenericComponentType()：获取泛型数组中元素的类型。注意无论从左向右有几个[]并列，这个方法仅仅脱去最右边的[]之后剩下的内容就作为这个方法的返回值。 举个关于GenericArrayType的简单使用例子： 123456789101112131415161718192021222324public class Main15&lt;T&gt; &#123; public static void main(String[] args) throws Exception &#123; Method[] methods = Main15.class.getMethods(); for (Method method : methods) &#123; if (\"method\".equals(method.getName())) &#123; Type[] genericParameterTypes = method.getGenericParameterTypes(); for (Type type : genericParameterTypes) &#123; if (type instanceof GenericArrayType) &#123; System.out.println(\"GenericArrayType --&gt; \" + type + \" getGenericComponentType --&gt; \" + ((GenericArrayType) type).getGenericComponentType()); &#125; else &#123; System.out.println(\"Not GenericArrayType --&gt; \" + type); &#125; &#125; &#125; &#125; &#125; public static &lt;T&gt; void method(String[] strings, List&lt;String&gt; ls, List&lt;String&gt;[] lsa, T[] ts, List&lt;T&gt;[] tla, T[][] tts) &#123; &#125;&#125; 输出结果： 123456Not GenericArrayType --&gt; class [Ljava.lang.String;Not GenericArrayType --&gt; java.util.List&lt;java.lang.String&gt;GenericArrayType --&gt; java.util.List&lt;java.lang.String&gt;[] getGenericComponentType --&gt; java.util.List&lt;java.lang.String&gt;GenericArrayType --&gt; T[] getGenericComponentType --&gt; TGenericArrayType --&gt; java.util.List&lt;T&gt;[] getGenericComponentType --&gt; java.util.List&lt;T&gt;GenericArrayType --&gt; T[][] getGenericComponentType --&gt; T[] 这里分析一下： String[] strings：数组是Class类型。 List&lt;String&gt; ls：列表是ParameterizedType类型。 List&lt;String&gt;[] lsa：数组是GenericArrayType类型，调用getGenericComponentType后返回的类型是java.util.List&lt;java.lang.String&gt;，也就是数组元素是ParameterizedType类型。 T[] ts：s数组是GenericArrayType类型，调用getGenericComponentType后返回的类型是T，也就是数组元素是TypeVariable类型。 List&lt;T&gt;[] tla：数组是GenericArrayType类型，调用getGenericComponentType后返回的类型是java.util.List&lt;T&gt;，也就是数组元素是ParameterizedType类型。 T[][] tts：数组是GenericArrayType类型，调用getGenericComponentType后返回的类型T[]，也就是数组元素是GenericArrayType类型。 泛型的约束 使用Java泛型的时候需要考虑一些限制，这些限制大多数是由泛型类型擦除引起的。 1、不能用基本类型实例化类型参数，也就是8种基本类型不能作为泛型参数，例如Pair&lt;int&gt;是非法的，会导致编译错误，而Pair&lt;Integer&gt;是合法的。 2、运行时的类型查询只能适用于原始类型(非参数化类型)。 1234567//下面的两种做法是错误的if(a instanceof Pair&lt;String&gt;) //Errorif(a instanceof Pair&lt;T&gt;) //Error// 正确做法if(a instanceof Pair) //Right 3、不能创建参数化类型的数组，例如Pair&lt;String&gt;[] arr = new Pair&lt;String&gt;[10]是非法的。 4、不能实例化类型变量或者类型变量数组，例如T t = new T()或者T[] arr = new T[10]都是非法的。 5、Varargs警告，这是因为第4点原因导致的，一般会发生在泛型类型变量作为可变参数的情况，例如public static &lt;T&gt; addAll(Collection&lt;T&gt; con,T ... ts)，第二个参数实际上就是泛型类型变量数组，但是这种情况是合法的，不过会受到编译器的警告，可以通过@SuppressWarnings(&quot;unchecked&quot;)注解或者@SafeVarargs注解标注该方法以消除警告。 6、不能在静态域或者方法中引用类型变量，例如private static T singleInstance;这样是非法的。 7、不能抛出或者抛出或者捕获泛型类型变量，但是如果在异常规范中使用泛型类型变量则是允许的，举两个例子仔细品味一下： 1234567891011121314151617// 反例public static &lt;T extends Throwable&gt; void doWork(Class&lt;T&gt; t) &#123; try&#123; &#125;catch(T t)&#123; //Error &#125;&#125;// 正例public static &lt;T extends Throwable&gt; void doWork(T t) throws T&#123; try&#123; &#125;catch(Throwable e)&#123; throw e; &#125;&#125; 8、通过使用@SuppressWarnings(&quot;unchecked&quot;)注解可以消除Java类型系统的部分基本限制，一般使用在强制转换原始类型为泛型类型(只是在编译层面告知编译器)的情况，如： 12345// 不加此注解会收到编译器的警告@SuppressWarnings(\"unchecked\")public static &lt;T extends Throwable&gt; void throwAs(Throwable e)&#123; throw (T) e;&#125; 其实还有泛型的继承规则和通配符规则(可以看下前面介绍的Type的子类型)等等，这里不详细展开。 再议泛型数组的问题 在Java泛型约束中，无法实例化参数化类型数组，例如Pair&lt;Integer&gt;[] table = new Pair&lt;Integer&gt;[10];是非法的。根本原因在于泛型类型的擦除和数组会记录元素类型的特性。举个例子，假设可以实例化参数化类型数组： 1Pair&lt;String&gt;[] table = new Pair&lt;String&gt;[10]; 上面的参数化类型数组在泛型擦除之后，数组实例table的类型为Pair[]，数组元素类型为Pair，可以强转为Object[]类型数组： 1Object[] objArray = table; 基于泛型擦除，数组objArray可以任意赋值Pair&lt;AnyType&gt;的泛型化实例，例如： 1234objArray[0] = new Pair&lt;Integer&gt;();objArray[1] = new Pair&lt;Long&gt;();objArray[2] = new Pair&lt;String&gt;();.... 这样子能够通过数组存储元素的检查，后续操作数组元素随时会出现ClassCastException。基于以上的原因，Java从编译层面直接拒绝创建参数化类型数组。 另外，类型变量数组的实例化也是非法的，如T[] tt = new T[10];，这是因为类型变量仅仅是编译期的字面量，其实和Java的类型体系是不相关的。 但是要注意一点：参数化类型数组和类型变量数组可以作为方法入参变量或者类的成员变量。例如下面的做法是合法的： 12345678910111213public class Pair&lt;T&gt; &#123; private Pair&lt;T&gt;[] attr; private T[] ts; public static &lt;T&gt; void method(Pair&lt;T&gt; pair) &#123; &#125; public static &lt;T&gt; void method(T[] ts) &#123; &#125;&#125; 最后一点，可以查看前一篇文章，其实可以使用反射创建泛型数组。 无限定通配符 泛型中支持无限定通配符&lt;?&gt;，使用无限定通配符类型的实例有以下限制： 所有的Getter方法只能返回Object类型的值。 所有的Setter方法只能赋值null，其他类型的值的设置都是非法的。 无限定通配符类型可以看做原始类型的一个影子类型，它屏蔽了除了null之外的设值操作，所有获取值的方法只能返回Object类型结果，这种特性使得通过无限定通配符类型进行一些简单的操作变得十分方便，例如： 123public static boolean hasNulls(Pair&lt;?&gt; p)&#123; return p.getFirst() == null || p.getSecond() == null;&#125; 如果反射用得比较熟的话，java.lang.Class也有类似的用法： 12Class&lt;?&gt; clazz = ...;Object instance = class.newInstance(); 桥方法(Bridge Method) 先说明一下什么是桥方法，看下面的代码： 1234567891011121314// 父类public interface Supper&lt;T&gt; &#123; void method(T t);&#125;// 其中一个子类public class Sub implements Supper&lt;Integer&gt; &#123; @Override public void method(Integer value) &#123; System.out.println(value); &#125;&#125; 父类Supper&lt;T&gt;在泛型擦除后原始类型是： 1234public interface Supper&#123; void method(Object t);&#125; 子类Sub虽然实现了父类Supper，但是它只实现了void method(Integer value)而没有实现父类中的void method(Object t)，这个时候，编译期编译器会为子类Sub创建此方法，也就是子类Sub会变成这样： 1234567891011public class Sub implements Supper&lt;Integer&gt; &#123; @Override public void method(Integer value) &#123; System.out.println(value); &#125; public void method(Object value) &#123; this.method((Integer) value); &#125;&#125; 如果你直接这样编写一个子类Sub是会编译报错，而上面这里编译器生成的void method(Object value)方法就是桥方法。可以用反射验证一下： 1234567891011121314151617public static void main(String[] args) throws Exception &#123; Method[] declaredMethods = Sub.class.getDeclaredMethods(); List&lt;Method&gt; methods = new ArrayList&lt;&gt;(); for (Method method : declaredMethods) &#123; if (method.getName().equals(\"method\")) &#123; methods.add(method); &#125; &#125; for (Method method : methods) &#123; System.out.println(String.format(\"name=%s,paramTypes=%s,isBridge=%s\", method.getName(), Arrays.toString(method.getParameterTypes()), method.isBridge())); &#125;&#125;//输出结果name=method,paramTypes=[class java.lang.Integer],isBridge=falsename=method,paramTypes=[class java.lang.Object],isBridge=true 桥方法的定义比较模糊，因此这里只考虑它出现的情况，不做盲目的定义。不单只是子类实现带有泛型参数的父类会产生桥方法，还有一种比较常见的情况是在方法覆盖的时候指定一个更加&quot;严格的&quot;返回值类型的时候，也会产生桥方法，例如： 12345678910111213141516171819public Employee implements Cloneable&#123; public Employee clone() throws CloneNotSupportedException&#123; //... &#125;&#125;// 这里实际上，Employee覆盖了Object的clone()方法，因此实际上编译后Employee如下public Employee implements Cloneable&#123; public Employee clone() throws CloneNotSupportedException&#123; //... &#125; // 这个是桥方法 public Object clone() throws CloneNotSupportedException&#123; //... &#125; &#125; 这是因为： 编译的时候Java的方法签名是方法名称加上方法参数类型列表，也就是方法名和参数类型列表确定一个方法的签名(这样就可以很好理解方法重载，还有Java中的参数都是形参，所以参数名称没有实质意义，只有参数类型才是有意义的)。 Java虚拟机定义一个方法的签名是由方法名称、方法返回值类型和方法参数类型列表组成，所以JVM认为返回值类型不同，而方法名称和参数类型列表一致的方法是不相同的方法。 仔细看，其实两种情况都是由于继承才导致桥方法出现。 JDK中操作泛型的API 这里列举一下JDK中笔者所知的操作泛型的相关API(可以会有遗漏)，这些API主要和反射操作相关： java.lang.Class中的相关方法： 方法 功能 Type[] getGenericInterfaces() 返回类实例的接口的泛型类型 Type getGenericSuperclass() 返回类实例的父类的泛型类型 java.lang.reflect.Constructor中的相关方法： 方法 功能 Type[] getGenericExceptionTypes() 返回构造器的异常的泛型类型 Type[] getGenericParameterTypes() 返回构造器的方法参数的泛型类型 java.lang.reflect.Method中的相关方法： 方法 功能 Type[] getGenericExceptionTypes() 返回方法的异常的泛型类型 Type[] getGenericParameterTypes() 返回方法参数的泛型类型 Type getGenericReturnType() 返回方法返回值的泛型类型 java.lang.reflect.Field中的相关方法： 方法 功能 Type getGenericType() 返回属性的泛型类型 如果在使用上面的方法得到的返回值和期望的返回值不相同，请加深对泛型类型擦除的认识。 小结 参考资料： 个人认为，泛型其实是JDK迭代过程中妥协和兼容历史的产物，它是一种没有实现的泛型，当然，提供编译期类型安全这一点可以让开发者避免类型转换出现人为错误，也就是说：Java中的泛型使得程序或者代码的可读性和安全性提高，这是它的最大优势。 《Java核心技术卷I-基础知识》 维基百科-Generics in Java (本文完 e-20181204-c-3d r-20181205)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Reflection","slug":"Java/Reflection","permalink":"http://throwable.club/blog/categories/Java/Reflection/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Reflection","slug":"Reflection","permalink":"http://throwable.club/blog/tags/Reflection/"}]},{"title":"深入分析Java反射(二)-数组和枚举","slug":"java-reflection-array-enum","date":"2018-12-02T04:06:19.000Z","updated":"2018-12-04T15:42:12.368Z","comments":true,"path":"2018/12/02/java-reflection-array-enum/","link":"","permalink":"http://throwable.club/2018/12/02/java-reflection-array-enum/","excerpt":"","text":"深入分析Java反射(二)-数组和枚举 前提 Java反射的API在JavaSE1.7的时候已经基本完善，但是本文编写的时候使用的是Oracle JDK11，因为JDK11对于sun包下的源码也上传了，可以直接通过IDE查看对应的源码和进行Debug。 本文主要介绍反射中可能用到的两个比较特殊的类型，数组和枚举，分别对应java.lang.reflect.Array和java.lang.Enum，后者其实并不是反射类库包中的类，但是反射的基础类库里面有使用枚举类型的方法。 数组类型 数组是一种包含固定数量的相同类型组件(Component)的引用类型对象，也就是说数组的长度是不可变，它的每个元素都是相同类型的。创建数组实例需要定义数组的长度和组件的类型。数组是由Java虚拟机实现(这一点很重要，这就是为什么JDK类库中没有数组对应的类型的原因，array也不是Java中的保留关键字，操作数组的底层方法都是native方法)，数组类型只有继承自java.lang.Object的方法，数组的length方法实际上并不属于数组类型的一部分，数组的length方法其实最终调用的是java.lang.reflect.Array#getLength()，注意到这个方法是native方法。java.lang.reflect.Array是基于反射操作数组的核心类。 使用非反射方式创建数组实例的过程如下： 12345fully_qualified_class_name[] variable_name = &#123;val1，val2，val3，...&#125;;fully_qualified_class_name[] variable_name = new fully_qualified_class_name[$&#123;fix_length&#125;];例如：int[] arr = new int[10]; 使用反射方式就是使用java.lang.reflect.Array中的相关方法： 123456789Class&lt;?&gt; c = Class.forName(cName);Object o = Array.newInstance(c, n);for (int i = 0; i &lt; n; i++) &#123; String v = cVals[i]; Constructor ctor = c.getConstructor(String.class); Object val = ctor.newInstance(v); Array.set(o, i, val);&#125;Object[] oo = (Object[]) o; 下面列举一下java.lang.reflect.Array中的方法： 方法 功能 static Object newInstance(Class&lt;?&gt; componentType, int length) 指定组件类型和数组固定长度创建一维数组 static Object newInstance(Class&lt;?&gt; componentType, int… dimensions) 指定组件类型和多个固定长度创建多维数组，维度的最大值为255 static native int getLength(Object array) 获取数组长度 static native Object get(Object array, int index) 通过下标访问数组元素 static native void set(Object array, int index, Object value) 通过下标设置数组元素 这里省略了一部分对于Int、Boolean等原始类型的Setter和Getter方法。 在java.lang.Class和数组相关的方法： 方法 功能 native boolean isArray() 判断类型是否数组类型 Class&lt;?&gt; getComponentType() 如果是数组类型则返回其组件类型，否则返回null 这里举个例子加深下印象： 1234567891011121314151617181920212223242526272829public class ArrayCreationMain &#123; /** * 这个是我们创建的最终目标数组 */ private static String R = \"java.math.BigInteger[] bi = &#123;123,234,345&#125;\"; private static final String[] S = new String[]&#123;\"123\", \"234\", \"345\"&#125;; public static void main(String[] args) throws Exception &#123; Class&lt;BigInteger&gt; componentType = BigInteger.class; Object arrayObject = Array.newInstance(componentType, 3); for (int i = 0; i &lt; S.length; i++) &#123; String each = S[i]; Constructor&lt;BigInteger&gt; constructor = componentType.getConstructor(String.class); BigInteger value = constructor.newInstance(each); Array.set(arrayObject, i, value); &#125; Object[] result = (Object[]) arrayObject; System.out.println(String.format(\"%s[] = %s\", componentType, Arrays.toString(result))); int length = Array.getLength(arrayObject); System.out.println(\"Length = \" + length); for (int i = 0; i &lt; length; i++) &#123; System.out.println(String.format(\"index = %d,value = %s\", i, Array.get(arrayObject, i))); &#125; Class&lt;?&gt; arrayObjectClass = arrayObject.getClass(); System.out.println(\"Is array type:\" + arrayObjectClass.isArray()); System.out.println(\"Component type:\" + arrayObjectClass.getComponentType()); &#125;&#125; 运行后输出： 1234567class java.math.BigInteger[] = [123, 234, 345]Length = 3index = 0,value = 123index = 1,value = 234index = 2,value = 345Is array type:trueComponent type:class java.math.BigInteger 需要注意的是，java.lang.reflect.Array中的Setter和Getter方法如果越界操作数组元素，会抛出ArrayIndexOutOfBoundsException，通过Setter设置和数组初始化时候的组件类型不一致的元素会抛出IllegalArgumentException。 细议数组类型 前面说到了数组类型的一些基础特性，这里补充一些比较高级的使用方法。 创建特定元素类型的数组： 因为Java泛型擦除的问题，实际上我们使用Array#newInstance方法只能得到一个Object类型的结果实例，其实这个结果实例的类型就是ComponentType[]，这里只是返回了它的父类(Object)类型实例，因此我们可以直接强转，例如： 1String[] strArray = (String[]) Array.newInstance(String.class, 3); 获取数组类型： 在非反射方式下，我们可以通过数组实例.class通过class字面量直接获取数组类型，例如： 1Class stringArrayClass = String[].class; 反射条件下，可以通过Class.forName()获取数组类型，但是调用此方法的时候有个限制，类名必须使用JVM可以识别的签名形式，就是[L${ComponentType};，注意Class.forName()无法获取原始类型(如int、boolean)的类型，例如： 123456// 不能漏了左边的[L和右边的;Class stringArrayClass = Class.forName(\"[Ljava.lang.String;\");// 下面这样做会抛出ClassNotFoundExceptionClass intClass1 = Class.forName(\"I\");Class intClass2 = Class.forName(\"int\"); 获取数组元素(组件)类型： 目前获取数组组件类型只能通过数组类型实例去调用Class#getComponentType()。 枚举类型 枚举是一种语言结构(Language Construct)，用于定义可以使用一组固定的名值对表示的类型安全的枚举(原文是：An enum is a language construct that is used to define type-safe enumerations which can be used when a fixed set of named values is desired)。所有枚举都继承自java.lang.Enum。枚举可以包含一个或者多个枚举常量，这些枚举常量都是该枚举的实例。枚举的声明其实和一个普通的Class的声明相似，因为它可以包含字段、方法和构造函数之类的成员。 因为枚举就是普通的Java类，因此反射相关类库中并没有添加一个java.lang.reflect.Enum类型，反射中的API和枚举相关的有： boolean java.lang.Class#isEnum()：判断类型是否枚举类型。 T[] java.lang.Class#getEnumConstants()：获取类型中所有的枚举常量。 boolean java.lang.reflect.Field#isEnumConstant()：判断属性是否枚举类型。 如果实例中的成员属性为枚举，那么枚举的反射操作实际上就是java.lang.reflect.Field的相关操作。 举个例子： 12345678910111213141516171819202122232425public class EnumerationMain &#123; enum Color &#123; RED, BLACK, BLUE &#125; public static class ColorHolder &#123; private Color color = Color.BLACK; &#125; public static void main(String[] args) throws Exception &#123; Class&lt;Color&gt; colorClass = Color.class; System.out.println(\"Color class is enum:\" + colorClass.isEnum()); System.out.println(\"Color values:\" + Arrays.toString(colorClass.getEnumConstants())); ColorHolder colorHolder = new ColorHolder(); Class&lt;ColorHolder&gt; holderClass = ColorHolder.class; Field field = holderClass.getDeclaredField(\"color\"); field.setAccessible(true); System.out.println(\"Old color:\" + field.get(colorHolder)); field.set(colorHolder, Color.RED); System.out.println(\"New color:\" + field.get(colorHolder)); &#125;&#125; 运行后输出： 1234Color class is enum:trueColor values:[RED, BLACK, BLUE]Old color:BLACKNew color:RED 之前写过一篇文章《JDK中枚举的底层实现》，从枚举类的字节码翻译出类的代码逻辑，这里翻出来那个例子(手机操作系统枚举)说一下： 1234567891011121314151617181920212223242526272829public enum PhoneOsEnum &#123; /** * 安卓 */ ANDROID(1, \"android\"), /** * ios */ IOS(2, \"ios\"); private final Integer type; private final String typeName; PhoneOsEnum(Integer type, String typeName) &#123; this.type = type; this.typeName = typeName; &#125; public Integer getType() &#123; return type; &#125; public String getTypeName() &#123; return typeName; &#125;&#125; 这个是我们使用Java的关于枚举的语法创建出来的枚举类型，是编译前我们看到的Java类文件，实际上，编译完成之后，枚举类型会变成一个普通的Java类，它有以下特点： 1、枚举类型会变成一个普通Java类，这个Java类会继承java.lang.Enum，并且把自身类型作为泛型参数类型，构造函数中必定包含name(字符串类型String)、ordinal(整型int)参数，因为父类java.lang.Enum的构造要求传入这两个参数。 2、所有的枚举成员属性都变成static final修饰的在第1步中提到的Java类的实例，属性的名称和原来枚举的名字一致，实例在静态代码块中创建。 3、新增了一个static final修饰的第1步中提到的Java类的数组实例，名称为$VALUES，此数组在静态代码块中创建，基于此数组还新增了一个静态方法values()，此方法就是直接返回数组的克隆。 也就是上面提到的PhoneOsEnum在编译完成之后会变成： 123456789101112131415161718192021222324252627282930313233343536public final class PhoneOsEnumeration extends Enum&lt;PhoneOsEnumeration&gt; &#123; public PhoneOsEnumeration(String name, int ordinal, Integer type, String typeName) &#123; super(name, ordinal); this.type = type; this.typeName = typeName; &#125; public Integer getType() &#123; return type; &#125; public String getTypeName() &#123; return typeName; &#125; public static PhoneOsEnumeration[] values() &#123; return $VALUES.clone(); &#125; public static PhoneOsEnumeration valueOf(String name) &#123; return Enum.valueOf(PhoneOsEnumeration.class, name); &#125; private final Integer type; private final String typeName; public static final PhoneOsEnumeration ANDROID; public static final PhoneOsEnumeration IOS; private static final PhoneOsEnumeration[] $VALUES; static &#123; ANDROID = new PhoneOsEnumeration(\"ANDROID\", 0, 1, \"android\"); IOS = new PhoneOsEnumeration(\"IOS\", 1, 2, \"ios\"); $VALUES = new PhoneOsEnumeration[]&#123;ANDROID, IOS&#125;; &#125;&#125; 实际上，如果你直接编写一个Java类去继承java.lang.Enum会编译报错，也就是Java希望把枚举的行为和特性交由自身控制而不是开发者去控制，从编译层面控制枚举的类型安全。如果细心一点会发现，枚举中valueOf(String name)也是由java.lang.Class提供的，追溯到最里层是T[] java.lang.Class#getEnumConstants()方法，其实有可能在构造$VALUES属性的时候也是用到这个方法，这一点就没有深究下去，编译层面的东西可能会牵涉很多方面的知识，还没有到达那种水平。 小结 数组和枚举在Java中的使用频率也是比较高的，特别是算法或者框架中，本文尝试从反射角度介绍这两个类型的使用方式，掌握它们对数组或者枚举的使用有很大的帮助。 (本文完 e-2018122-c-1-d r-2018124-c-1-d)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Reflection","slug":"Java/Reflection","permalink":"http://throwable.club/blog/categories/Java/Reflection/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Reflection","slug":"Reflection","permalink":"http://throwable.club/blog/tags/Reflection/"}]},{"title":"深入分析Java反射(一)-核心类库和方法","slug":"java-reflection-lib","date":"2018-12-02T04:00:05.000Z","updated":"2018-12-02T04:24:09.929Z","comments":true,"path":"2018/12/02/java-reflection-lib/","link":"","permalink":"http://throwable.club/2018/12/02/java-reflection-lib/","excerpt":"","text":"深入分析Java反射(一)-核心类库和方法 前提 Java反射的API在JavaSE1.7的时候已经基本完善，但是本文编写的时候使用的是Oracle JDK11，因为JDK11对于sun包下的源码也上传了，可以直接通过IDE查看对应的源码和进行Debug。 本文主要介绍反射的基本概念以及核心类Class、Constructor、Method、Field、Parameter的常用方法。 本文极长，请准备一个使自己舒服的姿势阅读。 什么是反射 反射(Reflection)是一种可以在运行时检查和动态调用类、构造、方法、属性等等的编程语言的能力，甚至可以不需要在编译期感知类的名称、方法的名称等等。Oracle关于Java反射的官方教程中指出反射是由应用程序使用，用于检查或修改在Java虚拟机中运行的应用程序的运行时行为，这是一个相对高级的功能，需要由掌握Java语言基础知识的开发者使用。 反射的优点有很多，前面提到可以检查或修改应用程序的运行时行为、抑制修饰符限制直接访问私有属性等等，这里主要列举一下它的缺点： 性能开销：由于反射涉及动态解析的类型，因此无法执行某些Java虚拟机优化。因此，反射操作的性能低于非反射操作，应避免在性能敏感应用程序中频繁调用反射操作代码片段。 安全限制：反射需要运行时权限，不能在安全管理器(security manager)下进行反射操作。 代码可移植性：反射代码打破了抽象，反射的类库有可能随着平台(JDK)升级发生改变，反射代码中允许执行非反射代码的逻辑例如允许访问私有字段，这些问题都有可能影响到代码的可移植性。 JDK中对和反射相关的类库集中在java.lang.reflect包和java.lang包中，java.lang.reflect包和java.lang包是开发者可以直接使用的，部分java.lang.reflect包中接口的实现类存放在sun.reflect包中，一般情况下sun包下的类库有可能跟随平台升级发生改变，一般尽量少用，否则有可能因为JDK升级导致原来的代码无法正常运行。还有部分反射相关的类库存放在jdk.internal.reflect包中，这个包是JDK内部使用的包，一般也不建议滥用其中的类库。可以理解为java.lang.reflect包和java.lang包中的类库就是面向开发者的类库。 图解反射核心类的体系 java.lang.reflect包反射核心类有核心类Class、Constructor、Method、Field、Parameter，它们的基础体系如下： java.lang.Class类继承体系: java.lang.reflect.Constructor类继承体系: java.lang.reflect.Method类继承体系: java.lang.reflect.Field类继承体系: java.lang.reflect.Parameter类继承体系: 由它们的类继承图可以看出： Class、Constructor、Method、Field、Parameter共有的父接口是AnnotatedElement。 Constructor、Method、Field共有的父类是AnnotatedElement、AccessibleObject和Member。 Constructor、Method共有的父类是AnnotatedElement、AccessibleObject、Member、GenericDeclaration和Executable。 下面会先简单分析AnnotatedElement、AccessibleObject、Member、GenericDeclaration、Executable几个类提供的功能，然后重点分析Class、Constructor、Method、Field、Parameter的常用方法。 这里先说一个规律，在Class中，getXXX()方法和getDeclearedXXX()方法有所区别。注解类型Annotation的操作方法例外，因为基于注解的修饰符必定是public的： getDeclaredMethod(s)：返回类或接口声明的所有方法，包括公共、保护、默认(包)访问和私有方法，但不包括继承的方法。对于获取Method对象，Method[] methods = clazz.getDeclaredMethods();返回的是clazz本类所有修饰符(public、default、private、protected)的方法数组，但是不包含继承而来的方法。 getMethod(s):返回某个类的所有公用(public)方法包括其继承类的公用方法，当然也包括它所实现接口的方法。对于获取Method对象，Method[] methods = clazz.getMethods();表示返回clazz的父类、父类接口、本类、本类接口中的全部修饰符为public的方法数组。 getDeclaredField(s)和getField(s)、getDeclaredConstructor(s)和getConstructor(s)同上。 getDeclaredAnnotation(s)：返回直接存在于此元素上的所有注解，此方法将忽略继承的注解，准确来说就是忽略@Inherited注解的作用。 getAnnotation(s)：返回此元素上存在的所有注解，包括继承的所有注解。 如果想获取一个类的所有修饰符的方法，包括所有父类中的方法，那么建议递归调用getDeclaredMethods()(所谓递归调用就是一直追溯目标类的父类递归调用getDeclaredMethods()方法直到父类为Object类型，这个思路可以参考Spring框架中的相关工具类)。获取一个类的所有Field、Constructor也可以类似操作，可以参考或者直接使用Spring中的工具类ReflectionUtils的相关方法。@Inherited元注解是一个标记注解，@Inherited阐述了某个被标注的Annotation类型是可以被继承的，详细的在分析AnnotatedElement的时候再展开。 Type接口 java.lang.reflect.Type接口是Java中所有类型的共同父类，这些类型包括原始类型、泛型类型、数组类型、类型变量和基本类型，接口定义如下： 123456public interface Type &#123; default String getTypeName() &#123; return toString(); &#125;&#125; AnnotatedElement接口 AnnotatedElement是一个接口，它定义的方法主要和注解操作相关，例如用于判断注解的存在性和获取注解等等。 方法 功能 boolean isAnnotationPresent(Class&lt;? extends Annotation&gt; annotationClass) 判断指定的注解类型在当前的实例上是否存在 &lt;T extends Annotation&gt; T getAnnotation(Class&lt;T&gt; annotationClass) 获取当前实例上指定注解类型的注解实例，不存在时返回null Annotation[] getAnnotations() 获取当前实例上所有注解实例，包括继承获得的注解，不存在则返回长度为0的数组 &lt;T extends Annotation&gt; T getDeclaredAnnotation(Class&lt;T&gt; annotationClass) 获取当前实例上指定注解类型的注解实例，不包括继承获得的注解，不存在则返回长度为0的数组 &lt;T extends Annotation&gt; T[] getDeclaredAnnotations(Class&lt;T&gt; annotationClass) 获取当前实例上所有的注解实例，不包括继承获得的注解，不存在则返回长度为0的数组 &lt;T extends Annotation&gt; T[] getDeclaredAnnotationsByType(Class&lt;T&gt; annotationClass) 在不使用@Repeatable的时候，功能和getDeclaredAnnotations方法一致，如果使用了@Repeatable，则合并解析@Repeatable后的结果 &lt;T extends Annotation&gt; T[] getAnnotationsByType(Class&lt;T&gt; annotationClass) 如果指定annotationClass注解类型可继承(使用了@Inherited)，那么递归调用getDeclaredAnnotationsByType 举个简单例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class Main &#123; public static void main(String[] args) &#123; Class&lt;?&gt; clazz = Sub.class; System.out.println(\"-----getAnnotations-----\"); Annotation[] annotations = clazz.getAnnotations(); for (Annotation annotation : annotations) &#123; System.out.println(annotation.toString()); &#125; System.out.println(\"-----getDeclaredAnnotation--&gt;SupperAnnotation-----\"); SupperAnnotation declaredSupperAnnotation = clazz.getDeclaredAnnotation(SupperAnnotation.class); System.out.println(declaredSupperAnnotation); System.out.println(\"-----getAnnotation--&gt;SupperAnnotation-----\"); SupperAnnotation supperAnnotation = clazz.getAnnotation(SupperAnnotation.class); System.out.println(supperAnnotation); System.out.println(\"-----getDeclaredAnnotation--&gt;SubAnnotation-----\"); SubAnnotation declaredSubAnnotation = clazz.getDeclaredAnnotation(SubAnnotation.class); System.out.println(declaredSubAnnotation); System.out.println(\"-----getDeclaredAnnotationsByType--&gt;SubAnnotation-----\"); SubAnnotation[] declaredSubAnnotationsByType = clazz.getDeclaredAnnotationsByType(SubAnnotation.class); for (SubAnnotation subAnnotation : declaredSubAnnotationsByType) &#123; System.out.println(subAnnotation); &#125; System.out.println(\"-----getDeclaredAnnotationsByType--&gt;SupperAnnotation-----\"); SupperAnnotation[] declaredSupperAnnotationsByType = clazz.getDeclaredAnnotationsByType(SupperAnnotation.class); for (SupperAnnotation supperAnnotation1 : declaredSupperAnnotationsByType) &#123; System.out.println(supperAnnotation1); &#125; System.out.println(\"-----getAnnotationsByType--&gt;SupperAnnotation-----\"); SupperAnnotation[] supperAnnotationsByType = clazz.getAnnotationsByType(SupperAnnotation.class); for (SupperAnnotation supperAnnotation2 : supperAnnotationsByType) &#123; System.out.println(supperAnnotation2); &#125; &#125; @SupperAnnotation private static class Supper &#123; &#125; @SubAnnotation private static class Sub extends Supper &#123; &#125; @Retention(RetentionPolicy.RUNTIME) @Inherited @Documented @Target(ElementType.TYPE) private @interface SupperAnnotation &#123; String value() default \"SupperAnnotation\"; &#125; @Retention(RetentionPolicy.RUNTIME) @Documented @Target(ElementType.TYPE) private @interface SubAnnotation &#123; String value() default \"SubAnnotation\"; &#125;&#125; 运行后输出： 1234567891011121314-----getAnnotations-----@org.throwable.inherited.Main$SupperAnnotation(value=SupperAnnotation)@org.throwable.inherited.Main$SubAnnotation(value=SubAnnotation)-----getDeclaredAnnotation--&gt;SupperAnnotation-----null-----getAnnotation--&gt;SupperAnnotation-----@org.throwable.inherited.Main$SupperAnnotation(value=SupperAnnotation)-----getDeclaredAnnotation--&gt;SubAnnotation-----@org.throwable.inherited.Main$SubAnnotation(value=SubAnnotation)-----getDeclaredAnnotationsByType--&gt;SubAnnotation-----@org.throwable.inherited.Main$SubAnnotation(value=SubAnnotation)-----getDeclaredAnnotationsByType--&gt;SupperAnnotation----------getAnnotationsByType--&gt;SupperAnnotation-----@org.throwable.inherited.Main$SupperAnnotation(value=SupperAnnotation) 可以尝试注释掉@Inherited再运行一次，对比一下结果。如果注释掉@Inherited，从Sub这个类永远无法获取到它的父类Supper中的@SupperAnnotation。Class、Constructor、Method、Field、Parameter都实现了AnnotatedElement接口，所以它们都具备操作注解的功能。 Member接口 Member接口注解提供成员属性的一些描述，主要提供的方法如下： 方法 功能 Class&lt;?&gt; getDeclaringClass() 获取声明的Class对象，也就是获取当前Member实例的来源Class对象 String getName() 获取实例的名称，对于Constructor返回全类名，对于Method返回方法名，对于Field返回属性名 int getModifiers() 获取实例的修饰符 boolean isSynthetic() 是否合成的 这些方法里面除了isSynthetic()都比较好理解。synthetic总的来说，是由编译器引入的字段、方法、类或其他结构，主要用于JVM内部使用，为了遵循某些规范而作的一些小技巧从而绕过这些规范，有点作弊的感觉，只不过是由编译器光明正大为之，一般开发者是没有权限的(但事实上有时候还是能被利用到的)。下面这个例子参考自synthetic Java合成类型: 123456789101112131415161718192021222324252627public class Main &#123; private static class Inner &#123; &#125; static void checkSynthetic (String name) &#123; try &#123; System.out.println (name + \" : \" + Class.forName (name).isSynthetic ()); &#125; catch (ClassNotFoundException exc) &#123; exc.printStackTrace (System.out); &#125; &#125; public static void main(String[] args) throws Exception &#123; new Inner (); checkSynthetic (\"com.fcc.test.Main\"); checkSynthetic (\"com.fcc.test.Main$Inner\"); checkSynthetic (\"com.fcc.test.Main$1\"); &#125;&#125;//打印结果：com.fcc.test.Main : falsecom.fcc.test.Main$Inner : falsecom.fcc.test.Main$1 : true//编译结果，生成三个class文件: Main.class/Main$Inner/Main$1.class// $FF: synthetic classclass Main$1 &#123;&#125; Inner这个内部类是私有的，私有内部类。拥有内部类的类编译后内外部类两者没有关系，那么私有内部类编译后默认是没有对外构造器的(如果以上代码中在Inner手动给一个public的构造器，Main$1是不会出现的)，但是我们又知道，外部类是可以引用内部类的，那么编译后，又是两个毫无关系的类，一个类没对外构造器，但另一个类确实是有对这个类的实例对象权限(这里就是重点，内部类哪怕没有public构造器，外部类都有实例化内部类对象的权限)的，这种情况下编译器就会生成一个合成类，也就是Main$1，一个什么也没有的空类(是的，什么也没有，连构造器都没有)。但到这里，仍然不明白其实现原理是怎么样的，原先以为合成类是那个内部类的副本，外部类访问内部类，在编译器认为只是和合成类交互，只是合成类只有外部类有权限访问，但是事实上，不管内部类怎么变化，合成类只是一个空的类，有点类似标记作用(真正作用却是不得而知)。 AccessibleObject类 AccessibleObject是一个普通Java类，实现了AnnotatedElement接口，但是对应AnnotatedElement的非默认方法的实现都是直接抛异常，也就是AnnotatedElement的接口方法必须由AccessibleObject的子类去实现，个人认为AccessibleObject应该设计为抽象类。AccessibleObject在JDK1.1的时候已经存在，在JDK9的时候被改进过，添加了一些新的方法，下面列举一下常用的方法： 方法 功能 void setAccessible(boolean flag) 设置实例是否可以访问，如果设置为true，可以抑制修饰符，直接进行访问 boolean isAccessible() 返回实例是否可以访问，实际上这个值并不准确，它只有在setAccessible被调用的时候才会更新 boolean trySetAccessible() 功能类似于setAccessible(boolean flag)，返回值决定是否抑制修饰符成功 static void setAccessible(AccessibleObject[] array, boolean flag) setAccessible(boolean flag)的批量操作方法 一般而言，我们需要通过getModifiers()方法判断修饰符是否public，如果是非public，则需要调用setAccessible(true)进行修饰符抑制，否则会因为无权限访问会抛出异常。 GenericDeclaration接口 GenericDeclaration接口继承自AnnotatedElement，它的源码如下： 1234public interface GenericDeclaration extends AnnotatedElement &#123; public TypeVariable&lt;?&gt;[] getTypeParameters();&#125; 新增了一个方法getTypeParameters()用于返回类型变量TypeVariable数组，这里的TypeVariable是类型变量，它的定义如下： 12345678910public interface TypeVariable&lt;D extends GenericDeclaration&gt; extends Type, AnnotatedElement &#123; //获得泛型的类型(Type)上限数组，若未明确声明上边界则默认为Object Type[] getBounds(); //获取声明该类型变量实体(即获得类、方法或构造器名) D getGenericDeclaration(); //获得泛型参数的字面量名称，即K、V、E之类名称 String getName(); //获得泛型的注解类型(AnnotatedType)上限数组，若未明确声明上则为长度为0的空数组 AnnotatedType[] getAnnotatedBounds();&#125; 后面的文章介绍泛型的时候再展开。 Executable类 Executable是一个抽象类，它继承自AccessibleObject，实现了Member和GenericDeclaration接口。Executable的实现类是Method和Constructor，它的主要功能是从Method和Constructor抽取出两者可以共用的一些方法例如注解的操作，参数的操作等等，这里不详细展开。 Modifier Modifier主要提供一系列的静态方法，用于判断基于int类型的修饰符参数的具体类型，这个修饰符参数来源于Class、Constructor、Method、Field、Parameter的getModifiers()方法。下面介绍一下Modifier的主要方法： 方法 功能 static boolean isAbstract(int mod) 整数modifier参数是否包括abstract修饰符 static boolean isFinal(int mod) 整数modifier参数是否包括final修饰符 static boolean isInterface(int mod) 整数modifier参数是否包括interface修饰符 static boolean isNative(int mod) 整数modifier参数是否包括native修饰符 static boolean isPrivate(int mod) 整数modifier参数是否包括private修饰符 static boolean isProtected(int mod) 整数modifier参数是否包括protected修饰符 static boolean isPublic(int mod) 整数modifier参数是否包括public修饰符 static boolean isStatic(int mod) 整数modifier参数是否包括static修饰符 static boolean isStrict(int mod) 整数modifier参数是否包括strictfp修饰符 static boolean isSynchronized(int mod) 整数modifier参数是否包括synchronized修饰符 static boolean isTransient(int mod) 整数modifier参数是否包括transient修饰符 static boolean isVolatile(int mod) 整数modifier参数是否包括volatile修饰符 static boolean toString(int mod) 返回描述指定修饰符中的访问修饰符标志的字符串 Class类 Class实现了Serializable、GenericDeclaration、Type、AnnotatedElement接口，它提供了类型判断、类型实例化、获取方法列表、获取字段列表、获取父类泛型类型等方法。下面主要介绍一下它的主要方法： 方法 功能 Class&lt;?&gt; forName(String className) 传入全类名创建Class实例 T newInstance() 通过当前的Class实例进行实例化对象，返回的就是新建的对象 int getModifiers() native方法，返回当前Class的修饰符 String getName() 返回类名称，虚拟机中类名表示 String getCanonicalName() 返回类名称，便于理解的类名表示 String getSimpleName() 返回类名称，源代码中给出的底层类的简单名称 Package getPackage() 返回类的包属性 String getPackageName() 返回类的包路径名称 String toGenericString() 返回描述此Class的字符串，其中包括类型参数的字面量 TypeVariable&lt;Class&lt;T&gt;&gt;[] getTypeParameters() 获取类定义泛型的类型变量 Class&lt;?&gt;[] getClasses() 获取所有的修饰符为public的成员Class，包括父类 Class&lt;?&gt;[] getDeclaredClasses() 获取本类所有修饰符的成员Class，不包括父类 Constructor&lt;?&gt;[] getConstructors() 获取所有的修饰符为public的构造器，包括父类 Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 获取参数类型匹配的修饰符为public的构造器，包括父类 Constructor&lt;?&gt;[] getDeclaredConstructors() 获取本类所有修饰符的构造器，不包括父类 Constructor&lt;T&gt;[] getDeclaredConstructor(Class&lt;?&gt;... parameterTypes) 获取本类参数类型匹配的所有修饰符的构造器，不包括父类 Method[] getMethods() 获取本类所有的修饰符为public的方法列表，包括父类 Method[] getDeclaredMethods() 获取本类所有修饰符的方法列表，不包括父类 Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 通过指定方法名和参数类型获取本类修饰符为public的方法，包括父类 Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) 通过指定方法名和参数类型获取本类不限修饰符的方法，不包括父类 Field[] getFields() 获取本类所有的修饰符为public的属性列表，包括父类 Field[] getDeclaredFields() 获取本类所有修饰符的属性列表，不包括父类 Field getField(String name) 通过指定属性名名获取本类修饰符为public的属性，包括父类 Field getDeclaredField(String name) 通过指定属性名获取本类不限修饰符的属性，不包括父类 Class&lt;?&gt;[] getInterfaces() 获取类实现的所有接口的Class数组 Type[] getGenericInterfaces() 获取类实现的所有泛型参数接口的Type数组 Class&lt;? super T&gt; getSuperclass() 获取当前类的父类的Class，如果当前类是Object、接口、基本数据类型(primitive)或者void，则返回null Type getGenericSuperclass() 获取当前类的泛型参数父类的Type，如果当前类是Object、接口、基本数据类型(primitive)或者void，则返回null native boolean isInstance(Object obj) 判断传入的object是否当前类的实例 native boolean isAssignableFrom(Class&lt;?&gt; cls) 判断传入的Class对象是否和当前类相同，或者是否当前类的超类或超接口 native boolean isInterface() 判断当前类是否接口 native boolean isArray() 判断当前类是否数组 native boolean isPrimitive() 判断当前类是否基本数据类型 boolean isAnnotation() 判断当前类是否注解类型 boolean isSynthetic() 判断当前类是否复合 native Class&lt;?&gt; getComponentType() 如果当前类是数组，返回数组元素的类型 Class&lt;?&gt; getEnclosingClass() 返回一个类，当前类(一般是成员类)在这个类(封闭类，相对于内部类的外部类或者说外面一层)中定义 Constructor&lt;?&gt; getEnclosingConstructor() 返回构造器，当前类是在这个构造函数中定义 Method getEnclosingMethod() 返回方法，当前类是在这个方法中定义 Module getModule() 返回模块，JDK9新增方法 getName()、getCanonicalName()和getSimpleName()都是用于获取类的名称，但是有所区别，下面举个列子说明一下： 123456789101112131415161718192021public class Main &#123; public static void main(String[] args) &#123; Supper&lt;String, List&lt;Integer&gt;&gt; supper = new Supper&lt;&gt;(); Class&lt;?&gt; clazz = supper.getClass(); System.out.println(\"name-&gt;\" + clazz.getName()); System.out.println(\"canonicalName-&gt;\" + clazz.getCanonicalName()); System.out.println(\"simpleName-&gt;\" + clazz.getSimpleName()); System.out.println(\"======================================\"); String[][] strings = new String[1][1]; System.out.println(\"name-&gt;\" + strings.getClass().getName()); System.out.println(\"canonicalName-&gt;\" + strings.getClass().getCanonicalName()); System.out.println(\"simpleName-&gt;\" + strings.getClass().getSimpleName()); &#125; private static class Supper&lt;K, V&gt; &#123; private K key; private V value; //省略setter和getter方法 &#125;&#125; 运行后输出结果： 1234567name-&gt;club.throwable.reflect.Main$SuppercanonicalName-&gt;club.throwable.reflect.Main.SuppersimpleName-&gt;Supper======================================name-&gt;[[Ljava.lang.String;canonicalName-&gt;java.lang.String[][]simpleName-&gt;String[][] 简单理解为： getName()：用于获取类在Java虚拟机中的类名表示。 getCanonicalName()：用于获取全类名，包括包路径，包路径以点号分隔。 getSimpleName()：用于获取类名，不包括包路径。 下面再举一个例子通过类名进行实例化对象和操作，从例子可以看到，实例化对象可以不依赖new关键字，这就是反射的强大之处： 123456789101112131415public class Main3 &#123; public static void main(String[] args) throws Exception &#123; Class&lt;?&gt; clazz = Class.forName(\"club.throwable.reflect.Main3$Supper\"); Supper supper = (Supper) clazz.newInstance(); System.out.println(supper.sayHello(\"throwable\")); &#125; public static class Supper &#123; public String sayHello(String name) &#123; return String.format(\"%s say hello!\", name); &#125; &#125;&#125; 这里需要注意一点，Class.forName方法只能使用在修饰符为public的类上，如果使用在其他修饰符类上会抛出异常(IllegalAccessException)，那么，如果上面的Supper类的修饰符修改为private，怎么样才能正常实例化它？这个问题将会在下面分析Constructor的时候得到解决。另外，这里的Class.forName方法不是获取Class实例的唯一方式，总结有以下三种方式： 1、使用类的字面量&quot;类名.class&quot;。类字面常量使得创建Class对象的引用时不会自动地初始化该对象，而是按照之前提到的加载，链接，初始化三个步骤，这三个步骤是个懒加载的过程，不使用的时候就不加载。 2、使用Class.forName(全类名);方法。 3、使用实例的getClass()方法。getClass()是所有的对象都能够使用的方法，因为getClass()方法是Object类的方法，所有的类都继承了Object，因此所有类的对象也都具有getClass()方法。 一般来说，使用&quot;类名.class&quot;，这样做即简单安全又比较高效。因为在编译时就会受到检查，因此不需要置于try语句块中，并且它根除了对forName()方法的调用(forName()方法是一个耗时比较多的方法)，所以相对比较高效。 最后，分析一下这几个比较难懂的方法getEnclosingClass()、getEnclosingConstructor()、getEnclosingMethod()： getEnclosingClass()：返回一个类，当前类(一般是成员类)在这个类(一般叫封闭类，相对于内部类的外部类或者说外面一层)中定义。 getEnclosingConstructor()：返回构造器，当前类是在这个构造函数中定义。 getEnclosingClass()：返回方法，当前类是在这个方法中定义。 我们在新建一个类的时候，这个类可以使另一个类中定义的成员类、构造方法中定义的内部类、方法中定义的内部类。可以通过当前的类反向获取定义当前的类的类、构造或者方法，这三种情况对应上面三个方法。举个例子： getEnclosingClass()方法使用例子： 123456789101112131415public class Main5 &#123; public static void main(String[] args) throws Exception&#123; Class&lt;Outter.Inner&gt; clazz = Outter.Inner.class; Class&lt;?&gt; enclosingClass = clazz.getEnclosingClass(); System.out.println(enclosingClass.getName()); &#125; // Inner类是Outter类的成员类 public static class Outter &#123; public static class Inner &#123; &#125; &#125;&#125; 输出结果： 1org.throwable.inherited.Main5$Outter 在这里，Inner就是当前定义的类，它是Outter的静态成员类，或者说Outter是Inner的封闭类，通过Inner的Class的getEnclosingClass()方法获取到的就是Outter的Class实例。 getEnclosingConstructor()方法使用例子： 1234567891011121314151617181920212223public class Main6 &#123; public static void main(String[] args) throws Exception &#123; Outter outter = new Outter(); &#125; public static class Outter &#123; //Outter的无参数构造器 public Outter() &#123; //构造中定义的内部类 class Inner &#123; &#125; Class&lt;Inner&gt; innerClass = Inner.class; Class&lt;?&gt; enclosingClass = innerClass.getEnclosingClass(); System.out.println(enclosingClass.getName()); Constructor&lt;?&gt; enclosingConstructor = innerClass.getEnclosingConstructor(); System.out.println(enclosingConstructor.getName()); &#125; &#125;&#125; 输出结果： 12org.throwable.inherited.Main6$Outterorg.throwable.inherited.Main6$Outter 在这里，Inner是Outter的无参数构造里面定义的构造内部类，它也只能在Outter的无参数构造里面使用，通过Inner的Class的getEnclosingConstructor()方法获取到的就是Outter的无参数构造。 getEnclosingMethod()方法使用例子： 1234567891011121314151617181920212223public class Main7 &#123; public static void main(String[] args) throws Exception &#123; Outter outter = new Outter(); outter.print(); &#125; public static class Outter &#123; public void print()&#123; //方法print中定义的内部类 class Inner &#123; &#125; Class&lt;Inner&gt; innerClass = Inner.class; Class&lt;?&gt; enclosingClass = innerClass.getEnclosingClass(); System.out.println(enclosingClass.getName()); Method enclosingMethod = innerClass.getEnclosingMethod(); System.out.println(enclosingMethod.getName()); &#125; &#125;&#125; 输出结果： 12org.throwable.inherited.Main7$Outterprint 在这里，Inner是Outter的print方法里面定义的方法内部类，它也只能在Outter的print方法里面使用，通过Inner的Class的getEnclosingMethod()方法获取到的就是Outter的print方法。这种方式可能不常用，但是可以在某版本的spring-jdbc的JdbcTemplate的源码中看到类似的类定义逻辑。 前面介绍过getXXX()方法和getDeclearedXXX()方法有所区别，这里做个对比表格： Class中获取Field列表的方法： Class中的API 获取所有的Field 包括继承的Field 包括私有的Field getDeclaredField() N N Y getField() N Y N getDeclaredFields() Y N Y getFields() Y Y N Class中获取Method列表的方法： Class中的API 获取所有的Method 包括继承的Method 包括私有的Method getDeclaredMethod() N N Y getMethod() N Y N getDeclaredMethods() Y N Y getMethods() Y Y N Class中获取Constructor列表的方法： Class中的API 获取所有的Constructor 包括私有的Constructor getDeclaredConstructor() N Y getConstructor() N N getDeclaredConstructors() Y Y getConstructors() Y N Constructor类 Constructor用于描述一个类的构造函数。它除了能获取到构造的注解信息、参数的注解信息、参数的信息之外，还有一个很重要的作用是可以抑制修饰符进行实例化，而Class的实例化方法newInstance只能实例化修饰符为public的类。Constructor的主要方法如下： 方法 功能 Class&lt;T&gt; getDeclaringClass() 获取当前构造的定义类 String getName() 获取当前构造的名称 int getModifiers() 获取当前构造的修饰符 String toGenericString() 返回描述此构造的字符串，其中包括类型参数的字面量 TypeVariable&lt;Constructor&lt;T&gt;&gt;[] getTypeParameters() 获取类定义泛型参数的类型变量 Class&lt;?&gt;[] getExceptionTypes() 获取当前构造异常类型数组，如果不存在则返回一个长度为0的数组 Type[] getGenericExceptionTypes() 获取当前构造异常类型数组的泛型类型，如果不存在则返回一个长度为0的数组 Type[] getGenericParameterTypes() 获取当前构造参数的泛型类型，如果不存在则返回一个长度为0的数组 Annotation[][] getParameterAnnotations() 获取当前构造参数的注解数组，这里是二维数组的原因是一个参数可以使用多个注解 int getParameterCount() 获取当前构造参数的数量 Class&lt;?&gt;[] getParameterTypes() 获取当前构造参数的Class数组 boolean isSynthetic() 当前构造是否复合的 boolean isVarArgs() 当前构造是否使用不定参数 T newInstance(Object…initargs) 使用此构造对象表示的构造方法来创建该构造方法的声明类的新实例，并用指定的初始化参数初始化该实例 Parameter[] getParameters() 返回此构造对象的参数Parameter数组，如果没有则返回一个长度为0的数组 void setAccessible(boolean flag) 抑制构造访问修饰符的权限判断 下面我们举个例子说明使用构造实例化对象可以抑制修饰符访问权限控制的问题： 1234567891011121314151617public class Main8 &#123; public static void main(String[] args) throws Exception&#123; Class&lt;Supper&gt; supperClass = Supper.class; Constructor&lt;Supper&gt; constructor = supperClass.getDeclaredConstructor(); constructor.setAccessible(Boolean.TRUE); Supper supper = constructor.newInstance(); supper.sayHello(\"throwable\"); &#125; private static class Supper &#123; public void sayHello(String name) &#123; System.out.println(String.format(\"%s say hello!\", name)); &#125; &#125;&#125; 输出结果： 1throwable say hello! 这就是为什么一些IOC容器的实现框架中实例化类的时候优先依赖于无参数构造的原因，如果使用Class#newInstance方法，上面的代码调用逻辑会抛异常。 Method类 Method用于描述一个类的方法。它除了能获取方法的注解信息，还能获取方法参数、返回值的注解信息和其他信息。Method常用的方法如下： 方法 功能 Class&lt;?&gt; getDeclaringClass() 获取方法对应的Class Object getDefaultValue() 获取方法上的注解成员的默认值 Class&lt;?&gt;[] getExceptionTypes() 获取方法上的异常类型数组，如果没有则返回一个长度为0的数组 Type[] getGenericExceptionTypes() 获取方法上的异常泛型类型Type数组，如果没有则返回一个长度为0的数组 Parameter[] getParameters() 返回方法的参数Parameter数组，如果没有则返回一个长度为0的数组 int getParameterCount() 返回方法的参数的数量 Class&lt;?&gt;[] getParameterTypes() 返回方法的参数的类型Class数组，如果没有则返回一个长度为0的数组 Annotation[][] getParameterAnnotations() 返回方法的注解Annotation数组，这里使用二维数组的原因是一个参数可以使用多个注解 TypeVariable&lt;Method&gt;[] getTypeParameters() 返回方法的泛型参数的类型变量 Type[] getGenericParameterTypes() 返回方法参数的泛型类型Type数组 Class&lt;?&gt; getReturnType() 返回方法的返回值的类型Class Type getGenericReturnType() 返回方法的返回值的泛型类型Type AnnotatedType getAnnotatedReturnType() 获取方法返回值的注解类型实例AnnotatedType boolean isBridge() 是否桥方法 boolean isDefault() 是否接口的默认方法 boolean isSynthetic() 是否复合的 boolean isVarArgs() 是否使用了不定参数 String toGenericString() 返回方法带有泛型字面量的描述字符串 String getName() 返回方法的名称 int getModifiers() 返回方法的修饰符 Object invoke(Object obj, Object… args) 对带有指定参数的指定对象调用由此方法对象表示的底层方法 void setAccessible(boolean flag) 抑制方法访问修饰符的权限判断 关注其中的invoke(Object obj, Object... args)方法，第一个是要调用这个方法的对象，剩下的方法的参数，返回值就是该方法执行的返回值。如果方法的修饰符不是public，在调用invoke方法前需要调用setAccessible(boolean flag)抑制方法访问修饰符的权限判断，否则会抛出异常。举个例子如下： 1234567891011121314151617public class Main10 &#123; public static void main(String[] args) throws Exception&#123; Class&lt;Supper&gt; supperClass = Supper.class; Supper supper = supperClass.newInstance(); Method sayHello = supperClass.getDeclaredMethod(\"sayHello\", String.class); sayHello.setAccessible(Boolean.TRUE); sayHello.invoke(supper,\"throwable\"); &#125; public static class Supper&#123; private void sayHello(String name)&#123; System.out.println(String.format(\"%s say hello!\", name)); &#125; &#125;&#125; 输出结果： 1throwable say hello! Field类 Field类用来描述一个类里面的属性或者叫成员变量，通过Field可以获取属性的注解信息、泛型信息，获取和设置属性的值等等。Field的主要方法如下： 方法 功能 String getName() 返回该属性的名称 int getModifiers() 返回该属性的修饰符 Class&lt;?&gt; getType() 返回该属性的类型Class Class&lt;?&gt; getParameterizedType() 返回该属性的泛型类型Type boolean isSynthetic() 该属性是否复合的 boolean isEnumConstant() 该属性是否枚举类型的元素 Object get(Object obj) 通过对象实例获取该属性的值 void set(Object obj,Object value) 通过对象实例设置该属性的值 void setAccessible(boolean flag) 抑制属性访问修饰符的权限判断 这里忽略了注解以及Field实现了FieldAccessor接口中的getBoolean、setBoolean等方法。下面举个例子说明一下Field的用法： 1234567891011121314151617181920212223242526public class Main12 &#123; public static void main(String[] args) throws Exception &#123; Class&lt;Supper&gt; supperClass = Supper.class; Supper supper = supperClass.newInstance(); Method sayHello = supperClass.getDeclaredMethod(\"sayHello\"); sayHello.setAccessible(Boolean.TRUE); Field name = supperClass.getDeclaredField(\"name\"); name.setAccessible(Boolean.TRUE); name.set(supper,\"throwable\"); System.out.println(\"Field get--&gt;\" + name.get(supper)); sayHello.invoke(supper); name.set(supper, \"throwable-10086\"); System.out.println(\"Field get--&gt;\" + name.get(supper)); sayHello.invoke(supper); &#125; public static class Supper &#123; private String name; private void sayHello() &#123; System.out.println(String.format(\"%s say hello!\", name)); &#125; &#125;&#125; 输出结果： 1234Field get--&gt;throwablethrowable say hello!Field get--&gt;throwable-10086throwable-10086 say hello! Parameter类 Parameter用于描述Method或者Constructor的参数，主要是用于获取参数的名称。因为在Java中没有形式参数的概念，也就是参数都是没有名称的。Jdk1.8新增了Parameter用来填补这个问题，使用javac编译器的时候加上-parameters参数的话，会在生成的.class文件中额外存储参数的元信息，这样会导致.class文件的大小增加。当你输入javac -help的时候，你会看到-parameters这个选项。获取Parameter的方法是Method或者Constructor的父类Executable的getParamaters方法。一般而言，Parameter是用于获取参数名称的后备方案，因为Jdk1.8之前没有这个类，并且即使使用了Jdk1.8如果javac编译器的时候没有加上-parameters参数的话，通过Parameter获取到的参数名称将会是&quot;arg0&quot;、“arg1”…&quot;argn&quot;类似的没有意义的参数名称。一般框架中使用其他方法解析方法或者构造器的参数名称，参考Spring的源码，具体是LocalVariableTableParameterNameDiscoverer，是使用ASM去解析和读取类文件字节码，提取参数名称。Parameter的主要方法如下： 方法 功能 String getName() 返回该参数的名称 int getModifiers() 返回该参数的修饰符 Class&lt;?&gt; getType() 返回该参数的类型Class Class&lt;?&gt; getParameterizedType() 返回该参数的泛型类型Type boolean isNamePresent() 该参数的名称是否保存在class文件中，需要编译时加参数-parameters boolean isImplicit() 该参数是否隐式声明 boolean isSynthetic() 该参数是否复合的 boolean isVarArgs() 该参数是否不定参数 这里举个例子，编译时候添加参数-parameters： 1234567891011121314151617181920212223public class Main11 &#123; public static void main(String[] args) throws Exception &#123; Class&lt;Supper&gt; supperClass = Supper.class; Method sayHello = supperClass.getDeclaredMethod(\"sayHello\", String.class); sayHello.setAccessible(Boolean.TRUE); Parameter[] parameters = sayHello.getParameters(); for (Parameter parameter : parameters) &#123; System.out.println(\"isNamePresent-&gt;\" + parameter.isNamePresent()); System.out.println(\"isImplicit-&gt;\" + parameter.isImplicit()); System.out.println(\"getName-&gt;\" + parameter.getName()); System.out.println(\"=====================\"); &#125; &#125; public static class Supper &#123; private void sayHello(String name) &#123; System.out.println(String.format(\"%s say hello!\", name)); &#125; &#125;&#125; 输出结果： 1234isNamePresent-&gt;trueisImplicit-&gt;falsegetName-&gt;name===================== 如果不设置编译参数-parameters，会输出下面的结果： 1234isNamePresent-&gt;falseisImplicit-&gt;falsegetName-&gt;arg0===================== 小结 这篇文章开篇对反射的基本进行介绍，后面花大量篇幅列举了相关类库的API和API使用，掌握这些类库，才能轻松地进行反射编程。 (本文完 e-2018122)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Reflection","slug":"Java/Reflection","permalink":"http://throwable.club/blog/categories/Java/Reflection/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Reflection","slug":"Reflection","permalink":"http://throwable.club/blog/tags/Reflection/"}]},{"title":"RabbitMQ扩展之直接回复(Direct reply-to)","slug":"rabbitmq-extension-direct-reply-to","date":"2018-12-01T11:04:46.000Z","updated":"2018-12-01T11:05:19.173Z","comments":true,"path":"2018/12/01/rabbitmq-extension-direct-reply-to/","link":"","permalink":"http://throwable.club/2018/12/01/rabbitmq-extension-direct-reply-to/","excerpt":"","text":"前提 本文内容参考RabbitMQ官方文档Direct reply-to。 直接回复 直接回复(Direct reply-to)是一种可以避免声明回复队列并且实现类似于RPC功能的一种特性。RabbitMQ中允许使用客户端和RabbitMQ消息代理中间件实现RPC模式，典型的做法是：RPC客户端发送请求(消息)到一个持久化的已知服务端队列，RPC服务端消费该服务端队列的消息，然后使用消息属性中的reply-to属性对应的值作为客户端回复队列发送回复消息到RPC客户端。 客户端回复队列需要考虑创建问题。客户端可以为每个请求-响应声明一个一次性的队列，但是这样的做法是十分低效的，因为即使是非持久状态下的非镜像队列，其删除的代价是昂贵的，特别是在集群模式之下。另一个可选的做法是：客户端为回复创建一个持久化的长期存在的队列，这种情况下队列的管理可能变得复杂，因为客户端本身可能不是长期存在的。 实际上，RabbitMQ提供了一个功能，允许RPC客户端直接从其RPC服务端接收回复，并且无需创建回复队列，依赖于RabbitMQ的消息中间件的功能，具体做法是： 对于RPC客户端： RPC客户端创建消费者的时候队列指定为伪队列amq.rabbitmq.reply-to，使用非手动ack模式(autoAck=true)进行消费，伪队列amq.rabbitmq.reply-to不需要显式声明，当然如果需要的话也可以显式声明。 发布消息的时候，消息属性中的reply-to属性需要指定为amq.rabbitmq.reply-to。 对于RPC服务端： RPC服务端接收消息后感知消息属性中的reply-to属性存在，它应该通过默认的交换器(名称为&quot;&quot;)和reply-to属性作为路由键发送回复消息，那么该回复消息就会直接投递到RPC客户端的消费者中。 如果RPC服务端需要进行一些长时间的计算逻辑，可能需要探测RPC服务端是否存活，可以使用一个一次性使用的信道对reply-to属性做一次队列声明，如果声明成功，队列amq.rabbitmq.reply-to并不会创建，如果声明失败，那么说明客户端已经失去连接。 注意事项： RPC客户端在创建伪队列amq.rabbitmq.reply-to消费者的时候必须使用非手动ack模式(autoAck=true)。 使用此机制发送的回复消息通常不具有容错能力，如果发布原始请求的客户端随后断开连接，它们将被丢弃。 伪队列amq.rabbitmq.reply-to可以在basic.consume、basic.publish和消息属性reply-to中使用，实际上，它并不是一个真实存在的队列，RabbitMQ的Web管理器或者rabbitmqctl list_queues命令都无法展示该伪队列的相关属性或者信息。 说实话，个人认为这种方式有个比较多的局限性： 同一个应用里面，只能使用唯一一个伪队列amq.rabbitmq.reply-to消费回复消息，并且RabbitMQ的Web管理器或者rabbitmqctl list_queues命令都无法展示该伪队列的相关属性或者信息，也就是无法对它进行监控或者管理。 对于多应用同时接进去同一个RabbitMQ消息中间件代理，这些应用之间无法同时使用amq.rabbitmq.reply-to这个特性，因为有可能A客户端发送的消息被远程服务回调到另一个不同的B客户端。 直接回复特性使用 使用伪队列amq.rabbitmq.reply-to的一个例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class ReplyToRawMain extends BaseChannelFactory &#123; private static final String FAKE_QUEUE = \"amq.rabbitmq.reply-to\"; private static final String RPC_QUEUE = \"rpc.queue\"; private static final String DEFAULT_EXCHANGE = \"\"; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; // 服务端队列 channel.queueDeclare(RPC_QUEUE, true, false, false, null); client(channel); server(channel); Thread.sleep(5000); &#125;); &#125; private static void client(Channel channel) throws Exception &#123; // 客户端消费 - no-ack,也就是autoAck = true channel.basicConsume(FAKE_QUEUE, true, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(String.format(\"[X-Client]\\ndeliveryTag:%s\\nexchange:%s\\nroutingKey:%s\\ncorrelationId:%s\\nreplyTo:%s\\ncontent:%s\\n\", envelope.getDeliveryTag(), envelope.getExchange(), envelope.getRoutingKey(), properties.getCorrelationId(), properties.getReplyTo(), new String(body, StandardCharsets.UTF_8))); &#125; &#125;); // 客户端发送 AMQP.BasicProperties basicProperties = new AMQP.BasicProperties.Builder() .correlationId(\"message-99999\") .replyTo(FAKE_QUEUE) .build(); channel.basicPublish(DEFAULT_EXCHANGE, RPC_QUEUE, basicProperties, \"Reply Message\".getBytes(StandardCharsets.UTF_8)); &#125; private static void server(Channel channel) throws Exception &#123; // 服务端消费 channel.basicConsume(RPC_QUEUE, true, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(String.format(\"[X-Server]\\ndeliveryTag:%s\\nexchange:%s\\nroutingKey:%s\\ncorrelationId:%s\\nreplyTo:%s\\ncontent:%s\\n\", envelope.getDeliveryTag(), envelope.getExchange(), envelope.getRoutingKey(), properties.getCorrelationId(), properties.getReplyTo(), new String(body, StandardCharsets.UTF_8))); // 服务端应答-&gt;客户端 AMQP.BasicProperties basicProperties = new AMQP.BasicProperties.Builder() .correlationId(properties.getCorrelationId()) .build(); channel.basicPublish(DEFAULT_EXCHANGE, properties.getReplyTo(), basicProperties, body); &#125; &#125;); &#125;&#125; 当然，可以直接创建一个真实的独占队列(生命周期跟客户端的连接绑定)作为回复队列，举个例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class ReplyToMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; // 服务端队列 channel.queueDeclare(\"rpc.queue\", true, false, false, null); // 客户端接收应答队列 - 排他队列,生命周期和连接绑定 AMQP.Queue.DeclareOk callback = channel.queueDeclare(\"\", false, true, false, null); System.out.println(\"建立排他应答队列:\" + callback.getQueue()); // 客户端消费 channel.basicConsume(callback.getQueue(), false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(String.format(\"[X-Client]\\ndeliveryTag:%s\\nroutingKey:%s\\ncorrelationId:%s\\nreplyTo:%s\\ncontent:%s\\n\", envelope.getDeliveryTag(), envelope.getRoutingKey(), properties.getCorrelationId(), properties.getReplyTo(), new String(body, StandardCharsets.UTF_8))); &#125; &#125;); // 服务端消费 channel.basicConsume(\"rpc.queue\", true, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(String.format(\"[X-Server]\\ndeliveryTag:%s\\nroutingKey:%s\\ncorrelationId:%s\\nreplyTo:%s\\ncontent:%s\\n\", envelope.getDeliveryTag(), envelope.getRoutingKey(), properties.getCorrelationId(), properties.getReplyTo(), new String(body, StandardCharsets.UTF_8))); // 服务端应答 AMQP.BasicProperties basicProperties = new AMQP.BasicProperties.Builder() .correlationId(properties.getCorrelationId()) .build(); channel.basicPublish(\"\", properties.getReplyTo(), basicProperties, body); &#125; &#125;); // 客户端发送 AMQP.BasicProperties basicProperties = new AMQP.BasicProperties.Builder() .correlationId(\"message-99999\") .replyTo(callback.getQueue()) .build(); channel.basicPublish(\"\", \"rpc.queue\", basicProperties, \"Reply Message\".getBytes(StandardCharsets.UTF_8)); Thread.sleep(5000); &#125;); &#125;&#125; 个人想法 在实际项目中，我们经常被RabbitMQ消息发送是否成功这个问题困扰，一般情况下，我们认为调用basic.publish只要不抛出异常就是发送消息成功，例如一个代码模板如下： 123456789101112public boolean sendMessage()&#123; boolean success = false; try &#123; channel.basicPublish(); // 发送成功 success = true; &#125;catch (Exception e)&#123; // 发送失败 log.error(); &#125; return success;&#125; 这个代码模板在极大多数情况下是合适的，但是有些时候我们确实需要消息的接收方告知发送方已经收到消息，这个时候就需要用到消息的回复功能，个人认为可选的方案有： 消息发布方基于伪队列amq.rabbitmq.reply进行消费，消息接收方回复到伪队列amq.rabbitmq.reply上。 消息发布方自定义独占队列进行消费，消息接收方回复到此独占队列。 消息发布方自定义持久化队列进行消费，消息接收方回复到此持久化队列。 其实，在AMQP.BasicProperties的replyTo属性中指定需要回复的队列名只是RabbitMQ提出的一种规约或者建议，并不是强制实行的方案，实际上可以自行选择回复队列或者忽略replyTo属性。","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"RabbitMQ","slug":"Middleware/RabbitMQ","permalink":"http://throwable.club/blog/categories/Middleware/RabbitMQ/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://throwable.club/blog/tags/RabbitMQ/"}]},{"title":"浅析JDK中ServiceLoader的源码","slug":"java-service-loader","date":"2018-11-29T16:39:32.000Z","updated":"2018-11-29T16:41:40.973Z","comments":true,"path":"2018/11/30/java-service-loader/","link":"","permalink":"http://throwable.club/2018/11/30/java-service-loader/","excerpt":"","text":"前提 紧接着上一篇《通过源码浅析JDK中的资源加载》，ServiceLoader是SPI(Service Provider Interface)中的服务类加载的核心类，也就是，这篇文章先介绍ServiceLoader的使用方式，再分析它的源码。 ServiceLoader的使用 这里先列举一个经典的例子，MySQL的Java驱动就是通过ServiceLoader加载的，先引入mysql-connector-java的依赖： 12345&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt;&lt;/dependency&gt; 查看这个依赖的源码包下的META-INF目录，可见： 我们接着查看java.lang.DriverManager，静态代码块里面有： 1234static &#123; loadInitialDrivers(); println(\"JDBC DriverManager initialized\");&#125; 其中，可以查看loadInitialDrivers()有如下的代码片段： java.lang.DriverManager是启动类加载器加载的基础类，但是它可以加载rt.jar包之外的类，上篇文章提到，这里打破了双亲委派模型，原因是：ServiceLoader中使用了线程上下文类加载器去加载类。这里JDBC加载的过程就是典型的SPI的使用，总结规律如下： 1、需要定义一个接口。 2、接口提供商需要实现第1步中的接口。 3、接口提供商在META-INF/services目录下建立一个文本文件，文件名是第1步中定义的接口的全限定类名，文本内容是接口的实现类的全限定类名，每个不同的实现占独立的一行。 4、使用ServiceLoader加载接口类，获取接口的实现的实例迭代器。 举个简单的实例，先定义一个接口和两个实现： 1234567891011121314151617181920public interface Say &#123; void say();&#125;public class SayBye implements Say &#123; @Override public void say() &#123; System.out.println(\"Bye!\"); &#125;&#125;public class SayHello implements Say &#123; @Override public void say() &#123; System.out.println(\"Hello!\"); &#125;&#125; 接着在项目的META-INF/services中添加文件如下： 最后通过main函数验证： 基于SPI或者说ServiceLoader加载接口实现这种方式也可以广泛使用在相对基础的组件中，因为这是一个成熟的规范。 ServiceLoader源码分析 上面通过一个经典例子和一个实例介绍了ServiceLoader的使用方式，接着我们深入分析ServiceLoader的源码。我们先看ServiceLoader的类签名和属性定义： 123456789101112131415161718192021public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt;&#123; //需要加载的资源的路径的目录，固定是ClassPath下的META-INF/services/ private static final String PREFIX = \"META-INF/services/\"; // ServiceLoader需要正在需要加载的类或者接口 // The class or interface representing the service being loaded private final Class&lt;S&gt; service; // ServiceLoader进行类加载的时候使用的类加载器引用 // The class loader used to locate, load, and instantiate providers private final ClassLoader loader; // 权限控制上下文 // The access control context taken when the ServiceLoader is created private final AccessControlContext acc; //基于实例的顺序缓存类的实现实例，其中Key为实现类的全限定类名 // Cached providers, in instantiation order private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;(); // 当前的\"懒查找\"迭代器，这个是ServiceLoader的核心 // The current lazy-lookup iterator private LazyIterator lookupIterator; //暂时忽略其他代码...&#125; ServiceLoader实现了Iterable接口，这一点提示了等下我们在分析它源码的时候，需要重点分析iterator()方法的实现。ServiceLoader依赖于类加载器实例进行类加载，它的核心属性LazyIterator是就是用来实现iterator()方法的，下文再重点分析。接着，我们分析ServiceLoader的构造函数： 12345678910111213public void reload() &#123; //清空缓存 providers.clear(); //构造LazyIterator实例 lookupIterator = new LazyIterator(service, loader);&#125;private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) &#123; service = Objects.requireNonNull(svc, \"Service interface cannot be null\"); loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; reload();&#125; ServiceLoader只有一个私有的构造函数，也就是它不能通过构造函数实例化，但是要实例化ServiceLoader必须依赖于它的静态方法调用私有构造去完成实例化操作，而实例化过程主要做了几步： 1、判断传入的接口或者类的Class实例不能为null，否则会抛出异常。 2、如果传入的ClassLoader实例为null，则使用应用类加载器(Application ClassLoader)。 3、实例化访问控制上下文。 4、调用实例方法reload()，清空目标加载类的实现类实例的缓存并且构造LazyIterator实例。 注意一点是实例方法reload()的修饰符是public，也就是可以主动调用去清空目标加载类的实现类实例的缓存和重新构造LazyIterator实例。接着看ServiceLoader提供的静态方法： 123456789101112131415161718public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader)&#123; return new ServiceLoader&lt;&gt;(service, loader);&#125;public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl);&#125;public static &lt;S&gt; ServiceLoader&lt;S&gt; loadInstalled(Class&lt;S&gt; service) &#123; ClassLoader cl = ClassLoader.getSystemClassLoader(); ClassLoader prev = null; while (cl != null) &#123; prev = cl; cl = cl.getParent(); &#125; return ServiceLoader.load(service, prev);&#125; 上面的三个公共静态方法都是用于构造ServiceLoader实例，其中load(Class&lt;S&gt; service, ClassLoader loader)就是典型的静态工厂方法，直接调用ServiceLoader的私有构造器进行实例化，除了需要指定加载类的目标类型，还需要传入类加载器的实例。load(Class&lt;S&gt; service)实际上也是委托到load(Class&lt;S&gt; service, ClassLoader loader)，不过它使用的类加载器指定为线程上下文类加载器，一般情况下，线程上下文类加载器获取到的就是应用类加载器(系统类加载器)。loadInstalled(Class&lt;S&gt; service)方法又看出了&quot;双亲委派模型&quot;的影子，它指定类加载器为最顶层的启动类加载器，最后也是委托到load(Class&lt;S&gt; service, ClassLoader loader)。接着我们需要重点分析ServiceLoader#iterator()： 1234567891011121314151617181920212223242526272829public Iterator&lt;S&gt; iterator() &#123; //Iterator的匿名实现 return new Iterator&lt;S&gt;() &#123; //目标类实现类实例缓存的Map的Entry的迭代器实例 Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); //先从缓存中判断是否有下一个实例，否则通过懒加载迭代器LazyIterator去判断是否存在下一个实例 public boolean hasNext() &#123; if (knownProviders.hasNext()) return true; return lookupIterator.hasNext(); &#125; //如果缓存中判断是否有下一个实例，如果有则从缓存中的值直接返回 //否则通过懒加载迭代器LazyIterator获取下一个实例 public S next() &#123; if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); &#125; //不支持移除操作，直接抛异常 public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125;;&#125; iterator()内部仅仅是Iterator接口的匿名实现，hasNext()和next()方法都是优先判断缓存中是否已经存在实现类的实例，如果存在则直接从缓存中返回，否则调用懒加载迭代器LazyIterator的实例去获取，而LazyIterator本身也是一个Iterator接口的实现，它是ServiceLoader的一个私有内部类，源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108private class LazyIteratorimplements Iterator&lt;S&gt;&#123; Class&lt;S&gt; service; ClassLoader loader; //加载的资源的URL集合 Enumeration&lt;URL&gt; configs = null; //所有需要加载的实现类的全限定类名的集合 Iterator&lt;String&gt; pending = null; //下一个需要加载的实现类的全限定类名 String nextName = null; private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) &#123; this.service = service; this.loader = loader; &#125; private boolean hasNextService() &#123; //如果下一个需要加载的实现类的全限定类名不为null，则说明资源中存在内容 if (nextName != null) &#123; return true; &#125; //如果加载的资源的URL集合为null则尝试进行加载 if (configs == null) &#123; try &#123; //资源的名称，META-INF/services + '需要加载的类的全限定类名' //这样得到的刚好是需要加载的文件的资源名称 String fullName = PREFIX + service.getName(); //这里其实ClassLoader实例应该不会为null if (loader == null) configs = ClassLoader.getSystemResources(fullName); else //从ClassPath加载资源 configs = loader.getResources(fullName); &#125; catch (IOException x) &#123; fail(service, \"Error locating configuration files\", x); &#125; &#125; //从资源中解析出需要加载的所有实现类的全限定类名 while ((pending == null) || !pending.hasNext()) &#123; if (!configs.hasMoreElements()) &#123; return false; &#125; pending = parse(service, configs.nextElement()); &#125; //获取下一个需要加载的实现类的全限定类名 nextName = pending.next(); return true; &#125; private S nextService() &#123; if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try &#123; //反射构造Class&lt;S&gt;实例 c = Class.forName(cn, false, loader); &#125; catch (ClassNotFoundException x) &#123; fail(service, \"Provider \" + cn + \" not found\"); &#125; //这里会做一次类型判断，也就是实现类必须是当前加载的类或者接口的派生类，否则抛出异常终止 if (!service.isAssignableFrom(c)) &#123; fail(service, \"Provider \" + cn + \" not a subtype\"); &#125; try &#123; //通过Class#newInstance()进行实例化，并且强制转化为对应的类型的实例 S p = service.cast(c.newInstance()); //添加缓存，Key为实现类的全限定类名，Value为实现类的实例 providers.put(cn, p); return p; &#125; catch (Throwable x) &#123; fail(service, \"Provider \" + cn + \" could not be instantiated\", x); &#125; throw new Error(); // This cannot happen &#125; public boolean hasNext() &#123; if (acc == null) &#123; return hasNextService(); &#125; else &#123; PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() &#123; public Boolean run() &#123; return hasNextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public S next() &#123; if (acc == null) &#123; return nextService(); &#125; else &#123; PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() &#123; public S run() &#123; return nextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125; LazyIterator也是Iterator接口的实现，它的Lazy特性表明它总是在ServiceLoader的Iterator接口匿名实现iterator()执行hasNext()判断是否有下一个实现或者next()获取下一个实现类的实例的时候才会&quot;懒判断&quot;或者&quot;懒加载&quot;下一个实现类的实例。最后是加载资源文件后对资源文件的解析过程的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657private Iterator&lt;String&gt; parse(Class&lt;?&gt; service, URL u) throws ServiceConfigurationError&#123; InputStream in = null; BufferedReader r = null; //存放文件中所有的实现类的全类名，每一行是一个元素 ArrayList&lt;String&gt; names = new ArrayList&lt;&gt;(); try &#123; in = u.openStream(); r = new BufferedReader(new InputStreamReader(in, \"utf-8\")); int lc = 1; while ((lc = parseLine(service, u, r, lc, names)) &gt;= 0); &#125; catch (IOException x) &#123; fail(service, \"Error reading configuration file\", x); &#125; finally &#123; try &#123; if (r != null) r.close(); if (in != null) in.close(); &#125; catch (IOException y) &#123; fail(service, \"Error closing configuration file\", y); &#125; &#125; //返回的是ArrayList的迭代器实例 return names.iterator();&#125;//解析资源文件中每一行的内容private int parseLine(Class&lt;?&gt; service, URL u, BufferedReader r, int lc, List&lt;String&gt; names)throws IOException, ServiceConfigurationError&#123; // 下一行没有内容，返回-1，便于上层可以跳出循环 String ln = r.readLine(); if (ln == null) &#123; return -1; &#125; //如果存在'#'字符，截取第一个'#'字符串之前的内容，'#'字符之后的属于注释内容 int ci = ln.indexOf('#'); if (ci &gt;= 0) ln = ln.substring(0, ci); ln = ln.trim(); int n = ln.length(); if (n != 0) &#123; //不能存在空格字符' '和特殊字符'\\t' if ((ln.indexOf(' ') &gt;= 0) || (ln.indexOf('\\t') &gt;= 0)) fail(service, u, lc, \"Illegal configuration-file syntax\"); int cp = ln.codePointAt(0); //判断第一个char是否一个合法的Java起始标识符 if (!Character.isJavaIdentifierStart(cp)) fail(service, u, lc, \"Illegal provider-class name: \" + ln); //判断所有其他字符串是否属于合法的Java标识符 for (int i = Character.charCount(cp); i &lt; n; i += Character.charCount(cp)) &#123; cp = ln.codePointAt(i); if (!Character.isJavaIdentifierPart(cp) &amp;&amp; (cp != '.')) fail(service, u, lc, \"Illegal provider-class name: \" + ln); &#125; //如果缓存中不存在加载出来的全类名或者已经加载的列表中不存在加载出来的全类名则添加进去加载的全类名列表中 if (!providers.containsKey(ln) &amp;&amp; !names.contains(ln)) names.add(ln); &#125; return lc + 1; &#125; 整个资源文件的解析过程并不复杂，主要包括文件内容的字符合法性判断和缓存避免重复加载的判断。 小结 SPI被广泛使用在第三方插件式类库的加载，最常见的如JDBC、JNDI、JCE(Java加密模块扩展)等类库。理解ServiceLoader的工作原理有助于编写扩展性良好的可插拔的类库。 (本文完 c-1-d e-20181014)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"}]},{"title":"通过源码浅析Java中的资源加载","slug":"java-resource-load","date":"2018-11-29T16:37:41.000Z","updated":"2018-12-02T02:20:27.998Z","comments":true,"path":"2018/11/30/java-resource-load/","link":"","permalink":"http://throwable.club/2018/11/30/java-resource-load/","excerpt":"","text":"前提 最近在做一个基础组件项目刚好需要用到JDK中的资源加载，这里说到的资源包括类文件和其他静态资源，刚好需要重新补充一下类加载器和资源加载的相关知识，整理成一篇文章。 什么是类加载器 虚拟机设计团队把类加载阶段中的&quot;通过一个类的全限定名来获取描述此类的二进制字节流&quot;这个动作放到了Java虚拟机外部实现，以便让应用程序自己决定如何去获取所需要的类，而实现这个动作的代码模块称为&quot;类加载器(ClassLoader)&quot;。 类加载器虽然只用于实现类加载的功能，但是它在Java程序中起到的作用不局限于类加载阶段。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立类在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类命名空间。上面这句话直观来说就是：比较两个类是否&quot;相等&quot;，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这个两个类是来源于同一个Class文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那么这两个类必然&quot;不相等&quot;。这里说到的&quot;相等&quot;包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法的返回结果，也包括使用instanceOf关键字做对象所属关系判定等情况。 类和加载它的类加载器确定类在Java虚拟机中的唯一性这个特点为后来出现的热更新类、热部署等技术提供了基础。 双亲委派模型 从Java虚拟机的角度来看，只有两种不同的类加载器： 1、第一种是启动类加载器(Bootstrap ClassLoader)，这个类加载器使用C++编程语言实现，是虚拟机的一部分。 2、另一种是其他的类加载器，这些类加载器都是由Java语言实现，独立于虚拟机之外，一般就是内部于JDK中，它们都继承自抽象类加载器java.lang.ClassLoader。 JDK中提供几个系统级别的类加载器： 1、启动类加载器(Bootstrap ClassLoader)：这个类加载器负责将存放在${JAVA_HONE}\\lib目录中，或者被XbootstrapPath参数所指定的目录中，并且是虚拟机基于一定规则(如文件名称规则，如rt.jar)标识的类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用，开发者在编写自定义类加载器如果想委派到启动类加载器只需直接使用null替代即可。 2、扩展类加载器(Extension ClassLoader)：这个类加载器由sun.misc.Launcher的静态内部类ExtClassLoader实现，它负责加载${JAVA_HONE}\\lib\\ext目录中，或者通过java.ext.dirs系统变量指定的路径中的所有类库，开发者可以直接使用此类加载器。 3、应用程序类加载器(Application ClassLoader)：这个类加载器由sun.misc.Launcher的静态内部类AppClassLoader实现，但是由于这个类加载器的实例是ClassLoader中静态方法getSystemClassLoader()中的返回值，一般也称它为系统类加载器。它负责加载用户类路径(ClassPath)上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自实现的类加载器，一般情况下这个系统类加载器就是应用程序中默认使用的类加载器。 4、线程上下文类加载器(Thread Context ClassLoader)：这个在下一小节&quot;破坏双亲委派模型&quot;再分析。 Java开发者开发出来的Java应用程序都是由上面四种类加载器相互配合进行类加载的，如果有必要还可以加入自定义的类加载器。其中，启动类加载器、扩展类加载器、应用程序类加载器和自定义类加载器之间存在着一定的关系： 上图展示的类加载器之间的层次关系称为双亲委派模型(Parents Delegation Model)。双亲委派模型要求除了顶层的类加载器(Java中顶层的类加载器一般是Bootstrap ClassLoader)，其他的类加载器都应当有自己的父类加载器。这些类加载器之间的父子关系一般不会以继承(Inheritance)的关系来实现，而是通过组合(Composition)的关系实现。类加载器层次关系这一点可以通过下面的代码验证一下： 1234567891011121314public class Main &#123; public static void main(String[] args) throws Exception&#123; ClassLoader classLoader = Main.class.getClassLoader(); System.out.println(classLoader); System.out.println(classLoader.getParent()); System.out.println(classLoader.getParent().getParent()); &#125;&#125;//输出结果，最后的null说明是Bootstrap ClassLoadersun.misc.Launcher$AppClassLoader@18b4aac2sun.misc.Launcher$ExtClassLoader@4629104anull 双亲委派模型的工作机制：如果一个类加载器收到了类加载的请求，它首先不会自己尝试去加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的类加载请求最终都应该传送到顶层的类加载器中，只有当父类加载器反馈自己无法完成当前的类加载请求的时候(也就是在它的搜索范围中没有找到所需要的类)，子类加载器才会尝试自己去加载类。不过这里有一点需要注意，每一个类加载器都会缓存已经加载过的类，也就是重复加载一个已经存在的类，那么就会从已经加载的缓存中加载，如果从当前类加载的缓存中判断类已经加载过，那么直接返回，否则会委派类加载请求到父类加载器。这个缓存机制在AppClassLoader和ExtensionClassLoader中都存在，至于BootstrapClassLoader未知。 双亲委派模型的优势：使用双亲委派模型来组织类加载器之间的关系，一个比较显著的优点是Java类随着加载它的类加载器一起具备了一种带有优先级的层次关系。例如java.lang包中的类库，它存放在rt.jar中，无论使用哪一个类加载加载java.lang包中的类，最终都是委派给处于模型顶层的启动类加载器进行加载，因此java.lang包中的类如java.lang.Object类在应用程序中的各类加载器环境中加载的都是同一个类。试想，如果可以使用用户自定义的ClassLoader去加载java.lang.Object，那么用户应用程序中就会出现多个java.lang.Object类，Java类型体系中最基础的类型也有多个，类型体系的基础行为无法保证，应用程序也会趋于混乱。如果尝试编写rt.jar中已经存在的同类名的类通过自定义的类加载进行加载，将会接收到虚拟机抛出的异常。 双亲委派模型的实现：类加载器双亲委派模型的实现提现在ClassLoader的源码中，主要是ClassLoader#loadClass()中。 1234567891011121314151617181920212223242526272829303132333435363738394041public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false);&#125;protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; //父加载器不为null，说明父加载器不是BootstrapClassLoader if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; //父加载器为null，说明父加载器是BootstrapClassLoader c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; //所有的父加载加载失败,则使用当前的类加载器进行类加载 if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); //记录一些统计数据如加载耗时、计数等 // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125; 破坏双亲委派模型 双亲委派模型在Java发展历史上出现了三次比较大&quot;被破坏&quot;的情况: 1、ClassLoader在JDK1.0已经存在，JDK1.2为了引入双亲委派模型并且需要向前兼容，java.lang.ClassLoader类添加了一个新的protected的findClass()方法，在这之前，用户去继承java.lang.ClassLoader只能重写其loadClass()方法才能实现自己的目标。 2、双亲委派模型自身存在缺陷：双亲委派很好地解决了各个类加载器的基础类的加载的统一问题(越基础的类由越上层的类加载器加载)，这些所谓的基础类就是大多数情况下作为用户调用的基础类库和基础API，但是无法解决这些基础类需要回调用户的代码这一个问题，典型的例子就是JNDI。JNDI的类库代码是启动类加载器加载的，但是它需要调用独立厂商实现并且部署在应用的ClassPath的JNDI的服务接口提供者(SPI，即是Service Provider Interface)的代码，但是启动类加载器无法加载ClassPath下的类库。为了解决这个问题，Java设计团队引入了不优雅的设计：线程上下文类加载器(Thread Context ClassLoader)，这个类加载器可以通过java.lang.Thread类的setContextClassLoader()设置，这样子，JNDI服务就可以使用线程上下文类加载器去加载所需的SPI类库，但是父类加载器中请求子类加载器去加载类这一点已经打破了双亲委派模型。目前，JNDI、JDBC、JCE、JAXB和JBI等模块都是通过此方式实现。 3、基于用户对应用程序动态性的热切追求：如代码热替换(HotSwap)、热模块部署等，说白了就是希望应用程序能像我们的计算机外设那样可以热插拔，因此催生出JSR-291以及它的业界实现OSGi，而OSGi定制了自己的类加载规则，不再遵循双亲委派模型，因此它可以通过自定义的类加载器机制轻易实现模块的热部署。 JDK中提供的资源加载API 前边花大量的篇幅去分析类加载器的预热知识，是因为JDK中的资源加载依赖于类加载器(其实类文件本来就是资源文件的一种，类加载的过程也是资源加载的过程)。这里先列举出JDK中目前常用的资源(Resource)加载的API，先看ClassLoader中提供的方法。 ClassLoader提供的资源加载API 12345678910111213141516171819//1.实例方法public URL getResource(String name)//这个方法仅仅是调用getResource(String name)返回URL实例直接调用URL实例的openStream()方法public InputStream getResourceAsStream(String name)//这个方法是getResource(String name)方法的复数版本public Enumeration&lt;URL&gt; getResources(String name) throws IOException//2.静态方法public static URL getSystemResource(String name)//这个方法仅仅是调用getSystemResource(String name)返回URL实例直接调用URL实例的openStream()方法public static InputStream getSystemResourceAsStream(String name)//这个方法是getSystemResources(String name)方法的复数版本public static Enumeration&lt;URL&gt; getSystemResources(String name) 总的来看，只有两个方法需要分析：getResource(String name)和getSystemResource(String name)。查看getResource(String name)的源码： 123456789101112public URL getResource(String name) &#123; URL url; if (parent != null) &#123; url = parent.getResource(name); &#125; else &#123; url = getBootstrapResource(name); &#125; if (url == null) &#123; url = findResource(name); &#125; return url;&#125; 是否似曾相识?这里明显就是使用了类加载过程中类似的双亲委派模型进行资源加载，这个方法在API注释中描述通常用于加载数据资源如images、audio、text等等，资源名称需要使用路径分隔符’/’。getResource(String name)方法中查找的根路径我们可以通过下面方法验证： 12345678910public class ResourceLoader &#123; public static void main(String[] args) throws Exception &#123; ClassLoader classLoader = ResourceLoader.class.getClassLoader(); URL resource = classLoader.getResource(\"\"); System.out.println(resource); &#125;&#125;//输出：file:/D:/Projects/rxjava-seed/target/classes/ 很明显输出的结果就是当前应用的ClassPath，总结来说：ClassLoader#getResource(String name)是基于用户应用程序的ClassPath搜索资源，资源名称必须使用路径分隔符’/‘去分隔目录，但是不能以’/'作为资源名的起始，也就是不能这样使用：classLoader.getResource(&quot;/img/doge.jpg&quot;)。接着我们再看一下ClassLoader#getSystemResource(String name)的源码： 12345678public static URL getSystemResource(String name) &#123; //实际上Application ClassLoader一般不会为null ClassLoader system = getSystemClassLoader(); if (system == null) &#123; return getBootstrapResource(name); &#125; return system.getResource(name);&#125; 此方法优先使用应用程序类加载器进行资源加载，如果应用程序类加载器为null(其实这种情况很少见)，则使用启动类加载器进行资源加载。如果应用程序类加载器不为null的情况下，它实际上退化为ClassLoader#getResource(String name)方法。 总结一下：ClassLoader提供的资源加载的方法中的核心方法是ClassLoader#getResource(String name)，它是基于用户应用程序的ClassPath搜索资源，遵循&quot;资源加载的双亲委派模型&quot;，资源名称必须使用路径分隔符’/‘去分隔目录，但是不能以’/'作为资源名的起始字符，其他几个方法都是基于此方法进行衍生，添加复数操作等其他操作。getResource(String name)方法不会显示抛出异常，当资源搜索失败的时候，会返回null。 Class提供的资源加载API java.lang.Class中也提供了资源加载的方法，如下： 12345678910111213141516171819public java.net.URL getResource(String name) &#123; name = resolveName(name); ClassLoader cl = getClassLoader0(); if (cl==null) &#123; // A system class. return ClassLoader.getSystemResource(name); &#125; return cl.getResource(name);&#125;public InputStream getResourceAsStream(String name) &#123; name = resolveName(name); ClassLoader cl = getClassLoader0(); if (cl==null) &#123; // A system class. return ClassLoader.getSystemResourceAsStream(name); &#125; return cl.getResourceAsStream(name);&#125; 从上面的源码来看，Class#getResource(String name)和Class#getResourceAsStream(String name)分别比ClassLoader#getResource(String name)和ClassLoader#getResourceAsStream(String name)只多了一步，就是搜索之前先进行资源名称的预处理resolveName(name)，我们重点看这个方法做了什么： 1234567891011121314151617181920private String resolveName(String name) &#123; if (name == null) &#123; return name; &#125; if (!name.startsWith(\"/\")) &#123; Class&lt;?&gt; c = this; while (c.isArray()) &#123; c = c.getComponentType(); &#125; String baseName = c.getName(); int index = baseName.lastIndexOf('.'); if (index != -1) &#123; name = baseName.substring(0, index).replace('.', '/') +\"/\"+name; &#125; &#125; else &#123; name = name.substring(1); &#125; return name;&#125; 逻辑相对比较简单： 1、如果资源名称以’/‘开头，那么直接去掉’/’，这个时候的资源查找实际上退化为ClassPath中的资源查找。 2、如果资源名称不以’/‘开头，那么解析出当前类的实际类型(因为当前类有可能是数组)，取出类型的包路径，替换包路径中的’.‘为’/’，再拼接原来的资源名称。举个例子：&quot;club.throwable.Main.class&quot;中调用了Main.class.getResource(&quot;doge.jpg&quot;)，那么这个调用的处理资源名称的结果就是club/throwable/doge.jpg。 小结：如果看过我之前写过的一篇URL和URI相关的文章就清楚，实际上Class#getResource(String name)和Class#getResourceAsStream(String name)的资源名称处理类似于相对URL的处理，而&quot;相对URL的处理&quot;的根路径就是应用程序的ClassPath。如果资源名称以’/‘开头，那么相当于从ClassPath中加载资源，如果资源名称不以’/'开头，那么相当于基于当前类的实际类型的包目录下加载资源。 实际上类似这样的资源加载方式在File类中也存在，这里就不再展开。 小结 理解JDK中的资源加载方式有助于编写一些通用的基础组件，像Spring里面的ResourceLoader、ClassPathResource这里比较实用的工具也是基于JDK资源加载的方式编写出来。下一篇博文《浅析JDK中ServiceLoader的源码》中的主角ServiceLoader就是基于类加载器的功能实现，它也是SPI中的服务类加载的核心类。 说实话，类加载器的&quot;双亲委派模型&quot;和&quot;破坏双亲委派模型&quot;是常见的面试题相关内容，这里可以简单列举两个面试题： 1、谈谈对类加载器的&quot;双亲委派模型&quot;的理解。 2、为什么要引入线程上下文类加载器(或者是对于问题1有打破这个模型的案例吗)? 希望这篇文章能帮助你理解和解决这两个问题。 参考资料： 《深入理解Java虚拟机第二版》 JavaSE-8源码 (本文完 c-1-d e-20181014)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"}]},{"title":"RabbitMQ扩展之消费者优先级","slug":"rabbitmq-extension-consumer-priority","date":"2018-11-29T16:21:49.000Z","updated":"2018-11-29T16:25:37.815Z","comments":true,"path":"2018/11/30/rabbitmq-extension-consumer-priority/","link":"","permalink":"http://throwable.club/2018/11/30/rabbitmq-extension-consumer-priority/","excerpt":"","text":"前提 本文来源于官方文档Consumer Priorities。 消费者优先级 消费者优先级的机制： 高优先级的消费者处于活跃状态的情况下优先接收和处理消息。 消息会流入到低优先级的活跃消费者仅当高优先级的消费者处于阻塞状态。 正常情况下，所有订阅同一个队列的活跃消费者以循环的(round-robin)方式从队列中接收消息。当使用了消费者优先级，如果多个活跃消费者使用了相同的高优先级属性，那么消息投递也是以循环的方式进行(其实使用了相同的优先级类似于没有启用优先级)。 活跃消费者的定义 活跃的消费者就是可以在不用等待的情况下接收和处理消息的消费者，也就是消费者如果无法接收消息，那么它就是出于非活跃状态(或者说阻塞状态)，阻塞的常见原因有： 使用了basic.qos之后，消费者在信道中未确认的预读取消息达到了上限。 网络阻塞。 因此，对于每个存在的队列，必定至少出现下面三种情况的其中一种： 队列没有活跃的消费者。 队列是空的。 队列正在忙于向消费者投递消息。 消费者可能在一秒内多次在活跃和阻塞状态之间切换，只要消费处理速度足够快。RabbitMQ不会通过Web管理插件或者rabbitmqctl命令公开消费者当前是活跃还是阻塞状态，换言之，只能通过客户端感知。 启用消费者优先级的时候，RabbitMQ会优先投递消息到优先级属性比较高的消费者，但是如果所有优先级高的消费者都处于阻塞状态，RabbitMQ会把消息投递到活跃的优先级稍低的消费者，而不是一直等待优先级高的消费者解除阻塞，造成优先级低的消费者一直处于饥饿状态。 使用消费者优先级特性 在使用basic.consume方法可以设置参数x-priority的值为整数，数字越大则优先级越高，未设置则使用默认值0。 1234567891011121314public class ConsumerPriorityMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; Map&lt;String, Object&gt; consumerArgs = new HashMap&lt;&gt;(8); consumerArgs.put(\"x-priority\", 10); channel.basicConsume(\"throwable.queue.direct\", true, consumerArgs, new DefaultConsumer(channel) &#123; &#125;); consumerArgs.put(\"x-priority\", 100); channel.basicConsume(\"throwable.queue.direct\", true, consumerArgs, new DefaultConsumer(channel) &#123; &#125;); &#125;); &#125;&#125; 上面的例子设置了两个消费者，后者的优先级为100，而前者的优先级为10。","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"RabbitMQ","slug":"Middleware/RabbitMQ","permalink":"http://throwable.club/blog/categories/Middleware/RabbitMQ/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://throwable.club/blog/tags/RabbitMQ/"}]},{"title":"RabbitMQ扩展之消费者消息预读取","slug":"rabbitmq-extension-consumer-prefetch","date":"2018-11-28T15:01:46.000Z","updated":"2018-11-28T15:21:11.162Z","comments":true,"path":"2018/11/28/rabbitmq-extension-consumer-prefetch/","link":"","permalink":"http://throwable.club/2018/11/28/rabbitmq-extension-consumer-prefetch/","excerpt":"","text":"前提 本文来源于官方文档Consumer Prefetch。 消费者消息预读取 消费者消息预读取是一个更加合理和高效的限制未确认消息数量的解决方式。 AMQP 0-9-1协议中定义了basic.qos方法用于限制信道或者连接上的未确认消息数量，这个消息数据量命名为prefetch_count。不幸的是，信道其实并不是限制未确认消息数量的理想范畴，因为单个信道有可能有多个消费者订阅多个不同的队列，所以信道和队列需要为发送的每个消息相互协调，以确保消息总数量不超过限制，造成了性能下降，单机性能出现瓶颈，在集群方案中耗时更加严重。 basic.qos定义了两个属性： prefetch_count：预读取消息的数量。 global：是否全局的。 在许多情况下，指定每个消费者的预读取消息数量更加合理。因此，RabbitMQ在basic.qos方法中重新定义了global标志的含义： global的值 prefetch_count在AMQP 0-9-1中的含义 prefetch_count在RabbitMQ中的含义 false 同一个信道上的消费者共享 单独应用于信道上的每个新消费者 true 所有消费者基于同一个连接共享 同一个信道上的消费者共享 basic.qos方法在RabbitMQ的Java驱动中对应三个方法： 1234567void basicQos(int prefetchSize, int prefetchCount, boolean global) throws IOException;// prefetchSize = 0void basicQos(int prefetchCount, boolean global) throws IOException;// prefetchSize = 0 , global = falsevoid basicQos(int prefetchCount) throws IOException; prefetchSize：预读取的消息内容大小上限(包含)，可以简单理解为消息有效载荷字节数组的最大长度限制，0表示无上限。 prefetchCount：预读取的消息数量上限，0表示无上限。 global：false表示prefetchCount单独应用于信道上的每个新消费者，true表示prefetchCount在同一个信道上的消费者共享。 限制单个消费者 123456789public class BasicQosSingle extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; channel.basicQos(10); //基于消费者进行限制 channel.basicConsume(\"throwable.queue.direct\",new DefaultConsumer(channel)&#123;&#125;); &#125;); &#125;&#125; 此消费者最多只能有10条预读取的未确认的消息。 独立限制多个消费者 基于同一个信道对多个队列建立不同的消费者： 123456789101112public class BasicQosMulti extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; DefaultConsumer consumer1 = new DefaultConsumer(channel) &#123;&#125;; DefaultConsumer consumer2 = new DefaultConsumer(channel) &#123;&#125;; channel.basicQos(10); //基于消费者进行限制 channel.basicConsume(\"throwable.queue.direct\",consumer1); channel.basicConsume(\"throwable.queue.fanout\",consumer2); &#125;); &#125;&#125; 每个费者最多只能有10条预读取的未确认的消息。 基于共享限制多个消费者 AMQP规范没有解释如果使用不同的global多次调用basic.qos会发生什么，RabbitMQ将此解释为意味着两个预取限制应该彼此独立地强制执行。 12345678910111213public class BasicQosShare extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; DefaultConsumer consumer1 = new DefaultConsumer(channel) &#123;&#125;; DefaultConsumer consumer2 = new DefaultConsumer(channel) &#123;&#125;; channel.basicQos(10, false); //基于消费者进行限制 channel.basicQos(15, true); //基于信道进行限制 channel.basicConsume(\"throwable.queue.direct\",consumer1); channel.basicConsume(\"throwable.queue.fanout\",consumer2); &#125;); &#125;&#125; 上面的代码表示： 两个消费者consumer1和consumer2基于信道最多只能有15条未确认的预读取消息。 消费者consumer1和consumer2自身最多只能有10条未确认的预读取消息。 也就是有双重限制，这种限制需要信道和队列之间协调，会耗费额外的性能。 消息预读取的意义 消息预读取可以理解为RabbitMQ Broker把未确认的消息批量推送到RabbitMQ的Java客户端中，由客户端先缓存这些消息，然后投递到消费者中。试想，如果在推模式下，没有消息预读取功能，RabbitMQ Broker每次投递一条消息到客户端消费者中，这样就会产生大量的IO操作，导致性能下降，此外，消费者处理速度有可能比较快，容易产生消费者饥饿的情况。可以根据消费者实际的消费速度和消息发布的速度，对消费者的预读取未确认消息的上限进行配置，这样在大多数场景下可以提高消费者的性能。","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"RabbitMQ","slug":"Middleware/RabbitMQ","permalink":"http://throwable.club/blog/categories/Middleware/RabbitMQ/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://throwable.club/blog/tags/RabbitMQ/"}]},{"title":"RabbitMQ扩展之消费者取消通知","slug":"rabbitmq-extension-confirm-cancel","date":"2018-11-28T15:00:07.000Z","updated":"2018-11-28T15:03:26.340Z","comments":true,"path":"2018/11/28/rabbitmq-extension-confirm-cancel/","link":"","permalink":"http://throwable.club/2018/11/28/rabbitmq-extension-confirm-cancel/","excerpt":"","text":"前提 本文来源于官方文档Consumer Cancel Notification。 消费者取消通知 当一个信道上建立的消费者订阅了一个队列，有可能出现各种原因导致消费停止。一个很明显的原因就是客户端在同一个信道上发出basic.cancel命令，消息中间件代理响应basic.cancel-ok，将会导致消费者被取消。还有其他的事件如队列的删除或者集群方案所在队列的集群节点失败也有可能导致消费者被取消，消费者被取消这个事件并不会通知客户端对应的信道，这样子会造成客户端无法感知消费者被取消。 为了避免上面这些情况出现，RabbitMQ引入了扩展特性：由于消息中间件代理出现的异常或者正常情况导致消费者取消，会向对应的消费者(信道)发送basic.cancel，但是由客户端信道主动向消息中间件代理发送basic.cancel以取消消费者的情况下不会受到消息中间件代理的basic.cancel回复。 有些情况下，客户端感知到异常(例如队列删除等)主动向消息中间件代理发送basic.cancel，这个时候，消息中间件代理也有可能因为队列删除主动向对应的消费者(信道)发送basic.cancel，也就是存在竞争，RabbitMQ代理收到前者的basic.cancel时不会出现异常，基于后者还是正常回复basic.cancel-ok。 举个例子，情况一：例如我们主动取消信道上的消费者： 123456789101112public class InitiativeBasicCancel extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; // 此方法返回的是消费者的标签 String consumerTag = channel.basicConsume(\"throwable.queue.direct\", new DefaultConsumer(channel) &#123; &#125;); channel.basicCancel(consumerTag); &#125;); &#125;&#125; 情况二：假如我们想监听消息中间件代理异步回调的basic.cancel和basic.cancel-ok，应该这样做： 12345678910111213141516171819public class AsyncBasicCancel extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; channel.basicConsume(\"throwable.queue.direct\", new DefaultConsumer(channel) &#123; @Override public void handleCancelOk(String consumerTag) &#123; System.out.println(\"收到来自消息中间件代理的basic.cancel-ok回复,consumerTag=\" + consumerTag); &#125; @Override public void handleCancel(String consumerTag) throws IOException &#123; System.out.println(\"收到来自消息中间件代理的basic.cancel回复,consumerTag=\" + consumerTag); &#125; &#125;); &#125;); &#125;&#125; 一般情况下，我们应该同时考虑情况一和情况二有可能同时发生(也就是前面说到的竞争)，并且做好相应的处理即可。","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"RabbitMQ","slug":"Middleware/RabbitMQ","permalink":"http://throwable.club/blog/categories/Middleware/RabbitMQ/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://throwable.club/blog/tags/RabbitMQ/"}]},{"title":"RabbitMQ消息发送、消费和确认","slug":"rabbitmq-send-consume-confirm","date":"2018-11-25T14:06:08.000Z","updated":"2018-11-25T14:13:55.422Z","comments":true,"path":"2018/11/25/rabbitmq-send-consume-confirm/","link":"","permalink":"http://throwable.club/2018/11/25/rabbitmq-send-consume-confirm/","excerpt":"","text":"前提 前一篇文章介绍到RabbitMQ相关组件的声明，组件声明完成之后，就可以发送消息和消费消息，消费消息的时候需要考虑消息的确认。 消息的发送 消息的发送只依赖于交互器(名称)、可选路由键和可选的Header参数，可选路由键和Header可以认为是路由参数。因为RabbitMQ有四种内建的交换器，加上特殊的默认交换器可以认为有五种，这里列举一下通过这五种交换器发送消息需要的参数： 交换器类型 路由参数 默认交换器(AMQP default) 交换器名称(空字符串)和队列名称 Direct交换器 交换器名称和路由键 Fanout交换器 交换器名称(API中必须提供路由键，可以随意输入) Topic交换器 交换器名称和路由键 Headers交换器 交换器名称和Header参数(API中必须提供路由键，可以随意输入) 消息的发布依赖于Channel的basicPublish方法，按照惯例查看其重载方法中参数列表长度最大的方法： 123456void basicPublish(String exchange, String routingKey, boolean mandatory, boolean immediate, BasicProperties props, byte[] body) throws IOException; exchange：交换器名称。 routingKey：路由键。 mandatory：是否强制的，如果此属性设置为true，消息发布的时候如果根据exchange和routingKey无法找到可达的目标队列，会调用AMQP方法basic.return将该消息返回给消息发布者；如果此属性设置为false，出现上面的情况，消息会被消息中间件代理直接丢弃。 immediate：是否立即的，如果此属性设置为true，消息通过exchange和routingKey找到目标队列(一个或者多个)，如果所有的目标队列都没有消费者，那么会调用AMQP方法basic.return将该消息返回给消息发布者。 props：BasicProperties类型，消息属性或者叫消息元数据，com.rabbitmq.client.MessageProperties已经提供了一些列的实现，如果不满足可以使用BasicProperties.Builder自行构建。 body：字节数组类型，消息的有效负载，一般我们说的消息或者消息体就是指这个。 值得注意的是：immediate属性在RabbitMQ-3.0版本已经被移除，具体原因是： 翻译一下就是：immediate属性原有的功能对于基础代码的复杂性太高，特别是在镜像队列的条件下。它还影响到镜像队列的性能优化，推荐使用TTL(Time To Live，队列消息过期特性)或者DLX(Dead Letter Exchange，死信交换器)替代。在RabbitMQ-3.0后的版本如果immediate设置为true，会抛异常。 举个消息发送的例子(下面的例子中，每次发送之前都声明交换器、队列和绑定，实际上我们不需要这样操作，如果依赖于Servlet容器，可以在容器启动之后做一次声明即可)： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class MessageSendMain extends BaseChannelFactory &#123; private static final String DEFAULT_EXCHANGE = \"\"; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; //使用Direct类型的交换器 channel.queueDeclare(\"throwable.queue.direct\", true, false, false, null); channel.exchangeDeclare(\"throwable.exchange.direct\", BuiltinExchangeType.DIRECT, true, false, null); channel.queueBind(\"throwable.queue.direct\", \"throwable.exchange.direct\", \"direct.routingKey\", null); //发送\"Direct Message\"到队列throwable.queue.direct channel.basicPublish(\"throwable.exchange.direct\", \"direct.routingKey\", MessageProperties.TEXT_PLAIN, \"Direct Message\".getBytes(StandardCharsets.UTF_8)); //其实也可以通过默认的交换器直接发送消息到队列throwable.queue.direct channel.basicPublish(DEFAULT_EXCHANGE, \"throwable.queue.direct\", MessageProperties.TEXT_PLAIN, \"Direct Message\".getBytes(StandardCharsets.UTF_8)); //使用Fanout类型的交换器 channel.queueDeclare(\"throwable.queue.fanout\", true, false, false, null); channel.exchangeDeclare(\"throwable.exchange.fanout\", BuiltinExchangeType.FANOUT, true, false, null); //这里路由键随便写，或者用空字符串也可以 channel.queueBind(\"throwable.queue.fanout\", \"throwable.exchange.fanout\", \"random\", null); channel.basicPublish(\"throwable.exchange.fanout\", \"random\", MessageProperties.TEXT_PLAIN, \"Fanout Message\".getBytes(StandardCharsets.UTF_8)); //使用Topic类型的交换器 channel.queueDeclare(\"throwable.queue.topic\", true, false, false, null); channel.exchangeDeclare(\"throwable.exchange.topic\", BuiltinExchangeType.TOPIC, true, false, null); channel.queueBind(\"throwable.queue.topic\", \"throwable.exchange.topic\", \"topic.routingKey.#\", null); channel.basicPublish(\"throwable.exchange.topic\", \"topic.routingKey.throwable\", MessageProperties.TEXT_PLAIN, \"Topic Message\".getBytes(StandardCharsets.UTF_8)); //使用Headers类型的交换器 channel.queueDeclare(\"throwable.queue.headers\", true, false, false, null); channel.exchangeDeclare(\"throwable.exchange.headers\", BuiltinExchangeType.HEADERS, true, false, null); Map&lt;String, Object&gt; headerBindingArgs = new HashMap&lt;&gt;(8); headerBindingArgs.put(\"headers.name\", \"throwable\"); headerBindingArgs.put(\"headers.age\", 25); headerBindingArgs.put(\"x-match\", \"all\"); //这里路由键随便写，或者用空字符串也可以,要添加Headers参数到绑定参数中 channel.queueBind(\"throwable.queue.headers\", \"throwable.exchange.headers\", \"random\", headerBindingArgs); AMQP.BasicProperties basicProperties = MessageProperties.TEXT_PLAIN; //这里发送消息的时候要添加Headers参数到消息属性中 AMQP.BasicProperties realBasicProperties = basicProperties.builder().headers(headerBindingArgs).build(); channel.basicPublish(\"throwable.exchange.headers\", \"random\", realBasicProperties, \"Headers Message\".getBytes(StandardCharsets.UTF_8)); &#125;); &#125;&#125; 消息的元数据 消息元数据接口是com.rabbitmq.client.BasicProperties，实现类是com.rabbitmq.client.AMQP$BasicProperties，可以看一下具体的属性： 123456789101112131415161718public static class BasicProperties extends com.rabbitmq.client.impl.AMQBasicProperties &#123; private String contentType; private String contentEncoding; private Map&lt;String,Object&gt; headers; private Integer deliveryMode; private Integer priority; private String correlationId; private String replyTo; private String expiration; private String messageId; private Date timestamp; private String type; private String userId; private String appId; private String clusterId; //省略Setter、Getter和Builder方法&#125; 属性分析： contentType：消息内容类型，类似于HTTP协议中的Content-Type，例如：application/json。 contentEncoding：消息内容编码，类似于MIME的内容编码，例如：gzip。 headers：头部属性，K-V结构，一般使用在Headers的交换器和绑定中，很多时候被开发者滥用用来传输一些自定义属性，其实也无可厚非。 deliveryMode：消息的持久化模式，deliveryMode=1代表消息不持久化(nonpersistent)，deliveryMode=2代表消息持久化(persistent)。 priority：消息优先级，可选值为0-255，值越大优先级越大，注意要和队列的优先级区分。 correlationId：客户端定义的用于客户端区分和标识消息的唯一标记。 replyTo：需要应答的目标队列名，只有一个持有值，不会有任何额外的操作，spring-amqp模块对这个值做了额外的操作，不要混淆原生Java驱动和二次封装的框架。 expiration：消息过期时间，单位为毫秒。 messageId：消息的唯一标识，消息中间件代理对消息接收去重的一个重要标识。 timestamp：消息发送时的时间戳。 type：可选的消息类型。 userId：可选的发布消息的用户的唯一标识。 appId：可选的发布消息的应用的唯一标识。 clusterId：集群唯一标识，AMQP-0-9-1已经弃用，供RabbitMQ集群应用程序使用的集群内路由标识符。 消息元数据的每个属性基本对应着AMQP规范中的属性值，以上的描述来源于AMQP协议，RabbitMQ中的实现要自行实践相关的属性。com.rabbitmq.client.MessageProperties中已经有几个现成的BasicProperties实例，如果合适的话可以直接拿过来使用： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class MessageProperties &#123; /** Empty basic properties, with no fields set */ public static final BasicProperties MINIMAL_BASIC = new BasicProperties(null, null, null, null, null, null, null, null, null, null, null, null, null, null); /** Empty basic properties, with only deliveryMode set to 2 (persistent) */ public static final BasicProperties MINIMAL_PERSISTENT_BASIC = new BasicProperties(null, null, null, 2, null, null, null, null, null, null, null, null, null, null); /** Content-type \"application/octet-stream\", deliveryMode 1 (nonpersistent), priority zero */ public static final BasicProperties BASIC = new BasicProperties(\"application/octet-stream\", null, null, 1, 0, null, null, null, null, null, null, null, null, null); /** Content-type \"application/octet-stream\", deliveryMode 2 (persistent), priority zero */ public static final BasicProperties PERSISTENT_BASIC = new BasicProperties(\"application/octet-stream\", null, null, 2, 0, null, null, null, null, null, null, null, null, null); /** Content-type \"text/plain\", deliveryMode 1 (nonpersistent), priority zero */ public static final BasicProperties TEXT_PLAIN = new BasicProperties(\"text/plain\", null, null, 1, 0, null, null, null, null, null, null, null, null, null); /** Content-type \"text/plain\", deliveryMode 2 (persistent), priority zero */ public static final BasicProperties PERSISTENT_TEXT_PLAIN = new BasicProperties(\"text/plain\", null, null, 2, 0, null, null, null, null, null, null, null, null, null);&#125; mandatory属性的作用 mandatory属性主要是用于消息发送路由失败后配置消息返回(return)功能使用，可以故意造一下消息发布路由失败的场景，验证一下mandatory属性的作用。之前的例子中曾经建立过一个Direct类型的交换throwable.exchange.direct和队列throwable.queue.direct基于路由键direct.routingKey进行了绑定，我们开启mandatory特性，故意把路由键弄错，看效果： 12345678910111213141516171819202122232425262728public class MandatoryMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; channel.basicPublish(\"throwable.exchange.direct\", \"doge\", true, false, null, \"Mandatory Message\".getBytes(StandardCharsets.UTF_8)); //使用addReturnListener(ReturnCallBack)也可以 channel.addReturnListener(new ReturnListener() &#123; @Override public void handleReturn(int replyCode, String replyText, String exchange, String routingKey, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; StringBuilder builder = new StringBuilder(); builder.append(\"返回码:\").append(replyCode).append(\"\\n\"); builder.append(\"返回信息:\").append(replyText).append(\"\\n\"); builder.append(\"交换器:\").append(exchange).append(\"\\n\"); builder.append(\"路由键:\").append(routingKey).append(\"\\n\"); builder.append(\"消息体:\").append(new String(body, StandardCharsets.UTF_8)); System.out.println(builder.toString()); &#125; &#125;); //因为是异步回调,这里要sleep一下 Thread.sleep(2000); &#125;); &#125;&#125; 执行之后，控制台打印： 12345返回码:312返回信息:NO_ROUTE交换器:throwable.exchange.direct路由键:doge消息体:Mandatory Message 可见路由失败的消息直接原样返回，这样就能确保路由错误的情况下消息也不会丢失。 消息发送的确认机制 前面提到的mandatory属性和消息返回机制能保证路由失败的消息也不丢失，实际上消息发送的时候允许使用消息发送确认(Confirm)机制，这样可以确认客户端发送的消息是否已经到达了消息中间件代理。消息发送的确认机制主要包括轻量级的确认和消息事务，这一小节介绍一下轻量级的确认。消息发送的轻量级确认需要把信道(Channel)更变为Confirm模式，通过等待消息中间件代理消息是否到达的确认回调，依赖到的方法或者类如下： 1234567891011121314151617181920212223//信道更变为Confirm模式Confirm.SelectOk confirmSelect() throws IOException;//等待消息中间件确认消息到达 - 同步阻塞法法boolean waitForConfirms() throws InterruptedException;//等待消息中间件确认消息到达，可以设置超时，单位毫秒 - 同步阻塞方法boolean waitForConfirms(long timeout) throws InterruptedException, TimeoutException;//等待消息中间件确认消息到达，存在任一消息未到达，则抛出IOException - 同步阻塞方法void waitForConfirmsOrDie() throws IOException, InterruptedException;//等待消息中间件确认消息到达，可以设置超时，单位毫秒，存在任一消息未到达，则抛出IOException - 同步阻塞方法void waitForConfirmsOrDie(long timeout) throws IOException, InterruptedException, TimeoutException;//消息发布确认回调接口public interface ConfirmListener &#123; void handleAck(long deliveryTag, boolean multiple) throws IOException; void handleNack(long deliveryTag, boolean multiple) throws IOException;&#125; 消息发送确认模式开启之后，每条消息都会基于同一个信道下新增一个投递标签(deliveryTag)属性，deliveryTag属性是从1开始递增的整数，只要新建一个信道实例就会重置为1，一定要十分注意，这个消息投递标签和消息消费中的信封(Envelope)中的deliveryTag不是同一个属性，后者虽然也是从1开始递增，但是它是基于队列而不是信道。举个简单的使用例子： 123456789101112131415161718192021222324252627public class ConfirmMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; channel.addConfirmListener(new ConfirmListener() &#123; @Override public void handleAck(long deliveryTag, boolean multiple) throws IOException &#123; System.out.println(String.format(\"消息发送确认回调成功,序号:%s,是否批量:%s\", deliveryTag, multiple)); &#125; @Override public void handleNack(long deliveryTag, boolean multiple) throws IOException &#123; System.out.println(String.format(\"消息发送确认回调失败,序号:%s,是否批量:%s\", deliveryTag, multiple)); &#125; &#125;); channel.confirmSelect(); channel.basicPublish(\"throwable.exchange.direct\", \"direct.routingKey\", MessageProperties.TEXT_PLAIN, \"Direct Message\".getBytes(StandardCharsets.UTF_8)); if (!channel.waitForConfirms()) &#123; System.out.println(\"消息发送确认失败!\"); &#125; else &#123; System.out.println(\"消息发送确认成功!\"); &#125; Thread.sleep(2000); &#125;); &#125;&#125; 消息发布确认基本上是遵循下面的代码模板： 12345678channel.addConfirmListener(new ConfirmListener() &#123; //...&#125;;channel.confirmSelect();channel.basicPublish();if (!channel.waitForConfirms()) &#123; //...&#125; 当然，这里演示的仅仅是单条的消息发布确认，这种做法性能会相对低下，但是可靠性会提高，编码难度也相对比较低。 消息发布事务 消息发布事务能够保证消息发布到RabbitMQ的Broker这个动作是一个原子操作，也就是开启了消息发布事务模式，消息能明确知道发布成功或者失败。使用消息发布事务需要把信道转换为事务模式，然后进行消息发布和事务提交(或者回滚)，依赖于下面的方法： 12345678//信道转换为事务模式Tx.SelectOk txSelect() throws IOException;//提交事务Tx.CommitOk txCommit() throws IOException;//回滚事务Tx.RollbackOk txRollback() throws IOException; 消息发布事务的基本代码模板如下： 1234567try &#123; channel.txSelect(); channel.basicPublish(); channel.txCommit(); &#125;catch (Exception e)&#123; channel.txRollback(); &#125; 举个简单的例子： 123456789101112131415public class MessagePublishTxMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; try &#123; channel.txSelect(); channel.basicPublish(\"throwable.exchange.direct\", \"direct.routingKey\", MessageProperties.TEXT_PLAIN, \"Direct Message\".getBytes(StandardCharsets.UTF_8)); channel.txCommit(); &#125; catch (Exception e) &#123; channel.txRollback(); &#125; &#125;); &#125;&#125; 一般来说，事物基本是遵循&quot;等价交换的原则&quot;，消息发布的可靠性是需要性能换取的，消息发布事务的可靠性是最高的，但是代价是它的性能是比较低的。 消息的消费 消息消费主要包括推模式和拉模式，区别如下： 推模式：客户端注册消费者到消息中间件代理的队列，也就是对队列进行订阅，消息中间件代理通过队列投递(deliver)消息到消费者中，典型方法是basic-consume。 拉模式：客户端主动向消息中间件代理拉取队列中的消息，典型方法是basic-get。 消息消费之推模式 推模式下，消息的消费依赖于Channel的basicConsume方法(用的是最新的RabbitMQ的Java驱动，关于消息消费的方法新增了不少，在3.X版本只有几个方法)： 1234567891011121314151617String basicConsume(String queue, boolean autoAck, String consumerTag, boolean noLocal, boolean exclusive, Map&lt;String, Object&gt; arguments, Consumer callback) throws IOException;String basicConsume(String queue, boolean autoAck, String consumerTag, boolean noLocal, boolean exclusive, Map&lt;String, Object&gt; arguments, DeliverCallback deliverCallback, CancelCallback cancelCallback, ConsumerShutdownSignalCallback shutdownSignalCallback) throws IOException; 别看第二个方法的参数列表很庞大很吓人，它只是把com.rabbitmq.client.Consumer接口的部分方法拆解出来做成单独的接口，方便使用Lambda表达式，参数分析如下： queue：消费者订阅的队列名称。 autoAck：是否自动确认(主动ack)。 consumerTag：消费者标签，队列中消费者的唯一标识，如果不指定则由消息中间件代理自动生成，停止消费者和取消消费者都是基于此标识属性。 noLocal：是否非本地的，如果此属性为true，则消息中间件代理不会投递消息到此消费者如果发布消息使用的连接和当前消费者建立的通道所在的连接是同一个连接，但是RabbitMQ不支持此属性。 exclusive：是否独占(排他)的，如果此属性为true，队列中只能有一个消费者(也就是当前设置了exclusive=true的消费者)，消费者关闭(shutdown) arguments：消费者参数，K-V结构。 下面看一下Consumer、DeliverCallback、CancelCallback和ConsumerShutdownSignalCallback的定义： 12345678910111213141516171819202122232425262728293031323334353637383940414243public interface Consumer &#123; //创建消费者成功的回调 void handleConsumeOk(String consumerTag); //消费者取消成功的回调 - 主动调用basicCancel或者队列删除等因素 void handleCancelOk(String consumerTag); //消费者取消的回调 - 主动调用basicCancel或者队列删除等因素 void handleCancel(String consumerTag) throws IOException; //消费者关闭的信号回调 void handleShutdownSignal(String consumerTag, ShutdownSignalException sig); //AMQP方法basic.recover-ok的回调 void handleRecoverOk(String consumerTag); //消息推模式下接受消息中间件代理投递的消息 - 核心方法 void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException;&#125;@FunctionalInterfacepublic interface DeliverCallback &#123; //Delivery中持有了Envelope、AMQP.BasicProperties和消息体body void handle(String consumerTag, Delivery message) throws IOException;&#125;@FunctionalInterfacepublic interface CancelCallback &#123; void handle(String consumerTag) throws IOException;&#125;@FunctionalInterfacepublic interface ConsumerShutdownSignalCallback &#123; void handleShutdownSignal(String consumerTag, ShutdownSignalException sig); &#125; DeliverCallback、CancelCallback和ConsumerShutdownSignalCallback实际上就是把Consumer接口中的部分方法抽离出来编写为函数式接口，没有特别的东西，所以我们还是关注Consumer接口的使用就可以了。Consumer接口有一个默认的实现类DefaultConsumer，可以直接使用。在旧版本的Java驱动中还存在一个废弃的QueueingConsumer，在5.X版本的驱动已经删除该类。其实，我们也可以自行实现Consumer接口，因为DefaultConsumer也仅仅是对Consumer接口进行了空实现，具体的方法还是需要我们覆盖实现自定义的逻辑。这里举个简单的使用例子： 123456789101112131415161718192021public class ConsumeMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; channel.basicConsume(\"throwable.queue.direct\", true, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(\"消息序号:\" + envelope.getDeliveryTag()); System.out.println(\"交换器:\" + envelope.getExchange()); System.out.println(\"路由键:\" + envelope.getRoutingKey()); System.out.println(\"消息内容:\" + new String(body, StandardCharsets.UTF_8)); &#125; &#125;); //消息消费是异步的，要想办法阻塞消费者所在的线程和主线程，否则会退出 Thread.sleep(Integer.MAX_VALUE); &#125;); &#125;&#125; 可以从Web管理界面看到消费者已经启动，消费者标签是由RabbitMQ代理随机生成的，我们开启了消息自动确认，所以Ack required一栏是空心的圆形，也就是不需要进行消息消费确认。还有一点需要注意的是：Consumer接口的回调也就是DefaultConsumer中的方法回调是委托到RabbitMQ的Java驱动中的线程池执行，过程是异步的，也就是我们在写Demo的时候需要想办法挂起DefaultConsumer实例所在的线程和主线程，否则会导致线程退出无法消费消息。 消息消费之拉模式 拉模式下，消息消费主要依赖于Channel的basicGet方法： 1GetResponse basicGet(String queue, boolean autoAck) throws IOException; 此方法很简单，只依赖于队列名称和是否自动确认两个参数，如果autoAck为false，需要手动确认。返回值如下： 123456789101112public class GetResponse &#123; //信封对象，主要用于获取消息的投递标签DeliveryTag、交换器、路由键等 private final Envelope envelope; //消息元数据 private final BasicProperties props; //消息体 private final byte[] body; //当前队列中剩余消息数量，只是个参考值 private final int messageCount; //省略Getter方法&#125; 信封对象中的投递标签DeliveryTag很重要，用于手动确认的时候指定对应的值。举个简单的使用例子： 12345678910public class BasicGetMain extends BaseChannelFactory&#123; public static void main(String[] args) throws Exception&#123; provideChannel(channel -&gt; &#123; GetResponse getResponse = channel.basicGet(\"throwable.queue.direct\", true); System.out.println(String.format(\"消息内容:%s,消息序号:%s\", new String(getResponse.getBody(), StandardCharsets.UTF_8), getResponse.getEnvelope().getDeliveryTag())); &#125;); &#125;&#125; 消息消费的确认机制 消息消费的确认机制保障消息中间件代理的消息成功投递到消费者中，主要包括三种类确认： 主动积极确认：主动积极确认成功后，消息会从队列中移除，支持批量确认操作，典型方法是basic-ack，下面直接叫ack。 主动消极确认：消极积极确认成功后，基于basic-get或者basic-consume等到的消息标签，可以选择消息重新入队列或者直接丢弃，支持批量操作，典型方法是basic-nack，下面直接叫nack。 拒绝：基于basic-get或者basic-consume等到的消息标签进行消息拒绝，可以选择丢弃或者重新入队，下面叫做reject。 nack和reject的基本功能是相同的，nack同时支持批量操作和单条操作，而reject只支持单条操作。消息消费确认其实是手动确认，如果针对的是basicConsume方法，则其autoAck属性需要设置为false，否则有可能会出现重复确认导致异常。 ack ack依赖于Channel的basicAck方法： 1void basicAck(long deliveryTag, boolean multiple) throws IOException; deliveryTag：Envelope(信封)对象中的消息标签。 multiple：是否使用批量积极确认，如果此属性为true，则消息标签小于当前deliveryTag的所有消息都会被主动积极确认，不了解此属性最好使用false。 1234567891011121314151617181920212223public class AckMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; //这里autoAck设置为false channel.basicConsume(\"throwable.queue.direct\", false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(\"消息序号:\" + envelope.getDeliveryTag()); System.out.println(\"交换器:\" + envelope.getExchange()); System.out.println(\"路由键:\" + envelope.getRoutingKey()); System.out.println(\"消息内容:\" + new String(body, StandardCharsets.UTF_8)); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;); //消息消费是异步的，要想办法阻塞消费者所在的线程和主线程，否则会退出 Thread.sleep(Integer.MAX_VALUE); &#125;); &#125;&#125; nack nack依赖于Channel的basicNack方法： 1void basicNack(long deliveryTag, boolean multiple, boolean requeue) throws IOException; deliveryTag：Envelope(信封)对象中的消息标签。 multiple：是否使用批量消极确认，如果此属性为true，则消息标签小于当前deliveryTag的所有消息都会被主动消极确认，不了解此属性最好使用false。 requeue：是否重新入队，如果此属性为true，消息会被重新放置回去对应队列(如果可能的话，会放回到原来的位置)，如果此属性为false，消息直接被丢弃。 1234567891011121314151617181920212223public class NackMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; //这里autoAck设置为false channel.basicConsume(\"throwable.queue.direct\", false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(\"消息序号:\" + envelope.getDeliveryTag()); System.out.println(\"交换器:\" + envelope.getExchange()); System.out.println(\"路由键:\" + envelope.getRoutingKey()); System.out.println(\"消息内容:\" + new String(body, StandardCharsets.UTF_8)); channel.basicNack(envelope.getDeliveryTag(), false, false); &#125; &#125;); //消息消费是异步的，要想办法阻塞消费者所在的线程和主线程，否则会退出 Thread.sleep(Integer.MAX_VALUE); &#125;); &#125;&#125; 属性requeue如果设置为true，需要谨慎设计程序的逻辑，否则很有可能导致消息一直重复消费失败并且重复重新入队，表现为消费者线程出现死循环逻辑，耗尽服务器CPU资源。 reject reject的用法和nack基本一致，不过reject没有批量处理功能，依赖于Channel的basicReject方法： 1void basicReject(long deliveryTag, boolean requeue) throws IOException; 简单举个使用例子： 123456789public class RejectMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; GetResponse getResponse = channel.basicGet(\"throwable.queue.direct\", true); channel.basicReject(getResponse.getEnvelope().getDeliveryTag(), false); &#125;); &#125;&#125; 消费消息不进行消息确认会怎么样 消息消费方法basiConsume中的autoAck属性设置为false，但是消费者接收到消息后不进行消息确认会怎么样？举个例子： 123456789101112131415161718192021222324public class NoneAckMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; channel.basicPublish(\"throwable.exchange.direct\", \"direct.routingKey\", MessageProperties.TEXT_PLAIN, \"Direct Message\".getBytes(StandardCharsets.UTF_8)); //autoAck = false channel.basicConsume(\"throwable.queue.direct\", false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(\"消息序号:\" + envelope.getDeliveryTag()); System.out.println(\"交换器:\" + envelope.getExchange()); System.out.println(\"路由键:\" + envelope.getRoutingKey()); System.out.println(\"消息内容:\" + new String(body, StandardCharsets.UTF_8)); &#125; &#125;); //消息消费是异步的，要想办法阻塞消费者所在的线程和主线程，否则会退出 Thread.sleep(Integer.MAX_VALUE); &#125;); &#125;&#125; 执行之后，控制台输出： 1234消息序号:1交换器:throwable.exchange.direct路由键:direct.routingKey消息内容:Direct Message 查看RabbitMQ的Web管理界面，发现消息由Ready转变为Unacked状态： 尝试终止消费者所在线程，再次观察RabbitMQ的Web管理界面对应队列： 发现消息由Unacked状态恢复为Ready。这里需要注意，只有Ready状态的消息才能被消息中间件代理投递到消费者。总的来说就是： 被路由到队列的新消息的状态为Ready，这种消息可以被消息中间件代理投递到客户端的消费者中。 客户端消费者在消费消息的时候，如果采用手动确认(autoAck=false)并且没有主动确认(也就是没有调用basicAck、basicNack或者basicReject)，那么消息就会变为Unacked状态，Unacked状态的消息只有当所有的消费者线程终止的时候，才会重新转变为Ready状态。 小结 这篇文章仅仅从基本使用来分析RabbitMQ中的消息发送、消费和确认的例子。关于消息发布确认机制和消息发布事务机制后面有专门的文章分析其性能和具体使用场景。 RabbitMQ中的消息发布确认(publish confirm)和消息消费(投递)确认(deliver confirm)能够确保消息发布和消息消费阶段消息不会丢失，至于策略应该根据具体场景选择，autoAck并不适合所有的场景。 (本文完 c-2-d e-a-20181125)","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"RabbitMQ","slug":"Middleware/RabbitMQ","permalink":"http://throwable.club/blog/categories/Middleware/RabbitMQ/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://throwable.club/blog/tags/RabbitMQ/"}]},{"title":"RabbitMQ队列、交换器和绑定的操作","slug":"rabbitmq-component-operation","date":"2018-11-24T18:23:59.000Z","updated":"2018-11-24T18:26:00.922Z","comments":true,"path":"2018/11/25/rabbitmq-component-operation/","link":"","permalink":"http://throwable.club/2018/11/25/rabbitmq-component-operation/","excerpt":"","text":"前提 如果能提前先阅读一下之前写过的一篇文章理解RabbitMQ中的AMQP-0-9-1模型，那么这篇文章应该会比较容易理解。 引入依赖 先确认已经安装了RabbitMQ的服务，并且开启了Web管理插件，方便直接从Web管理界面查找到队列、交换器和绑定。个人有软件洁癖，喜欢把软件和依赖保持升级到最新版本。引入RabbitMQ的Java驱动： 12345&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.5.0&lt;/version&gt;&lt;/dependency&gt; 本文介绍RabbitMQ通过其Java驱动声明队列、交换器和绑定。对于队列和交换器，其首次声明也是创建的操作。队列、交换器和绑定的声明依赖于通道(Channel)，对应的是com.rabbitmq.client.Channel接口。在使用RabbitMQ的Java驱动的时候，一般在我们都使用下面的方式进行组件的声明操作： 1、基于RabbitMQ连接信息构建com.rabbitmq.client.ConnectionFactory实例。 2、基于ConnectionFactory新建一个com.rabbitmq.client.Connection实例。 3、基于Connection新建一个com.rabbitmq.client.Channel实例。 4、通过Channel实例声明(删除、解除绑定)队列、交换器或者绑定(Channel实例是可以复用的)。 虽然Channel实例是可以复用的，但是为了简化测试方法的编写，我们可以写下个简单的基础类： 1234567891011121314151617181920212223public abstract class BaseChannelFactory &#123; protected static void provideChannel(ChannelAction channelAction) throws Exception &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost(\"localhost\"); connectionFactory.setPort(5672); connectionFactory.setUsername(\"guest\"); connectionFactory.setPassword(\"guest\"); Connection connection = connectionFactory.newConnection(); Channel channel = connection.createChannel(); try &#123; channelAction.doInChannel(channel); &#125; finally &#123; channel.close(); connection.close(); &#125; &#125; interface ChannelAction &#123; void doInChannel(Channel channel) throws Exception; &#125;&#125; 这样子，每次调用都是新建的Connection和Channel，我们只需要重点关注ChannelAction的实现即可。 在查看一下框架类型的API文档的时候有个很重要的技巧：如果提供的方法有重载，只需要看参数最多的基础方法。 队列的相关操作 队列的相关参数主要包括队列的声明(declare)、删除(delete)和清空队列消息(purge)。 队列的声明 队列的声明依赖于com.rabbitmq.client.Channel的queueDeclare方法。queueDeclare方法的多个重载都是同步方法，提供同样功能的还有一个异步方法queueDeclareNoWait。下面选取queueDeclare参数列表长度最大的方法进行分析： 12345Queue.DeclareOk queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments) throws IOException; 参数如下： queue：需要声明的队列名称。 durable：是否开启持久化特性，如果此属性为true，消息中间件代理重启后队列会被重新声明(也就是说不会被删除)，注意这个特性和消息的持久化特性完全不相关。 exclusive：是否独占的，如果此属性为true，则队列的存在性绑定在创建它的连接上，意味着队列只能被一个连接使用并且连接关闭之后队列会被删除。 autoDelete：是否自动删除，如果此属性为true，意味着队列不被使用的时候会被消息中间件代理删除，实际上意味着队列至少有一个消费者并且最后一个消费者解除订阅状态(一般是消费者对应的通道关闭)后队列会自动删除。 arguments：K-V结构，队列参数，一般和消息中间件代理或者插件的特性相关，如消息的过期时间(Message TTL)和队列长度等，后面会有专门文章介绍这些特性。 队列声明的返回值是Queue.DeclareOk实例： 123456public interface DeclareOk extends Method &#123; String getQueue(); int getMessageCount(); int getConsumerCount(); //...&#125; 可以从中得知声明的队列名、队列中的消息数量、队列当前的消费者数量，这个返回值对于无参数的queueDeclare方法十分有意义： 1Queue.DeclareOk queueDeclare() throws IOException; 因为这个方法声明的队列名称是由消息中间件代理随机生成，队列名就是通过返回值告知客户端的。这里贴一个简单的例子： 123456789public class QueueDeclareMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; AMQP.Queue.DeclareOk declareOk = channel.queueDeclare(\"throwable.queue\", true, false, false, null); System.out.println(declareOk.getQueue()); &#125;); &#125;&#125; 运行后控制台打印throwable.queue说明队列声明成功，可以查看RabbitMQ的Web管理界面： 可见队列的确已经被创建，但是Bindings一栏显示队列只绑定到默认的交换器中，这个时候其实已经可以通过默认的交换器向队列中发送消息。队列声明失败的时候会直接抛出异常，一般是IOException。上面的例子中是我们最常见到的队列声明方式，声明出来的队列开启了队列持久化特性、非独占的、非自动删除的，也就是即使RabbitMQ服务重启了，队列依然会存在(被重新声明)，但是并不是所有的场景都需要这种声明方式(说实话，目前笔者没碰到不使用这种声明方式的场景，有点惭愧)。还有一点需要重点关注：队列可以重复声明，但是声明所使用的参数必须一致，否则会抛出异常。 队列的被动(Passive)声明 队列的被动声明，其实是检查队列在消息代理中间件是否存在的判断方法，依赖于Channel的queueDeclarePassive方法： 1Queue.DeleteOk queueDelete(String queue) throws IOException; 它只依赖于一个参数-队列名称，如果队列名称对应的队列已经存在，则返回Queue.DeleteOk实例，如果队列不存在，会抛出IOException，通常是一个被包装为IOException的ShutdownSignalException，而ShutdownSignalException是运行时异常的子类。举个列子： 12345678910111213public class QueueDeclarePassiveMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; //队列throwable.queue已存在 AMQP.Queue.DeclareOk declareOk = channel.queueDeclarePassive(\"throwable.queue\"); System.out.println(declareOk.getQueue()); //队列throwable.queue.passive不存在 declareOk = channel.queueDeclarePassive(\"throwable.queue.passive\"); System.out.println(declareOk.getQueue()); &#125;); &#125;&#125; 由于throwable.queue.passive队列不存在，因此会抛出IOException，追踪异常栈查看底层的异常是： Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method&lt;channel.close&gt;(reply-code=404, reply-text=NOT_FOUND - no queue ‘throwable.queue.passive’ in vhost ‘/’, class-id=50, method-id=10) 利用这个方法的特性可以尝试编写一个方法确认队列是否存在，例如： 12345678910private static boolean isQueueExisted(Channel channel, String queueName) &#123; boolean flag = false; try &#123; channel.queuePurge(queueName); flag = true; &#125; catch (IOException e) &#123; //no-op &#125; return flag;&#125; 队列的删除 队列的删除对应的是Channel的queueDelete方法： 1234//基于队列名删除队列，不关注队列是否被使用，也不关注队列中是否存在消息Queue.DeleteOk queueDelete(String queue) throws IOException;Queue.DeleteOk queueDelete(String queue, boolean ifUnused, boolean ifEmpty) throws IOException; 参数如下： queue：队列名称。 ifUnused：判断队列是否被不被使用，如果为true，只有不被使用的队列才能被删除。 ifEmpty：判断队列是否为空(没有消息积压)，如果为true，只有空的队列才能被删除。 其实也就是只依赖队列名的单参数的queueDelete就是强制删除方法，举个例子： 12345678910public class QueueDeleteMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; AMQP.Queue.DeleteOk deleteOk = channel.queueDelete(\"throwable.queue\"); System.out.println(String.format(\"Delete queue [%s] successfully,message count = %d!\", \"throwable.queue\", deleteOk.getMessageCount())); &#125;); &#125;&#125; 一般来说，队列的删除功能权限最好不要下放到应用程序中，除非有特殊的需要，如果需要删除队列，最好使用queueDelete(String queue, boolean ifUnused, boolean ifEmpty)方法，否则有可能造成消息丢失。 队列的清空 队列的清空操作会删除队列中的所有消息，依赖的方法是Channel的queuePurge方法： 1Queue.PurgeOk queuePurge(String queue) throws IOException; 此方法会基于队列名清除对应队列中的所有内容，使用的时候需要谨慎，举个例子： 12345678910public class QueuePurgeMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; AMQP.Queue.PurgeOk purgeOk = channel.queuePurge(\"throwable.queue\"); System.out.println(String.format(\"Purge queue [%s] successfully,message count = %d!\", \"throwable.queue\", purgeOk.getMessageCount())); &#125;); &#125;&#125; 其实在Web管理界面中，每个队列所在的页面下有一个Purge按钮，该按钮的功能就是清空队列消息。 交换器的相关操作 交换器的相关操作主要包括交换器的声明和删除。 交换器的声明 交换器的声明方法依赖于Channel的exchangeDeclare方法，按照惯例查看它重载方法中参数列表长度最大的方法： 12345678910111213Exchange.DeclareOk exchangeDeclare(String exchange, BuiltinExchangeType type, boolean durable, boolean autoDelete, boolean internal, Map&lt;String, Object&gt; arguments) throws IOException;Exchange.DeclareOk exchangeDeclare(String exchange, String type, boolean durable, boolean autoDelete, boolean internal, Map&lt;String, Object&gt; arguments) throws IOException; 参数解释如下： exchange：交换器名称。 type：type可以为字符串或者BuiltinExchangeType类型，BuiltinExchangeType枚举只包括DIRECT、FANOUT、TOPIC和HEADERS，而字符串类型除了定义四种内建类型的交换器，实际上RabbitMQ允许自定义类型的交换器，不过很少使用。 durable：是否开启持久化特性，如果此属性为true，则消息中间件代理重启后，交换器不会删除，实际上是会被重新声明一次。 autoDelete：是否自动删除，如果此属性为true，当最后一个绑定到此交换器的队列解除绑定关系，交换器会被删除。 internal：是否内部的，如果此属性为true，该交换器只允许消息中间件代理使用，客户端无法使用。 arguments：交换器参数，K-V结构，参数一般和消息中间件代理或者插件的一些扩展特性相关，不依赖这些扩展特性直接使用null即可。 举个简单的使用例子： 12345678910public class ExchangeDeclareMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; channel.exchangeDeclare(\"throwable.exchange.direct\", BuiltinExchangeType.DIRECT, true, false, null); &#125;); &#125;&#125; 执行完毕之后，RabbitMQ的Web管理器的Exchanges的选项卡中就能看到对应的交换器： 因为没有声明交换器和队列的绑定，所以Bindings一栏是空的。 交换器的被动声明 交换器的被动声明类似于队列的被动声明，用于通过交换器名称检查是否存在对应的交换器，依赖于Channel的exchangeDeclarePassive方法： 1Exchange.DeclareOk exchangeDeclarePassive(String name) throws IOException; 举个例子： 1234567891011public class ExchangeDeclarePassiveMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; //throwable.exchange.direct存在 channel.exchangeDeclarePassive(\"throwable.exchange.direct\"); //throwable.exchange.fanout不存在,会抛出IOException channel.exchangeDeclarePassive(\"throwable.exchange.fanout\"); &#125;); &#125;&#125; 类似可以写个检查交换器是否存在的工具方法： 12345678910private boolean isExchangeExisted(Channel channel, String exchangeName) &#123; boolean flag = false; try &#123; channel.exchangeDeclarePassive(exchangeName); flag = true; &#125; catch (IOException e) &#123; //no-op &#125; return flag;&#125; 交换器的删除 交换器的删除依赖于Channel的exchangeDelete方法，方法只依赖于交换器的名称。 1Exchange.DeleteOk exchangeDelete(String exchange) throws IOException; 举个例子： 123456789public class ExchangeDeleteMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; channel.exchangeDelete(\"throwable.exchange.direct\"); &#125;); &#125;&#125; 绑定的声明 前面提到队列的声明和交换器的声明，队列和交换器创建之后，需要声明两者的绑定关系，Channel中提供了两种声明绑定关系的方法： queueBind方法，声明队列和交换器的绑定关系。 exchangeBind方法，声明交换器和交换器之间的绑定关系。 同时也提供解除绑定的方法： queueUnbind方法：解除队列和交换器的绑定关系。 exchangeUnbind方法：解除交换器之间的绑定关系。 队列和交换器的绑定和解绑 队列和交换器的绑定主要依赖于Channel的queueBind，而解绑主要依赖于queueUnbind方法，按照惯例看这两个方法重载方法中参数列表长度最大的方法： 123456789Queue.BindOk queueBind(String queue, String exchange, String routingKey, Map&lt;String, Object&gt; arguments) throws IOException;Queue.UnbindOk queueUnbind(String queue, String exchange, String routingKey, Map&lt;String, Object&gt; arguments) throws IOException; 注意这两个方法的参数列表完全一致： queue：队列名称。 exchange：交换器名称。 routingKey：路由键。 arguments：绑定参数，K-V结构，参数一般和消息中间件代理或者插件的一些扩展特性相关，不依赖这些扩展特性直接使用null即可。 基于声明队列和交换器间的绑定举个例子： 123456789public class QueueBindMain extends BaseChannelFactory&#123; public static void main(String[] args) throws Exception&#123; provideChannel(channel -&gt; &#123; //throwable.exchange.direct-&gt;throwable.queue channel.queueBind(\"throwable.queue\",\"throwable.exchange.direct\", \"throwable.routingKey\",null); &#125;); &#125;&#125; 声明成功之后，可以查看对应的队列和交换器中的Bindings一栏： 可见交换器和队列成功建立了绑定关系。接着可以尝试使用解绑方法进行绑定解除： 12345678public class QueueUnbindMain extends BaseChannelFactory&#123; public static void main(String[] args) throws Exception&#123; provideChannel(channel -&gt; &#123; channel.queueUnbind(\"throwable.queue\",\"throwable.exchange.direct\", \"throwable.routingKey\",null); &#125;); &#125;&#125; 交换器之间的绑定和解绑 RabbitMQ中支持两个不同的交换器之间进行绑定和解除绑定，绑定方法依赖于Channel的exchangeBind方法，解除绑定依赖于Channel的exchangeUnbind方法： 123456789Exchange.BindOk exchangeBind(String destination, String source, String routingKey, Map&lt;String, Object&gt; arguments) throws IOException;Exchange.UnbindOk exchangeUnbind(String destination, String source, String routingKey, Map&lt;String, Object&gt; arguments) throws IOException; 参数如下： destination：目标交换器名称。 source：来源交换器名称。 routingKey：路由键。 arguments：参数，K-V结构。 我们先预先建立一个Fanout类型的交换器，命名为throwable.exchange.fanout，接着，我们把Fanout类型的交换器throwable.exchange.fanout作为来源交换器，绑定到Direct类型的目标交换器throwable.exchange.direct上： 123456789public class ExchangeBindMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; channel.exchangeDeclare(\"throwable.exchange.fanout\", BuiltinExchangeType.FANOUT, true, false, null); channel.exchangeBind(\"throwable.exchange.direct\", \"throwable.exchange.fanout\", \"exchange.routingKey\"); &#125;); &#125;&#125; 现在可以查看交换器throwable.exchange.direct的Bindings一栏的信息： 这就是现在我们通过交换器throwable.exchange.fanout发送消息，消息会先到达交换器throwable.exchange.direct，然后再路由到队列throwable.queue中。多重绑定的交换器在一些复杂的场景有重要的作用，但是目前来看还没有碰到使用场景(一般来说，存在即合理)。 接着举个例子进行交换器之间的绑定解除： 12345678public class ExchangeUnbindMain extends BaseChannelFactory &#123; public static void main(String[] args) throws Exception &#123; provideChannel(channel -&gt; &#123; channel.exchangeUnbind(\"throwable.exchange.direct\", \"throwable.exchange.fanout\", \"exchange.routingKey\"); &#125;); &#125;&#125; 小结 一旦队列和交换器之间的绑定关系声明完毕，我们可以通过交换器和可选的路由键向队列中发送消息，可以注册消费者到队列中获取消息。RabbitMQ中的队列、交换器和绑定有个特点：组件的声明只承认第一次，也就是队列名、交换器名是唯一的，组件可以反复声明，不过声明所使用的参数必须和首次声明的参数一致。 (本文完 c-3-d e-a-20181125)","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"RabbitMQ","slug":"Middleware/RabbitMQ","permalink":"http://throwable.club/blog/categories/Middleware/RabbitMQ/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://throwable.club/blog/tags/RabbitMQ/"}]},{"title":"理解RabbitMQ中的AMQP-0-9-1模型","slug":"rabbitmq-amqp-model","date":"2018-11-21T15:51:22.000Z","updated":"2018-11-22T15:38:56.037Z","comments":true,"path":"2018/11/21/rabbitmq-amqp-model/","link":"","permalink":"http://throwable.club/2018/11/21/rabbitmq-amqp-model/","excerpt":"","text":"前提 之前有个打算在学习RabbitMQ之前，把AMQP详细阅读一次，挑出里面的重点内容。后来找了下RabbitMQ的官方文档，发现了有一篇文档专门介绍了RabbitMQ中实现的AMQP模型部分，于是直接基于此文档和个人理解写下这篇文章。 AMQP协议 AMQP全称是Advanced Message Queuing Protocol，它是一个(分布式)消息传递协议，使用和符合此协议的客户端能够基于使用和符合此协议的消息传递中间件代理(Broker，也就是经纪人，个人感觉叫代理合口一些)进行通信。AMQP目前已经推出协议1.0，实现此协议的比较知名的产品有StormMQ、RabbitMQ、Apache Qpid等。RabbitMQ实现的AMQP版本是0.9.1，官方文档中也提供了该协议pdf文本下载，有兴趣可以翻阅一下。 消息中间件代理的职责 Messaging Broker，这里称为消息中间件代理。它的职责是从发布者(Publisher，或者有些时候称为Producer，生产者)接收消息，然后把消息路由到消费者(Consumer，或者有些时候称为Listener，监听者)。 因为消息中间件代理、发布者客户端和消费者客户端都是基于AMQP这一网络消息协议，所以消息中间件代理、发布者客户端和消费者客户端可以在不同的机器上，从而实现分布式通讯和服务解耦。 消息中间件代理不仅仅提供了消息接收和消息路由这两个基本功能，还有其他高级的特性如消息持久化功能、监控功能等等。 AMQP-0-9-1在RabbitMQ中的基本模型 AMQP-0-9-1模型的基本视图是：消息发布者将消息发布到交换器(Exchange)中，交换器的角色有点类似于日常见到的邮局或者信箱。然后，交换器把消息的副本分发到队列(Queue)中，分发消息的时候遵循的规则叫做绑定(Binding)。接着，消息中间件代理向订阅队列的消费者发送消息(push模式)，或者消费者也可以主动从队列中拉取消息(fetch/pull模式)。 发布者在发布消息的时候可以指定消息属性(消息元数据)，某些消息元数据可能由消息中间件代理使用，其他消息元数据对于消息中间件代理而言是不透明的，仅供消息消费者使用。 由于网络是不可靠的，客户端可能无法接收消息或者处理消息失败，这个时候消息中间件代理无法感知消息是否正确传递到消费者中，因此AMQP模型提供了消息确认(Message Acknowledgement)的概念：当消息传递到消费者，消费者可以自动向消息中间件代理确认消息已经接收成功或者由应用程序开发者选择手动确认消息已经接收成功并且向消息中间件代理确认消息，消息中间件代理只有在接收到该消息(或者消息组)的确认通知后才会从队列中完全删除该消息。 在某些情况下，交换器无法正确路由到队列中，那么该消息就会返回给发布者，或者丢弃，或者如果消息中间件代理实现了&quot;死信队列(Dead Letter Queue)&quot;扩展，消息会被放置到死信队列中。消息发布者可以选择使用对应的参数控制路由失败的处理策略。 交换器和交换器类型 交互器(Exchange)是消息发送的第一站目的地，它的作用就是就收消息并且将其路由到零个或者多个队列。路由消息的算法取决于交互器的类型和路由规则(也就是Binding)。RabbitMQ消息中间件代理支持四种类型的交互器，分别是： 交换器类型 Broker默认预声明的交换器 Direct (空字符串[(AMQP default)])和amq.direct Fanout amq.fanout Topic amq.topic Headers amq.match (和RabbitMQ中的amq.headers) 声明交互器的时候需要提供一些列的属性，其中比较重要的属性如下： Name：交互器的名称。 Type：交换器的类型。 Durability：(交换器)持久化特性，如果启动此特性，则Broker重启后交换器依然存在，否则交换器会被删除。 Auto-delete：是否自动删除，如果启用此特性，当最后一个队列解除与交换器的绑定关系，交换器会被删除。 Arguments：可选参数，一般配合插件或者Broker的特性使用。 之所以存在Durability和Auto-delete特性是因为并发所有的场景和用例都要求交互器是持久化的。 Direct交换器 Direct类型的交换器基于消息路由键(RoutingKey)把消息传递到队列中。Direct交换器是消息单播路由的理想实现(当然，用于多播路由也可以)，它的工作原理如下： 队列使用路由键K绑定到交换器。 当具有路由键R的新消息到达交换器的时候，如果K = R，那么交换器会把消息传递到队列中。 默认交换器 默认交换器(Default Exchange)是一种特殊的Direct交互器，它的名称是空字符串(也就是&quot;&quot;)，它由消息中间件代理预声明，在RabbitMQ Broker中，它在Web管理界面中的名称是(AMQP default)。每个新创建的队列都会绑定到默认交换器，路由键就是该队列的队列名，也就是所有的队列都可以通过默认交换器进行消息投递，只需要指定路由键为相应的队列名即可。 Fanout交换器 Fanout其实是一个组合单词，fan也就是扇形，out就是向外发散的意思，Fanout交换器可以想象为&quot;扇形&quot;交换器。Fanout交换器会忽略路由键，它会路由消息到所有绑定到它的队列。也就是说，如果有N个队列绑定到一个Fanout交换器，当一个新的消息发布到该Fanout交换器，那么这条新消息的一个副本会分发到这N个队列中。Fanout交换器是消息广播路由的理想实现。 Topic交换器 Topic交换器基于路由键和绑定队列和交换器的模式进行匹配从而把消息路由到一个或者多个队列。绑定队列和交换器的Topic模式(这个模式串其实就是声明绑定时候的路由键，和消息发布的路由键并非同一个)一般使用点号(dot，也就是’.’)分隔，例如source.target.key，绑定模式支持通配符： 符号#匹配一个或者多个词，例如：source.target.#可以匹配source.target.doge、source.target.doge.throwable等等。 符号*只能匹配一个词，例如：source.target.*可以匹配source.target.doge、source.target.throwable等等。 对每一条消息，Topic交换器会遍历所有的绑定关系，检查消息指定的路由键是否匹配绑定关系中的路由键，如果匹配，则将消息推送到相应队列。 Topic交换器是消息多播路由的理想实现。 Headers交换器 Headers交换器是一种不常用的交换器，它使用多个属性进行路由，这些属性一般称为消息头，它不使用路由键进行消息路由。消息头(Message Headers)是消息属性(消息元数据)部分，因此，使用Headers交换器在建立队列和交换器的绑定关系的时候需要指定一组键值对，发送消息到Headers交换器时候，需要在消息属性中携带一组键值对作为消息头。消息头属性支持匹配规则x-match如下： x-match = all：表示所有的键值对都匹配才能接受到消息。 x-match = any：表示只要存在键值对匹配就能接受到消息。 Headers交换器也是忽略路由键的，只依赖于消息属性中的消息头进行消息路由。 队列 AMQP 0-9-1模型中的队列与其他消息或者任务队列系统中的队列非常相似：它们存储应用程序所使用的消息。队列和交换器的基本属性有类似的地方： Name：队列名称。 Durable：是否持久化，开启持久化意味着消息中间件代理重启后队列依然存在，否则队列会被删除。 Exclusive：是否独占的，开启队列独占特性意味着队列只能被一个连接使用并且连接关闭之后队列会被删除。 Auto-delete：是否自动删除，开启自动删除特性意味着队列至少有一个消费者并且最后一个消费者解除订阅状态(一般是消费者对应的通道关闭)后队列会自动删除。 Arguments：队列参数，一般和消息中间件代理或者插件的特性相关，如消息的过期时间(Message TTL)和队列长度等。 一个队列只有被声明(Declare)了才能使用，也就是队列的第一次声明就是队列的创建操作(因为第一次声明的时候队列并不存在)。如果使用相同的参数再次声明已经存在的队列，那么此次声明会不生效(当然也不会出现异常)。但是如果使用不相同的参数再次声明已经存在的队列，那么会抛出通道级别的异常，异常代码是406(PRECONDITION_FAILED)。 队列名称 队列名必须由255字节(bytes)长度以内的UTF-8编码字符组成。实现AMQP 0-9-1规范的消息中间件代理具备自动生成随机队列名的功能，也就是在声明队列的时候，队列名指定为空字符串，那么消息中间件代理会自动生成一个队列名，并且在队列声明的返回结果中带上对应的队列名。 以&quot;amq.&quot;开头的队列是由消息中间件代理内部生成的，有其特殊的作用，因此不能声明此类名称的新队列，否则会导致通道级别的异常，异常代码为403(ACCESS_REFUSED)。 队列的持久化特性 持久化的队列会持久化到磁盘中，这种队列在消息中间件代理重启后不会被删除。不开启持久化特性的队列称为瞬时(transient)队列，并非所有的场景都需要开启队列的持久化特性。 队列的持久化特性并不意味着路由到它上面的消息是持久化的，也就是队列的持久化跟消息的持久化是两回事。如果息中间件代理挂了，它重启后会重新声明开启了持久化特性的队列，这些队列中只有使用了消息持久化特性的消息会被恢复。 绑定 绑定(Binding)是交换器路由消息到队列的规则。例如交换器E可以路由消息到队列Q，那么Q必须通过一定的规则绑定到E。绑定中使用的某些交换器的类型决定了它可以使用可选的路由键(RoutingKey)。路由键的作用类似于过滤器，可以筛选某些发布到交换器的消息路由到目标队列。 如果发布的消息没有路由到任意一个目标队列，例如，消息已经发布到交换器，交换器中没有任何绑定，这个时候消息会被丢弃或者返回给发布者，取决于消息发布者发布消息时候使用的参数。 消费者 如果队列只有发布者生产消息，那么是没有意义的，必须有消费者对消息进行使用，或者叫这个操作为消息消费，消息消费的方式有两种： 消息代理中间件向消费者推送消息(推模式，代表方法是basic.consume)。 消费者主动向消息代理中间件拉取消息(拉模式，代表方法是basic.get)。 使用推模式的情况下，消费者必须指定需要订阅的队列。每个队列可以存在多个消费者，或者仅仅注册一个独占的消费者。 每个消费者(订阅者)都有一个称为消费者标签(consumer tag)的标识符，消费者标签是一个字符串。通过消费者标签可以实现取消订阅的操作。 消息确认 消费者应用程序有可能在接收和处理消息的时候崩溃，也有可能因为网络原因导致消息中间件代理投递消息到消费者的时候失败了，这样就会催生一个问题：AMQP消息中间件代理应该在什么时候从队列中删除消息？因此，AMQP 0-9-1规范提供了两种选择： 消息中间件代理向应用程序发送消息(使用AMQP方法basic.deliver或basic.get-ok)。 应用程序收到消息后向消息中间件代理发送确认(使用AMQP方法basic.ack &lt;= 个人感觉这个地方少写了basic.nack和basic.reject) 前一种称为自动确认模型(动作触发的同时进行了消息确认)，后一种称为显式确认模型。显式确认模型中，需要消费者主动向消息中间件代理进行消息主动确认，这个消息主动确认动作的执行时机完全由应用程序控制。消息主动确认有三种方式：积极确认(ack)、消极确认(nack)和拒绝(reject)。 预取消息 预取消息(Prefetching Messages)是一个特性。对于多个消费者共享同一个队列的情况，能够告知消息中间件代理在发送下一个确认之前指定每个消费者一次可以接收消息的消息量。这个特性可以理解为简单的负载均衡技术，在批量发布消息的场景下能够提高吞吐量。 消息属性和有效负载 AMQP模型中，消息具有属性值。AMQP 0-9-1规范定义了一些常见的属性，一般开发人员不需要太关注这些属性： Content type Content encoding Routing key Delivery mode (persistent or not) Message priority Message publishing timestamp Expiration period Publisher application id 这些通用的属性一般是消息中间件代理使用的，还有可以定制的可选属性header，形式是键值对，类似于HTTP中的请求头。消息属性是在发布消息的时候设置的。 AMQP消息还有一个有效载荷(payload，其实就是消息数据体)，AMQP代理将其视为不透明的字节数组，也就是AMQP代理不会检查或者修改消息的有效载荷。有些消息可能只包含属性而没有有效负载。通常使用序列化格式(如JSON，Thrift，Protocol Buffers和MessagePack)来序列化和结构化数据，以便将其作为消息有效负载发布。在一般约定下，消息属性中的Content type和Content encoding一般可以表明其序列化的方式。 消息发布支持消息的持久化特性，消息持久化特性开启后，消息中间件代理会把消息保存到磁盘中，如果重启代理消息也不会丢失。开启消息持久化特性将会影响性能，主要是因为涉及到刷盘操作。 AMQP-0-9-1方法 AMQP 0-9-1定义了一些方法，对应了客户端和消息中间件代理之间交互的一些操作方法，这些操作方法的设计跟面向对象编程语言中的方法没有任何共同之处。常用的交换器相关的操作方法有： exchange.declare exchange.declare-OK exchange.delete exchange.delete-OK 在逻辑上，上面几个操作方法在客户端和消息中间件代理之间的交互如下： 对于队列，也有类似的操作方法： queue.declare queue.declare-OK queue.delete queue.delete-OK 并非所有的AMQP操作方法都有响应结果操作方法，像消息发布方法basic.publish的使用是最广泛的，此操作方法没有对应的响应结果操作方法。有些操作方法可能有多个响应结果(操作方法)，例如basic.get。 连接(Connection) AMQP的连接(Connection)通常是长期存在的。AMQP是一种使用TCP进行可靠传递的应用程序级协议。AMQP连接使用用户身份验证，可以使用TLS(SSL)进行保护。当应用程序不再需要连接到AMQP代理时，它应该正常关闭AMQP连接，而不是突然关闭底层TCP连接。 通道(Channel) 某些应用程序需要与AMQP代理程序建立多个连接。但是，不希望同时打开许多TCP连接，因为这样做会消耗系统资源并使配置防火墙变得十分困难。通道(Channel)可以认为是&quot;共享一个单独的TCP连接的轻量级连接&quot;，一个AMQP连接可以拥有多个通道。 对于使用了多线程处理的应用程序，有一种使用场景十分普遍：每个线程开启一个新的通道使用，这些通道是线程间隔离的。 另外，每个特定的通道和其他通道是相互隔离的，每个执行的AMQP操作方法(包括响应)都携带一个通道的唯一标识，这样客户端就能通过该通道的唯一标识得知操作方法是对应哪个通道发生的。 虚拟主机(Virtual Host) 为了使单个消息中间件代理可以托管多个完全隔离的&quot;环境&quot;(这里的隔离指的是用户组、交互器、队列等)，AMQP提供了虚拟主机(Virtual Host)的概念。多个虚拟主机类似于许多主流的Web服务器的虚拟主机，提供了AMQP组件完全隔离的环境。AMQP客户端可以在连接消息中间件代理时指定需要连接的虚拟主机。 个人理解 关于Exchange、Queue和Binding 理解RabbitMQ中的AMQP模型，其实从开发者的角度来看，最重要的是Exchange、Queue、Binding三者的关系，这里谈谈个人的见解。消息的发布第一站总是Exchange，从模型上看，消息发布无法直接发送到队列中。Exchange本身不存储消息，它在接收到消息之后，会基于路由规则也就是Binding，把消息路由到目标Queue中。从实际操作来看，声明路由规则总是在发布消息和消费消息之前，也就是一般步骤如下： 1、声明Exchange。 2、声明Queue。 3、基于Exchange和Queue声明Binding，这个过程有可能自定义一个RoutingKey。 4、通过Exchange消息发布，这个过程有可能使用到上一步定义的RoutingKey。 5、通过Queue消费消息。 我们最关注的两个阶段，消息发布和消息消费中，消息发布实际上只跟Exchange有关，而消息消费实际上只跟Queue有关。Binding实际上就是Exchange和Queue的契约关系，会直接影响消息发布阶段的消息路由。那么，路由失败一般是什么情况导致的？路由失败，其实就是消息已经发布到Exchange，而Exchange中从既有的Binding中无法找到存在的目标Queue用于传递消息副本(一般而言，很少人会发送消息到一个不存在的Exchange)。消息路由失败，从理解AMQP的模型来看，可以从根本上避免的，除非是消息发布者故意胡乱使用或者人为错误使用了未存在的RoutingKey、Exchange或者说是Binding关系而导致的。 关于Exchange的类型 AMQP-0-9-1模型中支持了四种交换器direct(单播)、fanout(广播)、topic(多播)、headers，实际上，从使用者角度来看，四种交换器的功能是可以相互取代的。例如可以使用fanout类型交换器实现广播，其实使用direct类型交换器也是可以实现广播的，只是对应的direct类型交换器需要通过多个路由键绑定到多个目标队列中。在面对生产环境的技术选型的时候，我们需要考虑性能、维护难度、合理性等角度去考虑选择什么类型的交换器，就上面的广播消息的例子，显然使用fanout类型交换器可以避免声明多个绑定关系，这样在性能、合理性上是更优的选择。 关于负载均衡 在AMQP-0-9-1模型中，负载均衡的实现是基于消费者而不是基于队列(准确来说应该是消息传递到队列的方式)。实际上，出现消息生产速度大大超过消费者的消费速度的时候，队列中有可能会出现消息积压。AMQP-0-9-1模型中没有提供基于队列负载均衡的特性，也就是出现消息生产速度大大超过消费者的消费速度时候，并不会把消息路由到多个队列中，而是通过预取消息(Prefetching Messages)的特性，确定消息者的消费能力，从而调整消息中间件代理推送消息到对应消费者的数量，这样就能够实现消费速度快的消费者能够消费更多的消息，减少产生有消费者处于饥饿状态和有消费者长期处于忙碌状态的问题。 关于消息确认机制 AMQP中提供的消息确认机制主要包括积极确认(一般叫ack，Acknowledgement)、消极确认(一般叫nack，Negative Acknowledgement)和拒绝(reject)。消息确认机制是保证消息不丢失的重要措施，当消费者接收到消息中间件代理推送的消息时候，需要主动通知消息中间件代理消息已经确认投递成功，然后消息中间件代理才会从队列中删除对应的消息。没有主动确认的消息就会变为&quot;nack&quot;状态，可以想象为暂存在队列的&quot;nack区&quot;中，这些消息不会投递到消费者，直到消费者重启后，&quot;nack区&quot;中的消息会重新变为&quot;ready&quot;状态，可以重新投递给消费者。关于消息确认机制其实场景比较复杂，后面再做一篇文章专门分析。 小结 参考资料： AMQP 0-9-1 Model Explained","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"RabbitMQ","slug":"Middleware/RabbitMQ","permalink":"http://throwable.club/blog/categories/Middleware/RabbitMQ/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://throwable.club/blog/tags/RabbitMQ/"}]},{"title":"RabbitMQ服务端的安装和使用","slug":"rabbitmq-installation","date":"2018-11-17T17:05:10.000Z","updated":"2018-11-20T15:50:43.252Z","comments":true,"path":"2018/11/18/rabbitmq-installation/","link":"","permalink":"http://throwable.club/2018/11/18/rabbitmq-installation/","excerpt":"","text":"前提 工作接近3年，一直有使用RabbitMQ作为服务间解耦的中间件，但是一直没有做一系列学习和总结，这里决心做一个系列总结一下RabbitMQ的运维、使用以及生产中遇到的问题等，以便日后直接拿起来使用。整个系列使用的Linux系统为CentOS 7的最新版本CentOS-7-x86_64-Minimal-1804。而RabbitMQ Server使用当前最新的版本3.7.9.RELEASE。 RabbitMQ Server的安装 RabbitMQ Server使用Erlang语言编写，Erlang语言的并发编程支持比较优异，所以我们要先安装Erlang(类似于我们需要运行Java程序，要先安装JVM)： 12# 添加erlang的yum源rpm --import https://packages.erlang-solutions.com/rpm/erlang_solutions.asc 或者直接在目录/etc/yum.repos.d/手动添加一个新的.repo文件(文件名可以随意如erlang.repos)，内容是： 123456[erlang-solutions]name=CentOS $releasever - $basearch - Erlang Solutionsbaseurl=https://packages.erlang-solutions.com/rpm/centos/$releasever/$basearchgpgcheck=1gpgkey=https://packages.erlang-solutions.com/rpm/erlang_solutions.ascenabled=1 然后执行命令安装Erlang： 12# 安装erlangsudo yum install erlang 安装完成之后Erlang会自行后台运行，输入erl就能进入Erlang的命令行工具说明安装成功： 安装Erlang过程中如果提示： 12error: Failed dependencies: epel-release is needed by erlang-solutions-1.0-1.noarch 说明缺少epel-release依赖，通过sudo yum install epel-release安装epel-release即可。 接着可以安装RabbitMQ Server，先下载其RPM安装包： 12## 下载wget https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.7.9/rabbitmq-server-3.7.9-1.el7.noarch.rpm 接着在下载文件目录中执行安装命令： 1234# 在Yum仓库可以使用之前，需要让RPM工具信任RabbitMQ的rpm包的签名，需要执行下面的命令rpm --import https://www.rabbitmq.com/rabbitmq-release-signing-key.asc# Yum安装yum install rabbitmq-server-3.7.9-1.el7.noarch.rpm 安装完成后，RabbitMQ Server会自行在后台运行，这个时候可以执行命令rabbitmqctl status验证其状态： RabbitMQ Server启动于停止 RabbitMQ Server已经成功安装为CentOS 7的服务，它的启动和停止可以直接使用systemctl命令： 1234567891011121314# 启动systemctl start rabbitmq-server# 停止systemctl stop rabbitmq-server# 重启systemctl restart rabbitmq-server# 前台启动,shell关闭会shutdownrabbitmq-server start# 后台启动rabbitmq-server -detached 当然，也可以使用RabbitMQ Server的rabbitmqctl命令(格式是：rabbitmqctl [-n &lt;node&gt;] [-l] [-q] &lt;command&gt; [&lt;command options&gt;])： 1234# 停止Erlang上的node节点rabbitmqctl stop_app# 启动rabbitmqctl start_app 安装Web管理插件 RabbitMQ Server管理插件的命令是rabbitmq-plugins [-n &lt;node&gt;] [-l] [-q] &lt;command&gt; [&lt;command options&gt;]，command部分目前只有下面几个： 123456Commands: disable &lt;plugin&gt;|--all [--offline] [--online] enable &lt;plugin&gt;|--all [--offline] [--online] help &lt;command&gt; list [pattern] [--verbose] [--minimal] [--enabled] [--implicitly-enabled] set [&lt;plugin&gt;] [--offline] [--online] 我们可以通过命令rabbitmq-plugins list先展示所有可用的插件： 其中的rabbitmq_management就是我们需要安装的Web管理界面，执行下面的命令启用Web管理插件： 1rabbitmq-plugins enable rabbitmq_management 实际上是启用了rabbitmq_management、rabbitmq_management_agent、rabbitmq_web_dispatch三个插件。插件启动完毕后，我们需要添加一个新的用户或者修改原有的guest用户的权限，因为guest用户只允许使用localhost访问Web管理界面。 用户管理 用户账号密码管理常用命令如下： 12345678910# 新增一个用户rabbitmqctl add_user $&#123;username&#125; $&#123;password&#125;# 修改用户密码rabbitmqctl change_password $&#123;old_password&#125; $&#123;new_password&#125;# 验证用户密码rabbitmqctl authenticate_user $&#123;username&#125; $&#123;password&#125;# 删除用户rabbitmqctl delete_user $&#123;username&#125;# 展示用户列表rabbitmqctl list_users 例如创建一个用户名和密码都是root的账号：rabbitmqctl add_user root root。 用户角色(Tag)管理常用命令格式是rabbitmqctl set_user_tags ${username} ${tag...}，可选的角色类型有： Tag 描述 none 无角色，新创建的用户就是这类型的Tag management 具备Web管理界面访问权限 policymaker 具备management所有权限，可以管理policy和parameter monitoring 具备policymaker所有权限，可以监控连接、channel、节点信息等 administrator 管理员权限 例如为root账号赋予管理员权限：rabbitmqctl set_user_tags root administrator。 用户权限(Permission)管理常用命令如下： 12345678910111213141516# 添加权限# vhost：虚拟host，默认为\"/\"# username：用户名# conf：配置权限，可以用正则表达式# write：写权限，可以用正则表达式# read：读权限，可以用正则表达式rabbitmqctl set_permissions [-p vhost] $&#123;username&#125; $&#123;conf&#125; $&#123;write&#125; $&#123;read&#125;# 查看虚拟host权限rabbitmqctl list_permissions [-p vhost]# 查看用户权限rabbitmqctl list_user_permissions $&#123;username&#125;# 清除用户权限rabbitmqctl clear_permissions [-p vhost] $&#123;username&#125; 例如为root账号赋予虚拟host为&quot;/&quot;下的所有的配置、读、写权限：rabbitmqctl set_permissions root &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;。 我们可以使用root账号登录Web管理界面： 关于RabbitMQ Server多租户(虚拟Host)、角色、权限管理的其他细节暂时不展开，因为可能需要不少的篇幅才能说明。 小结 关于RabbitMQ Server的命令和运维方面的东西暂时不大量展开，按照上面几节搭建好的RabbitMQ服务对于测试或者开发调试已经基本可用，接着就可以通过官方提供的例子进行学习。 参考资料： https://www.erlang-solutions.com/resources/download.html http://www.rabbitmq.com/install-rpm.html 参考资料的链接在将来不确定是否有变，主要是参考了erlang和rabbitmq的官方文档的安装提示。 (本文完 c-1-d e-20181118)","categories":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/categories/Middleware/"},{"name":"RabbitMQ","slug":"Middleware/RabbitMQ","permalink":"http://throwable.club/blog/categories/Middleware/RabbitMQ/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"http://throwable.club/blog/tags/Middleware/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://throwable.club/blog/tags/RabbitMQ/"}]},{"title":"JVM应用度量框架Micrometer实战","slug":"jvm-micrometer-prometheus","date":"2018-11-17T03:34:18.000Z","updated":"2019-01-08T14:46:58.169Z","comments":true,"path":"2018/11/17/jvm-micrometer-prometheus/","link":"","permalink":"http://throwable.club/2018/11/17/jvm-micrometer-prometheus/","excerpt":"","text":"JVM应用度量框架Micrometer实战 前提 最近线上的项目使用了spring-actuator做度量统计收集，使用Prometheus进行数据收集，Grafana进行数据展示，用于监控生成环境机器的性能指标和业务数据指标。一般，我们叫这样的操作为&quot;埋点&quot;。SpringBoot中的依赖spring-actuator中集成的度量统计API使用的框架是Micrometer，官网是Micrometer.io。在实践中发现了业务开发者滥用了Micrometer的度量类型Counter，导致无论什么情况下都只使用计数统计的功能。这篇文章就是基于Micrometer分析其他的度量类型API的作用和适用场景。 Micrometer提供的度量类库 Meter是指一组用于收集应用中的度量数据的接口，Meter单词可以翻译为&quot;米&quot;或者&quot;千分尺&quot;，但是显然听起来都不是很合理，因此下文直接叫Meter，理解它为度量接口即可。Meter是由MeterRegistry创建和保存的，可以理解MeterRegistry是Meter的工厂和缓存中心，一般而言每个JVM应用在使用Micrometer的时候必须创建一个MeterRegistry的具体实现。Micrometer中，Meter的具体类型包括：Timer，Counter，Gauge，DistributionSummary，LongTaskTimer，FunctionCounter，FunctionTimer和TimeGauge。下面分节详细介绍这些类型的使用方法和实战使用场景。而一个Meter具体类型需要通过名字和Tag(这里指的是Micrometer提供的Tag接口)作为它的唯一标识，这样做的好处是可以使用名字进行标记，通过不同的Tag去区分多种维度进行数据统计。 MeterRegistry MeterRegistry在Micrometer是一个抽象类，主要实现包括： 1、SimpleMeterRegistry：每个Meter的最新数据可以收集到SimpleMeterRegistry实例中，但是这些数据不会发布到其他系统，也就是数据是位于应用的内存中的。 2、CompositeMeterRegistry：多个MeterRegistry聚合，内部维护了一个MeterRegistry的列表。 3、全局的MeterRegistry：工厂类io.micrometer.core.instrument.Metrics中持有一个静态final的CompositeMeterRegistry实例globalRegistry。 当然，使用者也可以自行继承MeterRegistry去实现自定义的MeterRegistry。SimpleMeterRegistry适合做调试的时候使用，它的简单使用方式如下： 123MeterRegistry registry = new SimpleMeterRegistry();Counter counter = registry.counter(\"counter\");counter.increment(); CompositeMeterRegistry实例初始化的时候，内部持有的MeterRegistry列表是空的，如果此时用它新增一个Meter实例，Meter实例的操作是无效的： 123456789CompositeMeterRegistry composite = new CompositeMeterRegistry();Counter compositeCounter = composite.counter(\"counter\");compositeCounter.increment(); // &lt;- 实际上这一步操作是无效的,但是不会报错SimpleMeterRegistry simple = new SimpleMeterRegistry();composite.add(simple); // &lt;- 向CompositeMeterRegistry实例中添加SimpleMeterRegistry实例compositeCounter.increment(); // &lt;-计数成功 全局的MeterRegistry的使用方式更加简单便捷，因为一切只需要操作工厂类Metrics的静态方法： 123Metrics.addRegistry(new SimpleMeterRegistry());Counter counter = Metrics.counter(\"counter\", \"tag-1\", \"tag-2\");counter.increment(); Tag与Meter的命名 Micrometer中，Meter的命名约定使用英文逗号(dot，也就是&quot;.&quot;)分隔单词。但是对于不同的监控系统，对命名的规约可能并不相同，如果命名规约不一致，在做监控系统迁移或者切换的时候，可能会对新的系统造成破坏。Micrometer中使用英文逗号分隔单词的命名规则，再通过底层的命名转换接口NamingConvention进行转换，最终可以适配不同的监控系统，同时可以消除监控系统不允许的特殊字符的名称和标记等。开发者也可以覆盖NamingConvention实现自定义的命名转换规则：registry.config().namingConvention(myCustomNamingConvention);。在Micrometer中，对一些主流的监控系统或者存储系统的命名规则提供了默认的转换方式，例如当我们使用下面的命名时候： 12MeterRegistry registry = ...registry.timer(\"http.server.requests\"); 对于不同的监控系统或者存储系统，命名会自动转换如下： 1、Prometheus - http_server_requests_duration_seconds。 2、Atlas - httpServerRequests。 3、Graphite - http.server.requests。 4、InfluxDB - http_server_requests。 其实NamingConvention已经提供了5种默认的转换规则：dot、snakeCase、camelCase、upperCamelCase和slashes。 另外，Tag(标签)是Micrometer的一个重要的功能，严格来说，一个度量框架只有实现了标签的功能，才能真正地多维度进行度量数据收集。Tag的命名一般需要是有意义的，所谓有意义就是可以根据Tag的命名可以推断出它指向的数据到底代表什么维度或者什么类型的度量指标。假设我们需要监控数据库的调用和Http请求调用统计，一般推荐的做法是： 123MeterRegistry registry = ...registry.counter(\"database.calls\", \"db\", \"users\")registry.counter(\"http.requests\", \"uri\", \"/api/users\") 这样，当我们选择命名为&quot;database.calls&quot;的计数器，我们可以进一步选择分组&quot;db&quot;或者&quot;users&quot;分别统计不同分组对总调用数的贡献或者组成。一个反例如下： 12345678MeterRegistry registry = ...registry.counter(\"calls\", \"class\", \"database\", \"db\", \"users\");registry.counter(\"calls\", \"class\", \"http\", \"uri\", \"/api/users\"); 通过命名&quot;calls&quot;得到的计数器，由于标签混乱，数据是基本无法分组统计分析，这个时候可以认为得到的时间序列的统计数据是没有意义的。可以定义全局的Tag，也就是全局的Tag定义之后，会附加到所有的使用到的Meter上(只要是使用同一个MeterRegistry)，全局的Tag可以这样定义： 1234MeterRegistry registry = ...registry.config().commonTags(\"stack\", \"prod\", \"region\", \"us-east-1\");// 和上面的意义是一样的registry.config().commonTags(Arrays.asList(Tag.of(\"stack\", \"prod\"), Tag.of(\"region\", \"us-east-1\"))); 像上面这样子使用，就能通过主机，实例，区域，堆栈等操作环境进行多维度深入分析。 还有两点点需要注意： 1、Tag的值必须不为null。 2、Micrometer中，Tag必须成对出现，也就是Tag必须设置为偶数个，实际上它们以Key=Value的形式存在，具体可以看io.micrometer.core.instrument.Tag接口： 12345678910111213public interface Tag extends Comparable&lt;Tag&gt; &#123; String getKey(); String getValue(); static Tag of(String key, String value) &#123; return new ImmutableTag(key, value); &#125; default int compareTo(Tag o) &#123; return this.getKey().compareTo(o.getKey()); &#125;&#125; 当然，有些时候，我们需要过滤一些必要的标签或者名称进行统计，或者为Meter的名称添加白名单，这个时候可以使用MeterFilter。MeterFilter本身提供一些列的静态方法，多个MeterFilter可以叠加或者组成链实现用户最终的过滤策略。例如： 1234MeterRegistry registry = ...registry.config() .meterFilter(MeterFilter.ignoreTags(\"http\")) .meterFilter(MeterFilter.denyNameStartsWith(\"jvm\")); 表示忽略&quot;http&quot;标签，拒绝名称以&quot;jvm&quot;字符串开头的Meter。更多用法可以参详一下MeterFilter这个类。 Meter的命名和Meter的Tag相互结合，以命名为轴心，以Tag为多维度要素，可以使度量数据的维度更加丰富，便于统计和分析。 Meters 前面提到Meter主要包括：Timer，Counter，Gauge，DistributionSummary，LongTaskTimer，FunctionCounter，FunctionTimer和TimeGauge。下面逐一分析它们的作用和个人理解的实际使用场景(应该说是生产环境)。 Counter Counter是一种比较简单的Meter，它是一种单值的度量类型，或者说是一个单值计数器。Counter接口允许使用者使用一个固定值(必须为正数)进行计数。准确来说：Counter就是一个增量为正数的单值计数器。这个举个很简单的使用例子： 1234MeterRegistry meterRegistry = new SimpleMeterRegistry();Counter counter = meterRegistry.counter(\"http.request\", \"createOrder\", \"/order/create\");counter.increment();System.out.println(counter.measure()); // [Measurement&#123;statistic='COUNT', value=1.0&#125;] 使用场景： Counter的作用是记录XXX的总量或者计数值，适用于一些增长类型的统计，例如下单、支付次数、Http请求总量记录等等，通过Tag可以区分不同的场景，对于下单，可以使用不同的Tag标记不同的业务来源或者是按日期划分，对于Http请求总量记录，可以使用Tag区分不同的URL。用下单业务举个例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//实体@Datapublic class Order &#123; private String orderId; private Integer amount; private String channel; private LocalDateTime createTime;&#125;public class CounterMain &#123; private static final DateTimeFormatter FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM-dd\"); static &#123; Metrics.addRegistry(new SimpleMeterRegistry()); &#125; public static void main(String[] args) throws Exception &#123; Order order1 = new Order(); order1.setOrderId(\"ORDER_ID_1\"); order1.setAmount(100); order1.setChannel(\"CHANNEL_A\"); order1.setCreateTime(LocalDateTime.now()); createOrder(order1); Order order2 = new Order(); order2.setOrderId(\"ORDER_ID_2\"); order2.setAmount(200); order2.setChannel(\"CHANNEL_B\"); order2.setCreateTime(LocalDateTime.now()); createOrder(order2); Search.in(Metrics.globalRegistry).meters().forEach(each -&gt; &#123; StringBuilder builder = new StringBuilder(); builder.append(\"name:\") .append(each.getId().getName()) .append(\",tags:\") .append(each.getId().getTags()) .append(\",type:\").append(each.getId().getType()) .append(\",value:\").append(each.measure()); System.out.println(builder.toString()); &#125;); &#125; private static void createOrder(Order order) &#123; //忽略订单入库等操作 Metrics.counter(\"order.create\", \"channel\", order.getChannel(), \"createTime\", FORMATTER.format(order.getCreateTime())).increment(); &#125;&#125; 控制台输出： 12name:order.create,tags:[tag(channel=CHANNEL_A), tag(createTime=2018-11-10)],type:COUNTER,value:[Measurement&#123;statistic='COUNT', value=1.0&#125;]name:order.create,tags:[tag(channel=CHANNEL_B), tag(createTime=2018-11-10)],type:COUNTER,value:[Measurement&#123;statistic='COUNT', value=1.0&#125;] 上面的例子是使用全局静态方法工厂类Metrics去构造Counter实例，实际上，io.micrometer.core.instrument.Counter接口提供了一个内部建造器类Counter.Builder去实例化Counter，Counter.Builder的使用方式如下： 1234567891011public class CounterBuilderMain &#123; public static void main(String[] args) throws Exception&#123; Counter counter = Counter.builder(\"name\") //名称 .baseUnit(\"unit\") //基础单位 .description(\"desc\") //描述 .tag(\"tagKey\", \"tagValue\") //标签 .register(new SimpleMeterRegistry());//绑定的MeterRegistry counter.increment(); &#125;&#125; FunctionCounter FunctionCounter是Counter的特化类型，它把计数器数值增加的动作抽象成接口类型ToDoubleFunction，这个接口JDK1.8中对于Function的特化类型接口。FunctionCounter的使用场景和Counter是一致的，这里介绍一下它的用法： 123456789101112131415161718192021public class FunctionCounterMain &#123; public static void main(String[] args) throws Exception &#123; MeterRegistry registry = new SimpleMeterRegistry(); AtomicInteger n = new AtomicInteger(0); //这里ToDoubleFunction匿名实现其实可以使用Lambda表达式简化为AtomicInteger::get FunctionCounter.builder(\"functionCounter\", n, new ToDoubleFunction&lt;AtomicInteger&gt;() &#123; @Override public double applyAsDouble(AtomicInteger value) &#123; return value.get(); &#125; &#125;).baseUnit(\"function\") .description(\"functionCounter\") .tag(\"createOrder\", \"CHANNEL-A\") .register(registry); //下面模拟三次计数 n.incrementAndGet(); n.incrementAndGet(); n.incrementAndGet(); &#125;&#125; FunctionCounter使用的一个明显的好处是，我们不需要感知FunctionCounter实例的存在，实际上我们只需要操作作为FunctionCounter实例构建元素之一的AtomicInteger实例即可，这种接口的设计方式在很多框架里面都可以看到。 Timer Timer(计时器)适用于记录耗时比较短的事件的执行时间，通过时间分布展示事件的序列和发生频率。所有的Timer的实现至少记录了发生的事件的数量和这些事件的总耗时，从而生成一个时间序列。Timer的基本单位基于服务端的指标而定，但是实际上我们不需要过于关注Timer的基本单位，因为Micrometer在存储生成的时间序列的时候会自动选择适当的基本单位。Timer接口提供的常用方法如下： 12345678910111213141516171819202122232425262728293031323334353637public interface Timer extends Meter &#123; ... void record(long var1, TimeUnit var3); default void record(Duration duration) &#123; this.record(duration.toNanos(), TimeUnit.NANOSECONDS); &#125; &lt;T&gt; T record(Supplier&lt;T&gt; var1); &lt;T&gt; T recordCallable(Callable&lt;T&gt; var1) throws Exception; void record(Runnable var1); default Runnable wrap(Runnable f) &#123; return () -&gt; &#123; this.record(f); &#125;; &#125; default &lt;T&gt; Callable&lt;T&gt; wrap(Callable&lt;T&gt; f) &#123; return () -&gt; &#123; return this.recordCallable(f); &#125;; &#125; long count(); double totalTime(TimeUnit var1); default double mean(TimeUnit unit) &#123; return this.count() == 0L ? 0.0D : this.totalTime(unit) / (double)this.count(); &#125; double max(TimeUnit var1); ...&#125; 实际上，比较常用和方便的方法是几个函数式接口入参的方法： 123456Timer timer = ...timer.record(() -&gt; dontCareAboutReturnValue());timer.recordCallable(() -&gt; returnValue());Runnable r = timer.wrap(() -&gt; dontCareAboutReturnValue());Callable c = timer.wrap(() -&gt; returnValue()); 使用场景： 根据个人经验和实践，总结如下： 1、记录指定方法的执行时间用于展示。 2、记录一些任务的执行时间，从而确定某些数据来源的速率，例如消息队列消息的消费速率等。 这里举个实际的例子，要对系统做一个功能，记录指定方法的执行时间，还是用下单方法做例子： 1234567891011121314151617181920212223242526public class TimerMain &#123; private static final Random R = new Random(); static &#123; Metrics.addRegistry(new SimpleMeterRegistry()); &#125; public static void main(String[] args) throws Exception &#123; Order order1 = new Order(); order1.setOrderId(\"ORDER_ID_1\"); order1.setAmount(100); order1.setChannel(\"CHANNEL_A\"); order1.setCreateTime(LocalDateTime.now()); Timer timer = Metrics.timer(\"timer\", \"createOrder\", \"cost\"); timer.record(() -&gt; createOrder(order1)); &#125; private static void createOrder(Order order) &#123; try &#123; TimeUnit.SECONDS.sleep(R.nextInt(5)); //模拟方法耗时 &#125; catch (InterruptedException e) &#123; //no-op &#125; &#125;&#125; 在实际生产环境中，可以通过spring-aop把记录方法耗时的逻辑抽象到一个切面中，这样就能减少不必要的冗余的模板代码。上面的例子是通过Mertics构造Timer实例，实际上也可以使用Builder构造： 123456MeterRegistry registry = ...Timer timer = Timer .builder(\"my.timer\") .description(\"a description of what this timer does\") // 可选 .tags(\"region\", \"test\") // 可选 .register(registry); 另外，Timer的使用还可以基于它的内部类Timer.Sample，通过start和stop两个方法记录两者之间的逻辑的执行耗时。例如： 123456Timer.Sample sample = Timer.start(registry);// 这里做业务逻辑Response response = ...sample.stop(registry.timer(\"my.timer\", \"response\", response.status())); FunctionTimer FunctionTimer是Timer的特化类型，它主要提供两个单调递增的函数(其实并不是单调递增，只是在使用中一般需要随着时间最少保持不变或者说不减少)：一个用于计数的函数和一个用于记录总调用耗时的函数，它的建造器的入参如下： 12345678public interface FunctionTimer extends Meter &#123; static &lt;T&gt; Builder&lt;T&gt; builder(String name, T obj, ToLongFunction&lt;T&gt; countFunction, ToDoubleFunction&lt;T&gt; totalTimeFunction, TimeUnit totalTimeFunctionUnit) &#123; return new Builder&lt;&gt;(name, obj, countFunction, totalTimeFunction, totalTimeFunctionUnit); &#125; ...&#125; 官方文档中的例子如下： 123456IMap&lt;?, ?&gt; cache = ...; // 假设使用了Hazelcast缓存registry.more().timer(\"cache.gets.latency\", Tags.of(\"name\", cache.getName()), cache, c -&gt; c.getLocalMapStats().getGetOperationCount(), //实际上就是cache的一个方法，记录缓存生命周期初始化的增量(个数) c -&gt; c.getLocalMapStats().getTotalGetLatency(), // Get操作的延迟时间总量，可以理解为耗时 TimeUnit.NANOSECONDS); 按照个人理解，ToDoubleFunction用于统计事件个数，ToDoubleFunction用于记录执行总时间，实际上两个函数都只是Function函数的变体，还有一个比较重要的是总时间的单位totalTimeFunctionUnit。简单的使用方式如下： 1234567891011121314public class FunctionTimerMain &#123; public static void main(String[] args) throws Exception &#123; //这个是为了满足参数,暂时不需要理会 Object holder = new Object(); AtomicLong totalTimeNanos = new AtomicLong(0); AtomicLong totalCount = new AtomicLong(0); FunctionTimer.builder(\"functionTimer\", holder, p -&gt; totalCount.get(), p -&gt; totalTimeNanos.get(), TimeUnit.NANOSECONDS) .register(new SimpleMeterRegistry()); totalTimeNanos.addAndGet(10000000); totalCount.incrementAndGet(); &#125;&#125; LongTaskTimer LongTaskTimer也是一种Timer的特化类型，主要用于记录长时间执行的任务的持续时间，在任务完成之前，被监测的事件或者任务仍然处于运行状态，任务完成的时候，任务执行的总耗时才会被记录下来。LongTaskTimer适合用于长时间持续运行的事件耗时的记录，例如相对耗时的定时任务。在Spring应用中，可以简单地使用@Scheduled和@Timed注解，基于spring-aop完成定时调度任务的总耗时记录： 12345@Timed(value = \"aws.scrape\", longTask = true)@Scheduled(fixedDelay = 360000)void scrapeResources() &#123; //这里做相对耗时的业务逻辑&#125; 当然，在非spring体系中也能方便地使用LongTaskTimer： 123456789101112131415public class LongTaskTimerMain &#123; public static void main(String[] args) throws Exception&#123; MeterRegistry meterRegistry = new SimpleMeterRegistry(); LongTaskTimer longTaskTimer = meterRegistry.more().longTaskTimer(\"longTaskTimer\"); longTaskTimer.record(() -&gt; &#123; //这里编写Task的逻辑 &#125;); //或者这样 Metrics.more().longTaskTimer(\"longTaskTimer\").record(()-&gt; &#123; //这里编写Task的逻辑 &#125;); &#125;&#125; Gauge Gauge(仪表)是获取当前度量记录值的句柄，也就是它表示一个可以任意上下浮动的单数值度量Meter。Gauge通常用于变动的测量值，测量值用ToDoubleFunction参数的返回值设置，如当前的内存使用情况，同时也可以测量上下移动的&quot;计数&quot;，比如队列中的消息数量。官网文档中提到Gauge的典型使用场景是用于测量集合或映射的大小或运行状态中的线程数。Gauge一般用于监测有自然上界的事件或者任务，而Counter一般使用于无自然上界的事件或者任务的监测，所以像Http请求总量计数应该使用Counter而非Gauge。MeterRegistry中提供了一些便于构建用于观察数值、函数、集合和映射的Gauge相关的方法： 123List&lt;String&gt; list = registry.gauge(\"listGauge\", Collections.emptyList(), new ArrayList&lt;&gt;(), List::size); List&lt;String&gt; list2 = registry.gaugeCollectionSize(\"listSize2\", Tags.empty(), new ArrayList&lt;&gt;()); Map&lt;String, Integer&gt; map = registry.gaugeMapSize(\"mapGauge\", Tags.empty(), new HashMap&lt;&gt;()); 上面的三个方法通过MeterRegistry构建Gauge并且返回了集合或者映射实例，使用这些集合或者映射实例就能在其size变化过程中记录这个变更值。更重要的优点是，我们不需要感知Gauge接口的存在，只需要像平时一样使用集合或者映射实例就可以了。此外，Gauge还支持java.lang.Number的子类，java.util.concurrent.atomic包中的AtomicInteger和AtomicLong，还有Guava提供的AtomicDouble： 123AtomicInteger n = registry.gauge(\"numberGauge\", new AtomicInteger(0));n.set(1);n.set(2); 除了使用MeterRegistry创建Gauge之外，还可以使用建造器流式创建： 123456//一般我们不需要操作Gauge实例Gauge gauge = Gauge .builder(\"gauge\", myObj, myObj::gaugeValue) .description(\"a description of what this gauge does\") // 可选 .tags(\"region\", \"test\") // 可选 .register(registry); 使用场景： 根据个人经验和实践，总结如下： 1、有自然(物理)上界的浮动值的监测，例如物理内存、集合、映射、数值等。 2、有逻辑上界的浮动值的监测，例如积压的消息、(线程池中)积压的任务等，其实本质也是集合或者映射的监测。 举个相对实际的例子，假设我们需要对登录后的用户发送一条短信或者推送，做法是消息先投放到一个阻塞队列，再由一个线程消费消息进行其他操作： 1234567891011121314151617181920212223242526272829303132public class GaugeMain &#123; private static final MeterRegistry MR = new SimpleMeterRegistry(); private static final BlockingQueue&lt;Message&gt; QUEUE = new ArrayBlockingQueue&lt;&gt;(500); private static BlockingQueue&lt;Message&gt; REAL_QUEUE; static &#123; REAL_QUEUE = MR.gauge(\"messageGauge\", QUEUE, Collection::size); &#125; public static void main(String[] args) throws Exception &#123; consume(); Message message = new Message(); message.setUserId(1L); message.setContent(\"content\"); REAL_QUEUE.put(message); &#125; private static void consume() throws Exception &#123; new Thread(() -&gt; &#123; while (true) &#123; try &#123; Message message = REAL_QUEUE.take(); //handle message System.out.println(message); &#125; catch (InterruptedException e) &#123; //no-op &#125; &#125; &#125;).start(); &#125;&#125; 上面的例子代码写得比较糟糕，只为了演示相关使用方式，切勿用于生产环境。 TimeGauge TimeGauge是Gauge的特化类型，相比Gauge，它的构建器中多了一个TimeUnit类型的参数，用于指定ToDoubleFunction入参的基础时间单位。这里简单举个使用例子： 1234567891011121314151617181920212223242526272829303132public class TimeGaugeMain &#123; private static final SimpleMeterRegistry R = new SimpleMeterRegistry(); public static void main(String[] args) throws Exception&#123; AtomicInteger count = new AtomicInteger(); TimeGauge.Builder&lt;AtomicInteger&gt; timeGauge = TimeGauge.builder(\"timeGauge\", count, TimeUnit.SECONDS, AtomicInteger::get); timeGauge.register(R); count.addAndGet(10086); print(); count.set(1); print(); &#125; private static void print()throws Exception&#123; Search.in(R).meters().forEach(each -&gt; &#123; StringBuilder builder = new StringBuilder(); builder.append(\"name:\") .append(each.getId().getName()) .append(\",tags:\") .append(each.getId().getTags()) .append(\",type:\").append(each.getId().getType()) .append(\",value:\").append(each.measure()); System.out.println(builder.toString()); &#125;); &#125;&#125;//输出name:timeGauge,tags:[],type:GAUGE,value:[Measurement&#123;statistic='VALUE', value=10086.0&#125;]name:timeGauge,tags:[],type:GAUGE,value:[Measurement&#123;statistic='VALUE', value=1.0&#125;] DistributionSummary Summary(摘要)主要用于跟踪事件的分布，在Micrometer中，对应的类是DistributionSummary(分发摘要)。它的使用方式和Timer十分相似，但是它的记录值并不依赖于时间单位。常见的使用场景：使用DistributionSummary测量命中服务器的请求的有效负载大小。使用MeterRegistry创建DistributionSummary实例如下： 1DistributionSummary summary = registry.summary(\"response.size\"); 通过建造器流式创建如下： 1234567DistributionSummary summary = DistributionSummary .builder(\"response.size\") .description(\"a description of what this summary does\") // 可选 .baseUnit(\"bytes\") // 可选 .tags(\"region\", \"test\") // 可选 .scale(100) // 可选 .register(registry); DistributionSummary中有很多构建参数跟缩放和直方图的表示相关，见下一节。 使用场景： 根据个人经验和实践，总结如下： 1、不依赖于时间单位的记录值的测量，例如服务器有效负载值，缓存的命中率等。 举个相对具体的例子： 1234567891011121314151617181920212223242526272829public class DistributionSummaryMain &#123; private static final DistributionSummary DS = DistributionSummary.builder(\"cacheHitPercent\") .register(new SimpleMeterRegistry()); private static final LoadingCache&lt;String, String&gt; CACHE = CacheBuilder.newBuilder() .maximumSize(1000) .recordStats() .expireAfterWrite(60, TimeUnit.SECONDS) .build(new CacheLoader&lt;String, String&gt;() &#123; @Override public String load(String s) throws Exception &#123; return selectFromDatabase(); &#125; &#125;); public static void main(String[] args) throws Exception&#123; String key = \"doge\"; String value = CACHE.get(key); record(); &#125; private static void record()throws Exception&#123; CacheStats stats = CACHE.stats(); BigDecimal hitCount = new BigDecimal(stats.hitCount()); BigDecimal requestCount = new BigDecimal(stats.requestCount()); DS.record(hitCount.divide(requestCount,2,BigDecimal.ROUND_HALF_DOWN).doubleValue()); &#125;&#125; 直方图和百分数配置 直方图和百分数配置适用于Summary和Timer，这部分相对复杂，等研究透了再补充。 基于SpirngBoot、Prometheus、Grafana集成 集成了Micrometer框架的JVM应用使用到Micrometer的API收集的度量数据位于内存之中，因此，需要额外的存储系统去存储这些度量数据，需要有监控系统负责统一收集和处理这些数据，还需要有一些UI工具去展示数据，一般大佬只喜欢看炫酷的图表或者动画。常见的存储系统就是时序数据库，主流的有Influx、Datadog等。比较主流的监控系统(主要是用于数据收集和处理)就是Prometheus(一般叫普罗米修斯，下面就这样叫吧)。而展示的UI目前相对用得比较多的就是Grafana。另外，Prometheus已经内置了一个时序数据库的实现，因此，在做一套相对完善的度量数据监控的系统只需要依赖目标JVM应用，Prometheus组件和Grafana组件即可。下面花一点时间从零开始搭建一个这样的系统，之前写的一篇文章基于Windows系统，操作可能跟生产环境不够接近，这次使用CentOS7。 SpirngBoot中使用Micrometer SpringBoot中的spring-boot-starter-actuator依赖已经集成了对Micrometer的支持，其中的metrics端点的很多功能就是通过Micrometer实现的，prometheus端点默认也是开启支持的，实际上actuator依赖的spring-boot-actuator-autoconfigure中集成了对很多框架的开箱即用的API，其中prometheus包中集成了对Prometheus的支持，使得使用了actuator可以轻易地让项目暴露出prometheus端点，作为Prometheus收集数据的客户端，Prometheus(服务端软件)可以通过此端点收集应用中Micrometer的度量数据。 我们先引入spring-boot-starter-actuator和spring-boot-starter-web，实现一个Counter和Timer作为示例。依赖： 1234567891011121314151617181920212223242526272829303132333435 &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.22&lt;/version&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 接着编写一个下单接口和一个消息发送模块，模拟用户下单之后向用户发送消息： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129//实体@Datapublic class Message &#123; private String orderId; private Long userId; private String content;&#125;@Datapublic class Order &#123; private String orderId; private Long userId; private Integer amount; private LocalDateTime createTime;&#125;//控制器和服务类@RestControllerpublic class OrderController &#123; @Autowired private OrderService orderService; @PostMapping(value = \"/order\") public ResponseEntity&lt;Boolean&gt; createOrder(@RequestBody Order order)&#123; return ResponseEntity.ok(orderService.createOrder(order)); &#125;&#125;@Slf4j@Servicepublic class OrderService &#123; private static final Random R = new Random(); @Autowired private MessageService messageService; public Boolean createOrder(Order order) &#123; //模拟下单 try &#123; int ms = R.nextInt(50) + 50; TimeUnit.MILLISECONDS.sleep(ms); log.info(\"保存订单模拟耗时&#123;&#125;毫秒...\", ms); &#125; catch (Exception e) &#123; //no-op &#125; //记录下单总数 Metrics.counter(\"order.count\", \"order.channel\", order.getChannel()).increment(); //发送消息 Message message = new Message(); message.setContent(\"模拟短信...\"); message.setOrderId(order.getOrderId()); message.setUserId(order.getUserId()); messageService.sendMessage(message); return true; &#125;&#125;@Slf4j@Servicepublic class MessageService implements InitializingBean &#123; private static final BlockingQueue&lt;Message&gt; QUEUE = new ArrayBlockingQueue&lt;&gt;(500); private static BlockingQueue&lt;Message&gt; REAL_QUEUE; private static final Executor EXECUTOR = Executors.newSingleThreadExecutor(); private static final Random R = new Random(); static &#123; REAL_QUEUE = Metrics.gauge(\"message.gauge\", Tags.of(\"message.gauge\", \"message.queue.size\"), QUEUE, Collection::size); &#125; public void sendMessage(Message message) &#123; try &#123; REAL_QUEUE.put(message); &#125; catch (InterruptedException e) &#123; //no-op &#125; &#125; @Override public void afterPropertiesSet() throws Exception &#123; EXECUTOR.execute(() -&gt; &#123; while (true) &#123; try &#123; Message message = REAL_QUEUE.take(); log.info(\"模拟发送短信,orderId:&#123;&#125;,userId:&#123;&#125;,内容:&#123;&#125;,耗时:&#123;&#125;毫秒\", message.getOrderId(), message.getUserId(), message.getContent(), R.nextInt(50)); &#125; catch (Exception e) &#123; throw new IllegalStateException(e); &#125; &#125; &#125;); &#125;&#125;//切面类@Component@Aspectpublic class TimerAspect &#123; @Around(value = \"execution(* club.throwable.smp.service.*Service.*(..))\") public Object around(ProceedingJoinPoint joinPoint) throws Throwable &#123; Signature signature = joinPoint.getSignature(); MethodSignature methodSignature = (MethodSignature) signature; Method method = methodSignature.getMethod(); Timer timer = Metrics.timer(\"method.cost.time\", \"method.name\", method.getName()); ThrowableHolder holder = new ThrowableHolder(); Object result = timer.recordCallable(() -&gt; &#123; try &#123; return joinPoint.proceed(); &#125; catch (Throwable e) &#123; holder.throwable = e; &#125; return null; &#125;); if (null != holder.throwable) &#123; throw holder.throwable; &#125; return result; &#125; private class ThrowableHolder &#123; Throwable throwable; &#125;&#125; yaml的配置如下： 12345678910server: port: 9091management: server: port: 10091 endpoints: web: exposure: include: '*' base-path: /management 注意多看spring官方文档关于Actuator的详细描述，在SpringBoot-2.x之后，配置Web端点暴露的权限控制和1.x有很大的不同。总结一下就是：除了shutdown端点之外，其他端点默认都是开启支持的(这里仅仅是开启支持，并不是暴露为Web端点，端点必须暴露为Web端点才能被访问)，禁用或者开启端点支持的配置方式如下： 1management.endpoint.$&#123;端点ID&#125;.enabled=true/false 可以查看actuator-api文档查看所有支持的端点的特性，这个是2.1.0.RELEASE版本的官方文档，不知道日后链接会不会挂掉。端点只开启支持，但是不暴露为Web端点，是无法通过http://{host}:{management.port}/{management.endpoints.web.base-path}/{endpointId}访问的。暴露监控端点为Web端点的配置是： 12management.endpoints.web.exposure.include=info,healthmanagement.endpoints.web.exposure.exclude=prometheus management.endpoints.web.exposure.include用于指定暴露为Web端点的监控端点，指定多个的时候用英文逗号分隔。management.endpoints.web.exposure.exclude用于指定不暴露为Web端点的监控端点，指定多个的时候用英文逗号分隔。 management.endpoints.web.exposure.include默认指定的只有info和health两个端点，我们可以直接指定暴露所有的端点：management.endpoints.web.exposure.include=*，如果采用YAML配置，记得*要加单引号’*’。暴露所有Web监控端点是一件比较危险的事情，如果需要在生产环境这样做，请务必先确认http://{host}:{management.port}不能通过公网访问(也就是监控端点访问的端口只能通过内网访问，这样可以方便后面说到的Prometheus服务端通过此端口收集数据)。 Prometheus的安装和配置 Prometheus目前的最新版本是2.5，鉴于笔者没深入玩过Docker，这里还是直接下载它的压缩包解压安装。 123wget https://github.com/prometheus/prometheus/releases/download/v2.5.0/prometheus-2.5.0.linux-amd64.tar.gztar xvfz prometheus-*.tar.gzcd prometheus-* 先编辑解压出来的目录下的prometheus配置文件prometheus.yml，主要修改scrape_configs节点的属性： 1234567891011scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. # 这里配置需要拉取度量信息的URL路径，这里选择应用程序的prometheus端点 metrics_path: /management/prometheus static_configs: # 这里配置host和port - targets: ['localhost:10091'] 配置拉取度量数据的路径为localhost:10091/management/metrics，此前记得把前一节提到的应用在虚拟机中启动。接着启动Prometheus应用： 12# 可选参数 --storage.tsdb.path=存储数据的路径，默认路径为./data./prometheus --config.file=prometheus.yml Prometheus引用的默认启动端口是9090，启动成功后，日志如下： 此时，访问http://${虚拟机host}:9090/targets就能看到当前Prometheus中执行的Job： 访问http://${虚拟机host}:9090/graph可以查找到我们定义的度量Meter和spring-boot-starter-actuator中已经定义好的一些关于JVM或者Tomcat的度量Meter。我们先对应用的/order接口进行调用，然后查看一下监控前面在应用中定义的order_count_total和method_cost_time_seconds_sum： 可以看到，Meter的信息已经被收集和展示，但是显然不够详细和炫酷，这个时候就需要使用Grafana的UI做一下点缀。 Grafana的安装和使用 Grafana的安装过程如下： 12wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.3.4-1.x86_64.rpm sudo yum localinstall grafana-5.3.4-1.x86_64.rpm 安装完成后，通过命令service grafana-server start启动即可，默认的启动端口为3000，通过http://${host}:3000访问即可。初始的账号密码都为admin，权限是管理员权限。接着需要在Home面板添加一个数据源，目的是对接Prometheus服务端从而可以拉取它里面的度量数据。数据源添加面板如下： 其实就是指向Prometheus服务端的端口就可以了。接下来可以天马行空地添加需要的面板，就下单数量统计的指标，可以添加一个Graph的面板： 配置面板的时候，需要在基础(General)中指定Title： 接着比较重要的是Metrics的配置，需要指定数据源和Prometheus的查询语句： 最好参考一下Prometheus的官方文档，稍微学习一下它的查询语言PromQL的使用方式，一个面板可以支持多个PromQL查询。前面提到的两项是基本配置，其他配置项一般是图表展示的辅助或者预警等辅助功能，这里先不展开，可以取Grafana的官网挖掘一下使用方式。然后我们再调用一下下单接口，过一段时间，图表的数据就会自动更新和展示： 接着添加一下项目中使用的Timer的Meter，便于监控方法的执行时间，完成之后大致如下： 上面的面板虽然设计相当粗糙，但是基本功能已经实现。设计面板并不是一件容易的事，如果有需要可以从Github中搜索一下grafana dashboard关键字找现成的开源配置使用或者二次加工后使用。 小结 常言道：工欲善其事，必先利其器。Micrometer是JVM应用的一款相当优异的度量框架，它提供基于Tag和丰富的度量类型和API便于多维度地进行不同角度度量数据的统计，可以方便地接入Prometheus进行数据收集，使用Grafana的面板进行炫酷的展示，提供了天然的spring-boot体系支持。但是，在实际的业务代码中，度量类型Counter经常被滥用，一旦工具被不加思考地滥用，就反而会成为混乱或者毒瘤。因此，这篇文章就是对Micrometer中的各种Meter的使用场景基于个人的理解做了调研和分析，分享一下实战中的经验和踩坑经历。 以前写过的一篇文章： 基于Prometheus搭建SpringCloud全方位立体监控体系 参考资料： https://micrometer.io/docs https://grafana.com https://prometheus.io (To be continue c-10-d n-e-20181102 最近有点忙，没办法经常更新 r-a-201918)","categories":[{"name":"Framework","slug":"Framework","permalink":"http://throwable.club/blog/categories/Framework/"},{"name":"Micrometer","slug":"Framework/Micrometer","permalink":"http://throwable.club/blog/categories/Framework/Micrometer/"}],"tags":[{"name":"Framework","slug":"Framework","permalink":"http://throwable.club/blog/tags/Framework/"},{"name":"Micrometer","slug":"Micrometer","permalink":"http://throwable.club/blog/tags/Micrometer/"}]},{"title":"基于Prometheus搭建SpringCloud全方位立体监控体系","slug":"spring-cloud-prometheus","date":"2018-11-10T08:54:27.000Z","updated":"2019-01-08T14:41:56.513Z","comments":true,"path":"2018/11/10/spring-cloud-prometheus/","link":"","permalink":"http://throwable.club/2018/11/10/spring-cloud-prometheus/","excerpt":"","text":"基于Prometheus搭建SpringCloud全方位立体监控体系 前提 最近公司在联合运维做一套全方位监控的系统，应用集群的技术栈是SpringCloud体系。虽然本人没有参与具体基础架构的研发，但是从应用引入的包和一些资料的查阅大致推算出具体的实现方案，这里做一次推演，详细记录一下整个搭建过程。 Prometheus是什么 Prometheus(普罗米修斯)，是一个开源的系统监控和告警的工具包，其采用Pull方式采集时间序列的度量数据，通过Http协议传输。它的工作方式是被监控的服务需要公开一个Prometheus端点，这端点是一个HTTP接口，该接口公开了度量的列表和当前的值，然后Prometheus应用从此接口定时拉取数据，一般可以存放在时序数据库中，然后通过可视化的Dashboard(例如Promdash或者Grafana)进行数据展示。当然，此文章不打算深入研究这个工具，只做应用层面的展示。这篇文章将会用到下面几个技术栈： SpringCloud体系，主要是注册中心和注册客户端。 spring-boot-starter-actuator，主要是提供了Prometheus端点，不用重复造轮子。 Prometheus的Java客户端。 Prometheus应用。 io.micrometer，SpringBoot标准下使用的度量工具包。 Grafana，可视化的Dashboard。 这里所有的软件或者依赖全部使用当前的最新版本，如果有坑踩了再填。其实，Prometheus本身也开发了一套Counter、Gauge、Timer等相关接口，不过SpringBoot中使用了io.micrometer中的套件，所以本文不深入分析Prometheus的Java客户端。 io.micrometer的使用 在SpringBoot2.X中，spring-boot-starter-actuator引入了io.micrometer，对1.X中的metrics进行了重构，主要特点是支持tag/label，配合支持tag/label的监控系统，使得我们可以更加方便地对metrics进行多维度的统计查询及监控。io.micrometer目前支持Counter、Gauge、Timer、Summary等多种不同类型的度量方式(不知道有没有遗漏)，下面逐个简单分析一下它们的作用和使用方式。 需要在SpringBoot项目下引入下面的依赖： 12345&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-core&lt;/artifactId&gt; &lt;version&gt;$&#123;micrometer.version&#125;&lt;/version&gt;&lt;/dependency&gt; 目前最新的micrometer.version为1.0.5。注意一点的是：io.micrometer支持Tag(标签)的概念，Tag是其metrics是否能够有多维度的支持的基础，Tag必须成对出现，也就是必须配置也就是偶数个Tag，有点类似于K-V的关系。 Counter Counter(计数器)简单理解就是一种只增不减的计数器。它通常用于记录服务的请求数量、完成的任务数量、错误的发生数量等等。举个例子： 12345678910111213141516171819202122232425262728293031import io.micrometer.core.instrument.Counter;import io.micrometer.core.instrument.Metrics;import io.micrometer.core.instrument.simple.SimpleMeterRegistry;/** * @author throwable * @version v1.0 * @description * @since 2018/7/19 23:10 */public class CounterSample &#123; public static void main(String[] args) throws Exception &#123; //tag必须成对出现，也就是偶数个 Counter counter = Counter.builder(\"counter\") .tag(\"counter\", \"counter\") .description(\"counter\") .register(new SimpleMeterRegistry()); counter.increment(); counter.increment(2D); System.out.println(counter.count()); System.out.println(counter.measure()); //全局静态方法 Metrics.addRegistry(new SimpleMeterRegistry()); counter = Metrics.counter(\"counter\", \"counter\", \"counter\"); counter.increment(10086D); counter.increment(10087D); System.out.println(counter.count()); System.out.println(counter.measure()); &#125;&#125; 输出： 12343.0[Measurement&#123;statistic='COUNT', value=3.0&#125;]20173.0[Measurement&#123;statistic='COUNT', value=20173.0&#125;] Counter的Measurement的statistic(可以理解为度量的统计角度)只有COUNT，也就是它只具备计数(它只有增量的方法，因此只增不减)，这一点从它的接口定义可知： 123456789101112public interface Counter extends Meter &#123; default void increment() &#123; increment(1.0); &#125; void increment(double amount); double count(); //忽略其他方法或者成员&#125; Counter还有一个衍生类型FunctionCounter，它是基于函数式接口ToDoubleFunction进行计数统计的，用法差不多。 Gauge Gauge(仪表)是一个表示单个数值的度量，它可以表示任意地上下移动的数值测量。Gauge通常用于变动的测量值，如当前的内存使用情况，同时也可以测量上下移动的&quot;计数&quot;，比如队列中的消息数量。举个例子： 12345678910111213141516171819202122232425262728293031import io.micrometer.core.instrument.Gauge;import io.micrometer.core.instrument.Metrics;import io.micrometer.core.instrument.simple.SimpleMeterRegistry;import java.util.concurrent.atomic.AtomicInteger;/** * @author throwable * @version v1.0 * @description * @since 2018/7/19 23:30 */public class GaugeSample &#123; public static void main(String[] args) throws Exception &#123; AtomicInteger atomicInteger = new AtomicInteger(); Gauge gauge = Gauge.builder(\"gauge\", atomicInteger, AtomicInteger::get) .tag(\"gauge\", \"gauge\") .description(\"gauge\") .register(new SimpleMeterRegistry()); atomicInteger.addAndGet(5); System.out.println(gauge.value()); System.out.println(gauge.measure()); atomicInteger.decrementAndGet(); System.out.println(gauge.value()); System.out.println(gauge.measure()); //全局静态方法，返回值竟然是依赖值，有点奇怪，暂时不选用 Metrics.addRegistry(new SimpleMeterRegistry()); AtomicInteger other = Metrics.gauge(\"gauge\", atomicInteger, AtomicInteger::get); &#125;&#125; 输出结果: 12345.0[Measurement&#123;statistic='VALUE', value=5.0&#125;]4.0[Measurement&#123;statistic='VALUE', value=4.0&#125;] Gauge关注的度量统计角度是VALUE(值)，它的构建方法中依赖于函数式接口ToDoubleFunction的实例(如例子中的实例方法引用AtomicInteger::get)和一个依赖于ToDoubleFunction改变自身值的实例(如例子中的AtomicInteger实例)，它的接口方法如下： 123456public interface Gauge extends Meter &#123; double value(); //忽略其他方法或者成员&#125; Timer Timer(计时器)同时测量一个特定的代码逻辑块的调用(执行)速度和它的时间分布。简单来说，就是在调用结束的时间点记录整个调用块执行的总时间，适用于测量短时间执行的事件的耗时分布，例如消息队列消息的消费速率。举个例子： 1234567891011121314151617181920212223242526272829303132import io.micrometer.core.instrument.Timer;import io.micrometer.core.instrument.simple.SimpleMeterRegistry;import java.util.concurrent.TimeUnit;/** * @author throwable * @version v1.0 * @description * @since 2018/7/19 23:44 */public class TimerSample &#123; public static void main(String[] args) throws Exception&#123; Timer timer = Timer.builder(\"timer\") .tag(\"timer\",\"timer\") .description(\"timer\") .register(new SimpleMeterRegistry()); timer.record(()-&gt;&#123; try &#123; TimeUnit.SECONDS.sleep(2); &#125;catch (InterruptedException e)&#123; //ignore &#125; &#125;); System.out.println(timer.count()); System.out.println(timer.measure()); System.out.println(timer.totalTime(TimeUnit.SECONDS)); System.out.println(timer.mean(TimeUnit.SECONDS)); System.out.println(timer.max(TimeUnit.SECONDS)); &#125;&#125; 输出结果： 123451[Measurement&#123;statistic='COUNT', value=1.0&#125;, Measurement&#123;statistic='TOTAL_TIME', value=2.000603975&#125;, Measurement&#123;statistic='MAX', value=2.000603975&#125;]2.0006039752.0006039752.000603975 Timer的度量统计角度主要包括记录执行的最大时间、总时间、平均时间、执行完成的总任务数，它提供多种的统计方法变体： 123456789101112131415161718192021222324public interface Timer extends Meter, HistogramSupport &#123; void record(long amount, TimeUnit unit); default void record(Duration duration) &#123; record(duration.toNanos(), TimeUnit.NANOSECONDS); &#125; &lt;T&gt; T record(Supplier&lt;T&gt; f); &lt;T&gt; T recordCallable(Callable&lt;T&gt; f) throws Exception; void record(Runnable f); default Runnable wrap(Runnable f) &#123; return () -&gt; record(f); &#125; default &lt;T&gt; Callable&lt;T&gt; wrap(Callable&lt;T&gt; f) &#123; return () -&gt; recordCallable(f); &#125; //忽略其他方法或者成员&#125; 这些record或者包装方法可以根据需要选择合适的使用，另外，一些度量属性(如下限和上限)或者单位可以自行配置，具体属性的相关内容可以查看DistributionStatisticConfig类，这里不详细展开。 另外，Timer有一个衍生类LongTaskTimer，主要是用来记录正在执行但是尚未完成的任务数，用法差不多。 Summary Summary(摘要)用于跟踪事件的分布。它类似于一个计时器，但更一般的情况是，它的大小并不一定是一段时间的测量值。在micrometer中，对应的类是DistributionSummary，它的用法有点像Timer，但是记录的值是需要直接指定，而不是通过测量一个任务的执行时间。举个例子： 123456789101112131415161718192021222324252627import io.micrometer.core.instrument.DistributionSummary;import io.micrometer.core.instrument.simple.SimpleMeterRegistry;/** * @author throwable * @version v1.0 * @description * @since 2018/7/19 23:55 */public class SummarySample &#123; public static void main(String[] args) throws Exception &#123; DistributionSummary summary = DistributionSummary.builder(\"summary\") .tag(\"summary\", \"summary\") .description(\"summary\") .register(new SimpleMeterRegistry()); summary.record(2D); summary.record(3D); summary.record(4D); System.out.println(summary.measure()); System.out.println(summary.count()); System.out.println(summary.max()); System.out.println(summary.mean()); System.out.println(summary.totalAmount()); &#125;&#125; 输出结果： 12345[Measurement&#123;statistic='COUNT', value=3.0&#125;, Measurement&#123;statistic='TOTAL', value=9.0&#125;, Measurement&#123;statistic='MAX', value=4.0&#125;]34.03.09.0 Summary的度量统计角度主要包括记录过的数据中的最大值、总数值、平均值和总次数。另外，一些度量属性(如下限和上限)或者单位可以自行配置，具体属性的相关内容可以查看DistributionStatisticConfig类，这里不详细展开。 小结 一般情况下，上面的Counter、Gauge、Timer、DistributionSummary例子可以满足日常开发需要，但是有些高级的特性这里没有展开，具体可以参考micrometer-spring-legacy这个依赖包，毕竟源码是老师，源码不会骗人。 spring-boot-starter-actuator的使用 spring-boot-starter-actuator在2.X版本中不仅升级了metrics为io.micrometer，很多配置方式也和1.X完全不同，鉴于前段时间没有维护SpringBoot技术栈的项目，现在重新看了下官网复习一下。引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;version&gt;$&#123;springboot.version&#125;&lt;/version&gt;&lt;/dependency&gt; 目前最新的springboot.version为2.0.3.RELEASE。在spring-boot-starter-actuator中，最大的变化就是配置的变化，原来在1.X版本是通过management.security.enabled控制是否可以忽略权限访问所有的监控端点，在2.X版本中，必须显式配置不需要权限验证对外开放的端点： 1234management.endpoints.web.exposure.include=*management.endpoints.web.exposure.exclude=env,beansmanagement.endpoints.jmx.exposure.include=management.endpoints.jmx.exposure.include=* 例如上面的配置，访问非/env和非/beans的端点，可以不受权限控制，也就是所有人都可以访问非/env和非/beans的端点。例如，如果我只想暴露/health端点，只需配置： 1management.endpoints.web.exposure.include=health 这一点需要特别注意，其他使用和1.X差不多。还有一点是，2.X中所有监控端点的访问url的默认路径前缀为：http://${host}/${port}/actuator，也就是想访问health端点就要访问http://${host}/${port}/actuator/health，当然也可以修改/actuator这个路径前缀。其他细节区别没有深入研究，可以参考文档。 搭建SpringCloud应用 接着先搭建一个SpringCloud应用群，主要包括注册中心(registry-center)和一个简单的服务节点(cloud-prometheus-sample)，其中注册中心只引入eureka-server的依赖，而服务节点用于对接Prometheus，引入eureka-client、spring-boot-starter-actuator、prometheus等依赖。 registry-center registry-center是一个单纯的服务注册中心，只需要引入eureka-server的依赖，添加一个启动类即可，添加的依赖如下： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 添加一个启动类： 123456789101112131415161718import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;/** * @author throwable * @version v1.0 * @description * @since 2018/7/21 9:06 */@SpringBootApplication@EnableEurekaServerpublic class RegistryCenterApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RegistryCenterApplication.class, args); &#125;&#125; 配置文件application.yaml如下： 1234567891011121314server: port: 9091spring: application: name: registry-centereureka: instance: hostname: localhost client: enabled: true register-with-eureka: false fetch-registry: false service-url: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 就是这么简单，启动入口类即可，启动的端口为9091。 cloud-prometheus-sample cloud-prometheus-sample主要作为eureka-client，接入spring-boot-starter-actuator和prometheus依赖，引入依赖如下： 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt; 这里引入的是micrometer-registry-prometheus而不是micrometer-spring-legacy是因为micrometer-spring-legacy是spring-integration(spring系统集成)的依赖，这里没有用到，但是里面很多实现可以参考。micrometer-registry-prometheus提供了基于actuator的端点，路径是…/prometheus。启动类如下： 123456789101112131415161718import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;/** * @author throwable * @version v1.0 * @description * @since 2018/7/21 9:13 */@SpringBootApplication@EnableEurekaClientpublic class SampleApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SampleApplication.class, args); &#125;&#125; 配置文件application.yaml如下： 12345678910server: port: 9092spring: application: name: cloud-prometheus-sampleeureka: instance: hostname: localhost client: service-url: http://localhost:9091/eureka/ 启动端口为9092，eureka的服务注册地址为：http://localhost:9091/eureka/，也就是registry-center中指定的默认数据区(defaultZone)的注册地址，先启动registry-center，再启动cloud-prometheus-sample，然后访问http://localhost:9091/： 访问http://localhost:9092/actuator/prometheus： 这些数据就是实时的度量数据，Prometheus(软件)配置好任务并且启动执行后，就是通过定时拉取/prometheus这个端点返回的数据进行数据聚合和展示的。 接着，我们先定制一个功能，统计cloud-prometheus-sample所有入站的Http请求数量(包括成功、失败和非法的)，添加如下代码： 123456789101112131415161718192021222324252627//请求拦截器@Componentpublic class SampleMvcInterceptor extends HandlerInterceptorAdapter &#123; private static final Counter COUNTER = Counter.builder(\"Http请求统计\") .tag(\"HttpCount\", \"HttpCount\") .description(\"Http请求统计\") .register(Metrics.globalRegistry); @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; COUNTER.increment(); &#125;&#125;//自定义Mvc配置@Componentpublic class SampleWebMvcConfigurer implements WebMvcConfigurer &#123; @Autowired private SampleMvcInterceptor sampleMvcInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(sampleMvcInterceptor); &#125;&#125; 重启cloud-prometheus-sample，直接访问几次不存在的根节点路径http://localhost:9092，再查看端点统计数据： 安装和使用Prometheus 先从Prometheus官方下载地址下载软件，这里用Windows10平台演示，直接下载prometheus-2.3.2.windows-amd64.tar.gz，个人有软件洁癖，用软件或者依赖喜欢最高版本，出现坑了自己填。解压后目录如下： 启动的话，直接运行prometheus.exe即可，这里先配置一下prometheus.yml： 12345678910111213global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093scrape_configs: - job_name: 'prometheus' metrics_path: /actuator/prometheus static_configs: - targets: ['localhost:9092'] 我们主要修改的是scrape_configs节点下的配置，这个节点时配置同步任务的，这里配置一个任务为’prometheus’，拉取数据的路径为/actuator/prometheus，目标host-port为’localhost:9092’，也就是cloud-prometheus-sample暴露的prometheus端点，Prometheus(软件)的默认启动端口为9090。启动后，同级目录下会生成一个data目录，实际上起到&quot;时序数据库&quot;的类似作用。访问Prometheus(软件)的控制台http://localhost:9090/targets: Prometheus度量统计的所有监控项可以在http://localhost:9090/graph中查看到。这里可以观察到HttpCount的统计，但是界面不够炫酷，配置项也少，因此需要引入Grafana。 安装和接入Grafana Grafana的安装也十分简单，它也是开箱即用的，就是配置的时候需要熟悉它的语法。先到Grafana官网下载页面下载一个适合系统的版本，这里选择Windows版本。解压之后，直接运行bin目录下的grafana-server.exe即可，默认的启动端口是3000，访问http://localhost:3000/，初始化账号密码是admin/admin，首次登陆需要修改密码，接着添加一个数据源： 接着添加一个新的命名为’sample’的Dashboard，添加一个Graph类型的Panel，配置其属性： A记录(查询命令)就是对应http://localhost:9090/graph中的查询命令的目标： 很简单，配置完毕之后，就可以看到高大上的统计图： 这里只是介绍了Grafana使用的冰山一角，更多配置和使用命令可以自行查阅它的官方文档。 原理和扩展 原理 下面是Prometheus的工作原理流程图，来源于其官网： 在SpringBoot项目中，它的工作原理如下： 这就是为什么能够使用Metrics的静态方法直接进行数据统计，因为Spring内部用MeterRegistryPostProcessor对Metrics内部持有的全局的CompositeMeterRegistry进行了合成操作，也就是所有MeterRegistry类型的Bean都会添加到Metrics内部持有的静态globalRegistry。 扩展 下面来个相对有生产意义的扩展实现，这篇文章提到SpringCloud体系的监控，我们需要扩展一个功能，记录一下每个有效的请求的执行时间。添加下面几个类或者方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182//注解@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface MethodMetric &#123; String name() default \"\"; String description() default \"\"; String[] tags() default &#123;&#125;;&#125;//切面类@Aspect@Componentpublic class HttpMethodCostAspect &#123; @Autowired private MeterRegistry meterRegistry; @Pointcut(\"@annotation(club.throwable.sample.aspect.MethodMetric)\") public void pointcut() &#123; &#125; @Around(value = \"pointcut()\") public Object process(ProceedingJoinPoint joinPoint) throws Throwable &#123; Method targetMethod = ((MethodSignature) joinPoint.getSignature()).getMethod(); //这里是为了拿到实现类的注解 Method currentMethod = ClassUtils.getUserClass(joinPoint.getTarget().getClass()) .getDeclaredMethod(targetMethod.getName(), targetMethod.getParameterTypes()); if (currentMethod.isAnnotationPresent(MethodMetric.class)) &#123; MethodMetric methodMetric = currentMethod.getAnnotation(MethodMetric.class); return processMetric(joinPoint, currentMethod, methodMetric); &#125; else &#123; return joinPoint.proceed(); &#125; &#125; private Object processMetric(ProceedingJoinPoint joinPoint, Method currentMethod, MethodMetric methodMetric) throws Throwable &#123; String name = methodMetric.name(); if (!StringUtils.hasText(name)) &#123; name = currentMethod.getName(); &#125; String desc = methodMetric.description(); if (!StringUtils.hasText(desc)) &#123; desc = name; &#125; String[] tags = methodMetric.tags(); if (tags.length == 0) &#123; tags = new String[2]; tags[0] = name; tags[1] = name; &#125; Timer timer = Timer.builder(name).tags(tags) .description(desc) .register(meterRegistry); return timer.record(() -&gt; &#123; try &#123; return joinPoint.proceed(); &#125; catch (Throwable throwable) &#123; throw new IllegalStateException(throwable); &#125; &#125;); &#125;&#125;//启动类里面添加方法@SpringBootApplication@EnableEurekaClient@RestControllerpublic class SampleApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SampleApplication.class, args); &#125; @MethodMetric @GetMapping(value = \"/hello\") public String hello(@RequestParam(name = \"name\", required = false, defaultValue = \"doge\") String name) &#123; return String.format(\"%s say hello!\", name); &#125;&#125; 配置好Grafana的面板，重启项目，多次调用/hello接口： 后记 如果想把监控界面做得更炫酷、更直观、更详细，可以先熟悉一下Prometheus的查询语法和Grafana的面板配置，此外，Grafana或者Prometheus都支持预警功能，可以接入钉钉机器人等以便及时发现问题作出预警。 参考资料： https://prometheus.io/ https://spring.io/ https://github.com/percona/grafana-dashboards 本文Demo项目仓库：https://github.com/zjcscut/spring-cloud-prometheus-sample (本文完 c-5-d e-a-20180721 r-a-201918)","categories":[{"name":"Spring","slug":"Spring","permalink":"http://throwable.club/blog/categories/Spring/"},{"name":"Prometheus","slug":"Spring/Prometheus","permalink":"http://throwable.club/blog/categories/Spring/Prometheus/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://throwable.club/blog/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://throwable.club/blog/tags/SpringCloud/"}]},{"title":"JDK中注解的底层实现","slug":"annotation-implementation","date":"2018-11-04T10:41:44.000Z","updated":"2018-11-04T10:45:13.629Z","comments":true,"path":"2018/11/04/annotation-implementation/","link":"","permalink":"http://throwable.club/2018/11/04/annotation-implementation/","excerpt":"","text":"前提 用Java快三年了，注解算是一个常用的类型，特别是在一些框架里面会大量使用注解做组件标识、配置或者策略。但是一直没有深入去探究JDK中的注解到底是什么，底层是怎么实现了?于是参考了一些资料，做了一次稍微详细的分析。 JDK的注解描述 参考JavaSE-8里面的JLS-9.6对注解的描述如下： 注解的声明如下： 123&#123;InterfaceModifier&#125; @ interface Identifier AnnotationTypeBody接口修饰符 @ interface 注解标识符 注解类型的内容 其中： 注解类型声明中的标识符指定了注解类型的名称。 如果注解类型与它的任何封闭类或接口具有相同的简单名称，则编译时会出现错误。 每个注解类型的直接父接口都是java.lang.annotation.Annotation。 既然所有注解类型的父接口都是java.lang.annotation.Annotation，那么我们可以看一下Annotation接口的文档： public interface Annotation The common interface extended by all annotation types. Note that an interface that manually extends this one does not define an annotation type. Also note that this interface does not itself define an annotation type. More information about annotation types can be found in section 9.6 of The Java™ Language Specification. The AnnotatedElement interface discusses compatibility concerns when evolving an annotation type from being non-repeatable to being repeatable. Since: 1.5 JavaSE-8中的文档对Annotation的描述和JLS-9.6中差不多，不过最后指明了可重复注解的兼容性考虑的问题，可重复注解在JDK1.8中由元注解@Repeatable实现。下面基于JDK8的最后一个版本java version 1.8.0_181探究一下注解在JDK中的底层实现。 注解实现探究 我们先定义一个十分简单的Counter注解如下： 1234567891011package club.throwable.annotation;import java.lang.annotation.*;@Retention(RetentionPolicy.RUNTIME)@Documented@Target(ElementType.TYPE)public @interface Counter &#123; int count() default 0;&#125; 我们先从直接使用@Counter注解，从直观上观察@Counter实例的类型： 12345678@Counter(count = 1)public class Main &#123; public static void main(String[] args) throws Exception&#123; Counter counter = Main.class.getAnnotation(Counter.class); System.out.println(counter.count()); &#125;&#125; @Counter实例从Debug过程中观察发现是JDK的一个代理类(并且InvocationHandler的实例是sun.reflect.annotation.AnnotationInvocationHandler，它是一个修饰符为default的sun包内可用的类)，为了验证这一点我们使用JDK的反编译命令查看@Counter的字节码： 1javap -c -v D:\\Projects\\rxjava-seed\\target\\classes\\club\\throwable\\annotation\\Counter.class @Counter反编译后的字节码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041Classfile /D:/Projects/rxjava-seed/target/classes/club/throwable/annotation/Counter.class Last modified 2018-10-6; size 487 bytes MD5 checksum 83cee23f426e5b51a096281068d8b555 Compiled from \"Counter.java\"public interface club.throwable.annotation.Counter extends java.lang.annotation.Annotation minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_INTERFACE, ACC_ABSTRACT, ACC_ANNOTATIONConstant pool: #1 = Class #19 // club/throwable/annotation/Counter #2 = Class #20 // java/lang/Object #3 = Class #21 // java/lang/annotation/Annotation #4 = Utf8 count #5 = Utf8 ()I #6 = Utf8 AnnotationDefault #7 = Integer 0 #8 = Utf8 SourceFile #9 = Utf8 Counter.java #10 = Utf8 RuntimeVisibleAnnotations #11 = Utf8 Ljava/lang/annotation/Retention; #12 = Utf8 value #13 = Utf8 Ljava/lang/annotation/RetentionPolicy; #14 = Utf8 RUNTIME #15 = Utf8 Ljava/lang/annotation/Documented; #16 = Utf8 Ljava/lang/annotation/Target; #17 = Utf8 Ljava/lang/annotation/ElementType; #18 = Utf8 TYPE #19 = Utf8 club/throwable/annotation/Counter #20 = Utf8 java/lang/Object #21 = Utf8 java/lang/annotation/Annotation&#123; public abstract int count(); descriptor: ()I flags: ACC_PUBLIC, ACC_ABSTRACT AnnotationDefault: default_value: I#7&#125;SourceFile: \"Counter.java\"RuntimeVisibleAnnotations: 0: #11(#12=e#13.#14) 1: #15() 2: #16(#12=[e#17.#18]) 如果熟悉字节码，从直观上可以得到下面的信息： 注解是一个接口，它继承自java.lang.annotation.Annotation父接口。 @Counter对应的接口接口除了继承了java.lang.annotation.Annotation中的抽象方法，自身定义了一个抽象方法public abstract int count();。 既然注解最后转化为一个接口，注解中定义的注解成员属性会转化为抽象方法，那么最后这些注解成员属性怎么进行赋值的呢?答案就是：为注解对应的接口生成一个实现该接口的动态代理类。直接点说就是：Java通过动态代理的方式生成了一个实现了&quot;注解对应接口&quot;的实例，该代理类实例实现了&quot;注解成员属性对应的方法&quot;，这个步骤类似于&quot;注解成员属性&quot;的赋值过程，这样子就可以在程序运行的时候通过反射获取到注解的成员属性(这里注解必须是运行时可见的，也就是使用了@Retention(RetentionPolicy.RUNTIME)，另外需要理解JDK原生动态代理和反射相关内容)。 注解对应的动态代理类实例 上面一些已经指出了，注解的最底层实现就是一个JDK的动态代理类，而这个动态代理类的生成过程我们完全可以通过Debug跟踪，这里列举一下笔者跟踪整个过程的流水账： 1、Class&lt;?&gt;#getAnnotation(Class&lt;A&gt; annotationClass)，通过类型获取注解实例。 2、Class&lt;?&gt;#annotationData()，获取注解的数据。 3、Class&lt;?&gt;#createAnnotationData(int classRedefinedCount)，构建注解的数据。 4、AnnotationParser#parseAnnotations(byte[] var0, ConstantPool var1, Class&lt;?&gt; var2)，这里已经是sun包下的类，无法看到源码，这个方法用于解析注解，这一步使用到字节码中常量池的索引解析，常量解析完毕会生成一个成员属性键值对作为下一个环节的入参，常量池的解析可以看AnnotationParser#parseMemberValue方法。 5、AnnotationParser#annotationForMap(final Class&lt;? extends Annotation&gt; var0, final Map&lt;String, Object&gt; var1)，同样是sun.reflect.annotation.AnnotationParser中的方法，用于生成注解的动态代理类。 注意第5步，贴出它的源码： 1234567public static Annotation annotationForMap(final Class&lt;? extends Annotation&gt; var0, final Map&lt;String, Object&gt; var1) &#123; return (Annotation)AccessController.doPrivileged(new PrivilegedAction&lt;Annotation&gt;() &#123; public Annotation run() &#123; return (Annotation)Proxy.newProxyInstance(var0.getClassLoader(), new Class[]&#123;var0&#125;, new AnnotationInvocationHandler(var0, var1)); &#125; &#125;);&#125; 熟悉JDK动态代理的这里的代码应该看起来很简单，就是生成一个标准的JDK动态代理，而InvocationHandler的实例是AnnotationInvocationHandler，可以看它的成员变量、构造方法和实现InvocationHandler接口的invoke方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class AnnotationInvocationHandler implements InvocationHandler, Serializable &#123; private static final long serialVersionUID = 6182022883658399397L; //保存了当前注解的类型 private final Class&lt;? extends Annotation&gt; type; //保存了注解的成员属性的名称和值的映射，注解成员属性的名称实际上就对应着接口中抽象方法的名称 private final Map&lt;String, Object&gt; memberValues; private transient volatile Method[] memberMethods = null; AnnotationInvocationHandler(Class&lt;? extends Annotation&gt; var1, Map&lt;String, Object&gt; var2) &#123; Class[] var3 = var1.getInterfaces(); if (var1.isAnnotation() &amp;&amp; var3.length == 1 &amp;&amp; var3[0] == Annotation.class) &#123; this.type = var1; this.memberValues = var2; &#125; else &#123; throw new AnnotationFormatError(\"Attempt to create proxy for a non-annotation type.\"); &#125; &#125; public Object invoke(Object var1, Method var2, Object[] var3) &#123; //获取当前执行的方法名称 String var4 = var2.getName(); Class[] var5 = var2.getParameterTypes(); if (var4.equals(\"equals\") &amp;&amp; var5.length == 1 &amp;&amp; var5[0] == Object.class) &#123; return this.equalsImpl(var3[0]); &#125; else if (var5.length != 0) &#123; throw new AssertionError(\"Too many parameters for an annotation method\"); &#125; else &#123; byte var7 = -1; switch(var4.hashCode()) &#123; case -1776922004: if (var4.equals(\"toString\")) &#123; var7 = 0; &#125; break; case 147696667: if (var4.equals(\"hashCode\")) &#123; var7 = 1; &#125; break; case 1444986633: if (var4.equals(\"annotationType\")) &#123; var7 = 2; &#125; &#125; switch(var7) &#123; case 0: return this.toStringImpl(); case 1: return this.hashCodeImpl(); case 2: return this.type; default: //利用方法名称从memberValues获取成员属性的赋值 Object var6 = this.memberValues.get(var4); if (var6 == null) &#123; throw new IncompleteAnnotationException(this.type, var4); &#125; else if (var6 instanceof ExceptionProxy) &#123; throw ((ExceptionProxy)var6).generateException(); &#125; else &#123; //这一步就是注解成员属性返回值获取的实际逻辑 //需要判断是否数据，如果是数据需要克隆一个数组 //不是数组直接返回 if (var6.getClass().isArray() &amp;&amp; Array.getLength(var6) != 0) &#123; var6 = this.cloneArray(var6); &#125; return var6; &#125; &#125; &#125; &#125;//忽略其他方法 这里需要重点注意一下的是：AnnotationInvocationHandler的成员变量Map&lt;String, Object&gt; memberValues存放着注解的成员属性的名称和值的映射，注解成员属性的名称实际上就对应着接口中抽象方法的名称，例如上面我们定义的@Counter注解生成代理类后，它的AnnotationInvocationHandler实例中的memberValues属性存放着键值对count=1。 既然知道了注解底层使用了JDK原生的Proxy，那么我们可以直接输出代理类到指定目录去分析代理类的源码，有两种方式可以输出Proxy类的源码： 1、通过Java系统属性设置System.setProperty(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;, &quot;true&quot;);。 2、通过-D参数指定，其实跟1差不多，参数是：-Dsun.misc.ProxyGenerator.saveGeneratedFiles=true。 这里使用方式1，修改一下上面用到的main方法： 12345public static void main(String[] args) throws Exception &#123; System.setProperty(\"sun.misc.ProxyGenerator.saveGeneratedFiles\", \"true\"); Counter counter = Main.class.getAnnotation(Counter.class); System.out.println(counter.count());&#125; 执行完毕之后，项目中多了一个目录： 其中$Proxy0是@Retention注解对应的动态代理类，而$Proxy1才是我们的@Counter对应的动态代理类，当然如果有更多的注解，那么有可能生成$ProxyN。接着我们直接看$Proxy1的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public final class $Proxy1 extends Proxy implements Counter &#123; private static Method m1; private static Method m2; private static Method m3; private static Method m4; private static Method m0; public $Proxy1(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final int count() throws &#123; try &#123; return (Integer)super.h.invoke(this, m3, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final Class annotationType() throws &#123; try &#123; return (Class)super.h.invoke(this, m4, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final int hashCode() throws &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); m3 = Class.forName(\"club.throwable.annotation.Counter\").getMethod(\"count\"); m4 = Class.forName(\"club.throwable.annotation.Counter\").getMethod(\"annotationType\"); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125; 显然，$Proxy1实现了Counter接口，它在代码的最后部分使用了静态代码块实例化了成员方法的Method实例，在前面的代码对这些Method进行了缓存，在调用成员方法的时候都是直接委托到InvocationHandler(AnnotationInvocationHandler)实例完成调用。我们在分析AnnotationInvocationHandler的时候看到，它只用到了Method的名称从Map从匹配出成员方法的结果，因此调用过程并不是反射调用，反而是直接的调用，效率类似于通过Key从Map实例中获取Value一样，是十分高效的。 小结 既然知道了注解的底层原理，我们可以编写一个&quot;注解接口&quot;和InvocationHandler实现来简单模拟整个过程。先定义一个接口： 1234public interface CounterAnnotation extends Annotation &#123; int count();&#125; InvocationHandler的简单实现： 123456789101112131415161718192021222324252627282930313233public class CounterAnnotationInvocationHandler implements InvocationHandler &#123; private final Map&lt;String, Object&gt; memberValues; private final Class&lt;? extends Annotation&gt; clazz; public CounterAnnotationInvocationHandler(Map&lt;String, Object&gt; memberValues, Class&lt;? extends Annotation&gt; clazz) &#123; this.memberValues = memberValues; this.clazz = clazz; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; String methodName = method.getName(); Object value; switch (methodName) &#123; case \"toString\": value = super.toString(); break; case \"hashCode\": value = super.hashCode(); break; case \"equals\": value = super.equals(args[0]); break; case \"annotationType\": value = clazz; break; default: value = memberValues.get(methodName); &#125; return value; &#125;&#125; 编写一个main方法： 1234567891011121314public class CounterAnnotationMain &#123; public static void main(String[] args) throws Exception&#123; //这里模拟了注解成员属性从常量池解析的过程 Map&lt;String,Object&gt; values = new HashMap&lt;&gt;(8); values.put(\"count\", 1); //生成代理类 CounterAnnotation proxy = (CounterAnnotation)Proxy.newProxyInstance(CounterAnnotationMain.class.getClassLoader(), new Class[]&#123;CounterAnnotation.class&#125;, new CounterAnnotationInvocationHandler(values, CounterAnnotation.class)); System.out.println(proxy.count()); &#125;&#125;//运行后控制台输出:1 (本文完 c-1-d e-20181006)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Annotation","slug":"Java/Annotation","permalink":"http://throwable.club/blog/categories/Java/Annotation/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Annotation","slug":"Annotation","permalink":"http://throwable.club/blog/tags/Annotation/"}]},{"title":"JDK中枚举的底层实现","slug":"enum-implementation","date":"2018-11-04T10:36:23.000Z","updated":"2018-11-17T07:52:01.552Z","comments":true,"path":"2018/11/04/enum-implementation/","link":"","permalink":"http://throwable.club/2018/11/04/enum-implementation/","excerpt":"","text":"前提 上一篇文章复习介绍了JDK中注解的底层实现，跟注解一样比较常用，但是底层实现比较神秘的还有枚举类型。趁着国庆假期的最后两天，把JDK中枚举的底层实现也进行一次探究。 通过例子查找本质 在探究JDK注解的底层实现的时候，因为预先参考了不少资料，所以整个过程有点&quot;未卜先知&quot;的意味，这里尝试用未知的角度去看注解的底层实现。先定义一个手机操作系统类型枚举PhoneOsEnum： 12345678910111213141516171819202122232425262728293031package club.throwable.enumeration;public enum PhoneOsEnum &#123; /** * 安卓 */ ANDROID(1, \"android\"), /** * ios */ IOS(2, \"ios\"); private final Integer type; private final String typeName; PhoneOsEnum(Integer type, String typeName) &#123; this.type = type; this.typeName = typeName; &#125; public Integer getType() &#123; return type; &#125; public String getTypeName() &#123; return typeName; &#125;&#125; 这是一个很简单的枚举，接着使用JDK的反编译工具反编译出其字节码，执行下面的命令： 1javap -c -v D:\\Projects\\rxjava-seed\\target\\classes\\club\\throwable\\enumeration\\PhoneOsEnum.class 然后就得到了关于PhoneOsEnum.class的很长的字节码，这里全部贴出来： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186Classfile /D:/Projects/rxjava-seed/target/classes/club/throwable/enumeration/PhoneOsEnum.class Last modified 2018-10-6; size 1561 bytes MD5 checksum 6d3186042f54233219000927a2f196aa Compiled from \"PhoneOsEnum.java\"public final class club.throwable.enumeration.PhoneOsEnum extends java.lang.Enum&lt;club.throwable.enumeration.PhoneOsEnum&gt; minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_FINAL, ACC_SUPER, ACC_ENUMConstant pool: #1 = Fieldref #4.#49 // club/throwable/enumeration/PhoneOsEnum.$VALUES:[Lclub/throwable/enumeration/PhoneOsEnum; #2 = Methodref #50.#51 // \"[Lclub/throwable/enumeration/PhoneOsEnum;\".clone:()Ljava/lang/Object; #3 = Class #26 // \"[Lclub/throwable/enumeration/PhoneOsEnum;\" #4 = Class #52 // club/throwable/enumeration/PhoneOsEnum #5 = Methodref #17.#53 // java/lang/Enum.valueOf:(Ljava/lang/Class;Ljava/lang/String;)Ljava/lang/Enum; #6 = Methodref #17.#54 // java/lang/Enum.\"&lt;init&gt;\":(Ljava/lang/String;I)V #7 = Fieldref #4.#55 // club/throwable/enumeration/PhoneOsEnum.type:Ljava/lang/Integer; #8 = Fieldref #4.#56 // club/throwable/enumeration/PhoneOsEnum.typeName:Ljava/lang/String; #9 = String #18 // ANDROID #10 = Methodref #57.#58 // java/lang/Integer.valueOf:(I)Ljava/lang/Integer; #11 = String #59 // android #12 = Methodref #4.#60 // club/throwable/enumeration/PhoneOsEnum.\"&lt;init&gt;\":(Ljava/lang/String;ILjava/lang/Integer;Ljava/lang/String;)V #13 = Fieldref #4.#61 // club/throwable/enumeration/PhoneOsEnum.ANDROID:Lclub/throwable/enumeration/PhoneOsEnum; #14 = String #20 // IOS #15 = String #62 // ios #16 = Fieldref #4.#63 // club/throwable/enumeration/PhoneOsEnum.IOS:Lclub/throwable/enumeration/PhoneOsEnum; #17 = Class #64 // java/lang/Enum #18 = Utf8 ANDROID #19 = Utf8 Lclub/throwable/enumeration/PhoneOsEnum; #20 = Utf8 IOS #21 = Utf8 type #22 = Utf8 Ljava/lang/Integer; #23 = Utf8 typeName #24 = Utf8 Ljava/lang/String; #25 = Utf8 $VALUES #26 = Utf8 [Lclub/throwable/enumeration/PhoneOsEnum; #27 = Utf8 values #28 = Utf8 ()[Lclub/throwable/enumeration/PhoneOsEnum; #29 = Utf8 Code #30 = Utf8 LineNumberTable #31 = Utf8 valueOf #32 = Utf8 (Ljava/lang/String;)Lclub/throwable/enumeration/PhoneOsEnum; #33 = Utf8 LocalVariableTable #34 = Utf8 name #35 = Utf8 &lt;init&gt; #36 = Utf8 (Ljava/lang/String;ILjava/lang/Integer;Ljava/lang/String;)V #37 = Utf8 this #38 = Utf8 Signature #39 = Utf8 (Ljava/lang/Integer;Ljava/lang/String;)V #40 = Utf8 getType #41 = Utf8 ()Ljava/lang/Integer; #42 = Utf8 getTypeName #43 = Utf8 ()Ljava/lang/String; #44 = Utf8 &lt;clinit&gt; #45 = Utf8 ()V #46 = Utf8 Ljava/lang/Enum&lt;Lclub/throwable/enumeration/PhoneOsEnum;&gt;; #47 = Utf8 SourceFile #48 = Utf8 PhoneOsEnum.java #49 = NameAndType #25:#26 // $VALUES:[Lclub/throwable/enumeration/PhoneOsEnum; #50 = Class #26 // \"[Lclub/throwable/enumeration/PhoneOsEnum;\" #51 = NameAndType #65:#66 // clone:()Ljava/lang/Object; #52 = Utf8 club/throwable/enumeration/PhoneOsEnum #53 = NameAndType #31:#67 // valueOf:(Ljava/lang/Class;Ljava/lang/String;)Ljava/lang/Enum; #54 = NameAndType #35:#68 // \"&lt;init&gt;\":(Ljava/lang/String;I)V #55 = NameAndType #21:#22 // type:Ljava/lang/Integer; #56 = NameAndType #23:#24 // typeName:Ljava/lang/String; #57 = Class #69 // java/lang/Integer #58 = NameAndType #31:#70 // valueOf:(I)Ljava/lang/Integer; #59 = Utf8 android #60 = NameAndType #35:#36 // \"&lt;init&gt;\":(Ljava/lang/String;ILjava/lang/Integer;Ljava/lang/String;)V #61 = NameAndType #18:#19 // ANDROID:Lclub/throwable/enumeration/PhoneOsEnum; #62 = Utf8 ios #63 = NameAndType #20:#19 // IOS:Lclub/throwable/enumeration/PhoneOsEnum; #64 = Utf8 java/lang/Enum #65 = Utf8 clone #66 = Utf8 ()Ljava/lang/Object; #67 = Utf8 (Ljava/lang/Class;Ljava/lang/String;)Ljava/lang/Enum; #68 = Utf8 (Ljava/lang/String;I)V #69 = Utf8 java/lang/Integer #70 = Utf8 (I)Ljava/lang/Integer;&#123; public static final club.throwable.enumeration.PhoneOsEnum ANDROID; descriptor: Lclub/throwable/enumeration/PhoneOsEnum; flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL, ACC_ENUM public static final club.throwable.enumeration.PhoneOsEnum IOS; descriptor: Lclub/throwable/enumeration/PhoneOsEnum; flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL, ACC_ENUM public static club.throwable.enumeration.PhoneOsEnum[] values(); descriptor: ()[Lclub/throwable/enumeration/PhoneOsEnum; flags: ACC_PUBLIC, ACC_STATIC Code: stack=1, locals=0, args_size=0 0: getstatic #1 // Field $VALUES:[Lclub/throwable/enumeration/PhoneOsEnum; 3: invokevirtual #2 // Method \"[Lclub/throwable/enumeration/PhoneOsEnum;\".clone:()Ljava/lang/Object; 6: checkcast #3 // class \"[Lclub/throwable/enumeration/PhoneOsEnum;\" 9: areturn LineNumberTable: line 9: 0 public static club.throwable.enumeration.PhoneOsEnum valueOf(java.lang.String); descriptor: (Ljava/lang/String;)Lclub/throwable/enumeration/PhoneOsEnum; flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=1, args_size=1 0: ldc #4 // class club/throwable/enumeration/PhoneOsEnum 2: aload_0 3: invokestatic #5 // Method java/lang/Enum.valueOf:(Ljava/lang/Class;Ljava/lang/String;)Ljava/lang/Enum; 6: checkcast #4 // class club/throwable/enumeration/PhoneOsEnum 9: areturn LineNumberTable: line 9: 0 LocalVariableTable: Start Length Slot Name Signature 0 10 0 name Ljava/lang/String; public java.lang.Integer getType(); descriptor: ()Ljava/lang/Integer; flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: getfield #7 // Field type:Ljava/lang/Integer; 4: areturn LineNumberTable: line 31: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lclub/throwable/enumeration/PhoneOsEnum; public java.lang.String getTypeName(); descriptor: ()Ljava/lang/String; flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: getfield #8 // Field typeName:Ljava/lang/String; 4: areturn LineNumberTable: line 35: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lclub/throwable/enumeration/PhoneOsEnum; static &#123;&#125;; descriptor: ()V flags: ACC_STATIC Code: stack=6, locals=0, args_size=0 0: new #4 // class club/throwable/enumeration/PhoneOsEnum 3: dup 4: ldc #9 // String ANDROID 6: iconst_0 7: iconst_1 8: invokestatic #10 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; 11: ldc #11 // String android 13: invokespecial #12 // Method \"&lt;init&gt;\":(Ljava/lang/String;ILjava/lang/Integer;Ljava/lang/String;)V 16: putstatic #13 // Field ANDROID:Lclub/throwable/enumeration/PhoneOsEnum; 19: new #4 // class club/throwable/enumeration/PhoneOsEnum 22: dup 23: ldc #14 // String IOS 25: iconst_1 26: iconst_2 27: invokestatic #10 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; 30: ldc #15 // String ios 32: invokespecial #12 // Method \"&lt;init&gt;\":(Ljava/lang/String;ILjava/lang/Integer;Ljava/lang/String;)V 35: putstatic #16 // Field IOS:Lclub/throwable/enumeration/PhoneOsEnum; 38: iconst_2 39: anewarray #4 // class club/throwable/enumeration/PhoneOsEnum 42: dup 43: iconst_0 44: getstatic #13 // Field ANDROID:Lclub/throwable/enumeration/PhoneOsEnum; 47: aastore 48: dup 49: iconst_1 50: getstatic #16 // Field IOS:Lclub/throwable/enumeration/PhoneOsEnum; 53: aastore 54: putstatic #1 // Field $VALUES:[Lclub/throwable/enumeration/PhoneOsEnum; 57: return LineNumberTable: line 14: 0 line 19: 19 line 9: 38&#125;Signature: #46 // Ljava/lang/Enum&lt;Lclub/throwable/enumeration/PhoneOsEnum;&gt;;SourceFile: \"PhoneOsEnum.java\" 先看类的签名是public final class club.throwable.enumeration.PhoneOsEnum extends java.lang.Enum&lt;club.throwable.enumeration.PhoneOsEnum&gt;，它的父类是java.lang.Enum，父类的泛型就是自身club.throwable.enumeration.PhoneOsEnum。上面的字节码的可读性相对比较低，直接翻译为Java代码(当然我们不能声明一个类直接继承java.lang.Enum，这里仅仅为了说明反编译后的枚举类的原型)如下： 123456789101112131415161718192021222324252627282930313233343536public final class PhoneOsEnumeration extends Enum&lt;PhoneOsEnumeration&gt; &#123; public PhoneOsEnumeration(String name, int ordinal, Integer type, String typeName) &#123; super(name, ordinal); this.type = type; this.typeName = typeName; &#125; public Integer getType() &#123; return type; &#125; public String getTypeName() &#123; return typeName; &#125; public static PhoneOsEnumeration[] values() &#123; return $VALUES.clone(); &#125; public static PhoneOsEnumeration valueOf(String name) &#123; return Enum.valueOf(PhoneOsEnumeration.class, name); &#125; private final Integer type; private final String typeName; public static final PhoneOsEnumeration ANDROID; public static final PhoneOsEnumeration IOS; private static final PhoneOsEnumeration[] $VALUES; static &#123; ANDROID = new PhoneOsEnumeration(\"ANDROID\", 0, 1, \"android\"); IOS = new PhoneOsEnumeration(\"IOS\", 1, 2, \"ios\"); $VALUES = new PhoneOsEnumeration[]&#123;ANDROID, IOS&#125;; &#125;&#125; 概括来说就是成员变量都是通过静态代码块声明，这里注意一点父类Enum实例化的时候需要覆盖父类构造器protected Enum(String name, int ordinal)，其他方法的实现都是十分简单。 JDK的枚举描述 国际惯例，先看一下JavaSE-8的语言规范中JLS-8.9对枚举类型的定义和描述： 感觉有点似曾相识，总结一下重要内容有以下几点： 枚举的声明格式是：{ClassModifier} enum Identifier [Superinterfaces] EnumBody，ClassModifier是修饰符，Identifier是枚举的名称可以类比为类名，枚举类型可以实现接口。 枚举类型不能使用abstract或者final修饰，否则会产生编译错误。 枚举类型的直接超类是java.lang.Enum。 枚举类型除了枚举常量定义之外没有其他实例，也就是枚举类型不能实例化。 枚举类型禁用反射操作进行实例化(这个特性就是Effetive Java中推荐使用枚举实现单例的原因)。 枚举的公共父类java.lang.Enum的源码如下(已经去掉全部注释)： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public abstract class Enum&lt;E extends Enum&lt;E&gt;&gt; implements Comparable&lt;E&gt;, Serializable &#123; private final String name; public final String name() &#123; return name; &#125; private final int ordinal; public final int ordinal() &#123; return ordinal; &#125; protected Enum(String name, int ordinal) &#123; this.name = name; this.ordinal = ordinal; &#125; public String toString() &#123; return name; &#125; public final boolean equals(Object other) &#123; return this==other; &#125; public final int hashCode() &#123; return super.hashCode(); &#125; protected final Object clone() throws CloneNotSupportedException &#123; throw new CloneNotSupportedException(); &#125; public final int compareTo(E o) &#123; Enum&lt;?&gt; other = (Enum&lt;?&gt;)o; Enum&lt;E&gt; self = this; if (self.getClass() != other.getClass() &amp;&amp; // optimization self.getDeclaringClass() != other.getDeclaringClass()) throw new ClassCastException(); return self.ordinal - other.ordinal; &#125; public final Class&lt;E&gt; getDeclaringClass() &#123; Class&lt;?&gt; clazz = getClass(); Class&lt;?&gt; zuper = clazz.getSuperclass(); return (zuper == Enum.class) ? (Class&lt;E&gt;)clazz : (Class&lt;E&gt;)zuper; &#125; public static &lt;T extends Enum&lt;T&gt;&gt; T valueOf(Class&lt;T&gt; enumType, String name) &#123; T result = enumType.enumConstantDirectory().get(name); if (result != null) return result; if (name == null) throw new NullPointerException(\"Name is null\"); throw new IllegalArgumentException( \"No enum constant \" + enumType.getCanonicalName() + \".\" + name); &#125; protected final void finalize() &#123; &#125; private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException &#123; throw new InvalidObjectException(\"can't deserialize enum\"); &#125; private void readObjectNoData() throws ObjectStreamException &#123; throw new InvalidObjectException(\"can't deserialize enum\"); &#125; &#125; 大部分方法都比较简单，值得注意的几点是： 1、valueOf方法依赖到的Class&lt;?&gt;#enumConstantDirectory()，这个方法首次调用完成之后，结果会缓存在Class&lt;?&gt;#enumConstantDirectory变量中。 2、Enum实现了Serializable接口，但是readObject和readObjectNoData直接抛出了InvalidObjectException异常，注释说到是&quot;防止默认的反序列化&quot;，这一点有点不明不白，既然禁用反序列化为何要实现Serializable接口，这里可能考虑到是否实现Serializable接口应该交给开发者决定。 3、Enum禁用克隆。 小结 JDK中枚举的底层实现就是使用了enum关键字声明的枚举类编译后最终会变成public final修饰同时实现了泛型接口java.lang.Enum并且指定泛型参数为自身的普通Java类，而成员属性和方法实现相关都是在编译完成后就已经成型的，枚举类型的成员变量都是通过静态代码块声明的。 (本文完 c-1-d e-20181006)","categories":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/categories/Java/"},{"name":"Enum","slug":"Java/Enum","permalink":"http://throwable.club/blog/categories/Java/Enum/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://throwable.club/blog/tags/Java/"},{"name":"Enum","slug":"Enum","permalink":"http://throwable.club/blog/tags/Enum/"}]},{"title":"Hi, theme-melody!","slug":"helloworld","date":"2018-11-03T16:00:00.000Z","updated":"2019-07-22T14:58:31.762Z","comments":true,"path":"2018/11/04/helloworld/","link":"","permalink":"http://throwable.club/2018/11/04/helloworld/","excerpt":"","text":"init 1hexo init [folder] Initializes a website. new 1hexo new [layout] &lt;title&gt; # hexo new post $&#123;article&#125; Creates a new article. generate 1$ hexo generate # hexo g Generates static files. Option Description -d, --deploy Deploy after generation finishes -w, --watch Watch file changes -b, --bail Raise an error if any unhandled exception is thrown during generation -f, --force Force regenerate publish 1$ hexo publish [layout] &lt;filename&gt; Publishes a draft. server 1$ hexo server # hexo s Option Description -p, --port Override default port -s, --static Only serve static files -l, --log Enable logger. Override logger format Starts a local server. By default, this is at http://localhost:4000/. deploy 1$ hexo deploy # hexo d clean 1$ hexo clean end I spent an afternoon updating blog topics and migrating articles.The theme has been updated to melody and I like it very much! test Not bloğuBurası bir not bloğu İpucu bloğuBurası bir ipucu bloğu İpucu bloğuBurası bir ipucu bloğu Dikkat bloğuBurası bir dikkat bloğu Uyarı bloğuBurası bir uyarı bloğu (To be continue…)","categories":[{"name":"hexo","slug":"hexo","permalink":"http://throwable.club/blog/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://throwable.club/blog/tags/hexo/"},{"name":"hexo theme","slug":"hexo-theme","permalink":"http://throwable.club/blog/tags/hexo-theme/"}]}]}